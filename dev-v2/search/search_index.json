{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Pydantic","text":"<p>Documentation for development version: f27e7ca.</p> <p>Pydantic is the most widely used Python library for data validation and coercion using Python type annotations.</p> <p>Success</p> <p>Already using Pydantic V1? See the Migration Guide for notes on upgrading to Pydantic V2 in your applications!</p>"},{"location":"#why-use-pydantic","title":"Why use Pydantic?","text":"<p>Built-in Python type annotations are a useful way to hint about the expected type of data, improving code clarity and supporting development tools. However, Python's type annotations are optional and don't affect the runtime behavior of the program.</p> <p>Static type checkers like mypy use type annotations to catch potential type-related errors before running the program. But static type checkers can't catch all errors, and they don't affect the runtime behavior of the program.</p> <p>Pydantic, on the other hand, uses type annotations to perform data validation and type coercion at runtime, which is particularly useful for ensuring the correctness of user or external data.</p> <p>Pydantic enables you to convert input data to Python standard library types and custom types in a controlled manner, ensuring they meet the specifications you've provided. This eliminates a significant amount of manual data validation and transformation code, making your program more robust and less prone to errors. It's particularly helpful when dealing with untrusted user input such as form data, JSON documents, and other data types.</p> <p>By providing a simple, declarative way of defining how data should be shaped, Pydantic helps you write cleaner, safer, and more reliable code.</p>"},{"location":"#features-of-pydantic","title":"Features of Pydantic","text":"<p>Some of the main features of Pydantic include:</p> <ul> <li>Data validation: Pydantic validates data as it is assigned to ensure it meets the requirements. It automatically handles a broad range of data types, including custom types and custom validators.</li> <li>Standard library and custom data types: Pydantic supports all of the Python standard library types, and you can define custom data types and specify how they should be validated and converted.</li> <li>Conversion types: Pydantic will not only validate data, but also convert it to the appropriate type if possible. For instance, a string containing a number will be converted to the proper numerical type.</li> <li>Custom and nested models: You can define models (similar to classes) that contain other models, allowing for complex data structures to be neatly and efficiently represented.</li> <li>Generic models: Pydantic supports generic models, which allow the declaration of models that are \"parameterized\" on one or more fields.</li> <li>Dataclasses: Pydantic supports <code>dataclasses.dataclass</code>, offering same data validation as using <code>BaseModel</code>.</li> <li>Model schema generation: Pydantic models can be converted to and from a JSON Schema, which can be useful for documentation, code generation, or other purposes.</li> <li>Error handling: Pydantic models raise informative errors when invalid data is provided, with the option to create your own custom errors.</li> <li>Settings management: The <code>BaseSettings</code> class from pydantic-settings provides a way to validate, document, and provide default values for environment variables.</li> </ul> <p>Pydantic is simple to use, even when doing complex things, and enables you to define and validate data in pure, canonical Python.</p> <p>Installing Pydantic is as simple as: <code>pip install pydantic</code>.</p>"},{"location":"#pydantic-examples","title":"Pydantic examples","text":"<p>To see Pydantic at work, let's start with a simple example, creating a custom class that inherits from <code>BaseModel</code>:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n\n\nexternal_data = {\n    'id': '123',\n    'signup_ts': '2019-06-01 12:22',\n}\n\nuser = User(**external_data)\n\nprint(user.model_dump())\n#&gt; {'id': 123, 'name': 'John Doe', 'signup_ts': datetime.datetime(2019, 6, 1, 12, 22)}\n</code></pre> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime | None = None\n\n\nexternal_data = {\n    'id': '123',\n    'signup_ts': '2019-06-01 12:22',\n}\n\nuser = User(**external_data)\n\nprint(user.model_dump())\n#&gt; {'id': 123, 'name': 'John Doe', 'signup_ts': datetime.datetime(2019, 6, 1, 12, 22)}\n</code></pre> <p>What's going on here:</p> <ul> <li><code>id</code> is of type <code>int</code>; the annotation-only declaration tells Pydantic that this field is required. Strings,   bytes, or floats will be coerced to ints if possible; otherwise an exception will be raised.</li> <li><code>name</code> is inferred as a string from the provided default; because it has a default, it is not required.</li> <li><code>signup_ts</code> is a <code>datetime</code> field that is not required (and takes the value <code>None</code> if a value is not supplied).   Pydantic will process either a unix timestamp int (e.g. <code>1496498400</code>) or a string representing the date and time.</li> </ul> <p>If validation fails, Pydantic will raise an error with a breakdown of what was wrong:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n\n\ntry:\n    User(name=1234)\nexcept ValidationError as e:\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('id',),\n            'msg': 'Field required',\n            'input': {'name': 1234},\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n        {\n            'type': 'string_type',\n            'loc': ('name',),\n            'msg': 'Input should be a valid string',\n            'input': 1234,\n            'url': 'https://errors.pydantic.dev/2/v/string_type',\n        },\n    ]\n    \"\"\"\n</code></pre> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime | None = None\n\n\ntry:\n    User(name=1234)\nexcept ValidationError as e:\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('id',),\n            'msg': 'Field required',\n            'input': {'name': 1234},\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n        {\n            'type': 'string_type',\n            'loc': ('name',),\n            'msg': 'Input should be a valid string',\n            'input': 1234,\n            'url': 'https://errors.pydantic.dev/2/v/string_type',\n        },\n    ]\n    \"\"\"\n</code></pre>"},{"location":"#who-is-using-pydantic","title":"Who is using Pydantic?","text":"<p>Hundreds of organisations and packages are using Pydantic. Some of the prominent companies and organizations around the world who are using Pydantic include:</p> <p>For a more comprehensive list of open-source projects using Pydantic see the list of dependents on github, or you can find some awesome projects using Pydantic in awesome-pydantic.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v20b3-2023-06-16","title":"v2.0b3 (2023-06-16)","text":"<p>Third beta pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20b2-2023-06-03","title":"v2.0b2 (2023-06-03)","text":"<p>Add <code>from_attributes</code> runtime flag to <code>TypeAdapter.validate_python</code> and <code>BaseModel.model_validate</code>.</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20b1-2023-06-01","title":"v2.0b1 (2023-06-01)","text":"<p>First beta pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a4-2023-05-05","title":"v2.0a4 (2023-05-05)","text":"<p>Fourth pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a3-2023-04-20","title":"v2.0a3 (2023-04-20)","text":"<p>Third pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a2-2023-04-12","title":"v2.0a2 (2023-04-12)","text":"<p>Second pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a1-2023-04-03","title":"v2.0a1 (2023-04-03)","text":"<p>First pre-release of Pydantic V2!</p> <p>See this post for more details.</p>"},{"location":"changelog/#v1109-2023-06-07","title":"v1.10.9 (2023-06-07)","text":"<ul> <li>Fix trailing zeros not ignored in Decimal validation, #5968 by @hramezani</li> <li>Fix mypy plugin for v1.4.0, #5928 by @cdce8p</li> <li>Add future and past date hypothesis strategies, #5850 by @bschoenmaeckers</li> <li>Discourage usage of Cython 3 with Pydantic 1.x, #5845 by @lig</li> </ul>"},{"location":"changelog/#v1108-2023-05-23","title":"v1.10.8 (2023-05-23)","text":"<ul> <li>Fix a bug in <code>Literal</code> usage with <code>typing-extension==4.6.0</code>, #5826 by @hramezani</li> <li>This solves the (closed) issue #3849 where aliased fields that use discriminated union fail to validate when the data contains the non-aliased field name, #5736 by @benwah</li> <li>Update email-validator dependency to &gt;=2.0.0post2, #5627 by @adriangb</li> <li>update <code>AnyClassMethod</code> for changes in python/typeshed[#9771](https://github.com/pydantic/pydantic/issues/9771), #5505 by @ITProKyle</li> </ul>"},{"location":"changelog/#v1107-2023-03-22","title":"v1.10.7 (2023-03-22)","text":"<ul> <li>Fix creating schema from model using <code>ConstrainedStr</code> with <code>regex</code> as dict key, #5223 by @matejetz</li> <li>Address bug in mypy plugin caused by explicit_package_bases=True, #5191 by @dmontagu</li> <li>Add implicit defaults in the mypy plugin for Field with no default argument, #5190 by @dmontagu</li> <li>Fix schema generated for Enum values used as Literals in discriminated unions, #5188 by @javibookline</li> <li>Fix mypy failures caused by the pydantic mypy plugin when users define <code>from_orm</code> in their own classes, #5187 by @dmontagu</li> <li>Fix <code>InitVar</code> usage with pydantic dataclasses, mypy version <code>1.1.1</code> and the custom mypy plugin, #5162 by @cdce8p</li> </ul>"},{"location":"changelog/#v1106-2023-03-08","title":"v1.10.6 (2023-03-08)","text":"<ul> <li>Implement logic to support creating validators from non standard callables by using defaults to identify them and unwrapping <code>functools.partial</code> and <code>functools.partialmethod</code> when checking the signature, #5126 by @JensHeinrich</li> <li>Fix mypy plugin for v1.1.1, and fix <code>dataclass_transform</code> decorator for pydantic dataclasses, #5111 by @cdce8p</li> <li>Raise <code>ValidationError</code>, not <code>ConfigError</code>, when a discriminator value is unhashable, #4773 by @kurtmckee</li> </ul>"},{"location":"changelog/#v1105-2023-02-15","title":"v1.10.5 (2023-02-15)","text":"<ul> <li>Fix broken parametrized bases handling with <code>GenericModel</code>s with complex sets of models, #5052 by @MarkusSintonen</li> <li>Invalidate mypy cache if plugin config changes, #5007 by @cdce8p</li> <li>Fix <code>RecursionError</code> when deep-copying dataclass types wrapped by pydantic, #4949 by @mbillingr</li> <li>Fix <code>X | Y</code> union syntax breaking <code>GenericModel</code>, #4146 by @thenx</li> <li>Switch coverage badge to show coverage for this branch/release, #5060 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1104-2022-12-30","title":"v1.10.4 (2022-12-30)","text":"<ul> <li>Change dependency to <code>typing-extensions&gt;=4.2.0</code>, #4885 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1103-2022-12-29","title":"v1.10.3 (2022-12-29)","text":"<p>NOTE: v1.10.3 was \"yanked\" from PyPI due to #4885 which is fixed in v1.10.4</p> <ul> <li>fix parsing of custom root models, #4883 by @gou177</li> <li>fix: use dataclass proxy for frozen or empty dataclasses, #4878 by @PrettyWood</li> <li>Fix <code>schema</code> and <code>schema_json</code> on models where a model instance is a one of default values, #4781 by @Bobronium</li> <li>Add Jina AI to sponsors on docs index page, #4767 by @samuelcolvin</li> <li>fix: support assignment on <code>DataclassProxy</code>, #4695 by @PrettyWood</li> <li>Add <code>postgresql+psycopg</code> as allowed scheme for <code>PostgreDsn</code> to make it usable with SQLAlchemy 2, #4689 by @morian</li> <li>Allow dict schemas to have both <code>patternProperties</code> and <code>additionalProperties</code>, #4641 by @jparise</li> <li>Fixes error passing None for optional lists with <code>unique_items</code>, #4568 by @mfulgo</li> <li>Fix <code>GenericModel</code> with <code>Callable</code> param raising a <code>TypeError</code>, #4551 by @mfulgo</li> <li>Fix field regex with <code>StrictStr</code> type annotation, #4538 by @sisp</li> <li>Correct <code>dataclass_transform</code> keyword argument name from <code>field_descriptors</code> to <code>field_specifiers</code>, #4500 by @samuelcolvin</li> <li>fix: avoid multiple calls of <code>__post_init__</code> when dataclasses are inherited, #4487 by @PrettyWood</li> <li>Reduce the size of binary wheels, #2276 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1102-2022-09-05","title":"v1.10.2 (2022-09-05)","text":"<ul> <li>Revert Change: Revert percent encoding of URL parts which was originally added in #4224, #4470 by @samuelcolvin</li> <li>Prevent long (length &gt; <code>4_300</code>) strings/bytes as input to int fields, see   python/cpython[#95778](https://github.com/pydantic/pydantic/issues/95778) and   CVE-2020-10735, #1477 by @samuelcolvin</li> <li>fix: dataclass wrapper was not always called, #4477 by @PrettyWood</li> <li>Use <code>tomllib</code> on Python 3.11 when parsing <code>mypy</code> configuration, #4476 by @hauntsaninja</li> <li>Basic fix of <code>GenericModel</code> cache to detect order of arguments in <code>Union</code> models, #4474 by @sveinugu</li> <li>Fix mypy plugin when using bare types like <code>list</code> and <code>dict</code> as <code>default_factory</code>, #4457 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1101-2022-08-31","title":"v1.10.1 (2022-08-31)","text":"<ul> <li>Add <code>__hash__</code> method to <code>pydancic.color.Color</code> class, #4454 by @czaki</li> </ul>"},{"location":"changelog/#v1100-2022-08-30","title":"v1.10.0 (2022-08-30)","text":"<ul> <li>Refactor the whole pydantic <code>dataclass</code> decorator to really act like its standard lib equivalent.   It hence keeps <code>__eq__</code>, <code>__hash__</code>, ... and makes comparison with its non-validated version possible.   It also fixes usage of <code>frozen</code> dataclasses in fields and usage of <code>default_factory</code> in nested dataclasses.   The support of <code>Config.extra</code> has been added.   Finally, config customization directly via a <code>dict</code> is now possible, #2557 by @PrettyWood BREAKING CHANGES:</li> <li>The <code>compiled</code> boolean (whether pydantic is compiled with cython) has been moved from <code>main.py</code> to <code>version.py</code></li> <li>Now that <code>Config.extra</code> is supported, <code>dataclass</code> ignores by default extra arguments (like <code>BaseModel</code>)</li> <li>Fix PEP487 <code>__set_name__</code> protocol in <code>BaseModel</code> for PrivateAttrs, #4407 by @tlambert03</li> <li>Allow for custom parsing of environment variables via <code>parse_env_var</code> in <code>Config</code>, #4406 by @acmiyaguchi</li> <li>Rename <code>master</code> to <code>main</code>, #4405 by @hramezani</li> <li>Fix <code>StrictStr</code> does not raise <code>ValidationError</code> when <code>max_length</code> is present in <code>Field</code>, #4388 by @hramezani</li> <li>Make <code>SecretStr</code> and <code>SecretBytes</code> hashable, #4387 by @chbndrhnns</li> <li>Fix <code>StrictBytes</code> does not raise <code>ValidationError</code> when <code>max_length</code> is present in <code>Field</code>, #4380 by @JeanArhancet</li> <li>Add support for bare <code>type</code>, #4375 by @hramezani</li> <li>Support Python 3.11, including binaries for 3.11 in PyPI, #4374 by @samuelcolvin</li> <li>Add support for <code>re.Pattern</code>, #4366 by @hramezani</li> <li>Fix <code>__post_init_post_parse__</code> is incorrectly passed keyword arguments when no <code>__post_init__</code> is defined, #4361 by @hramezani</li> <li>Fix implicitly importing <code>ForwardRef</code> and <code>Callable</code> from <code>pydantic.typing</code> instead of <code>typing</code> and also expose <code>MappingIntStrAny</code>, #4358 by @aminalaee</li> <li>remove <code>Any</code> types from the <code>dataclass</code> decorator so it can be used with the <code>disallow_any_expr</code> mypy option, #4356 by @DetachHead</li> <li>moved repo to <code>pydantic/pydantic</code>, #4348 by @yezz123</li> <li>fix \"extra fields not permitted\" error when dataclass with <code>Extra.forbid</code> is validated multiple times, #4343 by @detachhead</li> <li>Add Python 3.9 and 3.10 examples to docs, #4339 by @Bobronium</li> <li>Discriminated union models now use <code>oneOf</code> instead of <code>anyOf</code> when generating OpenAPI schema definitions, #4335 by @MaxwellPayne</li> <li>Allow type checkers to infer inner type of <code>Json</code> type. <code>Json[list[str]]</code> will be now inferred as <code>list[str]</code>,   <code>Json[Any]</code> should be used instead of plain <code>Json</code>.   Runtime behaviour is not changed, #4332 by @Bobronium</li> <li>Allow empty string aliases by using a <code>alias is not None</code> check, rather than <code>bool(alias)</code>, #4253 by @sergeytsaplin</li> <li>Update <code>ForwardRef</code>s in <code>Field.outer_type_</code>, #4249 by @JacobHayes</li> <li>The use of <code>__dataclass_transform__</code> has been replaced by <code>typing_extensions.dataclass_transform</code>, which is the preferred way to mark pydantic models as a dataclass under PEP 681, #4241 by @multimeric</li> <li>Use parent model's <code>Config</code> when validating nested <code>NamedTuple</code> fields, #4219 by @synek</li> <li>Update <code>BaseModel.construct</code> to work with aliased Fields, #4192 by @kylebamos</li> <li>Catch certain raised errors in <code>smart_deepcopy</code> and revert to <code>deepcopy</code> if so, #4184 by @coneybeare</li> <li>Add <code>Config.anystr_upper</code> and <code>to_upper</code> kwarg to constr and conbytes, #4165 by @satheler</li> <li>Fix JSON schema for <code>set</code> and <code>frozenset</code> when they include default values, #4155 by @aminalaee</li> <li>Teach the mypy plugin that methods decorated by <code>@validator</code> are classmethods, #4102 by @DMRobertson</li> <li>Improve mypy plugin's ability to detect required fields, #4086 by @richardxia</li> <li>Support fields of type <code>Type[]</code> in schema, #4051 by @aminalaee</li> <li>Add <code>default</code> value in JSON Schema when <code>const=True</code>, #4031 by @aminalaee</li> <li>Adds reserved word check to signature generation logic, #4011 by @strue36</li> <li>Fix Json strategy failure for the complex nested field, #4005 by @sergiosim</li> <li>Add JSON-compatible float constraint <code>allow_inf_nan</code>, #3994 by @tiangolo</li> <li>Remove undefined behaviour when <code>env_prefix</code> had characters in common with <code>env_nested_delimiter</code>, #3975 by @arsenron</li> <li>Support generics model with <code>create_model</code>, #3945 by @hot123s</li> <li>allow submodels to overwrite extra field info, #3934 by @PrettyWood</li> <li>Document and test structural pattern matching (PEP 636) on <code>BaseModel</code>, #3920 by @irgolic</li> <li>Fix incorrect deserialization of python timedelta object to ISO 8601 for negative time deltas.   Minus was serialized in incorrect place (\"P-1DT23H59M59.888735S\" instead of correct \"-P1DT23H59M59.888735S\"), #3899 by @07pepa</li> <li>Fix validation of discriminated union fields with an alias when passing a model instance, #3846 by @chornsby</li> <li>Add a CockroachDsn type to validate CockroachDB connection strings. The type   supports the following schemes: <code>cockroachdb</code>, <code>cockroachdb+psycopg2</code> and <code>cockroachdb+asyncpg</code>, #3839 by @blubber</li> <li>Fix MyPy plugin to not override pre-existing <code>__init__</code> method in models, #3824 by @patrick91</li> <li>Fix mypy version checking, #3783 by @KotlinIsland</li> <li>support overwriting dunder attributes of <code>BaseModel</code> instances, #3777 by @PrettyWood</li> <li>Added <code>ConstrainedDate</code> and <code>condate</code>, #3740 by @hottwaj</li> <li>Support <code>kw_only</code> in dataclasses, #3670 by @detachhead</li> <li>Add comparison method for <code>Color</code> class, #3646 by @aminalaee</li> <li>Drop support for python3.6, associated cleanup, #3605 by @samuelcolvin</li> <li>created new function <code>to_lower_camel()</code> for \"non pascal case\" camel case, #3463 by @schlerp</li> <li>Add checks to <code>default</code> and <code>default_factory</code> arguments in Mypy plugin, #3430 by @klaa97</li> <li>fix mangling of <code>inspect.signature</code> for <code>BaseModel</code>, #3413 by @fix-inspect-signature</li> <li>Adds the <code>SecretField</code> abstract class so that all the current and future secret fields like <code>SecretStr</code> and <code>SecretBytes</code> will derive from it, #3409 by @expobrain</li> <li>Support multi hosts validation in <code>PostgresDsn</code>, #3337 by @rglsk</li> <li>Fix parsing of very small numeric timedelta values, #3315 by @samuelcolvin</li> <li>Update <code>SecretsSettingsSource</code> to respect <code>config.case_sensitive</code>, #3273 by @JeanArhancet</li> <li>Add MongoDB network data source name (DSN) schema, #3229 by @snosratiershad</li> <li>Add support for multiple dotenv files, #3222 by @rekyungmin</li> <li>Raise an explicit <code>ConfigError</code> when multiple fields are incorrectly set for a single validator, #3215 by @SunsetOrange</li> <li>Allow ellipsis on <code>Field</code>s inside <code>Annotated</code> for <code>TypedDicts</code> required, #3133 by @ezegomez</li> <li>Catch overflow errors in <code>int_validator</code>, #3112 by @ojii</li> <li>Adds a <code>__rich_repr__</code> method to <code>Representation</code> class which enables pretty printing with Rich, #3099 by @willmcgugan</li> <li>Add percent encoding in <code>AnyUrl</code> and descendent types, #3061 by @FaresAhmedb</li> <li><code>validate_arguments</code> decorator now supports <code>alias</code>, #3019 by @MAD-py</li> <li>Avoid <code>__dict__</code> and <code>__weakref__</code> attributes in <code>AnyUrl</code> and IP address fields, #2890 by @nuno-andre</li> <li>Add ability to use <code>Final</code> in a field type annotation, #2766 by @uriyyo</li> <li>Update requirement to <code>typing_extensions&gt;=4.1.0</code> to guarantee <code>dataclass_transform</code> is available, #4424 by @commonism</li> <li>Add Explosion and AWS to main sponsors, #4413 by @samuelcolvin</li> <li>Update documentation for <code>copy_on_model_validation</code> to reflect recent changes, #4369 by @samuelcolvin</li> <li>Runtime warning if <code>__slots__</code> is passed to <code>create_model</code>, <code>__slots__</code> is then ignored, #4432 by @samuelcolvin</li> <li>Add type hints to <code>BaseSettings.Config</code> to avoid mypy errors, also correct mypy version compatibility notice in docs, #4450 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1100b1-2022-08-24","title":"v1.10.0b1 (2022-08-24)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v1100a2-2022-08-24","title":"v1.10.0a2 (2022-08-24)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v1100a1-2022-08-22","title":"v1.10.0a1 (2022-08-22)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v192-2022-08-11","title":"v1.9.2 (2022-08-11)","text":"<p>Revert Breaking Change: v1.9.1 introduced a breaking change where model fields were deep copied by default, this release reverts the default behaviour to match v1.9.0 and before, while also allow deep-copy behaviour via <code>copy_on_model_validation = 'deep'</code>. See #4092 for more information.</p> <ul> <li>Allow for shallow copies of model fields, <code>Config.copy_on_model_validation</code> is now a str which must be   <code>'none'</code>, <code>'deep'</code>, or <code>'shallow'</code> corresponding to not copying, deep copy &amp; shallow copy; default <code>'shallow'</code>,   #4093 by @timkpaine</li> </ul>"},{"location":"changelog/#v191-2022-05-19","title":"v1.9.1 (2022-05-19)","text":"<p>Thank you to pydantic's sponsors: @tiangolo, @stellargraph, @JonasKs, @grillazz, @Mazyod, @kevinalh, @chdsbd, @povilasb, @povilasb, @jina-ai, @mainframeindustries, @robusta-dev, @SendCloud, @rszamszur, @jodal, @hardbyte, @corleyma, @daddycocoaman, @Rehket, @jokull, @reillysiemens, @westonsteimel, @primer-io, @koxudaxi, @browniebroke, @stradivari96, @adriangb, @kamalgill, @jqueguiner, @dev-zero, @datarootsio, @RedCarpetUp for their kind support.</p> <ul> <li>Limit the size of <code>generics._generic_types_cache</code> and <code>generics._assigned_parameters</code>   to avoid unlimited increase in memory usage, #4083 by @samuelcolvin</li> <li>Add Jupyverse and FPS as Jupyter projects using pydantic, #4082 by @davidbrochart</li> <li>Speedup <code>__isinstancecheck__</code> on pydantic models when the type is not a model, may also avoid memory \"leaks\", #4081 by @samuelcolvin</li> <li>Fix in-place modification of <code>FieldInfo</code> that caused problems with PEP 593 type aliases, #4067 by @adriangb</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code> when using <code>pydantic.dataclasses.dataclass</code>, #4006 by @giuliano-oliveira</li> <li>Remove benchmarks from codebase and docs, #3973 by @samuelcolvin</li> <li>Typing checking with pyright in CI, improve docs on vscode/pylance/pyright, #3972 by @samuelcolvin</li> <li>Fix nested Python dataclass schema regression, #3819 by @himbeles</li> <li>Update documentation about lazy evaluation of sources for Settings, #3806 by @garyd203</li> <li>Prevent subclasses of bytes being converted to bytes, #3706 by @samuelcolvin</li> <li>Fixed \"error checking inheritance of\" when using PEP585 and PEP604 type hints, #3681 by @aleksul</li> <li>Allow self referencing <code>ClassVar</code>s in models, #3679 by @samuelcolvin</li> <li>Breaking Change, see #4106: Fix issue with self-referencing dataclass, #3675 by @uriyyo</li> <li>Include non-standard port numbers in rendered URLs, #3652 by @dolfinus</li> <li><code>Config.copy_on_model_validation</code> does a deep copy and not a shallow one, #3641 by @PrettyWood</li> <li>fix: clarify that discriminated unions do not support singletons, #3636 by @tommilligan</li> <li>Add <code>read_text(encoding='utf-8')</code> for <code>setup.py</code>, #3625 by @hswong3i</li> <li>Fix JSON Schema generation for Discriminated Unions within lists, #3608 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v190-2021-12-31","title":"v1.9.0 (2021-12-31)","text":"<p>Thank you to pydantic's sponsors: @sthagen, @timdrijvers, @toinbis, @koxudaxi, @ginomempin, @primer-io, @and-semakin, @westonsteimel, @reillysiemens, @es3n1n, @jokull, @JonasKs, @Rehket, @corleyma, @daddycocoaman, @hardbyte, @datarootsio, @jodal, @aminalaee, @rafsaf, @jqueguiner, @chdsbd, @kevinalh, @Mazyod, @grillazz, @JonasKs, @simw, @leynier, @xfenix for their kind support.</p>"},{"location":"changelog/#highlights","title":"Highlights","text":"<ul> <li>add Python 3.10 support, #2885 by @PrettyWood</li> <li>Discriminated unions, #619 by @PrettyWood</li> <li><code>Config.smart_union</code> for better union logic, #2092 by @PrettyWood</li> <li>Binaries for Macos M1 CPUs, #3498 by @samuelcolvin</li> <li>Complex types can be set via nested environment variables, e.g. <code>foo___bar</code>, #3159 by @Air-Mark</li> <li>add a dark mode to pydantic documentation, #2913 by @gbdlin</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code>, #2721 by @tiangolo</li> <li>Add \"exclude\" as a field parameter so that it can be configured using model config, #660 by @daviskirk</li> </ul>"},{"location":"changelog/#v190-2021-12-31-changes","title":"v1.9.0 (2021-12-31) Changes","text":"<ul> <li>Apply <code>update_forward_refs</code> to <code>Config.json_encodes</code> prevent name clashes in types defined via strings, #3583 by @samuelcolvin</li> <li>Extend pydantic's mypy plugin to support mypy versions <code>0.910</code>, <code>0.920</code>, <code>0.921</code> &amp; <code>0.930</code>, #3573 &amp; #3594 by @PrettyWood, @christianbundy, @samuelcolvin</li> </ul>"},{"location":"changelog/#v190a2-2021-12-24-changes","title":"v1.9.0a2 (2021-12-24) Changes","text":"<ul> <li>support generic models with discriminated union, #3551 by @PrettyWood</li> <li>keep old behaviour of <code>json()</code> by default, #3542 by @PrettyWood</li> <li>Removed typing-only <code>__root__</code> attribute from <code>BaseModel</code>, #3540 by @layday</li> <li>Build Python 3.10 wheels, #3539 by @mbachry</li> <li>Fix display of <code>extra</code> fields with model <code>__repr__</code>, #3234 by @cocolman</li> <li>models copied via <code>Config.copy_on_model_validation</code> always have all fields, #3201 by @PrettyWood</li> <li>nested ORM from nested dictionaries, #3182 by @PrettyWood</li> <li>fix link to discriminated union section by @PrettyWood</li> </ul>"},{"location":"changelog/#v190a1-2021-12-18-changes","title":"v1.9.0a1 (2021-12-18) Changes","text":"<ul> <li>Add support for <code>Decimal</code>-specific validation configurations in <code>Field()</code>, additionally to using <code>condecimal()</code>,   to allow better support from editors and tooling, #3507 by @tiangolo</li> <li>Add <code>arm64</code> binaries suitable for MacOS with an M1 CPU to PyPI, #3498 by @samuelcolvin</li> <li>Fix issue where <code>None</code> was considered invalid when using a <code>Union</code> type containing <code>Any</code> or <code>object</code>, #3444 by @tharradine</li> <li>When generating field schema, pass optional <code>field</code> argument (of type   <code>pydantic.fields.ModelField</code>) to <code>__modify_schema__()</code> if present, #3434 by @jasujm</li> <li>Fix issue when pydantic fail to parse <code>typing.ClassVar</code> string type annotation, #3401 by @uriyyo</li> <li>Mention Python &gt;= 3.9.2 as an alternative to <code>typing_extensions.TypedDict</code>, #3374 by @BvB93</li> <li>Changed the validator method name in the Custom Errors example   to more accurately describe what the validator is doing; changed from <code>name_must_contain_space</code> to <code>value_must_equal_bar</code>, #3327 by @michaelrios28</li> <li>Add <code>AmqpDsn</code> class, #3254 by @kludex</li> <li>Always use <code>Enum</code> value as default in generated JSON schema, #3190 by @joaommartins</li> <li>Add support for Mypy 0.920, #3175 by @christianbundy</li> <li><code>validate_arguments</code> now supports <code>extra</code> customization (used to always be <code>Extra.forbid</code>), #3161 by @PrettyWood</li> <li>Complex types can be set by nested environment variables, #3159 by @Air-Mark</li> <li>Fix mypy plugin to collect fields based on <code>pydantic.utils.is_valid_field</code> so that it ignores untyped private variables, #3146 by @hi-ogawa</li> <li>fix <code>validate_arguments</code> issue with <code>Config.validate_all</code>, #3135 by @PrettyWood</li> <li>avoid dict coercion when using dict subclasses as field type, #3122 by @PrettyWood</li> <li>add support for <code>object</code> type, #3062 by @PrettyWood</li> <li>Updates pydantic dataclasses to keep <code>_special</code> properties on parent classes, #3043 by @zulrang</li> <li>Add a <code>TypedDict</code> class for error objects, #3038 by @matthewhughes934</li> <li>Fix support for using a subclass of an annotation as a default, #3018 by @JacobHayes</li> <li>make <code>create_model_from_typeddict</code> mypy compliant, #3008 by @PrettyWood</li> <li>Make multiple inheritance work when using <code>PrivateAttr</code>, #2989 by @hmvp</li> <li>Parse environment variables as JSON, if they have a <code>Union</code> type with a complex subfield, #2936 by @cbartz</li> <li>Prevent <code>StrictStr</code> permitting <code>Enum</code> values where the enum inherits from <code>str</code>, #2929 by @samuelcolvin</li> <li>Make <code>SecretsSettingsSource</code> parse values being assigned to fields of complex types when sourced from a secrets file,   just as when sourced from environment variables, #2917 by @davidmreed</li> <li>add a dark mode to pydantic documentation, #2913 by @gbdlin</li> <li>Make <code>pydantic-mypy</code> plugin compatible with <code>pyproject.toml</code> configuration, consistent with <code>mypy</code> changes.   See the doc for more information, #2908 by @jrwalk</li> <li>add Python 3.10 support, #2885 by @PrettyWood</li> <li>Correctly parse generic models with <code>Json[T]</code>, #2860 by @geekingfrog</li> <li>Update contrib docs re: Python version to use for building docs, #2856 by @paxcodes</li> <li>Clarify documentation about pydantic's support for custom validation and strict type checking,   despite pydantic being primarily a parsing library, #2855 by @paxcodes</li> <li>Fix schema generation for <code>Deque</code> fields, #2810 by @sergejkozin</li> <li>fix an edge case when mixing constraints and <code>Literal</code>, #2794 by @PrettyWood</li> <li>Fix postponed annotation resolution for <code>NamedTuple</code> and <code>TypedDict</code> when they're used directly as the type of fields   within Pydantic models, #2760 by @jameysharp</li> <li>Fix bug when <code>mypy</code> plugin fails on <code>construct</code> method call for <code>BaseSettings</code> derived classes, #2753 by @uriyyo</li> <li>Add function overloading for a <code>pydantic.create_model</code> function, #2748 by @uriyyo</li> <li>Fix mypy plugin issue with self field declaration, #2743 by @uriyyo</li> <li>The colon at the end of the line \"The fields which were supplied when user was initialised:\" suggests that the code following it is related.   Changed it to a period, #2733 by @krisaoe</li> <li>Renamed variable <code>schema</code> to <code>schema_</code> to avoid shadowing of global variable name, #2724 by @shahriyarr</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code>, #2721 by @tiangolo</li> <li>add missing type annotations in <code>BaseConfig</code> and handle <code>max_length = 0</code>, #2719 by @PrettyWood</li> <li>Change <code>orm_mode</code> checking to allow recursive ORM mode parsing with dicts, #2718 by @nuno-andre</li> <li>Add episode 313 of the Talk Python To Me podcast, where Michael Kennedy and Samuel Colvin discuss Pydantic, to the docs, #2712 by @RatulMaharaj</li> <li>fix JSON schema generation when a field is of type <code>NamedTuple</code> and has a default value, #2707 by @PrettyWood</li> <li><code>Enum</code> fields now properly support extra kwargs in schema generation, #2697 by @sammchardy</li> <li>Breaking Change, see #3780: Make serialization of referenced pydantic models possible, #2650 by @PrettyWood</li> <li>Add <code>uniqueItems</code> option to <code>ConstrainedList</code>, #2618 by @nuno-andre</li> <li>Try to evaluate forward refs automatically at model creation, #2588 by @uriyyo</li> <li>Switch docs preview and coverage display to use smokeshow, #2580 by @samuelcolvin</li> <li>Add <code>__version__</code> attribute to pydantic module, #2572 by @paxcodes</li> <li>Add <code>postgresql+asyncpg</code>, <code>postgresql+pg8000</code>, <code>postgresql+psycopg2</code>, <code>postgresql+psycopg2cffi</code>, <code>postgresql+py-postgresql</code>   and <code>postgresql+pygresql</code> schemes for <code>PostgresDsn</code>, #2567 by @postgres-asyncpg</li> <li>Enable the Hypothesis plugin to generate a constrained decimal when the <code>decimal_places</code> argument is specified, #2524 by @cwe5590</li> <li>Allow <code>collections.abc.Callable</code> to be used as type in Python 3.9, #2519 by @daviskirk</li> <li>Documentation update how to custom compile pydantic when using pip install, small change in <code>setup.py</code>   to allow for custom CFLAGS when compiling, #2517 by @peterroelants</li> <li>remove side effect of <code>default_factory</code> to run it only once even if <code>Config.validate_all</code> is set, #2515 by @PrettyWood</li> <li>Add lookahead to ip regexes for <code>AnyUrl</code> hosts. This allows urls with DNS labels   looking like IPs to validate as they are perfectly valid host names, #2512 by @sbv-csis</li> <li>Set <code>minItems</code> and <code>maxItems</code> in generated JSON schema for fixed-length tuples, #2497 by @PrettyWood</li> <li>Add <code>strict</code> argument to <code>conbytes</code>, #2489 by @koxudaxi</li> <li>Support user defined generic field types in generic models, #2465 by @daviskirk</li> <li>Add an example and a short explanation of subclassing <code>GetterDict</code> to docs, #2463 by @nuno-andre</li> <li>add <code>KafkaDsn</code> type, <code>HttpUrl</code> now has default port 80 for http and 443 for https, #2447 by @MihanixA</li> <li>Add <code>PastDate</code> and <code>FutureDate</code> types, #2425 by @Kludex</li> <li>Support generating schema for <code>Generic</code> fields with subtypes, #2375 by @maximberg</li> <li>fix(encoder): serialize <code>NameEmail</code> to str, #2341 by @alecgerona</li> <li>add <code>Config.smart_union</code> to prevent coercion in <code>Union</code> if possible, see  the doc for more information, #2092 by @PrettyWood</li> <li>Add ability to use <code>typing.Counter</code> as a model field type, #2060 by @uriyyo</li> <li>Add parameterised subclasses to <code>__bases__</code> when constructing new parameterised classes, so that <code>A &lt;: B =&gt; A[int] &lt;: B[int]</code>, #2007 by @diabolo-dan</li> <li>Create <code>FileUrl</code> type that allows URLs that conform to RFC 8089.   Add <code>host_required</code> parameter, which is <code>True</code> by default (<code>AnyUrl</code> and subclasses), <code>False</code> in <code>RedisDsn</code>, <code>FileUrl</code>, #1983 by @vgerak</li> <li>add <code>confrozenset()</code>, analogous to <code>conset()</code> and <code>conlist()</code>, #1897 by @PrettyWood</li> <li>stop calling parent class <code>root_validator</code> if overridden, #1895 by @PrettyWood</li> <li>Add <code>repr</code> (defaults to <code>True</code>) parameter to <code>Field</code>, to hide it from the default representation of the <code>BaseModel</code>, #1831 by @fnep</li> <li>Accept empty query/fragment URL parts, #1807 by @xavier</li> </ul>"},{"location":"changelog/#v182-2021-05-11","title":"v1.8.2 (2021-05-11)","text":"<p>Warning</p> <p>A security vulnerability, level \"moderate\" is fixed in v1.8.2. Please upgrade ASAP. See security advisory CVE-2021-29510</p> <ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   see security advisory CVE-2021-29510</li> <li>fix schema generation with Enum by generating a valid name, #2575 by @PrettyWood</li> <li>fix JSON schema generation with a <code>Literal</code> of an enum member, #2536 by @PrettyWood</li> <li>Fix bug with configurations declarations that are passed as   keyword arguments during class creation, #2532 by @uriyyo</li> <li>Allow passing <code>json_encoders</code> in class kwargs, #2521 by @layday</li> <li>support arbitrary types with custom <code>__eq__</code>, #2483 by @PrettyWood</li> <li>support <code>Annotated</code> in <code>validate_arguments</code> and in generic models with Python 3.9, #2483 by @PrettyWood</li> </ul>"},{"location":"changelog/#v181-2021-03-03","title":"v1.8.1 (2021-03-03)","text":"<p>Bug fixes for regressions and new features from <code>v1.8</code></p> <ul> <li>allow elements of <code>Config.field</code> to update elements of a <code>Field</code>, #2461 by @samuelcolvin</li> <li>fix validation with a <code>BaseModel</code> field and a custom root type, #2449 by @PrettyWood</li> <li>expose <code>Pattern</code> encoder to <code>fastapi</code>, #2444 by @PrettyWood</li> <li>enable the Hypothesis plugin to generate a constrained float when the <code>multiple_of</code> argument is specified, #2442 by @tobi-lipede-oodle</li> <li>Avoid <code>RecursionError</code> when using some types like <code>Enum</code> or <code>Literal</code> with generic models, #2436 by @PrettyWood</li> <li>do not overwrite declared <code>__hash__</code> in subclasses of a model, #2422 by @PrettyWood</li> <li>fix <code>mypy</code> complaints on <code>Path</code> and <code>UUID</code> related custom types, #2418 by @PrettyWood</li> <li>Support properly variable length tuples of compound types, #2416 by @PrettyWood</li> </ul>"},{"location":"changelog/#v18-2021-02-26","title":"v1.8 (2021-02-26)","text":"<p>Thank you to pydantic's sponsors: @jorgecarleitao, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @koxudaxi, @timdrijvers, @mkeen, @meadsteve, @ginomempin, @primer-io, @and-semakin, @tomthorogood, @AjitZK, @westonsteimel, @Mazyod, @christippett, @CarlosDomingues, @Kludex, @r-m-n for their kind support.</p>"},{"location":"changelog/#highlights_1","title":"Highlights","text":"<ul> <li>Hypothesis plugin for testing, #2097 by @Zac-HD</li> <li>support for <code>NamedTuple</code> and <code>TypedDict</code>, #2216 by @PrettyWood</li> <li>Support <code>Annotated</code> hints on model fields, #2147 by @JacobHayes</li> <li><code>frozen</code> parameter on <code>Config</code> to allow models to be hashed, #1880 by @rhuille</li> </ul>"},{"location":"changelog/#changes","title":"Changes","text":"<ul> <li>Breaking Change, remove old deprecation aliases from v1, #2415 by @samuelcolvin:</li> <li>remove notes on migrating to v1 in docs</li> <li>remove <code>Schema</code> which was replaced by <code>Field</code></li> <li>remove <code>Config.case_insensitive</code> which was replaced by <code>Config.case_sensitive</code> (default <code>False</code>)</li> <li>remove <code>Config.allow_population_by_alias</code> which was replaced by <code>Config.allow_population_by_field_name</code></li> <li>remove <code>model.fields</code> which was replaced by <code>model.__fields__</code></li> <li>remove <code>model.to_string()</code> which was replaced by <code>str(model)</code></li> <li>remove <code>model.__values__</code> which was replaced by <code>model.__dict__</code></li> <li>Breaking Change: always validate only first sublevel items with <code>each_item</code>.   There were indeed some edge cases with some compound types where the validated items were the last sublevel ones, #1933 by @PrettyWood</li> <li>Update docs extensions to fix local syntax highlighting, #2400 by @daviskirk</li> <li>fix: allow <code>utils.lenient_issubclass</code> to handle <code>typing.GenericAlias</code> objects like <code>list[str]</code> in Python &gt;= 3.9, #2399 by @daviskirk</li> <li>Improve field declaration for pydantic <code>dataclass</code> by allowing the usage of pydantic <code>Field</code> or <code>'metadata'</code> kwarg of <code>dataclasses.field</code>, #2384 by @PrettyWood</li> <li>Making <code>typing-extensions</code> a required dependency, #2368 by @samuelcolvin</li> <li>Make <code>resolve_annotations</code> more lenient, allowing for missing modules, #2363 by @samuelcolvin</li> <li>Allow configuring models through class kwargs, #2356 by @Bobronium</li> <li>Prevent <code>Mapping</code> subclasses from always being coerced to <code>dict</code>, #2325 by @ofek</li> <li>fix: allow <code>None</code> for type <code>Optional[conset / conlist]</code>, #2320 by @PrettyWood</li> <li>Support empty tuple type, #2318 by @PrettyWood</li> <li>fix: <code>python_requires</code> metadata to require &gt;=3.6.1, #2306 by @hukkinj1</li> <li>Properly encode <code>Decimal</code> with, or without any decimal places, #2293 by @hultner</li> <li>fix: update <code>__fields_set__</code> in <code>BaseModel.copy(update=\u2026)</code>, #2290 by @PrettyWood</li> <li>fix: keep order of fields with <code>BaseModel.construct()</code>, #2281 by @PrettyWood</li> <li>Support generating schema for Generic fields, #2262 by @maximberg</li> <li>Fix <code>validate_decorator</code> so <code>**kwargs</code> doesn't exclude values when the keyword   has the same name as the <code>*args</code> or <code>**kwargs</code> names, #2251 by @cybojenix</li> <li>Prevent overriding positional arguments with keyword arguments in   <code>validate_arguments</code>, as per behaviour with native functions, #2249 by @cybojenix</li> <li>add documentation for <code>con*</code> type functions, #2242 by @tayoogunbiyi</li> <li>Support custom root type (aka <code>__root__</code>) when using <code>parse_obj()</code> with nested models, #2238 by @PrettyWood</li> <li>Support custom root type (aka <code>__root__</code>) with <code>from_orm()</code>, #2237 by @PrettyWood</li> <li>ensure cythonized functions are left untouched when creating models, based on #1944 by @kollmats, #2228 by @samuelcolvin</li> <li>Resolve forward refs for stdlib dataclasses converted into pydantic ones, #2220 by @PrettyWood</li> <li>Add support for <code>NamedTuple</code> and <code>TypedDict</code> types.   Those two types are now handled and validated when used inside <code>BaseModel</code> or pydantic <code>dataclass</code>.   Two utils are also added <code>create_model_from_namedtuple</code> and <code>create_model_from_typeddict</code>, #2216 by @PrettyWood</li> <li>Do not ignore annotated fields when type is <code>Union[Type[...], ...]</code>, #2213 by @PrettyWood</li> <li>Raise a user-friendly <code>TypeError</code> when a <code>root_validator</code> does not return a <code>dict</code> (e.g. <code>None</code>), #2209 by @masalim2</li> <li>Add a <code>FrozenSet[str]</code> type annotation to the <code>allowed_schemes</code> argument on the <code>strict_url</code> field type, #2198 by @Midnighter</li> <li>add <code>allow_mutation</code> constraint to <code>Field</code>, #2195 by @sblack-usu</li> <li>Allow <code>Field</code> with a <code>default_factory</code> to be used as an argument to a function   decorated with <code>validate_arguments</code>, #2176 by @thomascobb</li> <li>Allow non-existent secrets directory by only issuing a warning, #2175 by @davidolrik</li> <li>fix URL regex to parse fragment without query string, #2168 by @andrewmwhite</li> <li>fix: ensure to always return one of the values in <code>Literal</code> field type, #2166 by @PrettyWood</li> <li>Support <code>typing.Annotated</code> hints on model fields. A <code>Field</code> may now be set in the type hint with <code>Annotated[..., Field(...)</code>; all other annotations are ignored but still visible with <code>get_type_hints(..., include_extras=True)</code>, #2147 by @JacobHayes</li> <li>Added <code>StrictBytes</code> type as well as <code>strict=False</code> option to <code>ConstrainedBytes</code>, #2136 by @rlizzo</li> <li>added <code>Config.anystr_lower</code> and <code>to_lower</code> kwarg to <code>constr</code> and <code>conbytes</code>, #2134 by @tayoogunbiyi</li> <li>Support plain <code>typing.Tuple</code> type, #2132 by @PrettyWood</li> <li>Add a bound method <code>validate</code> to functions decorated with <code>validate_arguments</code>   to validate parameters without actually calling the function, #2127 by @PrettyWood</li> <li>Add the ability to customize settings sources (add / disable / change priority order), #2107 by @kozlek</li> <li>Fix mypy complaints about most custom pydantic types, #2098 by @PrettyWood</li> <li>Add a Hypothesis plugin for easier property-based testing with Pydantic's custom types - usage details here, #2097 by @Zac-HD</li> <li>add validator for <code>None</code>, <code>NoneType</code> or <code>Literal[None]</code>, #2095 by @PrettyWood</li> <li>Handle properly fields of type <code>Callable</code> with a default value, #2094 by @PrettyWood</li> <li>Updated <code>create_model</code> return type annotation to return type which inherits from <code>__base__</code> argument, #2071 by @uriyyo</li> <li>Add merged <code>json_encoders</code> inheritance, #2064 by @art049</li> <li>allow overwriting <code>ClassVar</code>s in sub-models without having to re-annotate them, #2061 by @layday</li> <li>add default encoder for <code>Pattern</code> type, #2045 by @PrettyWood</li> <li>Add <code>NonNegativeInt</code>, <code>NonPositiveInt</code>, <code>NonNegativeFloat</code>, <code>NonPositiveFloat</code>, #1975 by @mdavis-xyz</li> <li>Use % for percentage in string format of colors, #1960 by @EdwardBetts</li> <li>Fixed issue causing <code>KeyError</code> to be raised when building schema from multiple <code>BaseModel</code> with the same names declared in separate classes, #1912 by @JSextonn</li> <li>Add <code>rediss</code> (Redis over SSL) protocol to <code>RedisDsn</code>   Allow URLs without <code>user</code> part (e.g., <code>rediss://:pass@localhost</code>), #1911 by @TrDex</li> <li>Add a new <code>frozen</code> boolean parameter to <code>Config</code> (default: <code>False</code>).   Setting <code>frozen=True</code> does everything that <code>allow_mutation=False</code> does, and also generates a <code>__hash__()</code> method for the model. This makes instances of the model potentially hashable if all the attributes are hashable, #1880 by @rhuille</li> <li>fix schema generation with multiple Enums having the same name, #1857 by @PrettyWood</li> <li>Added support for 13/19 digits VISA credit cards in <code>PaymentCardNumber</code> type, #1416 by @AlexanderSov</li> <li>fix: prevent <code>RecursionError</code> while using recursive <code>GenericModel</code>s, #1370 by @xppt</li> <li>use <code>enum</code> for <code>typing.Literal</code> in JSON schema, #1350 by @PrettyWood</li> <li>Fix: some recursive models did not require <code>update_forward_refs</code> and silently behaved incorrectly, #1201 by @PrettyWood</li> <li>Fix bug where generic models with fields where the typevar is nested in another type <code>a: List[T]</code> are considered to be concrete. This allows these models to be subclassed and composed as expected, #947 by @daviskirk</li> <li>Add <code>Config.copy_on_model_validation</code> flag. When set to <code>False</code>, pydantic will keep models used as fields   untouched on validation instead of reconstructing (copying) them, #265 by @PrettyWood</li> </ul>"},{"location":"changelog/#v174-2021-05-11","title":"v1.7.4 (2021-05-11)","text":"<ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   See security advisory CVE-2021-29510</li> </ul>"},{"location":"changelog/#v173-2020-11-30","title":"v1.7.3 (2020-11-30)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen, @meadsteve for their kind support.</p> <ul> <li>fix: set right default value for required (optional) fields, #2142 by @PrettyWood</li> <li>fix: support <code>underscore_attrs_are_private</code> with generic models, #2138 by @PrettyWood</li> <li>fix: update all modified field values in <code>root_validator</code> when <code>validate_assignment</code> is on, #2116 by @PrettyWood</li> <li>Allow pickling of <code>pydantic.dataclasses.dataclass</code> dynamically created from a built-in <code>dataclasses.dataclass</code>, #2111 by @aimestereo</li> <li>Fix a regression where Enum fields would not propagate keyword arguments to the schema, #2109 by @bm424</li> <li>Ignore <code>__doc__</code> as private attribute when <code>Config.underscore_attrs_are_private</code> is set, #2090 by @PrettyWood</li> </ul>"},{"location":"changelog/#v172-2020-11-01","title":"v1.7.2 (2020-11-01)","text":"<ul> <li>fix slow <code>GenericModel</code> concrete model creation, allow <code>GenericModel</code> concrete name reusing in module, #2078 by @Bobronium</li> <li>keep the order of the fields when <code>validate_assignment</code> is set, #2073 by @PrettyWood</li> <li>forward all the params of the stdlib <code>dataclass</code> when converted into pydantic <code>dataclass</code>, #2065 by @PrettyWood</li> </ul>"},{"location":"changelog/#v171-2020-10-28","title":"v1.7.1 (2020-10-28)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen for their kind support.</p> <ul> <li>fix annotation of <code>validate_arguments</code> when passing configuration as argument, #2055 by @layday</li> <li>Fix mypy assignment error when using <code>PrivateAttr</code>, #2048 by @aphedges</li> <li>fix <code>underscore_attrs_are_private</code> causing <code>TypeError</code> when overriding <code>__init__</code>, #2047 by @samuelcolvin</li> <li>Fixed regression introduced in v1.7 involving exception handling in field validators when <code>validate_assignment=True</code>, #2044 by @johnsabath</li> <li>fix: pydantic <code>dataclass</code> can inherit from stdlib <code>dataclass</code>   and <code>Config.arbitrary_types_allowed</code> is supported, #2042 by @PrettyWood</li> </ul>"},{"location":"changelog/#v17-2020-10-26","title":"v1.7 (2020-10-26)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api for their kind support.</p>"},{"location":"changelog/#highlights_2","title":"Highlights","text":"<ul> <li>Python 3.9 support, thanks @PrettyWood</li> <li>Private model attributes, thanks @Bobronium</li> <li>\"secrets files\" support in <code>BaseSettings</code>, thanks @mdgilene</li> <li>convert stdlib dataclasses to pydantic dataclasses and use stdlib dataclasses in models, thanks @PrettyWood</li> </ul>"},{"location":"changelog/#changes_1","title":"Changes","text":"<ul> <li>Breaking Change: remove <code>__field_defaults__</code>, add <code>default_factory</code> support with <code>BaseModel.construct</code>.   Use <code>.get_default()</code> method on fields in <code>__fields__</code> attribute instead, #1732 by @PrettyWood</li> <li>Rearrange CI to run linting as a separate job, split install recipes for different tasks, #2020 by @samuelcolvin</li> <li>Allows subclasses of generic models to make some, or all, of the superclass's type parameters concrete, while   also defining new type parameters in the subclass, #2005 by @choogeboom</li> <li>Call validator with the correct <code>values</code> parameter type in <code>BaseModel.__setattr__</code>,   when <code>validate_assignment = True</code> in model config, #1999 by @me-ransh</li> <li>Force <code>fields.Undefined</code> to be a singleton object, fixing inherited generic model schemas, #1981 by @daviskirk</li> <li>Include tests in source distributions, #1976 by @sbraz</li> <li>Add ability to use <code>min_length/max_length</code> constraints with secret types, #1974 by @uriyyo</li> <li>Also check <code>root_validators</code> when <code>validate_assignment</code> is on, #1971 by @PrettyWood</li> <li>Fix const validators not running when custom validators are present, #1957 by @hmvp</li> <li>add <code>deque</code> to field types, #1935 by @wozniakty</li> <li>add basic support for Python 3.9, #1832 by @PrettyWood</li> <li>Fix typo in the anchor of exporting_models.md#modelcopy and incorrect description, #1821 by @KimMachineGun</li> <li>Added ability for <code>BaseSettings</code> to read \"secret files\", #1820 by @mdgilene</li> <li>add <code>parse_raw_as</code> utility function, #1812 by @PrettyWood</li> <li>Support home directory relative paths for <code>dotenv</code> files (e.g. <code>~/.env</code>), #1803 by @PrettyWood</li> <li>Clarify documentation for <code>parse_file</code> to show that the argument   should be a file path not a file-like object, #1794 by @mdavis-xyz</li> <li>Fix false positive from mypy plugin when a class nested within a <code>BaseModel</code> is named <code>Model</code>, #1770 by @selimb</li> <li>add basic support of Pattern type in schema generation, #1767 by @PrettyWood</li> <li>Support custom title, description and default in schema of enums, #1748 by @PrettyWood</li> <li>Properly represent <code>Literal</code> Enums when <code>use_enum_values</code> is True, #1747 by @noelevans</li> <li>Allows timezone information to be added to strings to be formatted as time objects. Permitted formats are <code>Z</code> for UTC   or an offset for absolute positive or negative time shifts. Or the timezone data can be omitted, #1744 by @noelevans</li> <li>Add stub <code>__init__</code> with Python 3.6 signature for <code>ForwardRef</code>, #1738 by @sirtelemak</li> <li>Fix behaviour with forward refs and optional fields in nested models, #1736 by @PrettyWood</li> <li>add <code>Enum</code> and <code>IntEnum</code> as valid types for fields, #1735 by @PrettyWood</li> <li>Change default value of <code>__module__</code> argument of <code>create_model</code> from <code>None</code> to <code>'pydantic.main'</code>.   Set reference of created concrete model to it's module to allow pickling (not applied to models created in   functions), #1686 by @Bobronium</li> <li>Add private attributes support, #1679 by @Bobronium</li> <li>add <code>config</code> to <code>@validate_arguments</code>, #1663 by @samuelcolvin</li> <li>Allow descendant Settings models to override env variable names for the fields defined in parent Settings models with   <code>env</code> in their <code>Config</code>. Previously only <code>env_prefix</code> configuration option was applicable, #1561 by @ojomio</li> <li>Support <code>ref_template</code> when creating schema <code>$ref</code>s, #1479 by @kilo59</li> <li>Add a <code>__call__</code> stub to <code>PyObject</code> so that mypy will know that it is callable, #1352 by @brianmaissy</li> <li><code>pydantic.dataclasses.dataclass</code> decorator now supports built-in <code>dataclasses.dataclass</code>.   It is hence possible to convert an existing <code>dataclass</code> easily to add Pydantic validation.   Moreover nested dataclasses are also supported, #744 by @PrettyWood</li> </ul>"},{"location":"changelog/#v162-2021-05-11","title":"v1.6.2 (2021-05-11)","text":"<ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   See security advisory CVE-2021-29510</li> </ul>"},{"location":"changelog/#v161-2020-07-15","title":"v1.6.1 (2020-07-15)","text":"<ul> <li>fix validation and parsing of nested models with <code>default_factory</code>, #1710 by @PrettyWood</li> </ul>"},{"location":"changelog/#v16-2020-07-11","title":"v1.6 (2020-07-11)","text":"<p>Thank you to pydantic's sponsors: @matin, @tiangolo, @chdsbd, @jorgecarleitao, and 1 anonymous sponsor for their kind support.</p> <ul> <li>Modify validators for <code>conlist</code> and <code>conset</code> to not have <code>always=True</code>, #1682 by @samuelcolvin</li> <li>add port check to <code>AnyUrl</code> (can't exceed 65536) ports are 16 insigned bits: <code>0 &lt;= port &lt;= 2**16-1</code> src: rfc793 header format, #1654 by @flapili</li> <li>Document default <code>regex</code> anchoring semantics, #1648 by @yurikhan</li> <li>Use <code>chain.from_iterable</code> in class_validators.py. This is a faster and more idiomatic way of using <code>itertools.chain</code>.   Instead of computing all the items in the iterable and storing them in memory, they are computed one-by-one and never   stored as a huge list. This can save on both runtime and memory space, #1642 by @cool-RR</li> <li>Add <code>conset()</code>, analogous to <code>conlist()</code>, #1623 by @patrickkwang</li> <li>make Pydantic errors (un)pickable, #1616 by @PrettyWood</li> <li>Allow custom encoding for <code>dotenv</code> files, #1615 by @PrettyWood</li> <li>Ensure <code>SchemaExtraCallable</code> is always defined to get type hints on BaseConfig, #1614 by @PrettyWood</li> <li>Update datetime parser to support negative timestamps, #1600 by @mlbiche</li> <li>Update mypy, remove <code>AnyType</code> alias for <code>Type[Any]</code>, #1598 by @samuelcolvin</li> <li>Adjust handling of root validators so that errors are aggregated from all failing root validators, instead of reporting on only the first root validator to fail, #1586 by @beezee</li> <li>Make <code>__modify_schema__</code> on Enums apply to the enum schema rather than fields that use the enum, #1581 by @therefromhere</li> <li>Fix behavior of <code>__all__</code> key when used in conjunction with index keys in advanced include/exclude of fields that are sequences, #1579 by @xspirus</li> <li>Subclass validators do not run when referencing a <code>List</code> field defined in a parent class when <code>each_item=True</code>. Added an example to the docs illustrating this, #1566 by @samueldeklund</li> <li>change <code>schema.field_class_to_schema</code> to support <code>frozenset</code> in schema, #1557 by @wangpeibao</li> <li>Call <code>__modify_schema__</code> only for the field schema, #1552 by @PrettyWood</li> <li>Move the assignment of <code>field.validate_always</code> in <code>fields.py</code> so the <code>always</code> parameter of validators work on inheritance, #1545 by @dcHHH</li> <li>Added support for UUID instantiation through 16 byte strings such as <code>b'\\x12\\x34\\x56\\x78' * 4</code>. This was done to support <code>BINARY(16)</code> columns in sqlalchemy, #1541 by @shawnwall</li> <li>Add a test assertion that <code>default_factory</code> can return a singleton, #1523 by @therefromhere</li> <li>Add <code>NameEmail.__eq__</code> so duplicate <code>NameEmail</code> instances are evaluated as equal, #1514 by @stephen-bunn</li> <li>Add datamodel-code-generator link in pydantic document site, #1500 by @koxudaxi</li> <li>Added a \"Discussion of Pydantic\" section to the documentation, with a link to \"Pydantic Introduction\" video by Alexander Hultn\u00e9r, #1499 by @hultner</li> <li>Avoid some side effects of <code>default_factory</code> by calling it only once   if possible and by not setting a default value in the schema, #1491 by @PrettyWood</li> <li>Added docs about dumping dataclasses to JSON, #1487 by @mikegrima</li> <li>Make <code>BaseModel.__signature__</code> class-only, so getting <code>__signature__</code> from model instance will raise <code>AttributeError</code>, #1466 by @Bobronium</li> <li>include <code>'format': 'password'</code> in the schema for secret types, #1424 by @atheuz</li> <li>Modify schema constraints on <code>ConstrainedFloat</code> so that <code>exclusiveMinimum</code> and   minimum are not included in the schema if they are equal to <code>-math.inf</code> and   <code>exclusiveMaximum</code> and <code>maximum</code> are not included if they are equal to <code>math.inf</code>, #1417 by @vdwees</li> <li>Squash internal <code>__root__</code> dicts in <code>.dict()</code> (and, by extension, in <code>.json()</code>), #1414 by @patrickkwang</li> <li>Move <code>const</code> validator to post-validators so it validates the parsed value, #1410 by @selimb</li> <li>Fix model validation to handle nested literals, e.g. <code>Literal['foo', Literal['bar']]</code>, #1364 by @DBCerigo</li> <li>Remove <code>user_required = True</code> from <code>RedisDsn</code>, neither user nor password are required, #1275 by @samuelcolvin</li> <li>Remove extra <code>allOf</code> from schema for fields with <code>Union</code> and custom <code>Field</code>, #1209 by @mostaphaRoudsari</li> <li>Updates OpenAPI schema generation to output all enums as separate models.   Instead of inlining the enum values in the model schema, models now use a <code>$ref</code>   property to point to the enum definition, #1173 by @calvinwyoung</li> </ul>"},{"location":"changelog/#v151-2020-04-23","title":"v1.5.1 (2020-04-23)","text":"<ul> <li>Signature generation with <code>extra: allow</code> never uses a field name, #1418 by @prettywood</li> <li>Avoid mutating <code>Field</code> default value, #1412 by @prettywood</li> </ul>"},{"location":"changelog/#v15-2020-04-18","title":"v1.5 (2020-04-18)","text":"<ul> <li>Make includes/excludes arguments for <code>.dict()</code>, <code>._iter()</code>, ..., immutable, #1404 by @AlexECX</li> <li>Always use a field's real name with includes/excludes in <code>model._iter()</code>, regardless of <code>by_alias</code>, #1397 by @AlexECX</li> <li>Update constr regex example to include start and end lines, #1396 by @lmcnearney</li> <li>Confirm that shallow <code>model.copy()</code> does make a shallow copy of attributes, #1383 by @samuelcolvin</li> <li>Renaming <code>model_name</code> argument of <code>main.create_model()</code> to <code>__model_name</code> to allow using <code>model_name</code> as a field name, #1367 by @kittipatv</li> <li>Replace raising of exception to silent passing  for non-Var attributes in mypy plugin, #1345 by @b0g3r</li> <li>Remove <code>typing_extensions</code> dependency for Python 3.8, #1342 by @prettywood</li> <li>Make <code>SecretStr</code> and <code>SecretBytes</code> initialization idempotent, #1330 by @atheuz</li> <li>document making secret types dumpable using the json method, #1328 by @atheuz</li> <li>Move all testing and build to github actions, add windows and macos binaries,   thank you @StephenBrown2 for much help, #1326 by @samuelcolvin</li> <li>fix card number length check in <code>PaymentCardNumber</code>, <code>PaymentCardBrand</code> now inherits from <code>str</code>, #1317 by @samuelcolvin</li> <li>Have <code>BaseModel</code> inherit from <code>Representation</code> to make mypy happy when overriding <code>__str__</code>, #1310 by @FuegoFro</li> <li>Allow <code>None</code> as input to all optional list fields, #1307 by @prettywood</li> <li>Add <code>datetime</code> field to <code>default_factory</code> example, #1301 by @StephenBrown2</li> <li>Allow subclasses of known types to be encoded with superclass encoder, #1291 by @StephenBrown2</li> <li>Exclude exported fields from all elements of a list/tuple of submodels/dicts with <code>'__all__'</code>, #1286 by @masalim2</li> <li>Add pydantic.color.Color objects as available input for Color fields, #1258 by @leosussan</li> <li>In examples, type nullable fields as <code>Optional</code>, so that these are valid mypy annotations, #1248 by @kokes</li> <li>Make <code>pattern_validator()</code> accept pre-compiled <code>Pattern</code> objects. Fix <code>str_validator()</code> return type to <code>str</code>, #1237 by @adamgreg</li> <li>Document how to manage Generics and inheritance, #1229 by @esadruhn</li> <li><code>update_forward_refs()</code> method of BaseModel now copies <code>__dict__</code> of class module instead of modyfying it, #1228 by @paul-ilyin</li> <li>Support instance methods and class methods with <code>@validate_arguments</code>, #1222 by @samuelcolvin</li> <li>Add <code>default_factory</code> argument to <code>Field</code> to create a dynamic default value by passing a zero-argument callable, #1210 by @prettywood</li> <li>add support for <code>NewType</code> of <code>List</code>, <code>Optional</code>, etc, #1207 by @Kazy</li> <li>fix mypy signature for <code>root_validator</code>, #1192 by @samuelcolvin</li> <li>Fixed parsing of nested 'custom root type' models, #1190 by @Shados</li> <li>Add <code>validate_arguments</code> function decorator which checks the arguments to a function matches type annotations, #1179 by @samuelcolvin</li> <li>Add <code>__signature__</code> to models, #1034 by @Bobronium</li> <li>Refactor <code>._iter()</code> method, 10x speed boost for <code>dict(model)</code>, #1017 by @Bobronium</li> </ul>"},{"location":"changelog/#v14-2020-01-24","title":"v1.4 (2020-01-24)","text":"<ul> <li>Breaking Change: alias precedence logic changed so aliases on a field always take priority over   an alias from <code>alias_generator</code> to avoid buggy/unexpected behaviour,   see here for details, #1178 by @samuelcolvin</li> <li>Add support for unicode and punycode in TLDs, #1182 by @jamescurtin</li> <li>Fix <code>cls</code> argument in validators during assignment, #1172 by @samuelcolvin</li> <li>completing Luhn algorithm for <code>PaymentCardNumber</code>, #1166 by @cuencandres</li> <li>add support for generics that implement <code>__get_validators__</code> like a custom data type, #1159 by @tiangolo</li> <li>add support for infinite generators with <code>Iterable</code>, #1152 by @tiangolo</li> <li>fix <code>url_regex</code> to accept schemas with <code>+</code>, <code>-</code> and <code>.</code> after the first character, #1142 by @samuelcolvin</li> <li>move <code>version_info()</code> to <code>version.py</code>, suggest its use in issues, #1138 by @samuelcolvin</li> <li>Improve pydantic import time by roughly 50% by deferring some module loading and regex compilation, #1127 by @samuelcolvin</li> <li>Fix <code>EmailStr</code> and <code>NameEmail</code> to accept instances of themselves in cython, #1126 by @koxudaxi</li> <li>Pass model class to the <code>Config.schema_extra</code> callable, #1125 by @therefromhere</li> <li>Fix regex for username and password in URLs, #1115 by @samuelcolvin</li> <li>Add support for nested generic models, #1104 by @dmontagu</li> <li>add <code>__all__</code> to <code>__init__.py</code> to prevent \"implicit reexport\" errors from mypy, #1072 by @samuelcolvin</li> <li>Add support for using \"dotenv\" files with <code>BaseSettings</code>, #1011 by @acnebs</li> </ul>"},{"location":"changelog/#v13-2019-12-21","title":"v1.3 (2019-12-21)","text":"<ul> <li>Change <code>schema</code> and <code>schema_model</code> to handle dataclasses by using their <code>__pydantic_model__</code> feature, #792 by @aviramha</li> <li>Added option for <code>root_validator</code> to be skipped if values validation fails using keyword <code>skip_on_failure=True</code>, #1049 by @aviramha</li> <li>Allow <code>Config.schema_extra</code> to be a callable so that the generated schema can be post-processed, #1054 by @selimb</li> <li>Update mypy to version 0.750, #1057 by @dmontagu</li> <li>Trick Cython into allowing str subclassing, #1061 by @skewty</li> <li>Prevent type attributes being added to schema unless the attribute <code>__schema_attributes__</code> is <code>True</code>, #1064 by @samuelcolvin</li> <li>Change <code>BaseModel.parse_file</code> to use <code>Config.json_loads</code>, #1067 by @kierandarcy</li> <li>Fix for optional <code>Json</code> fields, #1073 by @volker48</li> <li>Change the default number of threads used when compiling with cython to one,   allow override via the <code>CYTHON_NTHREADS</code> environment variable, #1074 by @samuelcolvin</li> <li>Run FastAPI tests during Pydantic's CI tests, #1075 by @tiangolo</li> <li>My mypy strictness constraints, and associated tweaks to type annotations, #1077 by @samuelcolvin</li> <li>Add <code>__eq__</code> to SecretStr and SecretBytes to allow \"value equals\", #1079 by @sbv-trueenergy</li> <li>Fix schema generation for nested None case, #1088 by @lutostag</li> <li>Consistent checks for sequence like objects, #1090 by @samuelcolvin</li> <li>Fix <code>Config</code> inheritance on <code>BaseSettings</code> when used with <code>env_prefix</code>, #1091 by @samuelcolvin</li> <li>Fix for <code>__modify_schema__</code> when it conflicted with <code>field_class_to_schema*</code>, #1102 by @samuelcolvin</li> <li>docs: Fix explanation of case sensitive environment variable names when populating <code>BaseSettings</code> subclass attributes, #1105 by @tribals</li> <li>Rename django-rest-framework benchmark in documentation, #1119 by @frankie567</li> </ul>"},{"location":"changelog/#v12-2019-11-28","title":"v1.2 (2019-11-28)","text":"<ul> <li>Possible Breaking Change: Add support for required <code>Optional</code> with <code>name: Optional[AnyType] = Field(...)</code>   and refactor <code>ModelField</code> creation to preserve <code>required</code> parameter value, #1031 by @tiangolo;   see here for details</li> <li>Add benchmarks for <code>cattrs</code>, #513 by @sebastianmika</li> <li>Add <code>exclude_none</code> option to <code>dict()</code> and friends, #587 by @niknetniko</li> <li>Add benchmarks for <code>valideer</code>, #670 by @gsakkis</li> <li>Add <code>parse_obj_as</code> and <code>parse_file_as</code> functions for ad-hoc parsing of data into arbitrary pydantic-compatible types, #934 by @dmontagu</li> <li>Add <code>allow_reuse</code> argument to validators, thus allowing validator reuse, #940 by @dmontagu</li> <li>Add support for mapping types for custom root models, #958 by @dmontagu</li> <li>Mypy plugin support for dataclasses, #966 by @koxudaxi</li> <li>Add support for dataclasses default factory, #968 by @ahirner</li> <li>Add a <code>ByteSize</code> type for converting byte string (<code>1GB</code>) to plain bytes, #977 by @dgasmith</li> <li>Fix mypy complaint about <code>@root_validator(pre=True)</code>, #984 by @samuelcolvin</li> <li>Add manylinux binaries for Python 3.8 to pypi, also support manylinux2010, #994 by @samuelcolvin</li> <li>Adds ByteSize conversion to another unit, #995 by @dgasmith</li> <li>Fix <code>__str__</code> and <code>__repr__</code> inheritance for models, #1022 by @samuelcolvin</li> <li>add testimonials section to docs, #1025 by @sullivancolin</li> <li>Add support for <code>typing.Literal</code> for Python 3.8, #1026 by @dmontagu</li> </ul>"},{"location":"changelog/#v111-2019-11-20","title":"v1.1.1 (2019-11-20)","text":"<ul> <li>Fix bug where use of complex fields on sub-models could cause fields to be incorrectly configured, #1015 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v11-2019-11-07","title":"v1.1 (2019-11-07)","text":"<ul> <li>Add a mypy plugin for type checking <code>BaseModel.__init__</code> and more, #722 by @dmontagu</li> <li>Change return type typehint for <code>GenericModel.__class_getitem__</code> to prevent PyCharm warnings, #936 by @dmontagu</li> <li>Fix usage of <code>Any</code> to allow <code>None</code>, also support <code>TypeVar</code> thus allowing use of un-parameterised collection types   e.g. <code>Dict</code> and <code>List</code>, #962 by @samuelcolvin</li> <li>Set <code>FieldInfo</code> on subfields to fix schema generation for complex nested types, #965 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v10-2019-10-23","title":"v1.0 (2019-10-23)","text":"<ul> <li>Breaking Change: deprecate the <code>Model.fields</code> property, use <code>Model.__fields__</code> instead, #883 by @samuelcolvin</li> <li>Breaking Change: Change the precedence of aliases so child model aliases override parent aliases,   including using <code>alias_generator</code>, #904 by @samuelcolvin</li> <li>Breaking change: Rename <code>skip_defaults</code> to <code>exclude_unset</code>, and add ability to exclude actual defaults, #915 by @dmontagu</li> <li>Add <code>**kwargs</code> to <code>pydantic.main.ModelMetaclass.__new__</code> so <code>__init_subclass__</code> can take custom parameters on extended   <code>BaseModel</code> classes, #867 by @retnikt</li> <li>Fix field of a type that has a default value, #880 by @koxudaxi</li> <li>Use <code>FutureWarning</code> instead of <code>DeprecationWarning</code> when <code>alias</code> instead of <code>env</code> is used for settings models, #881 by @samuelcolvin</li> <li>Fix issue with <code>BaseSettings</code> inheritance and <code>alias</code> getting set to <code>None</code>, #882 by @samuelcolvin</li> <li>Modify <code>__repr__</code> and <code>__str__</code> methods to be consistent across all public classes, add <code>__pretty__</code> to support   python-devtools, #884 by @samuelcolvin</li> <li>deprecation warning for <code>case_insensitive</code> on <code>BaseSettings</code> config, #885 by @samuelcolvin</li> <li>For <code>BaseSettings</code> merge environment variables and in-code values recursively, as long as they create a valid object   when merged together, to allow splitting init arguments, #888 by @idmitrievsky</li> <li>change secret types example, #890 by @ashears</li> <li>Change the signature of <code>Model.construct()</code> to be more user-friendly, document <code>construct()</code> usage, #898 by @samuelcolvin</li> <li>Add example for the <code>construct()</code> method, #907 by @ashears</li> <li>Improve use of <code>Field</code> constraints on complex types, raise an error if constraints are not enforceable,   also support tuples with an ellipsis <code>Tuple[X, ...]</code>, <code>Sequence</code> and <code>FrozenSet</code> in schema, #909 by @samuelcolvin</li> <li>update docs for bool missing valid value, #911 by @trim21</li> <li>Better <code>str</code>/<code>repr</code> logic for <code>ModelField</code>, #912 by @samuelcolvin</li> <li>Fix <code>ConstrainedList</code>, update schema generation to reflect <code>min_items</code> and <code>max_items</code> <code>Field()</code> arguments, #917 by @samuelcolvin</li> <li>Allow abstracts sets (eg. dict keys) in the <code>include</code> and <code>exclude</code> arguments of <code>dict()</code>, #921 by @samuelcolvin</li> <li>Fix JSON serialization errors on <code>ValidationError.json()</code> by using <code>pydantic_encoder</code>, #922 by @samuelcolvin</li> <li>Clarify usage of <code>remove_untouched</code>, improve error message for types with no validators, #926 by @retnikt</li> </ul>"},{"location":"changelog/#v10b2-2019-10-07","title":"v1.0b2 (2019-10-07)","text":"<ul> <li>Mark <code>StrictBool</code> typecheck as <code>bool</code> to allow for default values without mypy errors, #690 by @dmontagu</li> <li>Transfer the documentation build from sphinx to mkdocs, re-write much of the documentation, #856 by @samuelcolvin</li> <li>Add support for custom naming schemes for <code>GenericModel</code> subclasses, #859 by @dmontagu</li> <li>Add <code>if TYPE_CHECKING:</code> to the excluded lines for test coverage, #874 by @dmontagu</li> <li>Rename <code>allow_population_by_alias</code> to <code>allow_population_by_field_name</code>, remove unnecessary warning about it, #875 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v10b1-2019-10-01","title":"v1.0b1 (2019-10-01)","text":"<ul> <li>Breaking Change: rename <code>Schema</code> to <code>Field</code>, make it a function to placate mypy, #577 by @samuelcolvin</li> <li>Breaking Change: modify parsing behavior for <code>bool</code>, #617 by @dmontagu</li> <li>Breaking Change: <code>get_validators</code> is no longer recognised, use <code>__get_validators__</code>.   <code>Config.ignore_extra</code> and <code>Config.allow_extra</code> are no longer recognised, use <code>Config.extra</code>, #720 by @samuelcolvin</li> <li>Breaking Change: modify default config settings for <code>BaseSettings</code>; <code>case_insensitive</code> renamed to <code>case_sensitive</code>,   default changed to <code>case_sensitive = False</code>, <code>env_prefix</code> default changed to <code>''</code> - e.g. no prefix, #721 by @dmontagu</li> <li>Breaking change: Implement <code>root_validator</code> and rename root errors from <code>__obj__</code> to <code>__root__</code>, #729 by @samuelcolvin</li> <li>Breaking Change: alter the behaviour of <code>dict(model)</code> so that sub-models are nolonger   converted to dictionaries, #733 by @samuelcolvin</li> <li>Breaking change: Added <code>initvars</code> support to <code>post_init_post_parse</code>, #748 by @Raphael-C-Almeida</li> <li>Breaking Change: Make <code>BaseModel.json()</code> only serialize the <code>__root__</code> key for models with custom root, #752 by @dmontagu</li> <li>Breaking Change: complete rewrite of <code>URL</code> parsing logic, #755 by @samuelcolvin</li> <li>Breaking Change: preserve superclass annotations for field-determination when not provided in subclass, #757 by @dmontagu</li> <li>Breaking Change: <code>BaseSettings</code> now uses the special <code>env</code> settings to define which environment variables to   read, not aliases, #847 by @samuelcolvin</li> <li>add support for <code>assert</code> statements inside validators, #653 by @abdusco</li> <li>Update documentation to specify the use of <code>pydantic.dataclasses.dataclass</code> and subclassing <code>pydantic.BaseModel</code>, #710 by @maddosaurus</li> <li>Allow custom JSON decoding and encoding via <code>json_loads</code> and <code>json_dumps</code> <code>Config</code> properties, #714 by @samuelcolvin</li> <li>make all annotated fields occur in the order declared, #715 by @dmontagu</li> <li>use pytest to test <code>mypy</code> integration, #735 by @dmontagu</li> <li>add <code>__repr__</code> method to <code>ErrorWrapper</code>, #738 by @samuelcolvin</li> <li>Added support for <code>FrozenSet</code> members in dataclasses, and a better error when attempting to use types from the <code>typing</code> module that are not supported by Pydantic, #745 by @djpetti</li> <li>add documentation for Pycharm Plugin, #750 by @koxudaxi</li> <li>fix broken examples in the docs, #753 by @dmontagu</li> <li>moving typing related objects into <code>pydantic.typing</code>, #761 by @samuelcolvin</li> <li>Minor performance improvements to <code>ErrorWrapper</code>, <code>ValidationError</code> and datetime parsing, #763 by @samuelcolvin</li> <li>Improvements to <code>datetime</code>/<code>date</code>/<code>time</code>/<code>timedelta</code> types: more descriptive errors,   change errors to <code>value_error</code> not <code>type_error</code>, support bytes, #766 by @samuelcolvin</li> <li>fix error messages for <code>Literal</code> types with multiple allowed values, #770 by @dmontagu</li> <li>Improved auto-generated <code>title</code> field in JSON schema by converting underscore to space, #772 by @skewty</li> <li>support <code>mypy --no-implicit-reexport</code> for dataclasses, also respect <code>--no-implicit-reexport</code> in pydantic itself, #783 by @samuelcolvin</li> <li>add the <code>PaymentCardNumber</code> type, #790 by @matin</li> <li>Fix const validations for lists, #794 by @hmvp</li> <li>Set <code>additionalProperties</code> to false in schema for models with extra fields disallowed, #796 by @Code0x58</li> <li><code>EmailStr</code> validation method now returns local part case-sensitive per RFC 5321, #798 by @henriklindgren</li> <li>Added ability to validate strictness to <code>ConstrainedFloat</code>, <code>ConstrainedInt</code> and <code>ConstrainedStr</code> and added   <code>StrictFloat</code> and <code>StrictInt</code> classes, #799 by @DerRidda</li> <li>Improve handling of <code>None</code> and <code>Optional</code>, replace <code>whole</code> with <code>each_item</code> (inverse meaning, default <code>False</code>)   on validators, #803 by @samuelcolvin</li> <li>add support for <code>Type[T]</code> type hints, #807 by @timonbimon</li> <li>Performance improvements from removing <code>change_exceptions</code>, change how pydantic error are constructed, #819 by @samuelcolvin</li> <li>Fix the error message arising when a <code>BaseModel</code>-type model field causes a <code>ValidationError</code> during parsing, #820 by @dmontagu</li> <li>allow <code>getter_dict</code> on <code>Config</code>, modify <code>GetterDict</code> to be more like a <code>Mapping</code> object and thus easier to work with, #821 by @samuelcolvin</li> <li>Only check <code>TypeVar</code> param on base <code>GenericModel</code> class, #842 by @zpencerq</li> <li>rename <code>Model._schema_cache</code> -&gt; <code>Model.__schema_cache__</code>, <code>Model._json_encoder</code> -&gt; <code>Model.__json_encoder__</code>,   <code>Model._custom_root_type</code> -&gt; <code>Model.__custom_root_type__</code>, #851 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0322-2019-08-17","title":"v0.32.2 (2019-08-17)","text":"<p>(Docs are available here)</p> <ul> <li>fix <code>__post_init__</code> usage with dataclass inheritance, fix #739 by @samuelcolvin</li> <li>fix required fields validation on GenericModels classes, #742 by @amitbl</li> <li>fix defining custom <code>Schema</code> on <code>GenericModel</code> fields, #754 by @amitbl</li> </ul>"},{"location":"changelog/#v0321-2019-08-08","title":"v0.32.1 (2019-08-08)","text":"<ul> <li>do not validate extra fields when <code>validate_assignment</code> is on, #724 by @YaraslauZhylko</li> </ul>"},{"location":"changelog/#v032-2019-08-06","title":"v0.32 (2019-08-06)","text":"<ul> <li>add model name to <code>ValidationError</code> error message, #676 by @dmontagu</li> <li>breaking change: remove <code>__getattr__</code> and rename <code>__values__</code> to <code>__dict__</code> on <code>BaseModel</code>,   deprecation warning on use <code>__values__</code> attr, attributes access speed increased up to 14 times, #712 by @Bobronium</li> <li>support <code>ForwardRef</code> (without self-referencing annotations) in Python 3.6, #706 by @koxudaxi</li> <li>implement <code>schema_extra</code> in <code>Config</code> sub-class, #663 by @tiangolo</li> </ul>"},{"location":"changelog/#v0311-2019-07-31","title":"v0.31.1 (2019-07-31)","text":"<ul> <li>fix json generation for <code>EnumError</code>, #697 by @dmontagu</li> <li>update numerous dependencies</li> </ul>"},{"location":"changelog/#v031-2019-07-24","title":"v0.31 (2019-07-24)","text":"<ul> <li>better support for floating point <code>multiple_of</code> values, #652 by @justindujardin</li> <li>fix schema generation for <code>NewType</code> and <code>Literal</code>, #649 by @dmontagu</li> <li>fix <code>alias_generator</code> and field config conflict, #645 by @gmetzker and #658 by @Bobronium</li> <li>more detailed message for <code>EnumError</code>, #673 by @dmontagu</li> <li>add advanced exclude support for <code>dict</code>, <code>json</code> and <code>copy</code>, #648 by @Bobronium</li> <li>fix bug in <code>GenericModel</code> for models with concrete parameterized fields, #672 by @dmontagu</li> <li>add documentation for <code>Literal</code> type, #651 by @dmontagu</li> <li>add <code>Config.keep_untouched</code> for custom descriptors support, #679 by @Bobronium</li> <li>use <code>inspect.cleandoc</code> internally to get model description, #657 by @tiangolo</li> <li>add <code>Color</code> to schema generation, by @euri10</li> <li>add documentation for Literal type, #651 by @dmontagu</li> </ul>"},{"location":"changelog/#v0301-2019-07-15","title":"v0.30.1 (2019-07-15)","text":"<ul> <li>fix so nested classes which inherit and change <code>__init__</code> are correctly processed while still allowing <code>self</code> as a   parameter, #644 by @lnaden and @dgasmith</li> </ul>"},{"location":"changelog/#v030-2019-07-07","title":"v0.30 (2019-07-07)","text":"<ul> <li>enforce single quotes in code, #612 by @samuelcolvin</li> <li>fix infinite recursion with dataclass inheritance and <code>__post_init__</code>, #606 by @Hanaasagi</li> <li>fix default values for <code>GenericModel</code>, #610 by @dmontagu</li> <li>clarify that self-referencing models require Python 3.7+, #616 by @vlcinsky</li> <li>fix truncate for types, #611 by @dmontagu</li> <li>add <code>alias_generator</code> support, #622 by @Bobronium</li> <li>fix unparameterized generic type schema generation, #625 by @dmontagu</li> <li>fix schema generation with multiple/circular references to the same model, #621 by @tiangolo and @wongpat</li> <li>support custom root types, #628 by @koxudaxi</li> <li>support <code>self</code> as a field name in <code>parse_obj</code>, #632 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v029-2019-06-19","title":"v0.29 (2019-06-19)","text":"<ul> <li>support dataclasses.InitVar, #592 by @pfrederiks</li> <li>Updated documentation to elucidate the usage of <code>Union</code> when defining multiple types under an attribute's   annotation and showcase how the type-order can affect marshalling of provided values, #594 by @somada141</li> <li>add <code>conlist</code> type, #583 by @hmvp</li> <li>add support for generics, #595 by @dmontagu</li> </ul>"},{"location":"changelog/#v028-2019-06-06","title":"v0.28 (2019-06-06)","text":"<ul> <li>fix support for JSON Schema generation when using models with circular references in Python 3.7, #572 by @tiangolo</li> <li>support <code>__post_init_post_parse__</code> on dataclasses, #567 by @sevaho</li> <li>allow dumping dataclasses to JSON, #575 by @samuelcolvin and @DanielOberg</li> <li>ORM mode, #562 by @samuelcolvin</li> <li>fix <code>pydantic.compiled</code> on ipython, #573 by @dmontagu and @samuelcolvin</li> <li>add <code>StrictBool</code> type, #579 by @cazgp</li> </ul>"},{"location":"changelog/#v027-2019-05-30","title":"v0.27 (2019-05-30)","text":"<ul> <li>breaking change <code>_pydantic_post_init</code> to execute dataclass' original <code>__post_init__</code> before   validation, #560 by @HeavenVolkoff</li> <li>fix handling of generic types without specified parameters, #550 by @dmontagu</li> <li>breaking change (maybe): this is the first release compiled with cython, see the docs and please   submit an issue if you run into problems</li> </ul>"},{"location":"changelog/#v0270a1-2019-05-26","title":"v0.27.0a1 (2019-05-26)","text":"<ul> <li>fix JSON Schema for <code>list</code>, <code>tuple</code>, and <code>set</code>, #540 by @tiangolo</li> <li>compiling with cython, <code>manylinux</code> binaries, some other performance improvements, #548 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v026-2019-05-22","title":"v0.26 (2019-05-22)","text":"<ul> <li>fix to schema generation for <code>IPvAnyAddress</code>, <code>IPvAnyInterface</code>, <code>IPvAnyNetwork</code> #498 by @pilosus</li> <li>fix variable length tuples support, #495 by @pilosus</li> <li>fix return type hint for <code>create_model</code>, #526 by @dmontagu</li> <li>Breaking Change: fix <code>.dict(skip_keys=True)</code> skipping values set via alias (this involves changing   <code>validate_model()</code> to always returns <code>Tuple[Dict[str, Any], Set[str], Optional[ValidationError]]</code>), #517 by @sommd</li> <li>fix to schema generation for <code>IPv4Address</code>, <code>IPv6Address</code>, <code>IPv4Interface</code>,   <code>IPv6Interface</code>, <code>IPv4Network</code>, <code>IPv6Network</code> #532 by @euri10</li> <li>add <code>Color</code> type, #504 by @pilosus and @samuelcolvin</li> </ul>"},{"location":"changelog/#v025-2019-05-05","title":"v0.25 (2019-05-05)","text":"<ul> <li>Improve documentation on self-referencing models and annotations, #487 by @theenglishway</li> <li>fix <code>.dict()</code> with extra keys, #490 by @JaewonKim</li> <li>support <code>const</code> keyword in <code>Schema</code>, #434 by @Sean1708</li> </ul>"},{"location":"changelog/#v024-2019-04-23","title":"v0.24 (2019-04-23)","text":"<ul> <li>fix handling <code>ForwardRef</code> in sub-types, like <code>Union</code>, #464 by @tiangolo</li> <li>fix secret serialization, #465 by @atheuz</li> <li>Support custom validators for dataclasses, #454 by @primal100</li> <li>fix <code>parse_obj</code> to cope with dict-like objects, #472 by @samuelcolvin</li> <li>fix to schema generation in nested dataclass-based models, #474 by @NoAnyLove</li> <li>fix <code>json</code> for <code>Path</code>, <code>FilePath</code>, and <code>DirectoryPath</code> objects, #473 by @mikegoodspeed</li> </ul>"},{"location":"changelog/#v023-2019-04-04","title":"v0.23 (2019-04-04)","text":"<ul> <li>improve documentation for contributing section, #441 by @pilosus</li> <li>improve README.rst to include essential information about the package, #446 by @pilosus</li> <li><code>IntEnum</code> support, #444 by @potykion</li> <li>fix PyObject callable value, #409 by @pilosus</li> <li>fix <code>black</code> deprecation warnings after update, #451 by @pilosus</li> <li>fix <code>ForwardRef</code> collection bug, #450 by @tigerwings</li> <li>Support specialized <code>ClassVars</code>, #455 by @tyrylu</li> <li>fix JSON serialization for <code>ipaddress</code> types, #333 by @pilosus</li> <li>add <code>SecretStr</code> and <code>SecretBytes</code> types, #452 by @atheuz</li> </ul>"},{"location":"changelog/#v022-2019-03-29","title":"v0.22 (2019-03-29)","text":"<ul> <li>add <code>IPv{4,6,Any}Network</code> and <code>IPv{4,6,Any}Interface</code> types from <code>ipaddress</code> stdlib, #333 by @pilosus</li> <li>add docs for <code>datetime</code> types, #386 by @pilosus</li> <li>fix to schema generation in dataclass-based models, #408 by @pilosus</li> <li>fix path in nested models, #437 by @kataev</li> <li>add <code>Sequence</code> support, #304 by @pilosus</li> </ul>"},{"location":"changelog/#v0210-2019-03-15","title":"v0.21.0 (2019-03-15)","text":"<ul> <li>fix typo in <code>NoneIsNotAllowedError</code> message, #414 by @YaraslauZhylko</li> <li>add <code>IPvAnyAddress</code>, <code>IPv4Address</code> and <code>IPv6Address</code> types, #333 by @pilosus</li> </ul>"},{"location":"changelog/#v0201-2019-02-26","title":"v0.20.1 (2019-02-26)","text":"<ul> <li>fix type hints of <code>parse_obj</code> and similar methods, #405 by @erosennin</li> <li>fix submodel validation, #403 by @samuelcolvin</li> <li>correct type hints for <code>ValidationError.json</code>, #406 by @layday</li> </ul>"},{"location":"changelog/#v0200-2019-02-18","title":"v0.20.0 (2019-02-18)","text":"<ul> <li>fix tests for Python 3.8, #396 by @samuelcolvin</li> <li>Adds fields to the <code>dir</code> method for autocompletion in interactive sessions, #398 by @dgasmith</li> <li>support <code>ForwardRef</code> (and therefore <code>from __future__ import annotations</code>) with dataclasses, #397 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0200a1-2019-02-13","title":"v0.20.0a1 (2019-02-13)","text":"<ul> <li>breaking change (maybe): more sophisticated argument parsing for validators, any subset of   <code>values</code>, <code>config</code> and <code>field</code> is now permitted, eg. <code>(cls, value, field)</code>,   however the variadic key word argument (\"<code>**kwargs</code>\") must be called <code>kwargs</code>, #388 by @samuelcolvin</li> <li>breaking change: Adds <code>skip_defaults</code> argument to <code>BaseModel.dict()</code> to allow skipping of fields that   were not explicitly set, signature of <code>Model.construct()</code> changed, #389 by @dgasmith</li> <li>add <code>py.typed</code> marker file for PEP-561 support, #391 by @je-l</li> <li>Fix <code>extra</code> behaviour for multiple inheritance/mix-ins, #394 by @YaraslauZhylko</li> </ul>"},{"location":"changelog/#v0190-2019-02-04","title":"v0.19.0 (2019-02-04)","text":"<ul> <li>Support <code>Callable</code> type hint, fix #279 by @proofit404</li> <li>Fix schema for fields with <code>validator</code> decorator, fix #375 by @tiangolo</li> <li>Add <code>multiple_of</code> constraint to <code>ConstrainedDecimal</code>, <code>ConstrainedFloat</code>, <code>ConstrainedInt</code>   and their related types <code>condecimal</code>, <code>confloat</code>, and <code>conint</code> #371, thanks @StephenBrown2</li> <li>Deprecated <code>ignore_extra</code> and <code>allow_extra</code> Config fields in favor of <code>extra</code>, #352 by @liiight</li> <li>Add type annotations to all functions, test fully with mypy, #373 by @samuelcolvin</li> <li>fix for 'missing' error with <code>validate_all</code> or <code>validate_always</code>, #381 by @samuelcolvin</li> <li>Change the second/millisecond watershed for date/datetime parsing to <code>2e10</code>, #385 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0182-2019-01-22","title":"v0.18.2 (2019-01-22)","text":"<ul> <li>Fix to schema generation with <code>Optional</code> fields, fix #361 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0181-2019-01-17","title":"v0.18.1 (2019-01-17)","text":"<ul> <li>add <code>ConstrainedBytes</code> and <code>conbytes</code> types, #315 @Gr1N</li> <li>adding <code>MANIFEST.in</code> to include license in package <code>.tar.gz</code>, #358 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0180-2019-01-13","title":"v0.18.0 (2019-01-13)","text":"<ul> <li>breaking change: don't call validators on keys of dictionaries, #254 by @samuelcolvin</li> <li>Fix validators with <code>always=True</code> when the default is <code>None</code> or the type is optional, also prevent   <code>whole</code> validators being called for sub-fields, fix #132 by @samuelcolvin</li> <li>improve documentation for settings priority and allow it to be easily changed, #343 by @samuelcolvin</li> <li>fix <code>ignore_extra=False</code> and <code>allow_population_by_alias=True</code>, fix #257 by @samuelcolvin</li> <li>breaking change: Set <code>BaseConfig</code> attributes <code>min_anystr_length</code> and <code>max_anystr_length</code> to   <code>None</code> by default, fix #349 in #350 by @tiangolo</li> <li>add support for postponed annotations, #348 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0170-2018-12-27","title":"v0.17.0 (2018-12-27)","text":"<ul> <li>fix schema for <code>timedelta</code> as number, #325 by @tiangolo</li> <li>prevent validators being called repeatedly after inheritance, #327 by @samuelcolvin</li> <li>prevent duplicate validator check in ipython, fix #312 by @samuelcolvin</li> <li>add \"Using Pydantic\" section to docs, #323 by @tiangolo &amp; #326 by @samuelcolvin</li> <li>fix schema generation for fields annotated as <code>: dict</code>, <code>: list</code>,   <code>: tuple</code> and <code>: set</code>, #330 &amp; #335 by @nkonin</li> <li>add support for constrained strings as dict keys in schema, #332 by @tiangolo</li> <li>support for passing Config class in dataclasses decorator, #276 by @jarekkar   (breaking change: this supersedes the <code>validate_assignment</code> argument with <code>config</code>)</li> <li>support for nested dataclasses, #334 by @samuelcolvin</li> <li>better errors when getting an <code>ImportError</code> with <code>PyObject</code>, #309 by @samuelcolvin</li> <li>rename <code>get_validators</code> to <code>__get_validators__</code>, deprecation warning on use of old name, #338 by @samuelcolvin</li> <li>support <code>ClassVar</code> by excluding such attributes from fields, #184 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0161-2018-12-10","title":"v0.16.1 (2018-12-10)","text":"<ul> <li>fix <code>create_model</code> to correctly use the passed <code>__config__</code>, #320 by @hugoduncan</li> </ul>"},{"location":"changelog/#v0160-2018-12-03","title":"v0.16.0 (2018-12-03)","text":"<ul> <li>breaking change: refactor schema generation to be compatible with JSON Schema and OpenAPI specs, #308 by @tiangolo</li> <li>add <code>schema</code> to <code>schema</code> module to generate top-level schemas from base models, #308 by @tiangolo</li> <li>add additional fields to <code>Schema</code> class to declare validation for <code>str</code> and numeric values, #311 by @tiangolo</li> <li>rename <code>_schema</code> to <code>schema</code> on fields, #318 by @samuelcolvin</li> <li>add <code>case_insensitive</code> option to <code>BaseSettings</code> <code>Config</code>, #277 by @jasonkuhrt</li> </ul>"},{"location":"changelog/#v0150-2018-11-18","title":"v0.15.0 (2018-11-18)","text":"<ul> <li>move codebase to use black, #287 by @samuelcolvin</li> <li>fix alias use in settings, #286 by @jasonkuhrt and @samuelcolvin</li> <li>fix datetime parsing in <code>parse_date</code>, #298 by @samuelcolvin</li> <li>allow dataclass inheritance, fix #293 by @samuelcolvin</li> <li>fix <code>PyObject = None</code>, fix #305 by @samuelcolvin</li> <li>allow <code>Pattern</code> type, fix #303 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0140-2018-10-02","title":"v0.14.0 (2018-10-02)","text":"<ul> <li>dataclasses decorator, #269 by @Gaunt and @samuelcolvin</li> </ul>"},{"location":"changelog/#v0131-2018-09-21","title":"v0.13.1 (2018-09-21)","text":"<ul> <li>fix issue where int_validator doesn't cast a <code>bool</code> to an <code>int</code> #264 by @nphyatt</li> <li>add deep copy support for <code>BaseModel.copy()</code> #249, @gangefors</li> </ul>"},{"location":"changelog/#v0130-2018-08-25","title":"v0.13.0 (2018-08-25)","text":"<ul> <li>raise an exception if a field's name shadows an existing <code>BaseModel</code> attribute #242</li> <li>add <code>UrlStr</code> and <code>urlstr</code> types #236</li> <li>timedelta json encoding ISO8601 and total seconds, custom json encoders #247, by @cfkanesan and @samuelcolvin</li> <li>allow <code>timedelta</code> objects as values for properties of type <code>timedelta</code> (matches <code>datetime</code> etc. behavior) #247</li> </ul>"},{"location":"changelog/#v0121-2018-07-31","title":"v0.12.1 (2018-07-31)","text":"<ul> <li>fix schema generation for fields defined using <code>typing.Any</code> #237</li> </ul>"},{"location":"changelog/#v0120-2018-07-31","title":"v0.12.0 (2018-07-31)","text":"<ul> <li>add <code>by_alias</code> argument in <code>.dict()</code> and <code>.json()</code> model methods #205</li> <li>add Json type support #214</li> <li>support tuples #227</li> <li>major improvements and changes to schema #213</li> </ul>"},{"location":"changelog/#v0112-2018-07-05","title":"v0.11.2 (2018-07-05)","text":"<ul> <li>add <code>NewType</code> support #115</li> <li>fix <code>list</code>, <code>set</code> &amp; <code>tuple</code> validation #225</li> <li>separate out <code>validate_model</code> method, allow errors to be returned along with valid values #221</li> </ul>"},{"location":"changelog/#v0111-2018-07-02","title":"v0.11.1 (2018-07-02)","text":"<ul> <li>support Python 3.7 #216, thanks @layday</li> <li>Allow arbitrary types in model #209, thanks @oldPadavan</li> </ul>"},{"location":"changelog/#v0110-2018-06-28","title":"v0.11.0 (2018-06-28)","text":"<ul> <li>make <code>list</code>, <code>tuple</code> and <code>set</code> types stricter #86</li> <li>breaking change: remove msgpack parsing #201</li> <li>add <code>FilePath</code> and <code>DirectoryPath</code> types #10</li> <li>model schema generation #190</li> <li>JSON serialization of models and schemas #133</li> </ul>"},{"location":"changelog/#v0100-2018-06-11","title":"v0.10.0 (2018-06-11)","text":"<ul> <li>add <code>Config.allow_population_by_alias</code> #160, thanks @bendemaree</li> <li>breaking change: new errors format #179, thanks @Gr1N</li> <li>breaking change: removed <code>Config.min_number_size</code> and <code>Config.max_number_size</code> #183, thanks @Gr1N</li> <li>breaking change: correct behaviour of <code>lt</code> and <code>gt</code> arguments to <code>conint</code> etc. #188   for the old behaviour use <code>le</code> and <code>ge</code> #194, thanks @jaheba</li> <li>added error context and ability to redefine error message templates using <code>Config.error_msg_templates</code> #183,   thanks @Gr1N</li> <li>fix typo in validator exception #150</li> <li>copy defaults to model values, so different models don't share objects #154</li> </ul>"},{"location":"changelog/#v091-2018-05-10","title":"v0.9.1 (2018-05-10)","text":"<ul> <li>allow custom <code>get_field_config</code> on config classes #159</li> <li>add <code>UUID1</code>, <code>UUID3</code>, <code>UUID4</code> and <code>UUID5</code> types #167, thanks @Gr1N</li> <li>modify some inconsistent docstrings and annotations #173, thanks @YannLuo</li> <li>fix type annotations for exotic types #171, thanks @Gr1N</li> <li>re-use type validators in exotic types #171</li> <li>scheduled monthly requirements updates #168</li> <li>add <code>Decimal</code>, <code>ConstrainedDecimal</code> and <code>condecimal</code> types #170, thanks @Gr1N</li> </ul>"},{"location":"changelog/#v090-2018-04-28","title":"v0.9.0 (2018-04-28)","text":"<ul> <li>tweak email-validator import error message #145</li> <li>fix parse error of <code>parse_date()</code> and <code>parse_datetime()</code> when input is 0 #144, thanks @YannLuo</li> <li>add <code>Config.anystr_strip_whitespace</code> and <code>strip_whitespace</code> kwarg to <code>constr</code>,   by default values is <code>False</code> #163, thanks @Gr1N</li> <li>add <code>ConstrainedFloat</code>, <code>confloat</code>, <code>PositiveFloat</code> and <code>NegativeFloat</code> types #166, thanks @Gr1N</li> </ul>"},{"location":"changelog/#v080-2018-03-25","title":"v0.8.0 (2018-03-25)","text":"<ul> <li>fix type annotation for <code>inherit_config</code> #139</li> <li>breaking change: check for invalid field names in validators #140</li> <li>validate attributes of parent models #141</li> <li>breaking change: email validation now uses   email-validator #142</li> </ul>"},{"location":"changelog/#v071-2018-02-07","title":"v0.7.1 (2018-02-07)","text":"<ul> <li>fix bug with <code>create_model</code> modifying the base class</li> </ul>"},{"location":"changelog/#v070-2018-02-06","title":"v0.7.0 (2018-02-06)","text":"<ul> <li>added compatibility with abstract base classes (ABCs) #123</li> <li>add <code>create_model</code> method #113 #125</li> <li>breaking change: rename <code>.config</code> to <code>.__config__</code> on a model</li> <li>breaking change: remove deprecated <code>.values()</code> on a model, use <code>.dict()</code> instead</li> <li>remove use of <code>OrderedDict</code> and use simple dict #126</li> <li>add <code>Config.use_enum_values</code> #127</li> <li>add wildcard validators of the form <code>@validate('*')</code> #128</li> </ul>"},{"location":"changelog/#v064-2018-02-01","title":"v0.6.4 (2018-02-01)","text":"<ul> <li>allow Python date and times objects #122</li> </ul>"},{"location":"changelog/#v063-2017-11-26","title":"v0.6.3 (2017-11-26)","text":"<ul> <li>fix direct install without <code>README.rst</code> present</li> </ul>"},{"location":"changelog/#v062-2017-11-13","title":"v0.6.2 (2017-11-13)","text":"<ul> <li>errors for invalid validator use</li> <li>safer check for complex models in <code>Settings</code></li> </ul>"},{"location":"changelog/#v061-2017-11-08","title":"v0.6.1 (2017-11-08)","text":"<ul> <li>prevent duplicate validators, #101</li> <li>add <code>always</code> kwarg to validators, #102</li> </ul>"},{"location":"changelog/#v060-2017-11-07","title":"v0.6.0 (2017-11-07)","text":"<ul> <li>assignment validation #94, thanks petroswork!</li> <li>JSON in environment variables for complex types, #96</li> <li>add <code>validator</code> decorators for complex validation, #97</li> <li>depreciate <code>values(...)</code> and replace with <code>.dict(...)</code>, #99</li> </ul>"},{"location":"changelog/#v050-2017-10-23","title":"v0.5.0 (2017-10-23)","text":"<ul> <li>add <code>UUID</code> validation #89</li> <li>remove <code>index</code> and <code>track</code> from error object (json) if they're null #90</li> <li>improve the error text when a list is provided rather than a dict #90</li> <li>add benchmarks table to docs #91</li> </ul>"},{"location":"changelog/#v040-2017-07-08","title":"v0.4.0 (2017-07-08)","text":"<ul> <li>show length in string validation error</li> <li>fix aliases in config during inheritance #55</li> <li>simplify error display</li> <li>use unicode ellipsis in <code>truncate</code></li> <li>add <code>parse_obj</code>, <code>parse_raw</code> and <code>parse_file</code> helper functions #58</li> <li>switch annotation only fields to come first in fields list not last</li> </ul>"},{"location":"changelog/#v030-2017-06-21","title":"v0.3.0 (2017-06-21)","text":"<ul> <li>immutable models via <code>config.allow_mutation = False</code>, associated cleanup and performance improvement #44</li> <li>immutable helper methods <code>construct()</code> and <code>copy()</code> #53</li> <li>allow pickling of models #53</li> <li><code>setattr</code> is removed as <code>__setattr__</code> is now intelligent #44</li> <li><code>raise_exception</code> removed, Models now always raise exceptions #44</li> <li>instance method validators removed</li> <li>django-restful-framework benchmarks added #47</li> <li>fix inheritance bug #49</li> <li>make str type stricter so list, dict etc are not coerced to strings. #52</li> <li>add <code>StrictStr</code> which only always strings as input #52</li> </ul>"},{"location":"changelog/#v021-2017-06-07","title":"v0.2.1 (2017-06-07)","text":"<ul> <li>pypi and travis together messed up the deploy of <code>v0.2</code> this should fix it</li> </ul>"},{"location":"changelog/#v020-2017-06-07","title":"v0.2.0 (2017-06-07)","text":"<ul> <li>breaking change: <code>values()</code> on a model is now a method not a property,   takes <code>include</code> and <code>exclude</code> arguments</li> <li>allow annotation only fields to support mypy</li> <li>add pretty <code>to_string(pretty=True)</code> method for models</li> </ul>"},{"location":"changelog/#v010-2017-06-03","title":"v0.1.0 (2017-06-03)","text":"<ul> <li>add docs</li> <li>add history</li> </ul>"},{"location":"contributing/","title":"Contribute","text":"<p>We'd love you to contribute to Pydantic!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as discussions or issues. However, to report a security vulnerability, please see our security policy.</p> <p>To make it as simple as possible for us to help you, please include the output of the following call in your issue:</p> <p><pre><code>python -c \"import pydantic.utils; print(pydantic.utils.version_info())\"\n</code></pre> If you're using Pydantic prior to v1.3 (when <code>version_info()</code> was added), please manually include OS, Python version and pydantic version.</p> <p>Please try to always include the above unless you're unable to install Pydantic or know it's not relevant to your question or feature request.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>It should be extremely simple to get started and create a Pull Request. Pydantic is released regularly so you should see your improvements release in a matter of days or weeks.</p> <p>Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request.</p> <p>Pydantic V1 is in maintenance mode</p> <p>Pydantic v1 is in maintenance mode, meaning that only bug fixes and security fixes will be accepted. New features should be targeted at Pydantic v2.</p> <p>To submit a fix to Pydantic v1, use the <code>1.10.X-fixes</code> branch.</p> <p>If you're looking for something to get your teeth into, check out the \"help wanted\" label on github.</p> <p>To make contributing as easy and fast as possible, you'll want to run tests and linting locally. Luckily, Pydantic has few dependencies, doesn't require compiling and tests don't need access to databases, etc. Because of this, setting up and running the tests should be very simple.</p> <p>Tip</p> <p>tl;dr: use <code>make format</code> to fix formatting, <code>make</code> to run tests and linting &amp; <code>make docs</code> to build the docs.</p>"},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<p>You'll need the following prerequisites:</p> <ul> <li>Any Python version between Python 3.7 and 3.11</li> <li>virtualenv or other virtual environment tool</li> <li>git</li> <li>make</li> <li>PDM</li> </ul>"},{"location":"contributing/#installation-and-setup","title":"Installation and setup","text":"<p>Fork the repository on GitHub and clone your fork locally.</p> <pre><code># Clone your fork and cd into the repo directory\ngit clone git@github.com:&lt;your username&gt;/pydantic.git\ncd pydantic\n\n# Install PDM and pre-commit\n# We use pipx here, for other options see:\n# https://pdm.fming.dev/latest/#installation\n# https://pre-commit.com/#install\n# To get pipx itself:\n# https://pypa.github.io/pipx/\npipx install pdm pre-commit\n\n# Install pydantic, dependencies, test dependencies and doc dependencies\nmake install\n</code></pre>"},{"location":"contributing/#check-out-a-new-branch-and-make-your-changes","title":"Check out a new branch and make your changes","text":"<p>Create a new branch for your changes.</p> <pre><code># Checkout a new branch and make your changes\ngit checkout -b my-new-feature-branch\n# Make your changes...\n</code></pre>"},{"location":"contributing/#run-tests-and-linting","title":"Run tests and linting","text":"<p>Run tests and linting locally to make sure everything is working as expected.</p> <pre><code># Run automated code formatting and linting\nmake format\n# Pydantic uses black and ruff\n# (https://github.com/ambv/black, https://github.com/charliermarsh/ruff)\n\n# Run tests and linting\nmake\n# There are a few sub-commands in Makefile like `test`, `testcov` and `lint`\n# which you might want to use, but generally just `make` should be all you need.\n# You can run `make help` to see more options.\n</code></pre>"},{"location":"contributing/#build-documentation","title":"Build documentation","text":"<p>If you've made any changes to the documentation (including changes to function signatures, class definitions, or docstrings that will appear in the API documentation), make sure it builds successfully.</p> <pre><code># Build documentation\nmake docs\n# If you have changed the documentation, make sure it builds successfully.\n# You can also use `make docs-serve` to serve the documentation at localhost:8000\n</code></pre>"},{"location":"contributing/#commit-and-push-your-changes","title":"Commit and push your changes","text":"<p>Commit your changes, push your branch to GitHub, and create a pull request.</p> <p>Please follow the pull request template and fill in as much information as possible. Link to any relevant issues and include a description of your changes.</p> <p>When your pull request is ready for review, add a comment with the message \"please review\" and we'll take a look as soon as we can.</p>"},{"location":"contributing/#code-style-and-requirements","title":"Code style and requirements","text":"<p>TODO</p>"},{"location":"contributing/#documentation-style","title":"Documentation style","text":"<p>Documentation is written in Markdown and built using Material for MkDocs. API documentation is build from docstrings using mkdocstrings.</p>"},{"location":"contributing/#code-documentation","title":"Code documentation","text":"<p>When contributing to Pydantic, please make sure that all code is well documented. The following should be documented using properly formatted docstrings:</p> <ul> <li>Modules</li> <li>Class definitions</li> <li>Function definitions</li> <li>Module-level variables</li> </ul> <p>Pydantic uses Google-style docstrings formatted according to PEP 257 guidelines. (See Example Google Style Python Docstrings for further examples.)</p> <p>pydocstyle is used for linting docstrings. You can run <code>make format</code> to check your docstrings.</p> <p>Where this is a conflict between Google-style docstrings and pydocstyle linting, follow the pydocstyle linting hints.</p> <p>Class attributes and function arguments should be documented in the format \"name: description.\" When applicable, a return type should be documented with just a description. Types are inferred from the signature.</p> <pre><code>class Foo:\n\"\"\"A class docstring.\n\n    Attributes:\n        bar: A description of bar. Defaults to \"bar\".\n    \"\"\"\n\n    bar: str = 'bar'\n</code></pre> <pre><code>def bar(self, baz: int) -&gt; str:\n\"\"\"A function docstring.\n\n    Args:\n        baz: A description of `baz`.\n\n    Returns:\n        A description of the return value.\n    \"\"\"\n\n    return 'bar'\n</code></pre> <p>You may include example code in docstrings. This code should be complete, self-contained, and runnable. Docstring examples are tested using doctest, so make sure they are correct and complete. See FieldInfo.from_annotated_attribute() for an example.</p> <p>Class and instance attributes</p> <p>Class attributes should be documented in the class docstring.</p> <p>Instance attributes should be documented as \"Args\" in the <code>__init__</code> docstring.</p>"},{"location":"contributing/#guide-documentation","title":"Guide documentation","text":"<p>In general, documentation should be written in a friendly, approachable style. It should be easy to read and understand, and should be as concise as possible while still being complete.</p> <p>Code examples are encouraged, but should be kept short and simple. However, every code example should be complete, self-contained, and runnable. (If you're not sure how to do this, ask for help!) We prefer print output to naked asserts, but if you're testing something that doesn't have a useful print output, asserts are fine.</p> <p>Pydantic's test coverage will test all code examples in the documentation, so it's important that they are correct and complete. When adding a new code example, use <code>pytest --update-examples</code> to update the output and create Python version-specific examples when appropriate.</p> <pre><code># Run tests and update code examples\npytest --update-examples\n</code></pre>"},{"location":"install/","title":"Installation","text":"<p>Installation is as simple as:</p> <pre><code>pip install pydantic\n</code></pre> <p>Pydantic has a few dependencies:</p> <ul> <li><code>pydantic-core</code>: Core validation logic for pydantic written in rust.</li> <li><code>typing-extensions</code>: Backport of the standard library <code>typing</code> module.</li> <li><code>annotated-types</code>: Reusable constraint types to use with <code>typing.Annotated</code>.</li> </ul> <p>If you've got Python 3.7+ and <code>pip</code> installed, you're good to go.</p> <p>Pydantic is also available on conda under the conda-forge channel:</p> <pre><code>conda install pydantic -c conda-forge\n</code></pre>"},{"location":"install/#optional-dependencies","title":"Optional dependencies","text":"<p>Pydantic has the following optional dependencies:</p> <ul> <li>If you require email validation, you can add email-validator.</li> </ul> <p>To install optional dependencies along with Pydantic:</p> <pre><code>pip install pydantic[email]\n</code></pre> <p>Of course, you can also install requirements manually with <code>pip install email-validator</code>.</p>"},{"location":"install/#install-from-repository","title":"Install from repository","text":"<p>And if you prefer to install Pydantic directly from the repository:</p> <pre><code>pip install git+https://github.com/pydantic/pydantic@main#egg=pydantic\n# or with extras\npip install git+https://github.com/pydantic/pydantic@main#egg=pydantic[email]\n</code></pre>"},{"location":"migration/","title":"Migration Guide","text":"<p>The Pydantic V2 beta introduces a number of changes to the API, including some breaking changes.</p> <p>We believe Pydantic V2 is ready for your production applications. This page provides a guide highlighting the most important changes to help you migrate your code from Pydantic V1 to Pydantic V2.</p>"},{"location":"migration/#install-pydantic-v2-beta","title":"Install Pydantic V2 beta","text":"<p>Your feedback will be a critical part of ensuring that we have made the right tradeoffs with the API changes in Pydantic V2.</p> <p>To get started with the Pydantic V2 beta, install it from PyPI. We recommend using a virtual environment to isolate your testing environment:</p> <pre><code>pip install --pre -U \"pydantic&gt;=2.0b3\"\n</code></pre> <p>If you do encounter any issues, please create an issue in GitHub using the <code>bug V2</code> label. This will help us to actively monitor and track errors, and to continue to improve the library's performance.</p>"},{"location":"migration/#migration-guide","title":"Migration guide","text":""},{"location":"migration/#changes-to-pydanticbasemodel","title":"Changes to <code>pydantic.BaseModel</code>","text":"<p>Various method names have been changed; all non-deprecated <code>BaseModel</code> methods now have names matching either the format <code>model_.*</code> or <code>__.*pydantic.*__</code>. Where possible, we have retained the deprecated methods with their old names to help ease migration, but calling them will emit <code>DeprecationWarning</code>s.</p> Pydantic V1 Pydantic V2 <code>__fields__</code> <code>model_fields</code> <code>__private_attributes__</code> <code>__pydantic_private__</code> <code>__validators__</code> <code>__pydantic_validator__</code> <code>construct()</code> <code>model_construct()</code> <code>copy()</code> <code>model_copy()</code> <code>dict()</code> <code>model_dump()</code> <code>json_schema()</code> <code>model_json_schema()</code> <code>json()</code> <code>model_dump_json()</code> <code>parse_obj()</code> <code>model_validate()</code> <ul> <li>Some of the built-in data-loading functionality has been slated for removal. In particular,     <code>parse_raw</code> and <code>parse_file</code> are now deprecated. In Pydantic V2, <code>model_validate_json</code> works like <code>parse_raw</code>. Otherwise, you should load the data and then pass it to <code>model_validate</code>.</li> <li>The <code>from_orm</code> method has been deprecated; you can now just use <code>model_validate</code> (equivalent to <code>parse_obj</code> from   Pydantic V1) to achieve something similar, as long as you've set <code>from_attributes=True</code> in the model config.</li> <li>The <code>__eq__</code> method has changed for models.<ul> <li>Models can only be equal to other <code>BaseModel</code> instances.</li> <li>For two model instances to be equal, they must have the same:<ul> <li>Type (or, in the case of generic models, non-parametrized generic origin type)</li> <li>Field values</li> <li>Extra values (only relevant when <code>model_config['extra'] == 'allow'</code>)</li> <li>Private attribute values; models with different values of private attributes are no longer equal.</li> <li>Models are no longer equal to the dicts containing their data.</li> <li>Non-generic models of different types are never equal.</li> <li>Generic models with different origin types are never equal. We don't require exact type equality so that,     for example, instances of <code>MyGenericModel[Any]</code> could be equal to instances of <code>MyGenericModel[int]</code>.</li> </ul> </li> </ul> </li> <li>We have replaced the use of the <code>__root__</code> field to specify a \"custom root model\" with a new type called     <code>RootModel</code> which is intended to replace the functionality of     using a field called <code>__root__</code> in Pydantic V1.</li> <li>We have significantly expanded Pydantic's capabilities related to customizing serialization. In particular, we have     added the <code>@field_serializer</code>,     <code>@model_serializer</code>, and     <code>@computed_field</code> decorators, which each address various     shortcomings from Pydantic V1.<ul> <li>See Custom serializers for the usage docs of these new decorators.</li> <li>Due to performance overhead and implementation complexity, we have now removed support for specifying     <code>json_encoders</code> in the model config. This functionality was originally added for the purpose of achieving custom     serialization logic, and we think the new serialization decorators are a better choice in most common scenarios.     However, if your usage of <code>json_encoders</code> is not compatible with the new serialization decorators,     please create a GitHub issue letting us know. See Custom data types for further     details.</li> </ul> </li> <li>We have changed the behavior related to serializing subclasses of models when they occur as nested fields in a parent   model. In V1, we would always include all fields from the subclass instance. In V2, when we dump a model, we only   include the fields that are defined on the annotated type of the field. This helps prevent some accidental security   bugs. You can read more about this (including how to opt out of this behavior) in the   Subclass instances for fields of BaseModel, dataclasses, TypedDict   section of the model exporting docs.</li> <li><code>GetterDict</code> has been removed as it was just an implementation detail of <code>orm_mode</code>, which has been removed.</li> </ul>"},{"location":"migration/#changes-to-pydanticgenericsgenericmodel","title":"Changes to <code>pydantic.generics.GenericModel</code>","text":"<p>The <code>pydantic.generics.GenericModel</code> class is no longer necessary, and has been removed. Instead, you can now create generic <code>BaseModel</code> subclasses by just adding <code>Generic</code> as a parent class on a <code>BaseModel</code> subclass directly. This looks like <code>class MyGenericModel(BaseModel, Generic[T]): ...</code>.</p> <p>While it may not raise an error, we strongly advise against using parametrized generics in <code>isinstance</code> checks.</p> <ul> <li>For example, you should not do <code>isinstance(my_model, MyGenericModel[int])</code>.     However, it is fine to do <code>isinstance(my_model, MyGenericModel)</code>. (Note that for standard generics, it would raise     an error to do a subclass check with a parameterized generic.)</li> <li>If you need to perform <code>isinstance</code> checks against parametrized generics, you can do this by subclassing the     parametrized generic class. This looks like <code>class MyIntModel(MyGenericModel[int]): ...</code> and     <code>isinstance(my_model, MyIntModel)</code>.</li> </ul> <p>Find more information in the Generic models documentation.</p>"},{"location":"migration/#changes-to-pydanticfield","title":"Changes to <code>pydantic.Field</code>","text":"<p><code>Field</code> no longer supports arbitrary keyword arguments to be added to the JSON schema. Instead, any extra data you want to add to the JSON schema should be passed as a dictionary to the <code>json_schema_extra</code> keyword argument.</p> <p>The following properties have been removed from or changed in <code>Field</code>:</p> <ul> <li><code>const</code></li> <li><code>min_items</code> (use <code>min_length</code> instead)</li> <li><code>max_items</code> (use <code>max_length</code> instead)</li> <li><code>unique_items</code></li> <li><code>allow_mutation</code> (use <code>frozen</code> instead)</li> <li> <p><code>regex</code> (use <code>pattern</code> instead)</p> </li> <li> <p>[TODO: Need to document any other backwards-incompatible changes to <code>pydantic.Field</code>]</p> </li> </ul>"},{"location":"migration/#changes-to-dataclasses","title":"Changes to dataclasses","text":"<ul> <li>When used as fields, dataclasses (Pydantic or vanilla) no longer accept tuples as validation inputs; dicts should be   used instead.</li> <li>The <code>__post_init__</code> in Pydantic dataclasses will now be called after validation, rather than before.<ul> <li>As a result, the <code>__post_init_post_parse__</code> method would have become redundant, so has been removed.</li> </ul> </li> <li>We no longer support <code>extra='allow'</code> for Pydantic dataclasses, where extra fields passed to the initializer would be   stored as extra attributes on the dataclass. <code>extra='ignore'</code> is still supported for the purpose of ignoring   unexpected fields while parsing data, they just won't be stored on the instance.</li> <li>Pydantic dataclasses no longer have an attribute <code>__pydantic_model__</code>, and no longer use an underlying <code>BaseModel</code>   to perform validation or provide other functionality.<ul> <li>To perform validation, generate a JSON schema, or make use of   any other functionality that may have required <code>__pydantic_model__</code> in V1, you should now wrap the dataclass   with a <code>TypeAdapter</code> (discussed more below) and make use of its methods.</li> <li>[TODO: Add link to TypeAdapter documentation. You can find example usage in <code>tests/test_type_adapter.py</code>.]</li> </ul> </li> <li>In Pydantic V1, if you used a vanilla (i.e., non-Pydantic) dataclass as a field, the config of the parent type would   be used as though it was the config for the dataclass itself as well. In Pydantic V2, this is no longer the case.<ul> <li>[TODO: Need to specify how to override the config used for vanilla dataclass; possibly need to add functionality?]</li> </ul> </li> </ul>"},{"location":"migration/#changes-to-config","title":"Changes to config","text":"<ul> <li> <p>In Pydantic V2, to specify config on a model, you should set a class attribute called <code>model_config</code> to be a dict   with the key/value pairs you want to be used as the config. The Pydantic V1 behavior to create a class called <code>Config</code>   in the namespace of the parent <code>BaseModel</code> subclass is now deprecated.</p> </li> <li> <p>The following config settings have been removed:</p> <ul> <li><code>allow_mutation</code> \u2014 this has been removed. You should be able to use frozen equivalently (inverse of current use).</li> <li><code>error_msg_templates</code>.</li> <li><code>fields</code> \u2014 this was the source of various bugs, so has been removed.   You should be able to use <code>Annotated</code> on fields to modify them as desired.</li> <li><code>getter_dict</code> \u2014 <code>orm_mode</code> has been removed, and this implementation detail is no longer necessary.</li> <li><code>smart_union</code>.</li> <li><code>underscore_attrs_are_private</code> \u2014 the Pydantic V2 behavior is now the same as if this was always set   to <code>True</code> in Pydantic V1.</li> </ul> </li> <li> <p>The following config settings have been renamed:</p> <ul> <li><code>allow_population_by_field_name</code> \u2192 <code>populate_by_name</code></li> <li><code>anystr_lower</code> \u2192 <code>str_to_lower</code></li> <li><code>anystr_strip_whitespace</code> \u2192 <code>str_strip_whitespace</code></li> <li><code>anystr_upper</code> \u2192 <code>str_to_upper</code></li> <li><code>keep_untouched</code> \u2192 <code>ignored_types</code></li> <li><code>max_anystr_length</code> \u2192 <code>str_max_length</code></li> <li><code>min_anystr_length</code> \u2192 <code>str_min_length</code></li> <li><code>orm_mode</code> \u2192 <code>from_attributes</code></li> <li><code>schema_extra</code> \u2192 <code>json_schema_extra</code></li> <li><code>validate_all</code> \u2192 <code>validate_default</code></li> </ul> </li> </ul> <p>See Model Config for more details.</p>"},{"location":"migration/#changes-to-validators","title":"Changes to validators","text":""},{"location":"migration/#validator-and-root_validator-are-deprecated","title":"<code>@validator</code> and <code>@root_validator</code> are deprecated","text":"<ul> <li><code>@validator</code> has been deprecated, and should be replaced with <code>@field_validator</code>, which provides various new features     and improvements.<ul> <li>The new <code>@field_validator</code> decorator does not have the <code>each_item</code> keyword argument; validators you want to     apply to items within a generic container should be added by annotating the type argument. See     validators in Annotated metadata for details.     This looks like <code>List[Annotated[int, Field(ge=0)]]</code></li> <li>Even if you keep using the deprecated <code>@validator</code> decorator, you can no longer add the <code>field</code> or     <code>config</code> arguments to the signature of validator functions. If you need access to these, you'll need     to migrate to <code>@field_validator</code> \u2014 see the next section     for more details.</li> <li>If you use the <code>always=True</code> keyword argument to a validator function, note that standard validators     for the annotated type will also be applied even to defaults, not just the custom validators. For     example, despite the fact that the validator below will never error, the following code raises a <code>ValidationError</code>:</li> </ul> </li> </ul> <pre><code>from pydantic import BaseModel, validator\n\n\nclass Model(BaseModel):\n    x: str = 1\n\n    @validator('x', always=True)\n    @classmethod\n    def validate_x(cls, v):\n        return v\n\n\nModel()\n</code></pre> <ul> <li><code>@root_validator</code> has been deprecated, and should be replaced with     <code>@model_validator</code>, which also provides new features and improvements.<ul> <li>Under some circumstances (such as assignment when <code>model_config['validate_assignment'] is True</code>),     the <code>@model_validator</code> decorator will receive an instance of the model, not a dict of values. You may     need to be careful to handle this case.</li> <li>Even if you keep using the deprecated <code>@root_validator</code> decorator, due to refactors in validation logic,     you can no longer run with <code>skip_on_failure=False</code> (which is the default value of this keyword argument,     so must be set explicitly to <code>True</code>).</li> </ul> </li> </ul>"},{"location":"migration/#changes-to-validators-allowed-signatures","title":"Changes to <code>@validator</code>'s allowed signatures","text":"<p>In Pydantic V1, functions wrapped by <code>@validator</code> could receive keyword arguments with metadata about what was being validated. Some of these arguments have been removed from <code>@field_validator</code> in Pydantic V2:</p> <ul> <li><code>config</code>: Pydantic V2's config is now a dictionary instead of a class, which means this argument is no longer     backwards compatible. If you need to access the configuration you should migrate to <code>@field_validator</code> and use     <code>info.config</code>.</li> <li><code>field</code>: this argument used to be a <code>ModelField</code> object, which was a quasi-internal class that no longer exists     in Pydantic V2. Most of this information can still be accessed by using the field name from <code>info.field_name</code>     to index into <code>cls.model_fields</code></li> </ul> <pre><code>from pydantic import BaseModel, FieldValidationInfo, field_validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    def val_x(cls, v: int, info: FieldValidationInfo) -&gt; int:\n        assert info.config is not None\n        print(info.config.get('title'))\n        #&gt; Model\n        print(cls.model_fields[info.field_name].is_required())\n        #&gt; True\n        return v\n\n\nModel(x=1)\n</code></pre>"},{"location":"migration/#typeerror-is-no-longer-converted-to-validationerror-in-validators","title":"<code>TypeError</code> is no longer converted to <code>ValidationError</code> in validators","text":"<p>Previously, when raising a <code>TypeError</code> within a validator function, that error would be wrapped into a <code>ValidationError</code> and, in some cases (such as with FastAPI), these errors might be displayed to end users. This led to a variety of undesirable behavior \u2014 for example, calling a function with the wrong signature might produce a user-facing <code>ValidationError</code>.</p> <p>However, in Pydantic V2, when a <code>TypeError</code> is raised in a validator, it is no longer converted into a <code>ValidationError</code>:</p> <pre><code>import pytest\n\nfrom pydantic import BaseModel, field_validator  # or validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    def val_x(cls, v: int) -&gt; int:\n        return str.lower(v)  # raises a TypeError\n\n\nwith pytest.raises(TypeError):\n    Model(x=1)\n</code></pre> <p>This applies to all validation decorators.</p>"},{"location":"migration/#validator-behavior-changes","title":"Validator behavior changes","text":"<p>Pydantic V2 includes some changes to type coercion. For example:</p> <ul> <li>int, float, and decimal values are no longer coerced to strings.</li> <li>iterable of pairs is no longer coerced to a dict.</li> </ul> <p>See the Conversion table for details on Pydantic V2 type coercion defaults.</p>"},{"location":"migration/#the-allow_reuse-keyword-argument-is-no-longer-necessary","title":"The <code>allow_reuse</code> keyword argument is no longer necessary","text":"<p>Previously, Pydantic tracked \"reused\" functions in decorators as this was a common source of mistakes. We did this by comparing the function's fully qualified name (module name + function name), which could result in false positives. The <code>allow_reuse</code> keyword argument could be used to disable this when it was intentional.</p> <p>Our approach to detecting repeatedly defined functions has been overhauled to only error for redefinition within a single class, reducing false positives and bringing the behavior more in line with the errors that type checkers and linters would give for defining a method with the same name multiple times in a single class definition.</p> <p>In nearly all cases, if you were using <code>allow_reuse=True</code>, you should be able to simply delete that keyword argument and have things keep working as expected.</p>"},{"location":"migration/#validate_arguments-has-been-renamed-to-validate_call","title":"<code>@validate_arguments</code> has been renamed to <code>@validate_call</code>","text":"<p>In Pydantic V2, the <code>@validate_arguments</code> decorator has been renamed to <code>@validate_call</code>.</p> <p>In Pydantic V1, the decorated function had various attributes added, such as <code>raw_function</code>, and <code>validate</code> (which could be used to validate arguments without actually calling the decorated function). Due to limited use of these attributes, and performance-oriented changes in implementation, we have not preserved this functionality in <code>@validate_call</code>.</p>"},{"location":"migration/#input-types-are-not-preserved","title":"Input types are not preserved","text":"<p>In Pydantic V1 we made great efforts to preserve the types of all field inputs for generic collections when they were proper subtypes of the field annotations. For example, given the annotation <code>Mapping[str, int]</code> if you passed in a <code>collection.Counter()</code> you'd get a <code>collection.Counter()</code> as the value.</p> <p>Supporting this behavior in V2 would have negative performance implications for the general case (we'd have to check types every time) and would add a lot of complexity to validation. Further, even in V1 this behavior was inconsistent and partially broken: it did not work for many types (<code>str</code>, <code>UUID</code>, etc.), and for generic collections it's impossible to re-build the original input correctly without a lot of special casing (consider <code>ChainMap</code>; rebuilding the input is necessary because we need to replace values after validation, e.g. if coercing strings to ints).</p> <p>In Pydantic V2 we no longer attempt to preserve the input type in all cases; instead, we only promise that the output type will match the type annotations.</p> <p>Going back to the <code>Mapping</code> example, we promise the output will be a valid <code>Mapping</code>, and in practice it will be a plain <code>dict</code>:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Mapping\n\nfrom pydantic import TypeAdapter\n\n\nclass MyDict(dict):\n    pass\n\n\nta = TypeAdapter(Mapping[str, int])\nv = ta.validate_python(MyDict())\nprint(type(v))\n#&gt; &lt;class 'dict'&gt;\n</code></pre> <pre><code>from collections.abc import Mapping\n\nfrom pydantic import TypeAdapter\n\n\nclass MyDict(dict):\n    pass\n\n\nta = TypeAdapter(Mapping[str, int])\nv = ta.validate_python(MyDict())\nprint(type(v))\n#&gt; &lt;class 'dict'&gt;\n</code></pre> <p>If you want the output type to be a specific type, consider annotating it as such or implementing a custom validator:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, Mapping, TypeVar\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef restore_input_type(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n    return type(value)(handler(value))\n\n\nT = TypeVar('T')\nPreserveType = Annotated[T, WrapValidator(restore_input_type)]\n\n\nta = TypeAdapter(PreserveType[Mapping[str, int]])\n\n\nclass MyDict(dict):\n    pass\n\n\nv = ta.validate_python(MyDict())\nassert type(v) is MyDict\n</code></pre> <pre><code>from typing import Any, TypeVar\nfrom collections.abc import Mapping\n\nfrom typing import Annotated\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef restore_input_type(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n    return type(value)(handler(value))\n\n\nT = TypeVar('T')\nPreserveType = Annotated[T, WrapValidator(restore_input_type)]\n\n\nta = TypeAdapter(PreserveType[Mapping[str, int]])\n\n\nclass MyDict(dict):\n    pass\n\n\nv = ta.validate_python(MyDict())\nassert type(v) is MyDict\n</code></pre> <p>While we don't promise to preserve input types everywhere, we do preserve them for subclasses of <code>BaseModel</code>, and for dataclasses:</p> <pre><code>import pydantic.dataclasses\nfrom pydantic import BaseModel\n\n\nclass InnerModel(BaseModel):\n    x: int\n\n\nclass OuterModel(BaseModel):\n    inner: InnerModel\n\n\nclass SubInnerModel(InnerModel):\n    y: int\n\n\nm = OuterModel(inner=SubInnerModel(x=1, y=2))\nprint(m)\n#&gt; inner=SubInnerModel(x=1, y=2)\n\n\n@pydantic.dataclasses.dataclass\nclass InnerDataclass:\n    x: int\n\n\n@pydantic.dataclasses.dataclass\nclass SubInnerDataclass(InnerDataclass):\n    y: int\n\n\n@pydantic.dataclasses.dataclass\nclass OuterDataclass:\n    inner: InnerDataclass\n\n\nd = OuterDataclass(inner=SubInnerDataclass(x=1, y=2))\nprint(d)\n#&gt; OuterDataclass(inner=SubInnerDataclass(x=1, y=2))\n</code></pre>"},{"location":"migration/#changes-to-handling-of-standard-types","title":"Changes to Handling of Standard Types","text":""},{"location":"migration/#dicts","title":"Dicts","text":"<p>Iterables of pairs (which include empty iterables) no longer pass validation for fields of type <code>dict</code>.</p>"},{"location":"migration/#unions","title":"Unions","text":"<p>While union types will still attempt validation of each choice from left to right, they now preserve the type of the input whenever possible, even if the correct type is not the first choice for which the input would pass validation. As a demonstration, consider the following example:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: Union[int, str]\n\n\nprint(Model(x='1'))\n#&gt; x='1'\n</code></pre> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: int | str\n\n\nprint(Model(x='1'))\n#&gt; x='1'\n</code></pre> <p>In Pydantic V1, the printed result would have been <code>x=1</code>, since the value would pass validation as an <code>int</code>. In Pydantic V2, we recognize that the value is an instance of one of the cases and short-circuit the standard union validation.</p>"},{"location":"migration/#required-optional-and-nullable-fields","title":"Required, optional, and nullable fields","text":"<p>Pydantic V1 had a somewhat loose idea about \"required\" versus \"nullable\" fields. In Pydantic V2, these concepts are more clearly defined.</p> <p>Pydantic V2 will move to match <code>dataclasses</code>, thus you may explicitly specify a field as <code>required</code> or <code>optional</code> and whether the field accepts <code>None</code> or not.</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo(BaseModel):\n    f1: str  # required, cannot be None\n    f2: Optional[str]  # required, can be None - same as Union[str, None] / str | None\n    f3: Optional[str] = None  # not required, can be None\n    f4: str = 'Foobar'  # not required, but cannot be None\n\n\ntry:\n    Foo(f1=None, f2=None, f4='b')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Foo\n    f1\n      Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Foo(BaseModel):\n    f1: str  # required, cannot be None\n    f2: str | None  # required, can be None - same as Union[str, None] / str | None\n    f3: str | None = None  # not required, can be None\n    f4: str = 'Foobar'  # not required, but cannot be None\n\n\ntry:\n    Foo(f1=None, f2=None, f4='b')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Foo\n    f1\n      Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    \"\"\"\n</code></pre>"},{"location":"migration/#introduction-of-typeadapter","title":"Introduction of <code>TypeAdapter</code>","text":"<p>Pydantic V1 had weak support for validating or serializing non-<code>BaseModel</code> types.</p> <p>To work with them, you had to either create a \"root\" model or use the utility functions in <code>pydantic.tools</code> (namely, <code>parse_obj_as</code> and <code>schema_of</code>).</p> <p>In Pydantic V2 this is a lot easier: the <code>TypeAdapter</code> class lets you create an object with methods for validating, serializing, and producing JSON schemas for arbitrary types. This serves as a complete replacement for <code>parse_obj_as</code> and <code>schema_of</code> (which are now deprecated), and also covers some of the use cases of \"root\" models (<code>RootModel</code>, discussed above, covers the others).</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\nadapter = TypeAdapter(List[int])\nassert adapter.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(adapter.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <pre><code>from pydantic import TypeAdapter\n\nadapter = TypeAdapter(list[int])\nassert adapter.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(adapter.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <p>Due to limitations of inferring generic types with common type checkers, to get proper typing in some scenarios, you may need to explicitly specify the generic parameter:</p> <pre><code>from pydantic import TypeAdapter\n\nadapter: TypeAdapter[str | int] = TypeAdapter(str | int)\n...\n</code></pre> <p>[TODO: Add link to TypeAdapter documentation. For now, you can find example usage in <code>tests/test_type_adapter.py</code>.]</p>"},{"location":"migration/#defining-custom-types","title":"Defining custom types","text":"<p>We have completely overhauled the way custom types are defined in pydantic.</p> <p>We have exposed hooks for generating both <code>pydantic-core</code> and JSON schemas, allowing you to get all the performance benefits of Pydantic V2 even when using your own custom types.</p> <p>We have also introduced ways to use <code>typing.Annotated</code> to add custom validation to your own types.</p> <p>The main changes are:</p> <ul> <li><code>__get_validators__</code> should be replaced with <code>__get_pydantic_core_schema__</code>.   See Custom Data Types for more information.</li> <li><code>__modify_schema__</code> becomes <code>__get_pydantic_json_schema__</code>.   See JSON Schema Customization for more information.</li> </ul> <p>Additionally, you can use <code>typing.Annotated</code> to modify or provide the <code>__get_pydantic_core_schema__</code> and <code>__get_pydantic_json_schema__</code> functions of a type by annotating it, rather than modifying the type itself. This provides a powerful and flexible mechanism for integrating third-party types with Pydantic, and in some cases may help you remove hacks from Pydantic V1 introduced to work around the limitations for custom types.</p> <p>See Custom Data Types for more information.</p>"},{"location":"migration/#changes-to-json-schema-generation","title":"Changes to JSON schema generation","text":"<p>We received many requests over the years to make changes to the JSON schemas that pydantic generates.</p> <p>In Pydantic V2, we have tried to address many of the common requests:</p> <ul> <li>The JSON schema for <code>Optional</code> fields now indicates that the value <code>null</code> is allowed.</li> <li>The <code>Decimal</code> type is now exposed in JSON schema (and serialized) as a string.</li> <li>The JSON schema no longer preserves namedtuples as namedtuples.</li> <li>The JSON schema we generate by default now targets draft 2020-12 (with some OpenAPI extensions).</li> <li>When they differ, you can now specify if you want the JSON schema representing the inputs to validation,     or the outputs from serialization.</li> </ul> <p>However, there have been many reasonable requests over the years for changes which we have not chosen to implement.</p> <p>In Pydantic V1, even if you were willing to implement changes yourself, it was very difficult because the JSON schema generation process involved various recursive function calls; to override one, you'd have to copy and modify the whole implementation.</p> <p>In Pydantic V2, one of our design goals was to make it easier to customize JSON schema generation. To this end, we have introduced the class <code>GenerateJsonSchema</code>, which implements the translation of a type's pydantic-core schema into a JSON schema. By design, this class breaks the JSON schema generation process into smaller methods that can be easily overridden in subclasses to modify the \"global\" approach to generating JSON schema.</p> <p>The various methods that can be used to produce JSON schema (such as <code>BaseModel.model_json_schema</code> or <code>TypeAdapter.json_schema</code>) accept a keyword argument <code>schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema</code>, and you can pass your custom subclass to these methods in order to use your own approach to generating JSON schema.</p> <p>Hopefully this means that if you disagree with any of the choices we've made, or if you are reliant on behaviors in Pydantic V1 that have changed in Pydantic V2, you can use a custom <code>schema_generator</code>, modifying the <code>GenerateJsonSchema</code> class as necessary for your application.</p>"},{"location":"migration/#basesettings-has-moved-to-pydantic-settings","title":"<code>BaseSettings</code> has moved to <code>pydantic-settings</code>","text":"<p><code>BaseSettings</code>, the base object for Pydantic settings management, has been moved to a separate package, <code>pydantic-settings</code>.</p>"},{"location":"migration/#moved-in-pydantic-v2","title":"Moved in Pydantic V2","text":"Pydantic V1 Pydantic V2 <code>pydantic.utils.version_info</code> <code>pydantic.version.version_info</code> <code>pydantic.error_wrappers.ValidationError</code> <code>pydantic.ValidationError</code> <code>pydantic.utils.to_camel</code> <code>pydantic.alias_generators.to_pascal</code> <code>pydantic.utils.to_lower_camel</code> <code>pydantic.alias_generators.to_camel</code> <p>In addition, the following special-use types have been moved to the Pydantic Extra Types package, which may be installed separately if needed.</p> <ul> <li>Color Types</li> <li>Payment Card Numbers</li> </ul>"},{"location":"migration/#deprecated-and-moved-in-pydantic-v2","title":"Deprecated and moved in Pydantic V2","text":"Pydantic V1 Pydantic V2 <code>pydantic.tools.schema_of</code> <code>pydantic.deprecated.tools.schema_of</code> <code>pydantic.tools.parse_obj_as</code> <code>pydantic.deprecated.tools.parse_obj_as</code> <code>pydantic.tools.schema_json_of</code> <code>pydantic.deprecated.tools.schema_json_of</code> <code>pydantic.json.pydantic_encoder</code> <code>pydantic.deprecated.json.pydantic_encoder</code> <code>pydantic.validate_arguments</code> <code>pydantic.deprecated.decorator.validate_arguments</code> <code>pydantic.json.custom_pydantic_encoder</code> <code>pydantic.deprecated.json.custom_pydantic_encoder</code> <code>pydantic.json.timedelta_isoformat</code> <code>pydantic.deprecated.json.timedelta_isoformat</code> <code>pydantic.decorator.validate_arguments</code> <code>pydantic.deprecated.decorator.validate_arguments</code> <code>pydantic.class_validators.validator</code> <code>pydantic.deprecated.class_validators.validator</code> <code>pydantic.class_validators.root_validator</code> <code>pydantic.deprecated.class_validators.root_validator</code> <code>pydantic.utils.deep_update</code> <code>pydantic.v1.utils.deep_update</code> <code>pydantic.utils.GetterDict</code> <code>pydantic.v1.utils.GetterDict</code> <code>pydantic.utils.lenient_issubclass</code> <code>pydantic.v1.utils.lenient_issubclass</code> <code>pydantic.utils.lenient_isinstance</code> <code>pydantic.v1.utils.lenient_isinstance</code> <code>pydantic.utils.is_valid_field</code> <code>pydantic.v1.utils.is_valid_field</code> <code>pydantic.utils.update_not_none</code> <code>pydantic.v1.utils.update_not_none</code> <code>pydantic.utils.import_string</code> <code>pydantic.v1.utils.import_string</code> <code>pydantic.utils.Representation</code> <code>pydantic.v1.utils.Representation</code> <code>pydantic.utils.ROOT_KEY</code> <code>pydantic.v1.utils.ROOT_KEY</code> <code>pydantic.utils.smart_deepcopy</code> <code>pydantic.v1.utils.smart_deepcopy</code> <code>pydantic.utils.sequence_like</code> <code>pydantic.v1.utils.sequence_like</code>"},{"location":"migration/#removed-in-pydantic-v2","title":"Removed in Pydantic V2","text":"<ul> <li><code>pydantic.BaseSettings</code></li> <li><code>pydantic.ConstrainedBytes</code></li> <li><code>pydantic.ConstrainedDate</code></li> <li><code>pydantic.ConstrainedDecimal</code></li> <li><code>pydantic.ConstrainedFloat</code></li> <li><code>pydantic.ConstrainedFrozenSet</code></li> <li><code>pydantic.ConstrainedInt</code></li> <li><code>pydantic.ConstrainedList</code></li> <li><code>pydantic.ConstrainedSet</code></li> <li><code>pydantic.ConstrainedStr</code></li> <li><code>pydantic.JsonWrapper</code></li> <li><code>pydantic.NoneBytes</code></li> <li><code>pydantic.NoneStr</code></li> <li><code>pydantic.NoneStrBytes</code></li> <li><code>pydantic.Protocol</code></li> <li><code>pydantic.PyObject</code></li> <li><code>pydantic.Required</code></li> <li><code>pydantic.StrBytes</code></li> <li><code>pydantic.compiled</code></li> <li><code>pydantic.config.get_config</code></li> <li><code>pydantic.config.inherit_config</code></li> <li><code>pydantic.config.prepare_config</code></li> <li><code>pydantic.create_model_from_namedtuple</code></li> <li><code>pydantic.create_model_from_typeddict</code></li> <li><code>pydantic.dataclasses.create_pydantic_model_from_dataclass</code></li> <li><code>pydantic.dataclasses.make_dataclass_validator</code></li> <li><code>pydantic.dataclasses.set_validation</code></li> <li><code>pydantic.datetime_parse.parse_date</code></li> <li><code>pydantic.datetime_parse.parse_time</code></li> <li><code>pydantic.datetime_parse.parse_datetime</code></li> <li><code>pydantic.datetime_parse.parse_duration</code></li> <li><code>pydantic.error_wrappers.ErrorWrapper</code></li> <li><code>pydantic.errors.AnyStrMaxLengthError</code></li> <li><code>pydantic.errors.AnyStrMinLengthError</code></li> <li><code>pydantic.errors.ArbitraryTypeError</code></li> <li><code>pydantic.errors.BoolError</code></li> <li><code>pydantic.errors.BytesError</code></li> <li><code>pydantic.errors.CallableError</code></li> <li><code>pydantic.errors.ClassError</code></li> <li><code>pydantic.errors.ColorError</code></li> <li><code>pydantic.errors.ConfigError</code></li> <li><code>pydantic.errors.DataclassTypeError</code></li> <li><code>pydantic.errors.DateError</code></li> <li><code>pydantic.errors.DateNotInTheFutureError</code></li> <li><code>pydantic.errors.DateNotInThePastError</code></li> <li><code>pydantic.errors.DateTimeError</code></li> <li><code>pydantic.errors.DecimalError</code></li> <li><code>pydantic.errors.DecimalIsNotFiniteError</code></li> <li><code>pydantic.errors.DecimalMaxDigitsError</code></li> <li><code>pydantic.errors.DecimalMaxPlacesError</code></li> <li><code>pydantic.errors.DecimalWholeDigitsError</code></li> <li><code>pydantic.errors.DictError</code></li> <li><code>pydantic.errors.DurationError</code></li> <li><code>pydantic.errors.EmailError</code></li> <li><code>pydantic.errors.EnumError</code></li> <li><code>pydantic.errors.EnumMemberError</code></li> <li><code>pydantic.errors.ExtraError</code></li> <li><code>pydantic.errors.FloatError</code></li> <li><code>pydantic.errors.FrozenSetError</code></li> <li><code>pydantic.errors.FrozenSetMaxLengthError</code></li> <li><code>pydantic.errors.FrozenSetMinLengthError</code></li> <li><code>pydantic.errors.HashableError</code></li> <li><code>pydantic.errors.IPv4AddressError</code></li> <li><code>pydantic.errors.IPv4InterfaceError</code></li> <li><code>pydantic.errors.IPv4NetworkError</code></li> <li><code>pydantic.errors.IPv6AddressError</code></li> <li><code>pydantic.errors.IPv6InterfaceError</code></li> <li><code>pydantic.errors.IPv6NetworkError</code></li> <li><code>pydantic.errors.IPvAnyAddressError</code></li> <li><code>pydantic.errors.IPvAnyInterfaceError</code></li> <li><code>pydantic.errors.IPvAnyNetworkError</code></li> <li><code>pydantic.errors.IntEnumError</code></li> <li><code>pydantic.errors.IntegerError</code></li> <li><code>pydantic.errors.InvalidByteSize</code></li> <li><code>pydantic.errors.InvalidByteSizeUnit</code></li> <li><code>pydantic.errors.InvalidDiscriminator</code></li> <li><code>pydantic.errors.InvalidLengthForBrand</code></li> <li><code>pydantic.errors.JsonError</code></li> <li><code>pydantic.errors.JsonTypeError</code></li> <li><code>pydantic.errors.ListError</code></li> <li><code>pydantic.errors.ListMaxLengthError</code></li> <li><code>pydantic.errors.ListMinLengthError</code></li> <li><code>pydantic.errors.ListUniqueItemsError</code></li> <li><code>pydantic.errors.LuhnValidationError</code></li> <li><code>pydantic.errors.MissingDiscriminator</code></li> <li><code>pydantic.errors.MissingError</code></li> <li><code>pydantic.errors.NoneIsAllowedError</code></li> <li><code>pydantic.errors.NoneIsNotAllowedError</code></li> <li><code>pydantic.errors.NotDigitError</code></li> <li><code>pydantic.errors.NotNoneError</code></li> <li><code>pydantic.errors.NumberNotGeError</code></li> <li><code>pydantic.errors.NumberNotGtError</code></li> <li><code>pydantic.errors.NumberNotLeError</code></li> <li><code>pydantic.errors.NumberNotLtError</code></li> <li><code>pydantic.errors.NumberNotMultipleError</code></li> <li><code>pydantic.errors.PathError</code></li> <li><code>pydantic.errors.PathNotADirectoryError</code></li> <li><code>pydantic.errors.PathNotAFileError</code></li> <li><code>pydantic.errors.PathNotExistsError</code></li> <li><code>pydantic.errors.PatternError</code></li> <li><code>pydantic.errors.PyObjectError</code></li> <li><code>pydantic.errors.PydanticTypeError</code></li> <li><code>pydantic.errors.PydanticValueError</code></li> <li><code>pydantic.errors.SequenceError</code></li> <li><code>pydantic.errors.SetError</code></li> <li><code>pydantic.errors.SetMaxLengthError</code></li> <li><code>pydantic.errors.SetMinLengthError</code></li> <li><code>pydantic.errors.StrError</code></li> <li><code>pydantic.errors.StrRegexError</code></li> <li><code>pydantic.errors.StrictBoolError</code></li> <li><code>pydantic.errors.SubclassError</code></li> <li><code>pydantic.errors.TimeError</code></li> <li><code>pydantic.errors.TupleError</code></li> <li><code>pydantic.errors.TupleLengthError</code></li> <li><code>pydantic.errors.UUIDError</code></li> <li><code>pydantic.errors.UUIDVersionError</code></li> <li><code>pydantic.errors.UrlError</code></li> <li><code>pydantic.errors.UrlExtraError</code></li> <li><code>pydantic.errors.UrlHostError</code></li> <li><code>pydantic.errors.UrlHostTldError</code></li> <li><code>pydantic.errors.UrlPortError</code></li> <li><code>pydantic.errors.UrlSchemeError</code></li> <li><code>pydantic.errors.UrlSchemePermittedError</code></li> <li><code>pydantic.errors.UrlUserInfoError</code></li> <li><code>pydantic.errors.WrongConstantError</code></li> <li><code>pydantic.main.validate_model</code></li> <li><code>pydantic.networks.stricturl</code></li> <li><code>pydantic.parse_file_as</code></li> <li><code>pydantic.parse_raw_as</code></li> <li><code>pydantic.stricturl</code></li> <li><code>pydantic.tools.parse_file_as</code></li> <li><code>pydantic.tools.parse_raw_as</code></li> <li><code>pydantic.types.ConstrainedBytes</code></li> <li><code>pydantic.types.ConstrainedDate</code></li> <li><code>pydantic.types.ConstrainedDecimal</code></li> <li><code>pydantic.types.ConstrainedFloat</code></li> <li><code>pydantic.types.ConstrainedFrozenSet</code></li> <li><code>pydantic.types.ConstrainedInt</code></li> <li><code>pydantic.types.ConstrainedList</code></li> <li><code>pydantic.types.ConstrainedSet</code></li> <li><code>pydantic.types.ConstrainedStr</code></li> <li><code>pydantic.types.JsonWrapper</code></li> <li><code>pydantic.types.NoneBytes</code></li> <li><code>pydantic.types.NoneStr</code></li> <li><code>pydantic.types.NoneStrBytes</code></li> <li><code>pydantic.types.PyObject</code></li> <li><code>pydantic.types.StrBytes</code></li> <li><code>pydantic.typing.evaluate_forwardref</code></li> <li><code>pydantic.typing.AbstractSetIntStr</code></li> <li><code>pydantic.typing.AnyCallable</code></li> <li><code>pydantic.typing.AnyClassMethod</code></li> <li><code>pydantic.typing.CallableGenerator</code></li> <li><code>pydantic.typing.DictAny</code></li> <li><code>pydantic.typing.DictIntStrAny</code></li> <li><code>pydantic.typing.DictStrAny</code></li> <li><code>pydantic.typing.IntStr</code></li> <li><code>pydantic.typing.ListStr</code></li> <li><code>pydantic.typing.MappingIntStrAny</code></li> <li><code>pydantic.typing.NoArgAnyCallable</code></li> <li><code>pydantic.typing.NoneType</code></li> <li><code>pydantic.typing.ReprArgs</code></li> <li><code>pydantic.typing.SetStr</code></li> <li><code>pydantic.typing.StrPath</code></li> <li><code>pydantic.typing.TupleGenerator</code></li> <li><code>pydantic.typing.WithArgsTypes</code></li> <li><code>pydantic.typing.all_literal_values</code></li> <li><code>pydantic.typing.display_as_type</code></li> <li><code>pydantic.typing.get_all_type_hints</code></li> <li><code>pydantic.typing.get_args</code></li> <li><code>pydantic.typing.get_origin</code></li> <li><code>pydantic.typing.get_sub_types</code></li> <li><code>pydantic.typing.is_callable_type</code></li> <li><code>pydantic.typing.is_classvar</code></li> <li><code>pydantic.typing.is_finalvar</code></li> <li><code>pydantic.typing.is_literal_type</code></li> <li><code>pydantic.typing.is_namedtuple</code></li> <li><code>pydantic.typing.is_new_type</code></li> <li><code>pydantic.typing.is_none_type</code></li> <li><code>pydantic.typing.is_typeddict</code></li> <li><code>pydantic.typing.is_typeddict_special</code></li> <li><code>pydantic.typing.is_union</code></li> <li><code>pydantic.typing.new_type_supertype</code></li> <li><code>pydantic.typing.resolve_annotations</code></li> <li><code>pydantic.typing.typing_base</code></li> <li><code>pydantic.typing.update_field_forward_refs</code></li> <li><code>pydantic.typing.update_model_forward_refs</code></li> <li><code>pydantic.utils.ClassAttribute</code></li> <li><code>pydantic.utils.DUNDER_ATTRIBUTES</code></li> <li><code>pydantic.utils.PyObjectStr</code></li> <li><code>pydantic.utils.ValueItems</code></li> <li><code>pydantic.utils.almost_equal_floats</code></li> <li><code>pydantic.utils.get_discriminator_alias_and_values</code></li> <li><code>pydantic.utils.get_model</code></li> <li><code>pydantic.utils.get_unique_discriminator_alias</code></li> <li><code>pydantic.utils.in_ipython</code></li> <li><code>pydantic.utils.is_valid_identifier</code></li> <li><code>pydantic.utils.path_type</code></li> <li><code>pydantic.utils.validate_field_name</code></li> <li><code>pydantic.validate_model</code></li> </ul>"},{"location":"api/alias_generators/","title":"pydantic.alias_generators","text":"<p>Alias generators for converting between different capitalization conventions.</p>"},{"location":"api/alias_generators/#pydantic.alias_generators.to_camel","title":"to_camel","text":"<pre><code>to_camel(snake)\n</code></pre> <p>Convert a snake_case string to camelCase.</p> <p>Parameters:</p> Name Type Description Default <code>snake</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted camelCase string.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_camel(snake: str) -&gt; str:\n\"\"\"Convert a snake_case string to camelCase.\n\n    Args:\n        snake: The string to convert.\n\n    Returns:\n        The converted camelCase string.\n    \"\"\"\n    camel = to_pascal(snake)\n    return re.sub('(^_*[A-Z])', lambda m: m.group(1).lower(), camel)\n</code></pre>"},{"location":"api/alias_generators/#pydantic.alias_generators.to_pascal","title":"to_pascal","text":"<pre><code>to_pascal(snake)\n</code></pre> <p>Convert a snake_case string to PascalCase.</p> <p>Parameters:</p> Name Type Description Default <code>snake</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The PascalCase string.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_pascal(snake: str) -&gt; str:\n\"\"\"Convert a snake_case string to PascalCase.\n\n    Args:\n        snake: The string to convert.\n\n    Returns:\n        The PascalCase string.\n    \"\"\"\n    camel = snake.title()\n    return re.sub('([0-9A-Za-z])_(?=[0-9A-Z])', lambda m: m.group(1), camel)\n</code></pre>"},{"location":"api/alias_generators/#pydantic.alias_generators.to_snake","title":"to_snake","text":"<pre><code>to_snake(camel)\n</code></pre> <p>Convert a PascalCase or camelCase string to snake_case.</p> <p>Parameters:</p> Name Type Description Default <code>camel</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted string in snake_case.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_snake(camel: str) -&gt; str:\n\"\"\"Convert a PascalCase or camelCase string to snake_case.\n\n    Args:\n        camel: The string to convert.\n\n    Returns:\n        The converted string in snake_case.\n    \"\"\"\n    snake = re.sub(r'([a-zA-Z])([0-9])', lambda m: f'{m.group(1)}_{m.group(2)}', camel)\n    snake = re.sub(r'([a-z0-9])([A-Z])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)\n    return snake.lower()\n</code></pre>"},{"location":"api/color/","title":"pydantic.color","text":"<p>Color definitions are used as per the CSS3 CSS Color Module Level 3 specification.</p> <p>A few colors have multiple names referring to the sames colors, eg. <code>grey</code> and <code>gray</code> or <code>aqua</code> and <code>cyan</code>.</p> <p>In these cases the last color when sorted alphabetically takes preferences, eg. <code>Color((0, 255, 255)).as_named() == 'cyan'</code> because \"cyan\" comes after \"aqua\".</p> Deprecated <p>The <code>Color</code> class is deprecated, use <code>pydantic_extra_types</code> instead. See more about it here.</p>"},{"location":"api/color/#pydantic.color.Color","title":"Color","text":"<pre><code>Color(value)\n</code></pre> <p>         Bases: <code>_repr.Representation</code></p> <p>Represents a color.</p> Source code in <code>pydantic/color.py</code> <pre><code>def __init__(self, value: ColorType) -&gt; None:\n    self._rgba: RGBA\n    self._original: ColorType\n    if isinstance(value, (tuple, list)):\n        self._rgba = parse_tuple(value)\n    elif isinstance(value, str):\n        self._rgba = parse_str(value)\n    elif isinstance(value, Color):\n        self._rgba = value._rgba\n        value = value._original\n    else:\n        raise PydanticCustomError(\n            'color_error', 'value is not a valid color: value must be a tuple, list or string'\n        )\n\n    # if we've got here value must be a valid color\n    self._original = value\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_hex","title":"as_hex","text":"<pre><code>as_hex()\n</code></pre> <p>Returns the hexadecimal representation of the color.</p> <p>Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string a \"short\" representation of the color is possible and whether there's an alpha channel.</p> <p>Returns:</p> Type Description <code>str</code> <p>The hexadecimal representation of the color.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_hex(self) -&gt; str:\n\"\"\"Returns the hexadecimal representation of the color.\n\n    Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string\n    a \"short\" representation of the color is possible and whether there's an alpha channel.\n\n    Returns:\n        The hexadecimal representation of the color.\n    \"\"\"\n    values = [float_to_255(c) for c in self._rgba[:3]]\n    if self._rgba.alpha is not None:\n        values.append(float_to_255(self._rgba.alpha))\n\n    as_hex = ''.join(f'{v:02x}' for v in values)\n    if all(c in repeat_colors for c in values):\n        as_hex = ''.join(as_hex[c] for c in range(0, len(as_hex), 2))\n    return '#' + as_hex\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_hsl","title":"as_hsl","text":"<pre><code>as_hsl()\n</code></pre> <p>Color as an <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)</code> or <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_hsl(self) -&gt; str:\n\"\"\"Color as an `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)` or `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)` string.\"\"\"\n    if self._rgba.alpha is None:\n        h, s, li = self.as_hsl_tuple(alpha=False)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%})'\n    else:\n        h, s, li, a = self.as_hsl_tuple(alpha=True)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%}, {round(a, 2)})'\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_hsl_tuple","title":"as_hsl_tuple","text":"<pre><code>as_hsl_tuple(*, alpha=None)\n</code></pre> <p>Returns the color as an HSL or HSLA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[bool]</code> <p>Whether to include the alpha channel.</p> <ul> <li><code>None</code> (default): Include the alpha channel only if it's set (e.g. not <code>None</code>).</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>HslColorTuple</code> <p>The color as a tuple of hue, saturation, lightness, and alpha (if included). All elements are in the range 0 to 1.</p> Note <p>This is HSL as used in HTML and most other places, not HLS as used in Python's <code>colorsys</code>.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_hsl_tuple(self, *, alpha: Optional[bool] = None) -&gt; HslColorTuple:\n\"\"\"Returns the color as an HSL or HSLA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel.\n\n            - `None` (default): Include the alpha channel only if it's set (e.g. not `None`).\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        The color as a tuple of hue, saturation, lightness, and alpha (if included).\n            All elements are in the range 0 to 1.\n\n    Note:\n        This is HSL as used in HTML and most other places, not HLS as used in Python's `colorsys`.\n    \"\"\"\n    h, l, s = rgb_to_hls(self._rgba.r, self._rgba.g, self._rgba.b)  # noqa: E741\n    if alpha is None:\n        if self._rgba.alpha is None:\n            return h, s, l\n        else:\n            return h, s, l, self._alpha_float()\n    if alpha:\n        return h, s, l, self._alpha_float()\n    else:\n        # alpha is False\n        return h, s, l\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_named","title":"as_named","text":"<pre><code>as_named(*, fallback=False)\n</code></pre> <p>Returns the name of the color if it can be found in <code>COLORS_BY_VALUE</code> dictionary, otherwise returns the hexadecimal representation of the color or raises <code>ValueError</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fallback</code> <code>bool</code> <p>If True, falls back to returning the hexadecimal representation of the color instead of raising a ValueError when no named color is found.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The name of the color, or the hexadecimal representation of the color.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When no named color is found and fallback is <code>False</code>.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_named(self, *, fallback: bool = False) -&gt; str:\n\"\"\"Returns the name of the color if it can be found in `COLORS_BY_VALUE` dictionary,\n    otherwise returns the hexadecimal representation of the color or raises `ValueError`.\n\n    Args:\n        fallback: If True, falls back to returning the hexadecimal representation of\n            the color instead of raising a ValueError when no named color is found.\n\n    Returns:\n        The name of the color, or the hexadecimal representation of the color.\n\n    Raises:\n        ValueError: When no named color is found and fallback is `False`.\n    \"\"\"\n    if self._rgba.alpha is None:\n        rgb = cast(Tuple[int, int, int], self.as_rgb_tuple())\n        try:\n            return COLORS_BY_VALUE[rgb]\n        except KeyError as e:\n            if fallback:\n                return self.as_hex()\n            else:\n                raise ValueError('no named color found, use fallback=True, as_hex() or as_rgb()') from e\n    else:\n        return self.as_hex()\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_rgb","title":"as_rgb","text":"<pre><code>as_rgb()\n</code></pre> <p>Color as an <code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code> or <code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_rgb(self) -&gt; str:\n\"\"\"Color as an `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)` or `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)` string.\"\"\"\n    if self._rgba.alpha is None:\n        return f'rgb({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)})'\n    else:\n        return (\n            f'rgba({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)}, '\n            f'{round(self._alpha_float(), 2)})'\n        )\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.as_rgb_tuple","title":"as_rgb_tuple","text":"<pre><code>as_rgb_tuple(*, alpha=None)\n</code></pre> <p>Returns the color as an RGB or RGBA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>Optional[bool]</code> <p>Whether to include the alpha channel. There are three options for this input:</p> <ul> <li><code>None</code> (default): Include alpha only if it's set. (e.g. not <code>None</code>)</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>ColorTuple</code> <p>A tuple that contains the values of the red, green, and blue channels in the range 0 to 255. If alpha is included, it is in the range 0 to 1.</p> Source code in <code>pydantic/color.py</code> <pre><code>def as_rgb_tuple(self, *, alpha: Optional[bool] = None) -&gt; ColorTuple:\n\"\"\"Returns the color as an RGB or RGBA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel. There are three options for this input:\n\n            - `None` (default): Include alpha only if it's set. (e.g. not `None`)\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        A tuple that contains the values of the red, green, and blue channels in the range 0 to 255.\n            If alpha is included, it is in the range 0 to 1.\n    \"\"\"\n    r, g, b = (float_to_255(c) for c in self._rgba[:3])\n    if alpha is None:\n        if self._rgba.alpha is None:\n            return r, g, b\n        else:\n            return r, g, b, self._alpha_float()\n    elif alpha:\n        return r, g, b, self._alpha_float()\n    else:\n        # alpha is False\n        return r, g, b\n</code></pre>"},{"location":"api/color/#pydantic.color.Color.original","title":"original","text":"<pre><code>original()\n</code></pre> <p>Original value passed to <code>Color</code>.</p> Source code in <code>pydantic/color.py</code> <pre><code>def original(self) -&gt; ColorType:\n\"\"\"Original value passed to `Color`.\"\"\"\n    return self._original\n</code></pre>"},{"location":"api/color/#pydantic.color.float_to_255","title":"float_to_255","text":"<pre><code>float_to_255(c)\n</code></pre> <p>Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>float</code> <p>The float value to be converted. Must be between 0 and 1 (inclusive).</p> required <p>Returns:</p> Type Description <code>int</code> <p>The integer equivalent of the given float value rounded to the nearest whole number.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the given float value is outside the acceptable range of 0 to 1 (inclusive).</p> Source code in <code>pydantic/color.py</code> <pre><code>def float_to_255(c: float) -&gt; int:\n\"\"\"Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).\n\n    Args:\n        c: The float value to be converted. Must be between 0 and 1 (inclusive).\n\n    Returns:\n        The integer equivalent of the given float value rounded to the nearest whole number.\n\n    Raises:\n        ValueError: If the given float value is outside the acceptable range of 0 to 1 (inclusive).\n    \"\"\"\n    return int(round(c * 255))\n</code></pre>"},{"location":"api/color/#pydantic.color.ints_to_rgba","title":"ints_to_rgba","text":"<pre><code>ints_to_rgba(r, g, b, alpha=None)\n</code></pre> <p>Converts integer or string values for RGB color and an optional alpha value to an <code>RGBA</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>Union[int, str]</code> <p>An integer or string representing the red color value.</p> required <code>g</code> <code>Union[int, str]</code> <p>An integer or string representing the green color value.</p> required <code>b</code> <code>Union[int, str]</code> <p>An integer or string representing the blue color value.</p> required <code>alpha</code> <code>Optional[float]</code> <p>A float representing the alpha value. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of the <code>RGBA</code> class with the corresponding color and alpha values.</p> Source code in <code>pydantic/color.py</code> <pre><code>def ints_to_rgba(r: Union[int, str], g: Union[int, str], b: Union[int, str], alpha: Optional[float] = None) -&gt; RGBA:\n\"\"\"Converts integer or string values for RGB color and an optional alpha value to an `RGBA` object.\n\n    Args:\n        r: An integer or string representing the red color value.\n        g: An integer or string representing the green color value.\n        b: An integer or string representing the blue color value.\n        alpha: A float representing the alpha value. Defaults to None.\n\n    Returns:\n        An instance of the `RGBA` class with the corresponding color and alpha values.\n    \"\"\"\n    return RGBA(parse_color_value(r), parse_color_value(g), parse_color_value(b), parse_float_alpha(alpha))\n</code></pre>"},{"location":"api/color/#pydantic.color.parse_color_value","title":"parse_color_value","text":"<pre><code>parse_color_value(value, max_val=255)\n</code></pre> <p>Parse the color value provided and return a number between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[int, str]</code> <p>An integer or string color value.</p> required <code>max_val</code> <code>int</code> <p>Maximum range value. Defaults to 255.</p> <code>255</code> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the value is not a valid color.</p> <p>Returns:</p> Type Description <code>float</code> <p>A number between 0 and 1.</p> Source code in <code>pydantic/color.py</code> <pre><code>def parse_color_value(value: Union[int, str], max_val: int = 255) -&gt; float:\n\"\"\"Parse the color value provided and return a number between 0 and 1.\n\n    Args:\n        value: An integer or string color value.\n        max_val: Maximum range value. Defaults to 255.\n\n    Raises:\n        PydanticCustomError: If the value is not a valid color.\n\n    Returns:\n        A number between 0 and 1.\n    \"\"\"\n    try:\n        color = float(value)\n    except ValueError:\n        raise PydanticCustomError('color_error', 'value is not a valid color: color values must be a valid number')\n    if 0 &lt;= color &lt;= max_val:\n        return color / max_val\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: color values must be in the range 0 to {max_val}',\n            {'max_val': max_val},\n        )\n</code></pre>"},{"location":"api/color/#pydantic.color.parse_float_alpha","title":"parse_float_alpha","text":"<pre><code>parse_float_alpha(value)\n</code></pre> <p>Parse an alpha value checking it's a valid float in the range 0 to 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[None, str, float, int]</code> <p>The input value to parse.</p> required <p>Returns:</p> Type Description <code>Optional[float]</code> <p>The parsed value as a float, or <code>None</code> if the value was None or equal 1.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the input value cannot be successfully parsed as a float in the expected range.</p> Source code in <code>pydantic/color.py</code> <pre><code>def parse_float_alpha(value: Union[None, str, float, int]) -&gt; Optional[float]:\n\"\"\"Parse an alpha value checking it's a valid float in the range 0 to 1.\n\n    Args:\n        value: The input value to parse.\n\n    Returns:\n        The parsed value as a float, or `None` if the value was None or equal 1.\n\n    Raises:\n        PydanticCustomError: If the input value cannot be successfully parsed as a float in the expected range.\n    \"\"\"\n    if value is None:\n        return None\n    try:\n        if isinstance(value, str) and value.endswith('%'):\n            alpha = float(value[:-1]) / 100\n        else:\n            alpha = float(value)\n    except ValueError:\n        raise PydanticCustomError('color_error', 'value is not a valid color: alpha values must be a valid float')\n\n    if _utils.almost_equal_floats(alpha, 1):\n        return None\n    elif 0 &lt;= alpha &lt;= 1:\n        return alpha\n    else:\n        raise PydanticCustomError('color_error', 'value is not a valid color: alpha values must be in the range 0 to 1')\n</code></pre>"},{"location":"api/color/#pydantic.color.parse_hsl","title":"parse_hsl","text":"<pre><code>parse_hsl(h, h_units, sat, light, alpha=None)\n</code></pre> <p>Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>str</code> <p>The hue value.</p> required <code>h_units</code> <code>str</code> <p>The unit for hue value.</p> required <code>sat</code> <code>str</code> <p>The saturation value.</p> required <code>light</code> <code>str</code> <p>The lightness value.</p> required <code>alpha</code> <code>Optional[float]</code> <p>Alpha value.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of <code>RGBA</code>.</p> Source code in <code>pydantic/color.py</code> <pre><code>def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: Optional[float] = None) -&gt; RGBA:\n\"\"\"Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.\n\n    Args:\n        h: The hue value.\n        h_units: The unit for hue value.\n        sat: The saturation value.\n        light: The lightness value.\n        alpha: Alpha value.\n\n    Returns:\n        An instance of `RGBA`.\n    \"\"\"\n    s_value, l_value = parse_color_value(sat, 100), parse_color_value(light, 100)\n\n    h_value = float(h)\n    if h_units in {None, 'deg'}:\n        h_value = h_value % 360 / 360\n    elif h_units == 'rad':\n        h_value = h_value % rads / rads\n    else:\n        # turns\n        h_value = h_value % 1\n\n    r, g, b = hls_to_rgb(h_value, l_value, s_value)\n    return RGBA(r, g, b, parse_float_alpha(alpha))\n</code></pre>"},{"location":"api/color/#pydantic.color.parse_str","title":"parse_str","text":"<pre><code>parse_str(value)\n</code></pre> <p>Parse a string representing a color to an RGBA tuple.</p> <p>Possible formats for the input string include:</p> <ul> <li>named color, see <code>COLORS_BY_NAME</code></li> <li>hex short eg. <code>&lt;prefix&gt;fff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li>hex long eg. <code>&lt;prefix&gt;ffffff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li><code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code></li> <li><code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>A string representing a color.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input string cannot be parsed to an RGBA tuple.</p> Source code in <code>pydantic/color.py</code> <pre><code>def parse_str(value: str) -&gt; RGBA:\n\"\"\"Parse a string representing a color to an RGBA tuple.\n\n    Possible formats for the input string include:\n\n    * named color, see `COLORS_BY_NAME`\n    * hex short eg. `&lt;prefix&gt;fff` (prefix can be `#`, `0x` or nothing)\n    * hex long eg. `&lt;prefix&gt;ffffff` (prefix can be `#`, `0x` or nothing)\n    * `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)`\n    * `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)`\n\n    Args:\n        value: A string representing a color.\n\n    Returns:\n        An `RGBA` tuple parsed from the input string.\n\n    Raises:\n        ValueError: If the input string cannot be parsed to an RGBA tuple.\n    \"\"\"\n    value_lower = value.lower()\n    try:\n        r, g, b = COLORS_BY_NAME[value_lower]\n    except KeyError:\n        pass\n    else:\n        return ints_to_rgba(r, g, b, None)\n\n    m = re.fullmatch(r_hex_short, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v * 2, 16) for v in rgb)\n        if a:\n            alpha: Optional[float] = int(a * 2, 16) / 255\n        else:\n            alpha = None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_hex_long, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v, 16) for v in rgb)\n        if a:\n            alpha = int(a, 16) / 255\n        else:\n            alpha = None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_rgb, value_lower) or re.fullmatch(r_rgb_v4_style, value_lower)\n    if m:\n        return ints_to_rgba(*m.groups())  # type: ignore\n\n    m = re.fullmatch(r_hsl, value_lower) or re.fullmatch(r_hsl_v4_style, value_lower)\n    if m:\n        return parse_hsl(*m.groups())  # type: ignore\n\n    raise PydanticCustomError('color_error', 'value is not a valid color: string not recognised as a valid color')\n</code></pre>"},{"location":"api/color/#pydantic.color.parse_tuple","title":"parse_tuple","text":"<pre><code>parse_tuple(value)\n</code></pre> <p>Parse a tuple or list to get RGBA values.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Tuple[Any, ...]</code> <p>A tuple or list.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input tuple.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If tuple is not valid.</p> Source code in <code>pydantic/color.py</code> <pre><code>def parse_tuple(value: Tuple[Any, ...]) -&gt; RGBA:\n\"\"\"Parse a tuple or list to get RGBA values.\n\n    Args:\n        value: A tuple or list.\n\n    Returns:\n        An `RGBA` tuple parsed from the input tuple.\n\n    Raises:\n        PydanticCustomError: If tuple is not valid.\n    \"\"\"\n    if len(value) == 3:\n        r, g, b = (parse_color_value(v) for v in value)\n        return RGBA(r, g, b, None)\n    elif len(value) == 4:\n        r, g, b = (parse_color_value(v) for v in value[:3])\n        return RGBA(r, g, b, parse_float_alpha(value[3]))\n    else:\n        raise PydanticCustomError('color_error', 'value is not a valid color: tuples must have length 3 or 4')\n</code></pre>"},{"location":"api/config/","title":"pydantic.config","text":"<p>Configuration for Pydantic models.</p>"},{"location":"api/config/#pydantic.config.BaseConfig","title":"BaseConfig","text":"<p>This class is only retained for backwards compatibility.</p> <p>Deprecated</p> <p>BaseConfig is deprecated. Use the <code>pydantic.ConfigDict</code> instead.</p>"},{"location":"api/config/#pydantic.config.ConfigDict","title":"ConfigDict","text":"<p>         Bases: <code>TypedDict</code></p> <p>A dictionary-like class for configuring Pydantic models.</p> <p>Attributes:</p> Name Type Description <code>title</code> <code>str | None</code> <p>The title for the generated JSON schema. Defaults to <code>None</code>.</p> <code>str_to_lower</code> <code>bool</code> <p>Whether to convert all characters to lowercase for str &amp; bytes types. Defaults to <code>False</code>.</p> <code>str_to_upper</code> <code>bool</code> <p>Whether to convert all characters to uppercase for str &amp; bytes types. Defaults to <code>False</code>.</p> <code>str_strip_whitespace</code> <code>bool</code> <p>Whether to strip leading and trailing whitespace for str &amp; bytes types. Defaults to <code>False</code>.</p> <code>str_min_length</code> <code>int</code> <p>The minimum length for str &amp; bytes types. Defaults to <code>None</code>.</p> <code>str_max_length</code> <code>int | None</code> <p>The maximum length for str &amp; bytes types. Defaults to <code>None</code>.</p> <code>extra</code> <code>ExtraValues | None</code> <p>Whether to ignore, allow, or forbid extra attributes during model initialization. Accepts the string values of <code>'ignore'</code>, <code>'allow'</code>, or <code>'forbid'</code>. Defaults to <code>'ignore'</code>.</p> <ul> <li><code>'forbid'</code> will cause validation to fail if extra attributes are included.</li> <li><code>'ignore'</code> will silently ignore any extra attributes.</li> <li><code>'allow'</code> will assign the attributes to the model.</li> </ul> <p>See the dedicated section.</p> <code>frozen</code> <code>bool</code> <p>Whether or not models are faux-immutable, i.e. whether <code>__setattr__</code> is allowed, and also generates a <code>__hash__()</code> method for the model. This makes instances of the model potentially hashable if all the attributes are hashable. Defaults to <code>False</code>.</p> <p>Note</p> <p>On V1, this setting was called <code>allow_mutation</code>, and was <code>True</code> by default.</p> <code>populate_by_name</code> <code>bool</code> <p>Whether an aliased field may be populated by its name as given by the model attribute, as well as the alias. Defaults to <code>False</code>.</p> <p>Note</p> <p>The name of this configuration setting was changed in v2.0 from <code>allow_population_by_alias</code> to <code>populate_by_name</code>.</p> <code>use_enum_values</code> <code>bool</code> <p>Whether to populate models with the <code>value</code> property of enums, rather than the raw enum. This may be useful if you want to serialize <code>model.model_dump()</code> later. Defaults to <code>False</code>.</p> <code>validate_assignment</code> <code>bool</code> <p>Whether to perform validation on assignment to attributes. Defaults to <code>False</code>.</p> <code>arbitrary_types_allowed</code> <code>bool</code> <p>Whether to allow arbitrary user types for fields (they are validated simply by checking if the value is an instance of the type). If <code>False</code>, <code>RuntimeError</code> will be raised on model declaration. Defaults to <code>False</code>.</p> <p>See the dedicated section.</p> <code>from_attributes</code> <code>bool</code> <p>Whether to allow model creation from object attributes. Defaults to <code>False</code>.</p> <p>Note</p> <p>The name of this configuration setting was changed in v2.0 from <code>orm_mode</code> to <code>from_attributes</code>.</p> <code>loc_by_alias</code> <code>bool</code> <p>Whether to use the alias for error <code>loc</code>s. Defaults to <code>True</code>.</p> <code>alias_generator</code> <code>Callable[[str], str] | None</code> <p>a callable that takes a field name and returns an alias for it.</p> <p>See the dedicated section.</p> <code>ignored_types</code> <code>tuple[type, ...]</code> <p>A tuple of types that may occur as values of class attributes without annotations. This is typically used for custom descriptors (classes that behave like <code>property</code>). If an attribute is set on a class without an annotation and has a type that is not in this tuple (or otherwise recognized by pydantic), an error will be raised. Defaults to <code>()</code>.</p> <code>allow_inf_nan</code> <code>bool</code> <p>Whether to allow infinity (<code>+inf</code> an <code>-inf</code>) and NaN values to float fields. Defaults to <code>True</code>.</p> <code>json_schema_extra</code> <code>dict[str, object] | JsonSchemaExtraCallable | None</code> <p>A dict or callable to provide extra JSON schema properties. Defaults to <code>None</code>.</p> <code>strict</code> <code>bool</code> <p>Whether to make the configuration strict. Defaults to <code>False</code>.</p> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances']</code> <p>When and how to revalidate models and dataclasses during validation. Accepts the string values of <code>'never'</code>, <code>'always'</code> and <code>'subclass-instances'</code>. Defaults to <code>'never'</code>.</p> <ul> <li><code>'never'</code> will not revalidate models and dataclasses during validation</li> <li><code>'always'</code> will revalidate models and dataclasses during validation</li> <li><code>'subclass-instances'</code> will revalidate models and dataclasses during validation if the instance is a     subclass of the model or dataclass</li> </ul> <p>See the dedicated section.</p> <code>ser_json_timedelta</code> <code>Literal['iso8601', 'float']</code> <p>The format of JSON serialized timedeltas. Accepts the string values of <code>'iso8601'</code> and <code>'float'</code>. Defaults to <code>'iso8601'</code>.</p> <ul> <li><code>'iso8601'</code> will serialize timedeltas to ISO 8601 durations.</li> <li><code>'float'</code> will serialize timedeltas to the total number of seconds.</li> </ul> <code>ser_json_bytes</code> <code>Literal['utf8', 'base64']</code> <p>The encoding of JSON serialized bytes. Accepts the string values of <code>'utf8'</code> and <code>'base64'</code>. Defaults to <code>'utf8'</code>.</p> <ul> <li><code>'utf8'</code> will serialize bytes to UTF-8 strings.</li> <li><code>'base64'</code> will serialize bytes to base64 strings.</li> </ul> <code>validate_default</code> <code>bool</code> <p>Whether to validate default values during validation. Defaults to <code>False</code>.</p> <code>protected_namespaces</code> <code>tuple[str, ...]</code> <p>A <code>tuple</code> of strings that prevent model to have field which conflict with them. Defaults to <code>('model_', )</code>).</p> <p>See the dedicated section.</p> <code>hide_input_in_errors</code> <code>bool</code> <p>Whether to hide inputs when printing errors. Defaults to <code>False</code>.</p> <p>See the dedicated section.</p>"},{"location":"api/dataclasses/","title":"pydantic.dataclasses","text":"<p>Provide an enhanced dataclass that performs validation.</p>"},{"location":"api/dataclasses/#pydantic.dataclasses.dataclass","title":"dataclass","text":"<pre><code>dataclass(\n    _cls=None,\n    *,\n    init=False,\n    repr=True,\n    eq=True,\n    order=False,\n    unsafe_hash=False,\n    frozen=False,\n    config=None,\n    validate_on_init=None,\n    kw_only=False,\n    slots=False\n)\n</code></pre> <p>A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python <code>dataclasses</code>, but with added validation.</p> <p>This function should be used similarly to <code>dataclasses.dataclass</code>.</p> <p>Parameters:</p> Name Type Description Default <code>_cls</code> <code>type[_T] | None</code> <p>The target dataclass.</p> <code>None</code> <code>init</code> <code>Literal[False]</code> <p>Included for signature compatibility with <code>dataclasses.dataclass</code>, and is passed through to <code>dataclasses.dataclass</code> when appropriate. If specified, must be set to <code>False</code>, as pydantic inserts its own  <code>__init__</code> function.</p> <code>False</code> <code>repr</code> <code>bool</code> <p>A boolean indicating whether or not to include the field in the repr output.</p> <code>True</code> <code>eq</code> <code>bool</code> <p>Determines if a <code>__eq__</code> should be generated for the class.</p> <code>True</code> <code>order</code> <code>bool</code> <p>Determines if comparison magic methods should be generated, such as<code>__lt__</code>, but not <code>__eq__</code>.</p> <code>False</code> <code>unsafe_hash</code> <code>bool</code> <p>Determines if an unsafe hashing function should be included in the class.</p> <code>False</code> <code>frozen</code> <code>bool</code> <p>Determines if the generated class should be a 'frozen' dataclass, which does not allow its attributes to be modified from its constructor.</p> <code>False</code> <code>config</code> <code>ConfigDict | type[object] | None</code> <p>A configuration for the dataclass generation.</p> <code>None</code> <code>validate_on_init</code> <code>bool | None</code> <p>A deprecated parameter included for backwards compatibility; in V2, all pydantic dataclasses are validated on init.</p> <code>None</code> <code>kw_only</code> <code>bool</code> <p>Determines if <code>__init__</code> method parameters must be specified by keyword only. Defaults to <code>False</code>.</p> <code>False</code> <code>slots</code> <code>bool</code> <p>Determines if the generated class should be a 'slots' dataclass, which does not allow the addition of new attributes after instantiation.</p> <code>False</code> <p>Returns:</p> Type Description <code>Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]</code> <p>A decorator that accepts a class as its argument and returns a Pydantic dataclass.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>Raised if <code>init</code> is not <code>False</code> or <code>validate_on_init</code> is <code>False</code>.</p> Source code in <code>pydantic/dataclasses.py</code> <pre><code>@dataclass_transform(field_specifiers=(dataclasses.field, Field))\ndef dataclass(\n    _cls: type[_T] | None = None,\n    *,\n    init: Literal[False] = False,\n    repr: bool = True,\n    eq: bool = True,\n    order: bool = False,\n    unsafe_hash: bool = False,\n    frozen: bool = False,\n    config: ConfigDict | type[object] | None = None,\n    validate_on_init: bool | None = None,\n    kw_only: bool = False,\n    slots: bool = False,\n) -&gt; Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:\n\"\"\"A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclasses`,\n    but with added validation.\n\n    This function should be used similarly to `dataclasses.dataclass`.\n\n    Args:\n        _cls: The target dataclass.\n        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to\n            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its\n            own  `__init__` function.\n        repr: A boolean indicating whether or not to include the field in the __repr__ output.\n        eq: Determines if a `__eq__` should be generated for the class.\n        order: Determines if comparison magic methods should be generated, such as` __lt__`, but not `__eq__`.\n        unsafe_hash: Determines if an unsafe hashing function should be included in the class.\n        frozen: Determines if the generated class should be a 'frozen' dataclass, which does not allow its\n            attributes to be modified from its constructor.\n        config: A configuration for the dataclass generation.\n        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all pydantic dataclasses\n            are validated on init.\n        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.\n        slots: Determines if the generated class should be a 'slots' dataclass, which does not allow the addition of\n            new attributes after instantiation.\n\n    Returns:\n        A decorator that accepts a class as its argument and returns a Pydantic dataclass.\n\n    Raises:\n        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.\n    \"\"\"\n    assert init is False, 'pydantic.dataclasses.dataclass only supports init=False'\n    assert validate_on_init is not False, 'validate_on_init=False is no longer supported'\n\n    if sys.version_info &gt;= (3, 10):\n        kwargs = dict(kw_only=kw_only, slots=slots)\n    else:\n        kwargs = {}\n\n    def create_dataclass(cls: type[Any]) -&gt; type[PydanticDataclass]:\n\"\"\"Create a Pydantic dataclass from a regular dataclass.\n\n        Args:\n            cls: The class to create the Pydantic dataclass from.\n\n        Returns:\n            A Pydantic dataclass.\n        \"\"\"\n        original_cls = cls\n\n        config_dict = config\n        if config_dict is None:\n            # if not explicitly provided, read from the type\n            cls_config = getattr(cls, '__pydantic_config__', None)\n            if cls_config is not None:\n                config_dict = cls_config\n        config_wrapper = _config.ConfigWrapper(config_dict)\n        decorators = _decorators.DecoratorInfos.build(cls)\n\n        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator\n        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,\n        # since dataclasses.dataclass will set this as the __doc__\n        original_doc = cls.__doc__\n\n        if _pydantic_dataclasses.is_builtin_dataclass(cls):\n            # Don't preserve the docstring for vanilla dataclasses, as it may include the signature\n            # This matches v1 behavior, and there was an explicit test for it\n            original_doc = None\n\n            # We don't want to add validation to the existing std lib dataclass, so we will subclass it\n            #   If the class is generic, we need to make sure the subclass also inherits from Generic\n            #   with all the same parameters.\n            bases = (cls,)\n            if issubclass(cls, Generic):  # type: ignore\n                generic_base = Generic[cls.__parameters__]  # type: ignore\n                bases = bases + (generic_base,)\n            cls = types.new_class(cls.__name__, bases)\n\n        cls = dataclasses.dataclass(  # type: ignore[call-overload]\n            cls,\n            init=init,\n            repr=repr,\n            eq=eq,\n            order=order,\n            unsafe_hash=unsafe_hash,\n            frozen=frozen,\n            **kwargs,\n        )\n\n        cls.__pydantic_decorators__ = decorators  # type: ignore\n        cls.__doc__ = original_doc\n        cls.__module__ = original_cls.__module__\n        cls.__qualname__ = original_cls.__qualname__\n        pydantic_complete = _pydantic_dataclasses.complete_dataclass(\n            cls, config_wrapper, raise_errors=False, types_namespace=None\n        )\n        cls.__pydantic_complete__ = pydantic_complete  # type: ignore\n        return cls\n\n    if _cls is None:\n        return create_dataclass\n\n    return create_dataclass(_cls)\n</code></pre>"},{"location":"api/dataclasses/#pydantic.dataclasses.rebuild_dataclass","title":"rebuild_dataclass","text":"<pre><code>rebuild_dataclass(\n    cls,\n    *,\n    force=False,\n    raise_errors=True,\n    _parent_namespace_depth=2,\n    _types_namespace=None\n)\n</code></pre> <p>Try to rebuild the pydantic-core schema for the dataclass.</p> <p>This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.</p> <p>This is analogous to <code>BaseModel.model_rebuild</code>.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[PydanticDataclass]</code> <p>The class to build the dataclass core schema for.</p> required <code>force</code> <code>bool</code> <p>Whether to force the rebuilding of the model schema, defaults to <code>False</code>.</p> <code>False</code> <code>raise_errors</code> <code>bool</code> <p>Whether to raise errors, defaults to <code>True</code>.</p> <code>True</code> <code>_parent_namespace_depth</code> <code>int</code> <p>The depth level of the parent namespace, defaults to 2.</p> <code>2</code> <code>_types_namespace</code> <code>dict[str, Any] | None</code> <p>The types namespace, defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>Returns <code>None</code> if the schema is already \"complete\" and rebuilding was not required.</p> <code>bool | None</code> <p>If rebuilding was required, returns <code>True</code> if rebuilding was successful, otherwise <code>False</code>.</p> Source code in <code>pydantic/dataclasses.py</code> <pre><code>def rebuild_dataclass(\n    cls: type[PydanticDataclass],\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None,\n) -&gt; bool | None:\n\"\"\"Try to rebuild the pydantic-core schema for the dataclass.\n\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n    the initial attempt to build the schema, and automatic rebuilding fails.\n\n    This is analogous to `BaseModel.model_rebuild`.\n\n    Args:\n        cls: The class to build the dataclass core schema for.\n        force: Whether to force the rebuilding of the model schema, defaults to `False`.\n        raise_errors: Whether to raise errors, defaults to `True`.\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n        _types_namespace: The types namespace, defaults to `None`.\n\n    Returns:\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n    \"\"\"\n    if not force and cls.__pydantic_complete__:\n        return None\n    else:\n        if _types_namespace is not None:\n            types_namespace: dict[str, Any] | None = _types_namespace.copy()\n        else:\n            if _parent_namespace_depth &gt; 0:\n                frame_parent_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth) or {}\n                # Note: we may need to add something similar to cls.__pydantic_parent_namespace__ from BaseModel\n                #   here when implementing handling of recursive generics. See BaseModel.model_rebuild for reference.\n                types_namespace = frame_parent_ns\n            else:\n                types_namespace = {}\n\n            types_namespace = _typing_extra.get_cls_types_namespace(cls, types_namespace)\n        return _pydantic_dataclasses.complete_dataclass(\n            cls,\n            _config.ConfigWrapper(cls.__pydantic_config__, check=False),\n            raise_errors=raise_errors,\n            types_namespace=types_namespace,\n        )\n</code></pre>"},{"location":"api/errors/","title":"pydantic.errors","text":"<p>Pydantic-specific errors.</p>"},{"location":"api/errors/#pydantic.errors.PydanticErrorMixin","title":"PydanticErrorMixin","text":"<pre><code>PydanticErrorMixin(message, *, code)\n</code></pre> <p>A mixin class for common functionality shared by all Pydantic-specific errors.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>A message describing the error.</p> <code>code</code> <p>An optional error code from PydanticErrorCodes enum.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str, *, code: PydanticErrorCodes | None) -&gt; None:\n    self.message = message\n    self.code = code\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticImportError","title":"PydanticImportError","text":"<pre><code>PydanticImportError(message)\n</code></pre> <p>         Bases: <code>PydanticErrorMixin</code>, <code>ImportError</code></p> <p>An error raised when an import fails due to module changes between V1 and V2.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='import-error')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticInvalidForJsonSchema","title":"PydanticInvalidForJsonSchema","text":"<pre><code>PydanticInvalidForJsonSchema(message)\n</code></pre> <p>         Bases: <code>PydanticUserError</code></p> <p>An error raised during failures to generate a JSON schema for some <code>CoreSchema</code>.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='invalid-for-json-schema')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticSchemaGenerationError","title":"PydanticSchemaGenerationError","text":"<pre><code>PydanticSchemaGenerationError(message)\n</code></pre> <p>         Bases: <code>PydanticUserError</code></p> <p>An error raised during failures to generate a <code>CoreSchema</code> for some type.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='schema-for-unknown-type')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUndefinedAnnotation","title":"PydanticUndefinedAnnotation","text":"<pre><code>PydanticUndefinedAnnotation(name, message)\n</code></pre> <p>         Bases: <code>PydanticErrorMixin</code>, <code>NameError</code></p> <p>A subclass of <code>NameError</code> raised when handling undefined annotations during <code>CoreSchema</code> generation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>Name of the error.</p> <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, name: str, message: str) -&gt; None:\n    self.name = name\n    super().__init__(message=message, code='undefined-annotation')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUndefinedAnnotation.from_name_error","title":"from_name_error  <code>classmethod</code>","text":"<pre><code>from_name_error(name_error)\n</code></pre> <p>Convert a <code>NameError</code> to a <code>PydanticUndefinedAnnotation</code> error.</p> <p>Parameters:</p> Name Type Description Default <code>name_error</code> <code>NameError</code> <p><code>NameError</code> to be converted.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Converted <code>PydanticUndefinedAnnotation</code> error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>@classmethod\ndef from_name_error(cls, name_error: NameError) -&gt; Self:\n\"\"\"Convert a `NameError` to a `PydanticUndefinedAnnotation` error.\n\n    Args:\n        name_error: `NameError` to be converted.\n\n    Returns:\n        Converted `PydanticUndefinedAnnotation` error.\n    \"\"\"\n    try:\n        name = name_error.name  # type: ignore  # python &gt; 3.10\n    except AttributeError:\n        name = re.search(r\".*'(.+?)'\", str(name_error)).group(1)  # type: ignore[union-attr]\n    return cls(name=name, message=str(name_error))\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUserError","title":"PydanticUserError","text":"<p>         Bases: <code>PydanticErrorMixin</code>, <code>TypeError</code></p> <p>An error raised due to incorrect use of Pydantic.</p>"},{"location":"api/fields/","title":"pydantic.fields","text":"<p>Defining fields on models.</p>"},{"location":"api/fields/#pydantic.fields.AliasChoices","title":"AliasChoices","text":"<pre><code>AliasChoices(first_choice, *choices)\n</code></pre> <p>A data class used by <code>validation_alias</code> as a convenience to create aliases.</p> <p>Attributes:</p> Name Type Description <code>choices</code> <code>list[str | AliasPath]</code> <p>A list containing a string or <code>AliasPath</code>.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(self, first_choice: str | AliasPath, *choices: str | AliasPath) -&gt; None:\n    self.choices = [first_choice] + list(choices)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.AliasChoices.convert_to_aliases","title":"convert_to_aliases","text":"<pre><code>convert_to_aliases()\n</code></pre> <p>Converts arguments to a list of lists containing string or integer aliases.</p> <p>Returns:</p> Type Description <code>list[list[str | int]]</code> <p>The list of aliases.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def convert_to_aliases(self) -&gt; list[list[str | int]]:\n\"\"\"Converts arguments to a list of lists containing string or integer aliases.\n\n    Returns:\n        The list of aliases.\n    \"\"\"\n    aliases: list[list[str | int]] = []\n    for c in self.choices:\n        if isinstance(c, AliasPath):\n            aliases.append(c.convert_to_aliases())\n        else:\n            aliases.append([c])\n    return aliases\n</code></pre>"},{"location":"api/fields/#pydantic.fields.AliasPath","title":"AliasPath","text":"<pre><code>AliasPath(first_arg, *args)\n</code></pre> <p>A data class used by <code>validation_alias</code> as a convenience to create aliases.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>list[int | str]</code> <p>A list of string or integer aliases.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(self, first_arg: str, *args: str | int) -&gt; None:\n    self.path = [first_arg] + list(args)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.AliasPath.convert_to_aliases","title":"convert_to_aliases","text":"<pre><code>convert_to_aliases()\n</code></pre> <p>Converts arguments to a list of string or integer aliases.</p> <p>Returns:</p> Type Description <code>list[str | int]</code> <p>The list of aliases.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def convert_to_aliases(self) -&gt; list[str | int]:\n\"\"\"Converts arguments to a list of string or integer aliases.\n\n    Returns:\n        The list of aliases.\n    \"\"\"\n    return self.path\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ComputedFieldInfo","title":"ComputedFieldInfo","text":"<p>A container for data from <code>@computed_field</code> so that we can access it while building the pydantic-core schema.</p> <p>Attributes:</p> Name Type Description <code>decorator_repr</code> <code>typing.ClassVar[str]</code> <p>A class variable representing the decorator string, '@computed_field'.</p> <code>wrapped_property</code> <code>property</code> <p>The wrapped computed field property.</p> <code>return_type</code> <code>type[Any]</code> <p>The type of the computed field property's return value.</p> <code>alias</code> <code>str | None</code> <p>The alias of the property to be used during encoding and decoding.</p> <code>alias_priority</code> <code>int | None</code> <p>priority of the alias. This affects whether an alias generator is used</p> <code>title</code> <code>str | None</code> <p>Title of the computed field as in OpenAPI document, should be a short summary.</p> <code>description</code> <code>str | None</code> <p>Description of the computed field as in OpenAPI document.</p> <code>repr</code> <code>bool</code> <p>A boolean indicating whether or not to include the field in the repr output.</p>"},{"location":"api/fields/#pydantic.fields.FieldInfo","title":"FieldInfo","text":"<pre><code>FieldInfo(**kwargs)\n</code></pre> <p>         Bases: <code>_repr.Representation</code></p> <p>This class holds information about a field.</p> <p><code>FieldInfo</code> is used for any field definition regardless of whether the <code>Field()</code> function is explicitly used.</p> <p>Attributes:</p> Name Type Description <code>annotation</code> <code>type[Any] | None</code> <p>The type annotation of the field.</p> <code>default</code> <code>Any</code> <p>The default value of the field.</p> <code>default_factory</code> <code>typing.Callable[[], Any] | None</code> <p>The factory function used to construct the default for the field.</p> <code>alias</code> <code>str | None</code> <p>The alias name of the field.</p> <code>alias_priority</code> <code>int | None</code> <p>The priority of the field's alias.</p> <code>validation_alias</code> <code>str | AliasPath | AliasChoices | None</code> <p>The validation alias name of the field.</p> <code>serialization_alias</code> <code>str | None</code> <p>The serialization alias name of the field.</p> <code>title</code> <code>str | None</code> <p>The title of the field.</p> <code>description</code> <code>str | None</code> <p>The description of the field.</p> <code>examples</code> <code>list[Any] | None</code> <p>List of examples of the field.</p> <code>exclude</code> <code>bool | None</code> <p>Whether to exclude the field from the model schema.</p> <code>include</code> <code>bool | None</code> <p>Whether to include the field in the model schema.</p> <code>discriminator</code> <code>str | None</code> <p>Field name for discriminating the type in a tagged union.</p> <code>json_schema_extra</code> <code>dict[str, Any] | None</code> <p>Dictionary of extra JSON schema properties.</p> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen.</p> <code>final</code> <code>bool | None</code> <p>Whether the field is final.</p> <code>validate_default</code> <code>bool | None</code> <p>Whether to validate the default value of the field.</p> <code>repr</code> <code>bool</code> <p>Whether to include the field in representation of the model.</p> <code>init_var</code> <code>bool | None</code> <p>Whether the field should be included in the constructor of the dataclass.</p> <code>kw_only</code> <code>bool | None</code> <p>Whether the field should be a keyword-only argument in the constructor of the dataclass.</p> <code>metadata</code> <code>list[Any]</code> <p>List of metadata constraints.</p> <p>See the signature of <code>pydantic.fields.Field</code> for more details about the expected arguments.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -&gt; None:\n\"\"\"This class should generally not be initialized directly; instead, use the `pydantic.fields.Field` function\n    or one of the constructor classmethods.\n\n    See the signature of `pydantic.fields.Field` for more details about the expected arguments.\n    \"\"\"\n    self.annotation, annotation_metadata = self._extract_metadata(kwargs.get('annotation'))\n\n    default = kwargs.pop('default', PydanticUndefined)\n    if default is Ellipsis:\n        self.default = PydanticUndefined\n    else:\n        self.default = default\n\n    self.default_factory = kwargs.pop('default_factory', None)\n\n    if self.default is not PydanticUndefined and self.default_factory is not None:\n        raise TypeError('cannot specify both default and default_factory')\n\n    self.title = kwargs.pop('title', None)\n    self.alias = kwargs.pop('alias', None)\n    self.validation_alias = kwargs.pop('validation_alias', None)\n    self.serialization_alias = kwargs.pop('serialization_alias', None)\n    alias_is_set = any(alias is not None for alias in (self.alias, self.validation_alias, self.serialization_alias))\n    self.alias_priority = kwargs.pop('alias_priority', None) or 2 if alias_is_set else None\n    self.description = kwargs.pop('description', None)\n    self.examples = kwargs.pop('examples', None)\n    self.exclude = kwargs.pop('exclude', None)\n    self.include = kwargs.pop('include', None)\n    self.discriminator = kwargs.pop('discriminator', None)\n    self.repr = kwargs.pop('repr', True)\n    self.json_schema_extra = kwargs.pop('json_schema_extra', None)\n    self.validate_default = kwargs.pop('validate_default', None)\n    self.frozen = kwargs.pop('frozen', None)\n    self.final = kwargs.pop('final', None)\n    # currently only used on dataclasses\n    self.init_var = kwargs.pop('init_var', None)\n    self.kw_only = kwargs.pop('kw_only', None)\n\n    self.metadata = self._collect_metadata(kwargs) + annotation_metadata  # type: ignore\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.apply_typevars_map","title":"apply_typevars_map","text":"<pre><code>apply_typevars_map(typevars_map, types_namespace)\n</code></pre> <p>Apply a <code>typevars_map</code> to the annotation.</p> <p>This method is used when analyzing parametrized generic types to replace typevars with their concrete types.</p> <p>This method applies the <code>typevars_map</code> to the annotation in place.</p> <p>Parameters:</p> Name Type Description Default <code>typevars_map</code> <code>dict[Any, Any] | None</code> <p>A dictionary mapping type variables to their concrete types.</p> required <code>types_namespace</code> <code>dict | None</code> <p>A dictionary containing related types to the annotated type.</p> required See Also <p>pydantic._internal._generics.replace_types is used for replacing the typevars with     their concrete types.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def apply_typevars_map(self, typevars_map: dict[Any, Any] | None, types_namespace: dict[str, Any] | None) -&gt; None:\n\"\"\"Apply a `typevars_map` to the annotation.\n\n    This method is used when analyzing parametrized generic types to replace typevars with their concrete types.\n\n    This method applies the `typevars_map` to the annotation in place.\n\n    Args:\n        typevars_map: A dictionary mapping type variables to their concrete types.\n        types_namespace (dict | None): A dictionary containing related types to the annotated type.\n\n    See Also:\n        pydantic._internal._generics.replace_types is used for replacing the typevars with\n            their concrete types.\n    \"\"\"\n    annotation = _typing_extra.eval_type_lenient(self.annotation, types_namespace, None)\n    self.annotation = _generics.replace_types(annotation, typevars_map)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_annotated_attribute","title":"from_annotated_attribute  <code>classmethod</code>","text":"<pre><code>from_annotated_attribute(annotation, default)\n</code></pre> <p>Create <code>FieldInfo</code> from an annotation with a default value.</p> <p>Parameters:</p> Name Type Description Default <code>annotation</code> <code>type[Any]</code> <p>The type annotation of the field.</p> required <code>default</code> <code>Any</code> <p>The default value of the field.</p> required <p>Returns:</p> Type Description <code>typing_extensions.Self</code> <p>A field object with the passed values.</p> Example <pre><code>import pydantic, annotated_types, typing\n\nclass MyModel(pydantic.BaseModel):\n    foo: int = 4  # &lt;-- like this\n    bar: typing.Annotated[int, annotated_types.Gt(4)] = 4  # &lt;-- or this\n    spam: typing.Annotated[int, pydantic.Field(gt=4)] = 4  # &lt;-- or this\n</code></pre> Source code in <code>pydantic/fields.py</code> <pre><code>@classmethod\ndef from_annotated_attribute(cls, annotation: type[Any], default: Any) -&gt; typing_extensions.Self:\n\"\"\"Create `FieldInfo` from an annotation with a default value.\n\n    Args:\n        annotation: The type annotation of the field.\n        default: The default value of the field.\n\n    Returns:\n        A field object with the passed values.\n\n    Example:\n        ```python\n        import pydantic, annotated_types, typing\n\n        class MyModel(pydantic.BaseModel):\n            foo: int = 4  # &lt;-- like this\n            bar: typing.Annotated[int, annotated_types.Gt(4)] = 4  # &lt;-- or this\n            spam: typing.Annotated[int, pydantic.Field(gt=4)] = 4  # &lt;-- or this\n        ```\n    \"\"\"\n    final = False\n    if _typing_extra.is_finalvar(annotation):\n        final = True\n        if annotation is not typing_extensions.Final:\n            annotation = typing_extensions.get_args(annotation)[0]\n\n    if isinstance(default, cls):\n        default.annotation, annotation_metadata = cls._extract_metadata(annotation)\n        default.metadata += annotation_metadata\n        default.final = final\n        return default\n    elif isinstance(default, dataclasses.Field):\n        init_var = False\n        if annotation is dataclasses.InitVar:\n            if sys.version_info &lt; (3, 8):\n                raise RuntimeError('InitVar is not supported in Python 3.7 as type information is lost')\n\n            init_var = True\n            annotation = Any\n        elif isinstance(annotation, dataclasses.InitVar):\n            init_var = True\n            annotation = annotation.type\n        pydantic_field = cls._from_dataclass_field(default)\n        pydantic_field.annotation, annotation_metadata = cls._extract_metadata(annotation)\n        pydantic_field.metadata += annotation_metadata\n        pydantic_field.final = final\n        pydantic_field.init_var = init_var\n        pydantic_field.kw_only = getattr(default, 'kw_only', None)\n        return pydantic_field\n    else:\n        if _typing_extra.is_annotated(annotation):\n            first_arg, *extra_args = typing_extensions.get_args(annotation)\n            field_info = cls._find_field_info_arg(extra_args)\n            if field_info is not None:\n                if not field_info.is_required():\n                    raise TypeError('Default may not be specified twice on the same field')\n                new_field_info = copy(field_info)\n                new_field_info.default = default\n                new_field_info.annotation = first_arg\n                new_field_info.metadata += [a for a in extra_args if not isinstance(a, FieldInfo)]\n                return new_field_info\n\n        return cls(annotation=annotation, default=default, final=final)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_annotation","title":"from_annotation  <code>classmethod</code>","text":"<pre><code>from_annotation(annotation)\n</code></pre> <p>Creates a <code>FieldInfo</code> instance from a bare annotation.</p> <p>Parameters:</p> Name Type Description Default <code>annotation</code> <code>type[Any]</code> <p>An annotation object.</p> required <p>Returns:</p> Type Description <code>typing_extensions.Self</code> <p>An instance of the field metadata.</p> Example <p>This is how you can create a field from a bare annotation like this:</p> <pre><code>import pydantic\nclass MyModel(pydantic.BaseModel):\n    foo: int  # &lt;-- like this\n</code></pre> <p>We also account for the case where the annotation can be an instance of <code>Annotated</code> and where one of the (not first) arguments in <code>Annotated</code> are an instance of <code>FieldInfo</code>, e.g.:</p> <pre><code>import pydantic, annotated_types, typing\n\nclass MyModel(pydantic.BaseModel):\n    foo: typing.Annotated[int, annotated_types.Gt(42)]\n    bar: typing.Annotated[int, Field(gt=42)]\n</code></pre> Source code in <code>pydantic/fields.py</code> <pre><code>@classmethod\ndef from_annotation(cls, annotation: type[Any]) -&gt; typing_extensions.Self:\n\"\"\"Creates a `FieldInfo` instance from a bare annotation.\n\n    Args:\n        annotation: An annotation object.\n\n    Returns:\n        An instance of the field metadata.\n\n    Example:\n        This is how you can create a field from a bare annotation like this:\n\n        ```python\n        import pydantic\n        class MyModel(pydantic.BaseModel):\n            foo: int  # &lt;-- like this\n        ```\n\n        We also account for the case where the annotation can be an instance of `Annotated` and where\n        one of the (not first) arguments in `Annotated` are an instance of `FieldInfo`, e.g.:\n\n        ```python\n        import pydantic, annotated_types, typing\n\n        class MyModel(pydantic.BaseModel):\n            foo: typing.Annotated[int, annotated_types.Gt(42)]\n            bar: typing.Annotated[int, Field(gt=42)]\n        ```\n\n    \"\"\"\n    final = False\n    if _typing_extra.is_finalvar(annotation):\n        final = True\n        if annotation is not typing_extensions.Final:\n            annotation = typing_extensions.get_args(annotation)[0]\n\n    if _typing_extra.is_annotated(annotation):\n        first_arg, *extra_args = typing_extensions.get_args(annotation)\n        if _typing_extra.is_finalvar(first_arg):\n            final = True\n        field_info = cls._find_field_info_arg(extra_args)\n        if field_info:\n            new_field_info = copy(field_info)\n            new_field_info.annotation = first_arg\n            new_field_info.final = final\n            new_field_info.metadata += [a for a in extra_args if not isinstance(a, FieldInfo)]\n            return new_field_info\n\n    return cls(annotation=annotation, final=final)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_field","title":"from_field  <code>classmethod</code>","text":"<pre><code>from_field(default=PydanticUndefined, **kwargs)\n</code></pre> <p>Create a new <code>FieldInfo</code> object with the <code>Field</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The default value for the field. Defaults to Undefined.</p> <code>PydanticUndefined</code> <code>**kwargs</code> <code>Unpack[_FromFieldInfoInputs]</code> <p>Additional arguments dictionary.</p> <code>{}</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If 'annotation' is passed as a keyword argument.</p> <p>Returns:</p> Type Description <code>typing_extensions.Self</code> <p>A new FieldInfo object with the given parameters.</p> Example <p>This is how you can create a field with default value like this:</p> <pre><code>import pydantic\n\nclass MyModel(pydantic.BaseModel):\n    foo: int = pydantic.Field(4, ...)\n</code></pre> Source code in <code>pydantic/fields.py</code> <pre><code>@classmethod\ndef from_field(\n    cls, default: Any = PydanticUndefined, **kwargs: Unpack[_FromFieldInfoInputs]\n) -&gt; typing_extensions.Self:\n\"\"\"Create a new `FieldInfo` object with the `Field` function.\n\n    Args:\n        default: The default value for the field. Defaults to Undefined.\n        **kwargs: Additional arguments dictionary.\n\n    Raises:\n        TypeError: If 'annotation' is passed as a keyword argument.\n\n    Returns:\n        A new FieldInfo object with the given parameters.\n\n    Example:\n        This is how you can create a field with default value like this:\n\n        ```python\n        import pydantic\n\n        class MyModel(pydantic.BaseModel):\n            foo: int = pydantic.Field(4, ...)\n        ```\n    \"\"\"\n    if 'annotation' in kwargs:\n        raise TypeError('\"annotation\" is not permitted as a Field keyword argument')\n    return cls(default=default, **kwargs)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.get_default","title":"get_default","text":"<pre><code>get_default(*, call_default_factory=False)\n</code></pre> <p>Get the default value.</p> <p>We expose an option for whether to call the default_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via <code>model_construct</code>).</p> <p>Parameters:</p> Name Type Description Default <code>call_default_factory</code> <code>bool</code> <p>Whether to call the default_factory or not. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>The default value, calling the default factory if requested or <code>None</code> if not set.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def get_default(self, *, call_default_factory: bool = False) -&gt; Any:\n\"\"\"Get the default value.\n\n    We expose an option for whether to call the default_factory (if present), as calling it may\n    result in side effects that we want to avoid. However, there are times when it really should\n    be called (namely, when instantiating a model via `model_construct`).\n\n    Args:\n        call_default_factory: Whether to call the default_factory or not. Defaults to `False`.\n\n    Returns:\n        The default value, calling the default factory if requested or `None` if not set.\n    \"\"\"\n    if self.default_factory is None:\n        return _utils.smart_deepcopy(self.default)\n    elif call_default_factory:\n        return self.default_factory()\n    else:\n        return None\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.is_required","title":"is_required","text":"<pre><code>is_required()\n</code></pre> <p>Check if the argument is required.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the argument is required, <code>False</code> otherwise.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def is_required(self) -&gt; bool:\n\"\"\"Check if the argument is required.\n\n    Returns:\n        `True` if the argument is required, `False` otherwise.\n    \"\"\"\n    return self.default is PydanticUndefined and self.default_factory is None\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.rebuild_annotation","title":"rebuild_annotation","text":"<pre><code>rebuild_annotation()\n</code></pre> <p>Rebuilds the original annotation for use in function signatures.</p> <p>If metadata is present, it adds it to the original annotation using an <code>AnnotatedAlias</code>. Otherwise, it returns the original annotation as is.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The rebuilt annotation.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def rebuild_annotation(self) -&gt; Any:\n\"\"\"Rebuilds the original annotation for use in function signatures.\n\n    If metadata is present, it adds it to the original annotation using an\n    `AnnotatedAlias`. Otherwise, it returns the original annotation as is.\n\n    Returns:\n        The rebuilt annotation.\n    \"\"\"\n    if not self.metadata:\n        return self.annotation\n    else:\n        # Annotated arguments must be a tuple\n        return typing_extensions.Annotated[(self.annotation, *self.metadata)]  # type: ignore\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ModelPrivateAttr","title":"ModelPrivateAttr","text":"<pre><code>ModelPrivateAttr(\n    default=PydanticUndefined, *, default_factory=None\n)\n</code></pre> <p>         Bases: <code>_repr.Representation</code></p> <p>A descriptor for private attributes in class models.</p> <p>Attributes:</p> Name Type Description <code>default</code> <p>The default value of the attribute if not provided.</p> <code>default_factory</code> <p>A callable function that generates the default value of the attribute if not provided.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(\n    self, default: Any = PydanticUndefined, *, default_factory: typing.Callable[[], Any] | None = None\n) -&gt; None:\n    self.default = default\n    self.default_factory = default_factory\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ModelPrivateAttr.get_default","title":"get_default","text":"<pre><code>get_default()\n</code></pre> <p>Retrieve the default value of the object.</p> <p>If <code>self.default_factory</code> is <code>None</code>, the method will return a deep copy of the <code>self.default</code> object.</p> <p>If <code>self.default_factory</code> is not <code>None</code>, it will call <code>self.default_factory</code> and return the value returned.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The default value of the object.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def get_default(self) -&gt; Any:\n\"\"\"Retrieve the default value of the object.\n\n    If `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\n\n    If `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\n\n    Returns:\n        The default value of the object.\n    \"\"\"\n    return _utils.smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\n</code></pre>"},{"location":"api/fields/#pydantic.fields.Field","title":"Field","text":"<pre><code>Field(\n    default=PydanticUndefined,\n    *,\n    default_factory=None,\n    alias=None,\n    alias_priority=None,\n    validation_alias=None,\n    serialization_alias=None,\n    title=None,\n    description=None,\n    examples=None,\n    exclude=None,\n    include=None,\n    discriminator=None,\n    json_schema_extra=None,\n    frozen=None,\n    final=None,\n    validate_default=None,\n    repr=True,\n    init_var=None,\n    kw_only=None,\n    pattern=None,\n    strict=None,\n    gt=None,\n    ge=None,\n    lt=None,\n    le=None,\n    multiple_of=None,\n    allow_inf_nan=None,\n    max_digits=None,\n    decimal_places=None,\n    min_length=None,\n    max_length=None,\n    **extra\n)\n</code></pre> <p>Create a field for objects that can be configured.</p> <p>Used to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (<code>int</code>, <code>float</code>, <code>Decimal</code>) and some apply only to <code>str</code>.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>Default value if the field is not set.</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>typing.Callable[[], Any] | None</code> <p>A callable to generate the default value, such as :func:<code>~datetime.utcnow</code>.</p> <code>None</code> <code>alias</code> <code>str | None</code> <p>An alternative name for the attribute.</p> <code>None</code> <code>alias_priority</code> <code>int | None</code> <p>Priority of the alias. This affects whether an alias generator is used.</p> <code>None</code> <code>validation_alias</code> <code>str | AliasPath | AliasChoices | None</code> <p>'Whitelist' validation step. The field will be the single one allowed by the alias or set of aliases defined.</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>'Blacklist' validation step. The vanilla field will be the single one of the alias' or set of aliases' fields and all the other fields will be ignored at serialization time.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Human-readable title.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Human-readable description.</p> <code>None</code> <code>examples</code> <code>list[Any] | None</code> <p>Example values for this field.</p> <code>None</code> <code>exclude</code> <code>bool | None</code> <p>Whether to exclude the field from the model schema.</p> <code>None</code> <code>include</code> <code>bool | None</code> <p>Whether to include the field in the model schema.</p> <code>None</code> <code>discriminator</code> <code>str | None</code> <p>Field name for discriminating the type in a tagged union.</p> <code>None</code> <code>json_schema_extra</code> <code>dict[str, Any] | None</code> <p>Any additional JSON schema data for the schema property.</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen.</p> <code>None</code> <code>final</code> <code>bool | None</code> <p>Whether the field is final.</p> <code>None</code> <code>validate_default</code> <code>bool | None</code> <p>Run validation that isn't only checking existence of defaults. <code>True</code> by default.</p> <code>None</code> <code>repr</code> <code>bool</code> <p>A boolean indicating whether to include the field in the <code>__repr__</code> output.</p> <code>True</code> <code>init_var</code> <code>bool | None</code> <p>Whether the field should be included in the constructor of the dataclass.</p> <code>None</code> <code>kw_only</code> <code>bool | None</code> <p>Whether the field should be a keyword-only argument in the constructor of the dataclass.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>If <code>True</code> (the default is <code>None</code>), the field should be validated strictly.</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>Greater than. If set, value must be greater than this. Only applicable to numbers.</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>Less than. If set, value must be less than this. Only applicable to numbers.</p> <code>None</code> <code>le</code> <code>float | None</code> <p>Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.</p> <code>None</code> <code>multiple_of</code> <code>float | None</code> <p>Value must be a multiple of this. Only applicable to numbers.</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>Minimum length for strings.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>Maximum length for strings.</p> <code>None</code> <code>pattern</code> <code>str | None</code> <p>Pattern for strings.</p> <code>None</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Allow <code>inf</code>, <code>-inf</code>, <code>nan</code>. Only applicable to numbers.</p> <code>None</code> <code>max_digits</code> <code>int | None</code> <p>Maximum number of allow digits for strings.</p> <code>None</code> <code>decimal_places</code> <code>int | None</code> <p>Maximum number of decimal places allowed for numbers.</p> <code>None</code> <code>extra</code> <code>Unpack[_EmptyKwargs]</code> <p>Include extra fields used by the JSON schema.</p> <p>Warning</p> <p>The <code>extra</code> kwargs is deprecated. Use <code>json_schema_extra</code> instead.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The generated <code>FieldInfo</code> object</p> Source code in <code>pydantic/fields.py</code> <pre><code>def Field(  # C901\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: typing.Callable[[], Any] | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = None,\n    validation_alias: str | AliasPath | AliasChoices | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    examples: list[Any] | None = None,\n    exclude: bool | None = None,\n    include: bool | None = None,\n    discriminator: str | None = None,\n    json_schema_extra: dict[str, Any] | None = None,\n    frozen: bool | None = None,\n    final: bool | None = None,\n    validate_default: bool | None = None,\n    repr: bool = True,\n    init_var: bool | None = None,\n    kw_only: bool | None = None,\n    pattern: str | None = None,\n    strict: bool | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    multiple_of: float | None = None,\n    allow_inf_nan: bool | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    **extra: Unpack[_EmptyKwargs],\n) -&gt; Any:\n\"\"\"Create a field for objects that can be configured.\n\n    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\n    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\n\n    Args:\n        default: Default value if the field is not set.\n        default_factory: A callable to generate the default value, such as :func:`~datetime.utcnow`.\n        alias: An alternative name for the attribute.\n        alias_priority: Priority of the alias. This affects whether an alias generator is used.\n        validation_alias: 'Whitelist' validation step. The field will be the single one allowed by the alias or set of\n            aliases defined.\n        serialization_alias: 'Blacklist' validation step. The vanilla field will be the single one of the alias' or set\n            of aliases' fields and all the other fields will be ignored at serialization time.\n        title: Human-readable title.\n        description: Human-readable description.\n        examples: Example values for this field.\n        exclude: Whether to exclude the field from the model schema.\n        include: Whether to include the field in the model schema.\n        discriminator: Field name for discriminating the type in a tagged union.\n        json_schema_extra: Any additional JSON schema data for the schema property.\n        frozen: Whether the field is frozen.\n        final: Whether the field is final.\n        validate_default: Run validation that isn't only checking existence of defaults. `True` by default.\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\n        init_var: Whether the field should be included in the constructor of the dataclass.\n        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\n        strict: If `True` (the default is `None`), the field should be validated strictly.\n        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\n        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\n        lt: Less than. If set, value must be less than this. Only applicable to numbers.\n        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\n        multiple_of: Value must be a multiple of this. Only applicable to numbers.\n        min_length: Minimum length for strings.\n        max_length: Maximum length for strings.\n        pattern: Pattern for strings.\n        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to numbers.\n        max_digits: Maximum number of allow digits for strings.\n        decimal_places: Maximum number of decimal places allowed for numbers.\n        extra: Include extra fields used by the JSON schema.\n\n            !!! warning Deprecated\n                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\n\n    Returns:\n        The generated `FieldInfo` object\n    \"\"\"\n    # Check deprecated and removed params from V1. This logic should eventually be removed.\n    const = extra.pop('const', None)  # type: ignore\n    if const is not None:\n        raise PydanticUserError('`const` is removed, use `Literal` instead', code='removed-kwargs')\n\n    min_items = extra.pop('min_items', None)  # type: ignore\n    if min_items is not None:\n        warn('`min_items` is deprecated and will be removed, use `min_length` instead', DeprecationWarning)\n        if min_length is None:\n            min_length = min_items  # type: ignore\n\n    max_items = extra.pop('max_items', None)  # type: ignore\n    if max_items is not None:\n        warn('`max_items` is deprecated and will be removed, use `max_length` instead', DeprecationWarning)\n        if max_length is None:\n            max_length = max_items  # type: ignore\n\n    unique_items = extra.pop('unique_items', None)  # type: ignore\n    if unique_items is not None:\n        raise PydanticUserError(\n            (\n                '`unique_items` is removed, use `Set` instead'\n                '(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)'\n            ),\n            code='removed-kwargs',\n        )\n\n    allow_mutation = extra.pop('allow_mutation', None)  # type: ignore\n    if allow_mutation is not None:\n        warn('`allow_mutation` is deprecated and will be removed. use `frozen` instead', DeprecationWarning)\n        if allow_mutation is False:\n            frozen = True\n\n    regex = extra.pop('regex', None)  # type: ignore\n    if regex is not None:\n        raise PydanticUserError('`regex` is removed. use `pattern` instead', code='removed-kwargs')\n\n    if extra:\n        warn(\n            'Extra keyword arguments on `Field` is deprecated and will be removed. use `json_schema_extra` instead',\n            DeprecationWarning,\n        )\n        if not json_schema_extra:\n            json_schema_extra = extra  # type: ignore\n\n    if validation_alias and not isinstance(validation_alias, (str, AliasChoices, AliasPath)):\n        raise TypeError('Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`')\n\n    if serialization_alias is None and isinstance(alias, str):\n        serialization_alias = alias\n\n    return FieldInfo.from_field(\n        default,\n        default_factory=default_factory,\n        alias=alias,\n        alias_priority=alias_priority,\n        validation_alias=validation_alias or alias,\n        serialization_alias=serialization_alias,\n        title=title,\n        description=description,\n        examples=examples,\n        exclude=exclude,\n        include=include,\n        discriminator=discriminator,\n        json_schema_extra=json_schema_extra,\n        frozen=frozen,\n        final=final,\n        pattern=pattern,\n        validate_default=validate_default,\n        repr=repr,\n        init_var=init_var,\n        kw_only=kw_only,\n        strict=strict,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        multiple_of=multiple_of,\n        min_length=min_length,\n        max_length=max_length,\n        allow_inf_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n    )\n</code></pre>"},{"location":"api/fields/#pydantic.fields.PrivateAttr","title":"PrivateAttr","text":"<pre><code>PrivateAttr(\n    default=PydanticUndefined, *, default_factory=None\n)\n</code></pre> <p>Indicates that attribute is only used internally and never mixed with regular fields.</p> <p>Private attributes are not checked by Pydantic, so it's up to you to maintain their accuracy.</p> <p>Private attributes are stored in <code>__private_attributes__</code> on the model.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The attribute's default value. Defaults to Undefined.</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>typing.Callable[[], Any] | None</code> <p>Callable that will be called when a default value is needed for this attribute. If both <code>default</code> and <code>default_factory</code> are set, an error will be raised.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>An instance of <code>ModelPrivateAttr</code> class.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>default</code> and <code>default_factory</code> are set.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def PrivateAttr(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: typing.Callable[[], Any] | None = None,\n) -&gt; Any:\n\"\"\"Indicates that attribute is only used internally and never mixed with regular fields.\n\n    Private attributes are not checked by Pydantic, so it's up to you to maintain their accuracy.\n\n    Private attributes are stored in `__private_attributes__` on the model.\n\n    Args:\n        default: The attribute's default value. Defaults to Undefined.\n        default_factory: Callable that will be\n            called when a default value is needed for this attribute.\n            If both `default` and `default_factory` are set, an error will be raised.\n\n    Returns:\n        An instance of `ModelPrivateAttr` class.\n\n    Raises:\n        ValueError: If both `default` and `default_factory` are set.\n    \"\"\"\n    if default is not PydanticUndefined and default_factory is not None:\n        raise TypeError('cannot specify both default and default_factory')\n\n    return ModelPrivateAttr(\n        default,\n        default_factory=default_factory,\n    )\n</code></pre>"},{"location":"api/fields/#pydantic.fields.computed_field","title":"computed_field","text":"<pre><code>computed_field(\n    __f=None,\n    *,\n    alias=None,\n    alias_priority=None,\n    title=None,\n    description=None,\n    repr=True,\n    return_type=None\n)\n</code></pre> <p>Decorate to include <code>property</code> and <code>cached_property</code> when serializing models.</p> <p>If applied to functions not yet decorated with <code>@property</code> or <code>@cached_property</code>, the function is automatically wrapped with <code>property</code>.</p> <p>Parameters:</p> Name Type Description Default <code>__f</code> <code>PropertyT | None</code> <p>the function to wrap.</p> <code>None</code> <code>alias</code> <code>str | None</code> <p>alias to use when serializing this computed field, only used when <code>by_alias=True</code></p> <code>None</code> <code>alias_priority</code> <code>int | None</code> <p>priority of the alias. This affects whether an alias generator is used</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title to used when including this computed field in JSON Schema, currently unused waiting for #4697</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Description to used when including this computed field in JSON Schema, defaults to the functions docstring, currently unused waiting for #4697</p> <code>None</code> <code>repr</code> <code>bool</code> <p>whether to include this computed field in model repr</p> <code>True</code> <code>return_type</code> <code>Any</code> <p>optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a <code>TypeError</code> is raised. If you don't include a return type Any is used, which does runtime introspection to handle arbitrary objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>PropertyT | typing.Callable[[PropertyT], PropertyT]</code> <p>A proxy wrapper for the property.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def computed_field(\n    __f: PropertyT | None = None,\n    *,\n    alias: str | None = None,\n    alias_priority: int | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    repr: bool = True,\n    return_type: Any = None,\n) -&gt; PropertyT | typing.Callable[[PropertyT], PropertyT]:\n\"\"\"Decorate to include `property` and `cached_property` when serializing models.\n\n    If applied to functions not yet decorated with `@property` or `@cached_property`, the function is\n    automatically wrapped with `property`.\n\n    Args:\n        __f: the function to wrap.\n        alias: alias to use when serializing this computed field, only used when `by_alias=True`\n        alias_priority: priority of the alias. This affects whether an alias generator is used\n        title: Title to used when including this computed field in JSON Schema, currently unused waiting for #4697\n        description: Description to used when including this computed field in JSON Schema, defaults to the functions\n            docstring, currently unused waiting for #4697\n        repr: whether to include this computed field in model repr\n        return_type: optional return for serialization logic to expect when serializing to JSON, if included\n            this must be correct, otherwise a `TypeError` is raised.\n            If you don't include a return type Any is used, which does runtime introspection to handle arbitrary\n            objects.\n\n    Returns:\n        A proxy wrapper for the property.\n    \"\"\"\n\n    def dec(f: Any) -&gt; Any:\n        nonlocal description, return_type, alias_priority\n        if description is None and f.__doc__:\n            description = inspect.cleandoc(f.__doc__)\n\n        return_type = _decorators.get_function_return_type(f, return_type)\n        if return_type is None:\n            raise PydanticUserError(\n                'Computed field is missing return type annotation or specifying `return_type`'\n                ' to the `@computed_field` decorator (e.g. `@computed_field(return_type=int|str)`)',\n                code='model-field-missing-annotation',\n            )\n\n        # if the function isn't already decorated with `@property` (or another descriptor), then we wrap it now\n        f = _decorators.ensure_property(f)\n        alias_priority = (alias_priority or 2) if alias is not None else None\n        dec_info = ComputedFieldInfo(f, return_type, alias, alias_priority, title, description, repr)\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    if __f is None:\n        return dec\n    else:\n        return dec(__f)\n</code></pre>"},{"location":"api/functional_serializers/","title":"pydantic.functional_serializers","text":"<p>This module contains related classes and functions for serialization.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.PlainSerializer","title":"PlainSerializer","text":"<p>Plain serializers use a function to modify the output of serialization.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.SerializerFunction</code> <p>The serializer function.</p> <code>return_type</code> <code>Any</code> <p>Optional return type for the function, if omitted it will be inferred from the type annotation.</p> <code>when_used</code> <code>Literal['always', 'unless-none', 'json', 'json-unless-none']</code> <p>The serialization condition. Accepts a string with values <code>'always'</code>, <code>'unless-none'</code>, <code>'json'</code>, and <code>'json-unless-none'</code>. Defaults to 'always'.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.WrapSerializer","title":"WrapSerializer","text":"<p>Wrap serializers receive the raw inputs along with a handler function that applies the standard serialization logic, and can modify the resulting value before returning it as the final output of serialization.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.WrapSerializerFunction</code> <p>The function to be wrapped.</p> <code>return_type</code> <code>Any</code> <p>The return type for the function, if omitted it will be inferred from the type annotation.</p> <code>when_used</code> <code>Literal['always', 'unless-none', 'json', 'json-unless-none']</code> <p>Determines when this serializer should be used. Accepts a string with values <code>'always'</code>, <code>'unless-none'</code>, <code>'json'</code>, and <code>'json-unless-none'</code>. Defaults to 'always'.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.field_serializer","title":"field_serializer","text":"<pre><code>field_serializer(\n    *fields,\n    mode=\"plain\",\n    return_type=None,\n    when_used=\"always\",\n    check_fields=None\n)\n</code></pre> <p>Decorate methods on the class indicating that they should be used to serialize fields.</p> <p>Four signatures are supported:</p> <ul> <li><code>(self, value: Any, info: FieldSerializationInfo)</code></li> <li><code>(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)</code></li> <li><code>(value: Any, info: SerializationInfo)</code></li> <li><code>(value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>str</code> <p>Which field(s) the method should be called on.</p> <code>()</code> <code>mode</code> <code>Literal['plain', 'wrap']</code> <p><code>plain</code> means the function will be called instead of the default serialization logic, <code>wrap</code> means the function will be called with an argument to optionally call the default serialization logic.</p> <code>'plain'</code> <code>return_type</code> <code>Any</code> <p>Optional return type for the function, if omitted it will be inferred from the type annotation.</p> <code>None</code> <code>when_used</code> <code>Literal['always', 'unless-none', 'json', 'json-unless-none']</code> <p>Determines the serializer will be used for serialization.</p> <code>'always'</code> <code>check_fields</code> <code>bool | None</code> <p>Whether to check that the fields actually exist on the model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[Any], Any]</code> <p>A decorator that can be used to decorate a function to be used as a field serializer.</p> Source code in <code>pydantic/functional_serializers.py</code> <pre><code>def field_serializer(\n    *fields: str,\n    mode: Literal['plain', 'wrap'] = 'plain',\n    return_type: Any = None,\n    when_used: Literal['always', 'unless-none', 'json', 'json-unless-none'] = 'always',\n    check_fields: bool | None = None,\n) -&gt; Callable[[Any], Any]:\n\"\"\"Decorate methods on the class indicating that they should be used to serialize fields.\n\n    Four signatures are supported:\n\n    - `(self, value: Any, info: FieldSerializationInfo)`\n    - `(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)`\n    - `(value: Any, info: SerializationInfo)`\n    - `(value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)`\n\n    Args:\n        fields: Which field(s) the method should be called on.\n        mode: `plain` means the function will be called instead of the default serialization logic,\n            `wrap` means the function will be called with an argument to optionally call the\n            default serialization logic.\n        return_type: Optional return type for the function, if omitted it will be inferred from the type annotation.\n        when_used: Determines the serializer will be used for serialization.\n        check_fields: Whether to check that the fields actually exist on the model.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a field serializer.\n    \"\"\"\n\n    def dec(\n        f: Callable[..., Any] | staticmethod[Any, Any] | classmethod[Any, Any, Any]\n    ) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        dec_info = _decorators.FieldSerializerDecoratorInfo(\n            fields=fields,\n            mode=mode,\n            return_type=_decorators.get_function_return_type(f, return_type),\n            when_used=when_used,\n            check_fields=check_fields,\n        )\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    return dec\n</code></pre>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.model_serializer","title":"model_serializer","text":"<pre><code>model_serializer(\n    __f=None,\n    *,\n    mode=\"plain\",\n    when_used=\"always\",\n    return_type=None\n)\n</code></pre> <p>Decorate a function which will be called to serialize the model.</p> <p>Parameters:</p> Name Type Description Default <code>__f</code> <code>Callable[..., Any] | None</code> <p>The function to be decorated.</p> <code>None</code> <code>mode</code> <code>Literal['plain', 'wrap']</code> <p>The serialization mode. <code>'plain'</code> means the function will be called instead of the default serialization logic, <code>'wrap'</code> means the function will be called with an argument to optionally call the default serialization logic.</p> <code>'plain'</code> <code>when_used</code> <code>Literal['always', 'unless-none', 'json', 'json-unless-none']</code> <p>Determines when this serializer should be used. Accepts a string with values <code>'always'</code>, <code>'unless-none'</code>, <code>'json'</code>, <code>'json-unless-none'</code>. Defaults to <code>'always'</code>.</p> <code>'always'</code> <code>return_type</code> <code>Any</code> <p>The return type for the function, if omitted it will be inferred from the type annotation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[Any], Any]</code> <p>A decorator that can be used to decorate a function to be used as a model serializer.</p> Source code in <code>pydantic/functional_serializers.py</code> <pre><code>def model_serializer(\n    __f: Callable[..., Any] | None = None,\n    *,\n    mode: Literal['plain', 'wrap'] = 'plain',\n    when_used: Literal['always', 'unless-none', 'json', 'json-unless-none'] = 'always',\n    return_type: Any = None,\n) -&gt; Callable[[Any], Any]:\n\"\"\"Decorate a function which will be called to serialize the model.\n\n    Args:\n        __f: The function to be decorated.\n        mode: The serialization mode. `'plain'` means the function will be called\n            instead of the default serialization logic, `'wrap'` means the function will be called with an argument\n            to optionally call the default serialization logic.\n        when_used: Determines when this serializer should be used. Accepts a string with values `'always'`,\n            `'unless-none'`, `'json'`, `'json-unless-none'`. Defaults to `'always'`.\n        return_type: The return type for the function, if omitted it will be inferred from the type annotation.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a model serializer.\n    \"\"\"\n\n    def dec(f: Callable[..., Any]) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        dec_info = _decorators.ModelSerializerDecoratorInfo(\n            mode=mode, return_type=_decorators.get_function_return_type(f, return_type), when_used=when_used\n        )\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    if __f is None:\n        return dec\n    else:\n        return dec(__f)  # type: ignore\n</code></pre>"},{"location":"api/functional_validators/","title":"pydantic.functional_validators","text":"<p>This module contains related classes and functions for validation.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.AfterValidator","title":"AfterValidator","text":"<p>A metadata class that indicates that a validation should be applied after the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.NoInfoValidatorFunction | core_schema.GeneralValidatorFunction</code> <p>The validator function.</p> Example <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, AfterValidator, ValidationError\n\n\nMyInt = Annotated[int, AfterValidator(lambda v: v + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a=1).a)\n# &gt; 2\n\ntry:\n    Model(a='a')\nexcept ValidationError as e:\n    print(e.json(indent=2))\n\"\"\"\n[\n    {\n        \"type\": \"int_parsing\",\n        \"loc\": [\n            \"a\"\n        ],\n        \"msg\": \"Input should be a valid integer, unable to parse string as an integer\",\n        \"input\": \"a\",\n        \"url\": \"https://errors.pydantic.dev/0.38.0/v/int_parsing\"\n    }\n]\n\"\"\"\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.BeforeValidator","title":"BeforeValidator","text":"<p>A metadata class that indicates that a validation should be applied before the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.NoInfoValidatorFunction | core_schema.GeneralValidatorFunction</code> <p>The validator function.</p> Example <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, BeforeValidator\n\n\nMyInt = Annotated[int, BeforeValidator(lambda v: v + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a=1).a)\n# &gt; 2\n\ntry:\n    Model(a='a')\nexcept TypeError as e:\n    print(e)\n    #&gt; can only concatenate str (not \"int\") to str\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.InstanceOf","title":"InstanceOf","text":"<p>Generic type for annotating a type that is an instance of a given class.</p> Example <pre><code>from pydantic import BaseModel, InstanceOf\n\nclass Foo:\n    ...\n\nclass Bar(BaseModel):\n    foo: InstanceOf[Foo]\n\nBar(foo=Foo())\ntry:\n    Bar(foo=42)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    [\n    \u2502   {\n    \u2502   \u2502   'type': 'is_instance_of',\n    \u2502   \u2502   'loc': ('foo',),\n    \u2502   \u2502   'msg': 'Input should be an instance of Foo',\n    \u2502   \u2502   'input': 42,\n    \u2502   \u2502   'ctx': {'class': 'Foo'},\n    \u2502   \u2502   'url': 'https://errors.pydantic.dev/0.38.0/v/is_instance_of'\n    \u2502   }\n    ]\n    \"\"\"\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelAfterValidator","title":"ModelAfterValidator","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='after'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelAfterValidatorWithoutInfo","title":"ModelAfterValidatorWithoutInfo","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='after'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelBeforeValidator","title":"ModelBeforeValidator","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='before'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelBeforeValidatorWithoutInfo","title":"ModelBeforeValidatorWithoutInfo","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='before'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidator","title":"ModelWrapValidator","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='wrap'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidatorHandler","title":"ModelWrapValidatorHandler","text":"<p>         Bases: <code>_core_schema.ValidatorFunctionWrapHandler</code>, <code>Protocol[_ModelTypeCo]</code></p> <p>@model_validator decorated function handler argument type. This is used when <code>mode='wrap'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidatorWithoutInfo","title":"ModelWrapValidatorWithoutInfo","text":"<p>         Bases: <code>Protocol</code></p> <p>A @model_validator decorated function signature. This is used when <code>mode='wrap'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.PlainValidator","title":"PlainValidator","text":"<p>A metadata class that indicates that a validation should be applied instead of the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.NoInfoValidatorFunction | core_schema.GeneralValidatorFunction</code> <p>The validator function.</p> Example <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, PlainValidator\n\n\nMyInt = Annotated[int, PlainValidator(lambda v: int(v) + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a='1').a)\n# &gt; 2\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.SkipValidation","title":"SkipValidation","text":"<p>If this is applied as an annotation (e.g., via <code>x: Annotated[int, SkipValidation]</code>), validation will be     skipped. You can also use <code>SkipValidation[int]</code> as a shorthand for <code>Annotated[int, SkipValidation]</code>.</p> <p>This can be useful if you want to use a type annotation for documentation/IDE/type-checking purposes, and know that it is safe to skip validation for one or more of the fields.</p> <p>Because this converts the validation schema to <code>any_schema</code>, subsequent annotation-applied transformations may not have the expected effects. Therefore, when used, this annotation should generally be the final annotation applied to a type.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.WrapValidator","title":"WrapValidator","text":"<p>A metadata class that indicates that a validation should be applied around the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>core_schema.GeneralWrapValidatorFunction | core_schema.FieldWrapValidatorFunction</code> <p>The validator function.</p> <pre><code>from datetime import datetime\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, ValidationError, WrapValidator\n\n\ndef validate_timestamp(v, handler):\n    if v == \"now\":\n        # we don't want to bother with further validation, just return the new value\n        return datetime.now()\n    try:\n        return handler(v)\n    except ValidationError:\n        # validation failed, in this case we want to return a default value\n        return datetime(2000, 1, 1)\n\n\nMyTimestamp = Annotated[datetime, WrapValidator(validate_timestamp)]\n\n\nclass Model(BaseModel):\n    a: MyTimestamp\n\n\nprint(Model(a=\"now\").a)\n# &gt; 2023-01-22 23:10:00.000000\nprint(Model(a=\"invalid\").a)\n# &gt; 2000-01-01 00:00:00.000000\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.field_validator","title":"field_validator","text":"<pre><code>field_validator(\n    __field, *fields, mode=\"after\", check_fields=None\n)\n</code></pre> <p>Decorate methods on the class indicating that they should be used to validate fields.</p> <p>Parameters:</p> Name Type Description Default <code>__field</code> <code>str</code> <p>The first field the <code>field_validator</code> should be called on; this is separate from <code>fields</code> to ensure an error is raised if you don't pass at least one.</p> required <code>*fields</code> <code>str</code> <p>Additional field(s) the <code>field_validator</code> should be called on.</p> <code>()</code> <code>mode</code> <code>FieldValidatorModes</code> <p>Specifies whether to validate the fields before or after validation.</p> <code>'after'</code> <code>check_fields</code> <code>bool | None</code> <p>Whether to check that the fields actually exist on the model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[Any], Any]</code> <p>A decorator that can be used to decorate a function to be used as a field_validator.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <ul> <li>If <code>@field_validator</code> is used bare (with no fields).</li> <li>If the args passed to <code>@field_validator</code> as fields are not strings.</li> <li>If <code>@field_validator</code> applied to instance methods.</li> </ul> Source code in <code>pydantic/functional_validators.py</code> <pre><code>def field_validator(\n    __field: str,\n    *fields: str,\n    mode: FieldValidatorModes = 'after',\n    check_fields: bool | None = None,\n) -&gt; Callable[[Any], Any]:\n\"\"\"Decorate methods on the class indicating that they should be used to validate fields.\n\n    Args:\n        __field: The first field the `field_validator` should be called on; this is separate\n            from `fields` to ensure an error is raised if you don't pass at least one.\n        *fields: Additional field(s) the `field_validator` should be called on.\n        mode: Specifies whether to validate the fields before or after validation.\n        check_fields: Whether to check that the fields actually exist on the model.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a field_validator.\n\n    Raises:\n        PydanticUserError:\n            - If `@field_validator` is used bare (with no fields).\n            - If the args passed to `@field_validator` as fields are not strings.\n            - If `@field_validator` applied to instance methods.\n    \"\"\"\n    if isinstance(__field, FunctionType):\n        raise PydanticUserError(\n            '`@field_validator` should be used with fields and keyword arguments, not bare. '\n            \"E.g. usage should be `@validator('&lt;field_name&gt;', ...)`\",\n            code='validator-no-fields',\n        )\n    fields = __field, *fields\n    if not all(isinstance(field, str) for field in fields):  # type: ignore\n        raise PydanticUserError(\n            '`@field_validator` fields should be passed as separate string args. '\n            \"E.g. usage should be `@validator('&lt;field_name_1&gt;', '&lt;field_name_2&gt;', ...)`\",\n            code='validator-invalid-fields',\n        )\n\n    def dec(\n        f: Callable[..., Any] | staticmethod[Any, Any] | classmethod[Any, Any, Any]\n    ) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        if _decorators.is_instance_method_from_sig(f):\n            raise PydanticUserError(\n                '`@field_validator` cannot be applied to instance methods', code='validator-instance-method'\n            )\n\n        # auto apply the @classmethod decorator\n        f = _decorators.ensure_classmethod_based_on_signature(f)\n\n        dec_info = _decorators.FieldValidatorDecoratorInfo(fields=fields, mode=mode, check_fields=check_fields)\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    return dec\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.model_validator","title":"model_validator","text":"<pre><code>model_validator(*, mode)\n</code></pre> <p>Decorate model methods for validation purposes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['wrap', 'before', 'after']</code> <p>A required string literal that specifies the validation mode. It can be one of the following: 'wrap', 'before', or 'after'.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>A decorator that can be used to decorate a function to be used as a model validator.</p> Source code in <code>pydantic/functional_validators.py</code> <pre><code>def model_validator(\n    *,\n    mode: Literal['wrap', 'before', 'after'],\n) -&gt; Any:\n\"\"\"Decorate model methods for validation purposes.\n\n    Args:\n        mode: A required string literal that specifies the validation mode.\n            It can be one of the following: 'wrap', 'before', or 'after'.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a model validator.\n    \"\"\"\n\n    def dec(f: Any) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        # auto apply the @classmethod decorator\n        f = _decorators.ensure_classmethod_based_on_signature(f)\n        dec_info = _decorators.ModelValidatorDecoratorInfo(mode=mode)\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    return dec\n</code></pre>"},{"location":"api/json_schema/","title":"pydantic.json_schema","text":""},{"location":"api/json_schema/#pydantic.json_schema.CoreSchemaOrFieldType","title":"CoreSchemaOrFieldType  <code>module-attribute</code>","text":"<pre><code>CoreSchemaOrFieldType = Literal[\n    core_schema.CoreSchemaType,\n    core_schema.CoreSchemaFieldType,\n]\n</code></pre> <p>A type alias for defined schema types that represents a union of <code>core_schema.CoreSchemaType</code> and <code>core_schema.CoreSchemaFieldType</code>.</p>"},{"location":"api/json_schema/#pydantic.json_schema.DEFAULT_REF_TEMPLATE","title":"DEFAULT_REF_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_REF_TEMPLATE = '#/$defs/{model}'\n</code></pre> <p>The default format string used to generate reference names.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaMode","title":"JsonSchemaMode  <code>module-attribute</code>","text":"<pre><code>JsonSchemaMode = Literal['validation', 'serialization']\n</code></pre> <p>A type alias that represents the mode of a JSON schema; either 'validation' or 'serialization'.</p> <p>For some types, the inputs to validation differ from the outputs of serialization. For example, computed fields will only be present when serializing, and should not be provided when validating. This flag provides a way to indicate whether you want the JSON schema required for validation inputs, or that will be matched by serialization outputs.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaValue","title":"JsonSchemaValue  <code>module-attribute</code>","text":"<pre><code>JsonSchemaValue = Dict[str, Any]\n</code></pre> <p>A type alias for a JSON schema value. This is a dictionary of string keys to arbitrary values.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaWarningKind","title":"JsonSchemaWarningKind  <code>module-attribute</code>","text":"<pre><code>JsonSchemaWarningKind = Literal[\n    \"skipped-choice\", \"non-serializable-default\"\n]\n</code></pre> <p>A type alias representing the kinds of warnings that can be emitted during JSON schema generation.</p> <p>See <code>GenerateJsonSchema.render_warning_message</code> for more details.</p>"},{"location":"api/json_schema/#pydantic.json_schema.Examples","title":"Examples","text":"<p>Add examples to a JSON schema.</p> <p>Examples should be a map of example names (strings) to example values (any valid JSON).</p> <p>If <code>mode</code> is set this will only apply to that schema generation mode, allowing you to add different examples for validation and serialization.</p>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema","title":"GenerateJsonSchema","text":"<pre><code>GenerateJsonSchema(\n    by_alias=True, ref_template=DEFAULT_REF_TEMPLATE\n)\n</code></pre> <p>A class for generating JSON schemas.</p> <p>This class generates JSON schemas based on configured parameters. The default schema dialect is 'https://json-schema.org/draft/2020-12/schema'. The class uses <code>by_alias</code> to configure how fields with multiple names are handled and <code>ref_template</code> to format reference names.</p> <p>Attributes:</p> Name Type Description <code>schema_dialect</code> <code>str</code> <p>The JSON schema dialect used to generate the schema. See Declaring a Dialect in the JSON Schema documentation for more information about dialects.</p> <code>ignored_warning_kinds</code> <code>set</code> <p>Warnings to ignore when generating the schema. <code>self.render_warning_message</code> will do nothing if its argument <code>kind</code> is in <code>ignored_warning_kinds</code>; this value can be modified on subclasses to easily control which warnings are emitted.</p> <code>by_alias</code> <code>bool</code> <p>Whether or not to use field names when generating the schema.</p> <code>ref_template</code> <code>str</code> <p>The format string used when generating reference names.</p> <code>core_to_json_refs</code> <code>dict</code> <p>A mapping of core refs to JSON refs.</p> <code>core_to_defs_refs</code> <code>dict</code> <p>A mapping of core refs to definition refs.</p> <code>defs_to_core_refs</code> <code>dict</code> <p>A mapping of definition refs to core refs.</p> <code>json_to_defs_refs</code> <code>dict</code> <p>A mapping of JSON refs to definition refs.</p> <code>definitions</code> <code>dict</code> <p>Definitions in the schema.</p> <code>collisions</code> <code>set</code> <p>Definitions with colliding names. When collisions are detected, we choose a non-colliding name during generation, but we also track the colliding tag so that it can be remapped for the first occurrence at the end of the process.</p> <code>defs_ref_fallbacks</code> <code>dict</code> <p>Core refs to fallback definitions refs.</p> <code>_schema_type_to_method</code> <code>dict</code> <p>A mapping of schema types to generator methods.</p> <code>_used</code> <code>bool</code> <p>Set to <code>True</code> after generating a schema to avoid re-use issues.</p> <code>mode</code> <code>JsonSchemaMode</code> <p>The schema mode.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether or not to include field names.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The format string to use when generating reference names.</p> <code>DEFAULT_REF_TEMPLATE</code> <p>Raises:</p> Type Description <code>JsonSchemaError</code> <p>If the instance of the class is inadvertently re-used after generating a schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def __init__(self, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE):\n    self.by_alias = by_alias\n    self.ref_template = ref_template\n\n    self.core_to_json_refs: dict[CoreModeRef, JsonRef] = {}\n    self.core_to_defs_refs: dict[CoreModeRef, DefsRef] = {}\n    self.defs_to_core_refs: dict[DefsRef, CoreModeRef] = {}\n    self.json_to_defs_refs: dict[JsonRef, DefsRef] = {}\n\n    self.definitions: dict[DefsRef, JsonSchemaValue] = {}\n\n    # When collisions are detected, we choose a non-colliding name\n    # during generation, but we also track the colliding tag so that it\n    # can be remapped for the first occurrence at the end of the process\n    self.collisions: set[DefsRef] = set()\n    self.defs_ref_fallbacks: dict[CoreModeRef, list[DefsRef]] = {}\n\n    self._schema_type_to_method = self.build_schema_type_to_method()\n\n    # This changes to True after generating a schema, to prevent issues caused by accidental re-use\n    # of a single instance of a schema generator\n    self._used = False\n\n    self.mode: JsonSchemaMode = 'validation'\n\n    # When we encounter definitions we need to try to build them immediately\n    # so that they are available schemas that reference them\n    # But it's possible that that CoreSchema was never going to be used\n    # (e.g. because the CoreSchema that references short circuits is JSON schema generation without needing\n    #  the reference) so instead of failing altogether if we can't build a definition we\n    # store the error raised and re-throw it if we end up needing that def\n    self.core_defs_invalid_for_json_schema: dict[DefsRef, PydanticInvalidForJsonSchema] = {}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.ValidationsMapping","title":"ValidationsMapping","text":"<p>This class just contains mappings from core_schema attribute names to the corresponding JSON schema attribute names. While I suspect it is unlikely to be necessary, you can in principle override this class in a subclass of GenerateJsonSchema (by inheriting from GenerateJsonSchema.ValidationsMapping) to change these mappings.</p>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.any_schema","title":"any_schema","text":"<pre><code>any_schema(schema)\n</code></pre> <p>Returns a schema that matches any value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.AnySchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def any_schema(self, schema: core_schema.AnySchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches any value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.bool_schema","title":"bool_schema","text":"<pre><code>bool_schema(schema)\n</code></pre> <p>Returns a schema that matches a Boolean value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.BoolSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def bool_schema(self, schema: core_schema.BoolSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a Boolean value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'boolean'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.build_schema_type_to_method","title":"build_schema_type_to_method","text":"<pre><code>build_schema_type_to_method()\n</code></pre> <p>Builds a dictionary mapping <code>CoreSchemaOrFieldType</code> to a callable method that generates a <code>JsonSchema</code> value for a given <code>CoreSchemaOrField</code>.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]]</code> <p>A dictionary containing the mapping of <code>CoreSchemaOrFieldType</code> to a callable method.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If no method has been defined for generating a JSON schema for a given pydantic core schema type.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def build_schema_type_to_method(\n    self,\n) -&gt; dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]]:\n\"\"\"Builds a dictionary mapping `CoreSchemaOrFieldType` to a callable method that generates a `JsonSchema` value\n    for a given `CoreSchemaOrField`.\n\n    Returns:\n        dict: A dictionary containing the mapping of `CoreSchemaOrFieldType` to a callable method.\n\n    Raises:\n        TypeError: If no method has been defined for generating a JSON schema for a given pydantic core schema type.\n    \"\"\"\n    mapping: dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]] = {}\n    core_schema_types: list[CoreSchemaOrFieldType] = _typing_extra.all_literal_values(\n        CoreSchemaOrFieldType  # type: ignore\n    )\n    for key in core_schema_types:\n        method_name = f\"{key.replace('-', '_')}_schema\"\n        try:\n            mapping[key] = getattr(self, method_name)\n        except AttributeError as e:  # pragma: no cover\n            raise TypeError(\n                f'No method for generating JsonSchema for core_schema.type={key!r} '\n                f'(expected: {type(self).__name__}.{method_name})'\n            ) from e\n    return mapping\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.bytes_schema","title":"bytes_schema","text":"<pre><code>bytes_schema(schema)\n</code></pre> <p>Returns a schema that matches a bytes value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.BytesSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def bytes_schema(self, schema: core_schema.BytesSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a bytes value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string', 'format': 'binary'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.bytes)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.callable_schema","title":"callable_schema","text":"<pre><code>callable_schema(schema)\n</code></pre> <p>Returns a schema that checks if a value is callable, equivalent to Python's <code>callable</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.CallableSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def callable_schema(self, schema: core_schema.CallableSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that checks if a value is callable, equivalent to Python's `callable` method.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.handle_invalid_for_json_schema(schema, 'core_schema.CallableSchema')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.date_schema","title":"date_schema","text":"<pre><code>date_schema(schema)\n</code></pre> <p>Returns a schema that matches a date value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.DateSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def date_schema(self, schema: core_schema.DateSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a date value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string', 'format': 'date'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.date)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.datetime_schema","title":"datetime_schema","text":"<pre><code>datetime_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>datetime</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.DatetimeSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def datetime_schema(self, schema: core_schema.DatetimeSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `datetime` value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'date-time'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.dict_schema","title":"dict_schema","text":"<pre><code>dict_schema(schema)\n</code></pre> <p>Returns a schema that matches a dict schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.DictSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def dict_schema(self, schema: core_schema.DictSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a dict schema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: JsonSchemaValue = {'type': 'object'}\n\n    keys_schema = self.generate_inner(schema['keys_schema']).copy() if 'keys_schema' in schema else {}\n    keys_pattern = keys_schema.pop('pattern', None)\n\n    values_schema = self.generate_inner(schema['values_schema']).copy() if 'values_schema' in schema else {}\n    values_schema.pop('title', None)  # don't give a title to the additionalProperties\n    if values_schema or keys_pattern is not None:  # don't add additionalProperties if it's empty\n        if keys_pattern is None:\n            json_schema['additionalProperties'] = values_schema\n        else:\n            json_schema['patternProperties'] = {keys_pattern: values_schema}\n\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.object)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.emit_warning","title":"emit_warning","text":"<pre><code>emit_warning(kind, detail)\n</code></pre> <p>This method simply emits PydanticJsonSchemaWarnings based on handling in the <code>warning_message</code> method.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def emit_warning(self, kind: JsonSchemaWarningKind, detail: str) -&gt; None:\n\"\"\"This method simply emits PydanticJsonSchemaWarnings based on handling in the `warning_message` method.\"\"\"\n    message = self.render_warning_message(kind, detail)\n    if message is not None:\n        warnings.warn(message, PydanticJsonSchemaWarning)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_is_present","title":"field_is_present","text":"<pre><code>field_is_present(field)\n</code></pre> <p>Whether the field should be included in the generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_is_present(self, field: CoreSchemaField) -&gt; bool:\n\"\"\"Whether the field should be included in the generated JSON schema.\"\"\"\n    if self.mode == 'serialization':\n        # If you still want to include the field in the generated JSON schema,\n        # override this method and return True\n        return not field.get('serialization_exclude')\n    elif self.mode == 'validation':\n        return True\n    else:\n        assert_never(self.mode)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_is_required","title":"field_is_required","text":"<pre><code>field_is_required(field)\n</code></pre> <p>Whether the field should be marked as required in the generated JSON schema. (Note that this is irrelevant if the field is not present in the JSON schema.).</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_is_required(\n    self, field: core_schema.ModelField | core_schema.DataclassField | core_schema.TypedDictField\n) -&gt; bool:\n\"\"\"Whether the field should be marked as required in the generated JSON schema.\n    (Note that this is irrelevant if the field is not present in the JSON schema.).\n    \"\"\"\n    if self.mode == 'serialization':\n        return not field.get('serialization_exclude')\n    elif self.mode == 'validation':\n        if field['type'] == 'typed-dict-field':\n            return field['required']  # type: ignore  # required is always populated\n        else:\n            return field['schema']['type'] != 'default'\n    else:\n        assert_never(self.mode)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_title_should_be_set","title":"field_title_should_be_set","text":"<pre><code>field_title_should_be_set(schema)\n</code></pre> <p>Returns true if a field with the given schema should have a title set based on the field name.</p> <p>Intuitively, we want this to return true for schemas that wouldn't otherwise provide their own title (e.g., int, float, str), and false for those that would (e.g., BaseModel subclasses).</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_title_should_be_set(self, schema: CoreSchemaOrField) -&gt; bool:\n\"\"\"Returns true if a field with the given schema should have a title set based on the field name.\n\n    Intuitively, we want this to return true for schemas that wouldn't otherwise provide their own title\n    (e.g., int, float, str), and false for those that would (e.g., BaseModel subclasses).\n    \"\"\"\n    if _core_utils.is_core_schema_field(schema):\n        if schema['type'] == 'computed-field':\n            field_schema = schema['return_schema']\n        else:\n            field_schema = schema['schema']\n        return self.field_title_should_be_set(field_schema)\n\n    elif _core_utils.is_core_schema(schema):\n        if schema.get('ref'):  # things with refs, such as models and enums, should not have titles set\n            return False\n        if schema['type'] in {'default', 'nullable', 'definitions'}:\n            return self.field_title_should_be_set(schema['schema'])  # type: ignore[typeddict-item]\n        if _core_utils.is_function_with_inner_schema(schema):\n            return self.field_title_should_be_set(schema['schema'])\n        if schema['type'] == 'definition-ref':\n            # Referenced schemas should not have titles set for the same reason\n            # schemas with refs should not\n            return False\n        return True  # anything else should have title set\n\n    else:\n        raise PydanticInvalidForJsonSchema(f'Unexpected schema type: schema={schema}')  # pragma: no cover\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.float_schema","title":"float_schema","text":"<pre><code>float_schema(schema)\n</code></pre> <p>Returns a schema that matches a Float value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.FloatSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def float_schema(self, schema: core_schema.FloatSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a Float value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: dict[str, Any] = {'type': 'number'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.numeric)\n    json_schema = {k: v for k, v in json_schema.items() if v not in {math.inf, -math.inf}}\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.frozenset_schema","title":"frozenset_schema","text":"<pre><code>frozenset_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>frozenset</code> schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.FrozenSetSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def frozenset_schema(self, schema: core_schema.FrozenSetSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `frozenset` schema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self._common_set_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate","title":"generate","text":"<pre><code>generate(schema, mode='validation')\n</code></pre> <p>Generates a JSON schema for a specified schema in a specified mode.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>A Pydantic model.</p> required <code>mode</code> <code>JsonSchemaMode</code> <p>The mode in which to generate the schema. Defaults to 'validation'.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>A JSON schema representing the specified schema.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>If the JSON schema generator has already been used to generate a JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate(self, schema: CoreSchema, mode: JsonSchemaMode = 'validation') -&gt; JsonSchemaValue:\n\"\"\"Generates a JSON schema for a specified schema in a specified mode.\n\n    Args:\n        schema: A Pydantic model.\n        mode: The mode in which to generate the schema. Defaults to 'validation'.\n\n    Returns:\n        A JSON schema representing the specified schema.\n\n    Raises:\n        PydanticUserError: If the JSON schema generator has already been used to generate a JSON schema.\n    \"\"\"\n    self.mode = mode\n    if self._used:\n        raise PydanticUserError(\n            'This JSON schema generator has already been used to generate a JSON schema. '\n            f'You must create a new instance of {type(self).__name__} to generate a new JSON schema.',\n            code='json-schema-already-used',\n        )\n\n    json_schema = self.generate_inner(schema)\n    json_ref_counts = self.get_json_ref_counts(json_schema)\n\n    # Remove the top-level $ref if present; note that the _generate method already ensures there are no sibling keys\n    ref = cast(JsonRef, json_schema.get('$ref'))\n    while ref is not None:  # may need to unpack multiple levels\n        ref_json_schema = self.get_schema_from_definitions(ref)\n        if json_ref_counts[ref] &gt; 1 or ref_json_schema is None:\n            # Keep the ref, but use an allOf to remove the top level $ref\n            json_schema = {'allOf': [{'$ref': ref}]}\n        else:\n            # \"Unpack\" the ref since this is the only reference\n            json_schema = ref_json_schema.copy()  # copy to prevent recursive dict reference\n            json_ref_counts[ref] -= 1\n        ref = cast(JsonRef, json_schema.get('$ref'))\n\n    # Remove any definitions that, thanks to $ref-substitution, are no longer present.\n    # I think this should only _possibly_ apply to the root model, though I'm not 100% sure.\n    # It might be safe to remove this logic, but I'm keeping it for now\n    all_json_refs = list(self.json_to_defs_refs.keys())\n    for k in all_json_refs:\n        if json_ref_counts[k] &lt; 1:\n            del self.definitions[self.json_to_defs_refs[k]]\n\n    json_schema = self.resolve_collisions(json_schema)\n    if self.definitions:\n        json_schema['$defs'] = self.definitions\n\n    # For now, we will not set the $schema key. However, if desired, this can be easily added by overriding\n    # this method and adding the following line after a call to super().generate(schema):\n    # json_schema['$schema'] = self.schema_dialect\n\n    self._used = True\n    return _sort_json_schema(json_schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate_definitions","title":"generate_definitions","text":"<pre><code>generate_definitions(inputs)\n</code></pre> <p>Given a list of core_schema, generates all JSON schema definitions from a list of core schemas, and returns the generated definitions paired with a mapping from the input keys to the definition references.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Sequence[tuple[JsonSchemaKeyT, JsonSchemaMode, core_schema.CoreSchema]]</code> <p>A sequence of tuples, where:</p> <ul> <li><code>JsonSchemaKeyT</code> will be paired with <code>JsonSchemaMode</code> to form the keys of the first returned     dictionary.</li> <li><code>JsonSchemaMode</code> is a JSON schema mode, either 'validation' or 'serialization'.</li> <li><code>core_schema.CoreSchema</code> is a Pydantic <code>core_schema</code>.</li> </ul> required <p>Returns:</p> Type Description <code>tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef], dict[DefsRef, JsonSchemaValue]]</code> <p>A 2-tuple, where:</p> <ul> <li>The first element is a dictionary whose keys are tuples of a JSON schema key type and mode, and     whose values are <code>DefsRef</code>.</li> <li>The second element is a dictionary whose keys are <code>DefsRef</code> and whose values are <code>JsonSchemaValue</code>.</li> </ul> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>Raised if the JSON schema generator has already been used to generate a JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate_definitions(\n    self, inputs: Sequence[tuple[JsonSchemaKeyT, JsonSchemaMode, core_schema.CoreSchema]]\n) -&gt; tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef], dict[DefsRef, JsonSchemaValue]]:\n\"\"\"Given a list of core_schema, generates all JSON schema definitions from a list of core schemas, and\n    returns the generated definitions paired with a mapping from the input keys to the definition references.\n\n    Args:\n        inputs: A sequence of tuples, where:\n\n            - `JsonSchemaKeyT` will be paired with `JsonSchemaMode` to form the keys of the first returned\n                dictionary.\n            - `JsonSchemaMode` is a JSON schema mode, either 'validation' or 'serialization'.\n            - `core_schema.CoreSchema` is a Pydantic `core_schema`.\n\n    Returns:\n        A 2-tuple, where:\n\n            - The first element is a dictionary whose keys are tuples of a JSON schema key type and mode, and\n                whose values are `DefsRef`.\n            - The second element is a dictionary whose keys are `DefsRef` and whose values are `JsonSchemaValue`.\n\n    Raises:\n        PydanticUserError: Raised if the JSON schema generator has already been used to generate a JSON schema.\n    \"\"\"\n    if self._used:\n        raise PydanticUserError(\n            'This JSON schema generator has already been used to generate a JSON schema. '\n            f'You must create a new instance of {type(self).__name__} to generate a new JSON schema.',\n            code='json-schema-already-used',\n        )\n\n    for key, mode, schema in inputs:\n        self.mode = mode\n        self.generate_inner(schema)\n\n    self.resolve_collisions({})\n\n    refs_map: dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef] = {}\n    for key, mode, schema in inputs:\n        self.mode = mode\n        json_schema = self.generate_inner(schema)\n        if '$ref' in json_schema:\n            json_ref = cast(JsonRef, json_schema['$ref'])\n            defs_ref = self.json_to_defs_refs.get(json_ref)\n            if defs_ref is not None:\n                refs_map[(key, mode)] = defs_ref\n\n    self._used = True\n    return refs_map, _sort_json_schema(self.definitions)  # type: ignore\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate_inner","title":"generate_inner","text":"<pre><code>generate_inner(schema)\n</code></pre> <p>Generates a JSON schema for a given <code>CoreSchemaOrField</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchemaOrField</code> <p>The given <code>CoreSchemaOrField</code> to generate JSON schema for.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate_inner(self, schema: CoreSchemaOrField) -&gt; JsonSchemaValue:\n\"\"\"Generates a JSON schema for a given `CoreSchemaOrField`.\n\n    Args:\n        schema: The given `CoreSchemaOrField` to generate JSON schema for.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # If a schema with the same CoreRef has been handled, just return a reference to it\n    # Note that this assumes that it will _never_ be the case that the same CoreRef is used\n    # on types that should have different JSON schemas\n    if 'ref' in schema:\n        core_ref = CoreRef(schema['ref'])  # type: ignore[typeddict-item]\n        core_mode_ref = (core_ref, self.mode)\n        if core_mode_ref in self.core_to_defs_refs and self.core_to_defs_refs[core_mode_ref] in self.definitions:\n            return {'$ref': self.core_to_json_refs[core_mode_ref]}\n\n    # Generate the JSON schema, accounting for the json_schema_override and core_schema_override\n    metadata_handler = _core_metadata.CoreMetadataHandler(schema)\n\n    def populate_defs(core_schema: CoreSchema, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n        if 'ref' in core_schema:\n            core_ref = CoreRef(core_schema['ref'])  # type: ignore[typeddict-item]\n            defs_ref, ref_json_schema = self.get_cache_defs_ref_schema(core_ref)\n            json_ref = JsonRef(ref_json_schema['$ref'])\n            self.json_to_defs_refs[json_ref] = defs_ref\n            # Replace the schema if it's not a reference to itself\n            # What we want to avoid is having the def be just a ref to itself\n            # which is what would happen if we blindly assigned any\n            if json_schema.get('$ref', None) != json_ref:\n                self.definitions[defs_ref] = json_schema\n                self.core_defs_invalid_for_json_schema.pop(defs_ref, None)\n            json_schema = ref_json_schema\n        if '$ref' in json_schema and len(json_schema.keys()) &gt; 1:\n            # technically you can't have any other keys next to a \"$ref\"\n            # but it's an easy mistake to make and not hard to correct automatically here\n            json_schema = json_schema.copy()\n            ref = json_schema.pop('$ref')\n            json_schema = {'allOf': [{'$ref': ref}], **json_schema}\n        return json_schema\n\n    def handler_func(schema_or_field: CoreSchemaOrField) -&gt; JsonSchemaValue:\n\"\"\"Generate a JSON schema based on the input schema.\n\n        Args:\n            schema_or_field: The schema data to generate a JSON schema from.\n\n        Returns:\n            The generated JSON schema.\n\n        Raises:\n            TypeError: If an unexpected schema type is encountered.\n        \"\"\"\n        # Generate the core-schema-type-specific bits of the schema generation:\n        if _core_utils.is_core_schema(schema_or_field) or _core_utils.is_core_schema_field(schema_or_field):\n            generate_for_schema_type = self._schema_type_to_method[schema_or_field['type']]\n            json_schema = generate_for_schema_type(schema_or_field)\n        else:\n            raise TypeError(f'Unexpected schema type: schema={schema_or_field}')\n        if _core_utils.is_core_schema(schema_or_field):\n            json_schema = populate_defs(schema_or_field, json_schema)\n        return json_schema\n\n    current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(self, handler_func)\n\n    for js_modify_function in metadata_handler.metadata.get('pydantic_js_functions', ()):\n\n        def new_handler_func(\n            schema_or_field: CoreSchemaOrField,\n            current_handler: GetJsonSchemaHandler = current_handler,\n            js_modify_function: GetJsonSchemaFunction = js_modify_function,\n        ) -&gt; JsonSchemaValue:\n            json_schema = js_modify_function(schema_or_field, current_handler)\n            if _core_utils.is_core_schema(schema_or_field):\n                json_schema = populate_defs(schema_or_field, json_schema)\n            return json_schema\n\n        current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(self, new_handler_func)\n\n    return current_handler(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generator_schema","title":"generator_schema","text":"<pre><code>generator_schema(schema)\n</code></pre> <p>Returns a JSON schema that represents the provided GeneratorSchema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.GeneratorSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generator_schema(self, schema: core_schema.GeneratorSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a JSON schema that represents the provided GeneratorSchema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    items_schema = {} if 'items_schema' not in schema else self.generate_inner(schema['items_schema'])\n    json_schema = {'type': 'array', 'items': items_schema}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_cache_defs_ref_schema","title":"get_cache_defs_ref_schema","text":"<pre><code>get_cache_defs_ref_schema(core_ref)\n</code></pre> <p>This method wraps the get_defs_ref method with some cache-lookup/population logic, and returns both the produced defs_ref and the JSON schema that will refer to the right definition.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_cache_defs_ref_schema(self, core_ref: CoreRef) -&gt; tuple[DefsRef, JsonSchemaValue]:\n\"\"\"This method wraps the get_defs_ref method with some cache-lookup/population logic,\n    and returns both the produced defs_ref and the JSON schema that will refer to the right definition.\n    \"\"\"\n    core_mode_ref = (core_ref, self.mode)\n    maybe_defs_ref = self.core_to_defs_refs.get(core_mode_ref)\n    if maybe_defs_ref is not None:\n        json_ref = self.core_to_json_refs[core_mode_ref]\n        return maybe_defs_ref, {'$ref': json_ref}\n\n    defs_ref = self.get_defs_ref(core_mode_ref)\n\n    # populate the ref translation mappings\n    self.core_to_defs_refs[core_mode_ref] = defs_ref\n    self.defs_to_core_refs[defs_ref] = core_mode_ref\n\n    json_ref = JsonRef(self.ref_template.format(model=defs_ref))\n    self.core_to_json_refs[core_mode_ref] = json_ref\n    self.json_to_defs_refs[json_ref] = defs_ref\n    ref_json_schema = {'$ref': json_ref}\n    return defs_ref, ref_json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_defs_ref","title":"get_defs_ref","text":"<pre><code>get_defs_ref(core_mode_ref)\n</code></pre> <p>Override this method to change the way that definitions keys are generated from a core reference.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_defs_ref(self, core_mode_ref: CoreModeRef) -&gt; DefsRef:\n\"\"\"Override this method to change the way that definitions keys are generated from a core reference.\"\"\"\n    # Split the core ref into \"components\"; generic origins and arguments are each separate components\n    core_ref, mode = core_mode_ref\n    components = re.split(r'([\\][,])', core_ref)\n    # Remove IDs from each component\n    components = [x.split(':')[0] for x in components]\n    core_ref_no_id = ''.join(components)\n    # Remove everything before the last period from each \"component\"\n    components = [re.sub(r'(?:[^.[\\]]+\\.)+((?:[^.[\\]]+))', r'\\1', x) for x in components]\n    short_ref = ''.join(components)\n\n    mode_title = _MODE_TITLE_MAPPING[mode]\n    # It is important that the generated defs_ref values be such that at least one could not\n    # be generated for any other core_ref. Currently, this should be the case because we include\n    # the id of the source type in the core_ref\n    choices = [\n        DefsRef(self.normalize_name(short_ref)),  # name\n        DefsRef(self.normalize_name(short_ref + mode_title)),  # name + mode\n        DefsRef(self.normalize_name(core_ref_no_id)),  # module + qualname\n        DefsRef(self.normalize_name(core_ref_no_id + mode_title)),  # module + qualname + mode\n        DefsRef(self.normalize_name(core_ref)),  # module + qualname + id\n        DefsRef(self.normalize_name(core_ref + mode_title)),  # module + qualname + id + mode\n    ]\n\n    self.defs_ref_fallbacks[core_mode_ref] = choices[1:]\n\n    for choice in choices:\n        if self.defs_to_core_refs.get(choice, core_mode_ref) == core_mode_ref:\n            return choice\n        else:\n            self.collisions.add(choice)\n\n    return choices[-1]  # should never get here if the final choice is guaranteed unique\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_json_ref_counts","title":"get_json_ref_counts","text":"<pre><code>get_json_ref_counts(json_schema)\n</code></pre> <p>Get all values corresponding to the key '$ref' anywhere in the json_schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_json_ref_counts(self, json_schema: JsonSchemaValue) -&gt; dict[JsonRef, int]:\n\"\"\"Get all values corresponding to the key '$ref' anywhere in the json_schema.\"\"\"\n    json_refs: dict[JsonRef, int] = Counter()\n\n    def _add_json_refs(schema: Any) -&gt; None:\n        if isinstance(schema, dict):\n            if '$ref' in schema:\n                json_ref = JsonRef(schema['$ref'])\n                already_visited = json_ref in json_refs\n                json_refs[json_ref] += 1\n                if already_visited:\n                    return  # prevent recursion on a definition that was already visited\n                def_ref = self.json_to_defs_refs[json_ref]\n                if def_ref in self.core_defs_invalid_for_json_schema:\n                    raise self.core_defs_invalid_for_json_schema[def_ref]\n                _add_json_refs(self.definitions[def_ref])\n            for v in schema.values():\n                _add_json_refs(v)\n        elif isinstance(schema, list):\n            for v in schema:\n                _add_json_refs(v)\n\n    _add_json_refs(json_schema)\n    return json_refs\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.handle_ref_overrides","title":"handle_ref_overrides","text":"<pre><code>handle_ref_overrides(json_schema)\n</code></pre> <p>It is not valid for a schema with a top-level $ref to have sibling keys.</p> <p>During our own schema generation, we treat sibling keys as overrides to the referenced schema, but this is not how the official JSON schema spec works.</p> <p>Because of this, we first remove any sibling keys that are redundant with the referenced schema, then if any remain, we transform the schema from a top-level '$ref' to use allOf to move the $ref out of the top level. (See bottom of https://swagger.io/docs/specification/using-ref/ for a reference about this behavior)</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def handle_ref_overrides(self, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n\"\"\"It is not valid for a schema with a top-level $ref to have sibling keys.\n\n    During our own schema generation, we treat sibling keys as overrides to the referenced schema,\n    but this is not how the official JSON schema spec works.\n\n    Because of this, we first remove any sibling keys that are redundant with the referenced schema, then if\n    any remain, we transform the schema from a top-level '$ref' to use allOf to move the $ref out of the top level.\n    (See bottom of https://swagger.io/docs/specification/using-ref/ for a reference about this behavior)\n    \"\"\"\n    if '$ref' in json_schema:\n        # prevent modifications to the input; this copy may be safe to drop if there is significant overhead\n        json_schema = json_schema.copy()\n\n        referenced_json_schema = self.get_schema_from_definitions(JsonRef(json_schema['$ref']))\n        if referenced_json_schema is None:\n            # This can happen when building schemas for models with not-yet-defined references.\n            # It may be a good idea to do a recursive pass at the end of the generation to remove\n            # any redundant override keys.\n            if len(json_schema) &gt; 1:\n                # Make it an allOf to at least resolve the sibling keys issue\n                json_schema = json_schema.copy()\n                json_schema.setdefault('allOf', [])\n                json_schema['allOf'].append({'$ref': json_schema['$ref']})\n                del json_schema['$ref']\n\n            return json_schema\n        for k, v in list(json_schema.items()):\n            if k == '$ref':\n                continue\n            if k in referenced_json_schema and referenced_json_schema[k] == v:\n                del json_schema[k]  # redundant key\n        if len(json_schema) &gt; 1:\n            # There is a remaining \"override\" key, so we need to move $ref out of the top level\n            json_ref = JsonRef(json_schema['$ref'])\n            del json_schema['$ref']\n            assert 'allOf' not in json_schema  # this should never happen, but just in case\n            json_schema['allOf'] = [{'$ref': json_ref}]\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.int_schema","title":"int_schema","text":"<pre><code>int_schema(schema)\n</code></pre> <p>Returns a schema that matches an int value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.IntSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def int_schema(self, schema: core_schema.IntSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches an int value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: dict[str, Any] = {'type': 'integer'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.numeric)\n    json_schema = {k: v for k, v in json_schema.items() if v not in {math.inf, -math.inf}}\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.is_instance_schema","title":"is_instance_schema","text":"<pre><code>is_instance_schema(schema)\n</code></pre> <p>Returns a schema that checks if a value is an instance of a class, equivalent to Python's <code>isinstance</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.IsInstanceSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def is_instance_schema(self, schema: core_schema.IsInstanceSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that checks if a value is an instance of a class, equivalent to Python's `isinstance`\n    method.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.handle_invalid_for_json_schema(schema, f'core_schema.IsInstanceSchema ({schema[\"cls\"]})')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.is_subclass_schema","title":"is_subclass_schema","text":"<pre><code>is_subclass_schema(schema)\n</code></pre> <p>Returns a schema that checks if a value is a subtype of a class, equivalent to Python's <code>issubclass</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.IsSubclassSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def is_subclass_schema(self, schema: core_schema.IsSubclassSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that checks if a value is a subtype of a class, equivalent to Python's `issubclass` method.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # Note: This is for compatibility with V1; you can override if you want different behavior.\n    return {}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.json_or_python_schema","title":"json_or_python_schema","text":"<pre><code>json_or_python_schema(schema)\n</code></pre> <p>Always uses the json schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def json_or_python_schema(self, schema: core_schema.JsonOrPythonSchema) -&gt; JsonSchemaValue:\n\"\"\"Always uses the json schema.\"\"\"\n    return self.generate_inner(schema['json_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.lax_or_strict_schema","title":"lax_or_strict_schema","text":"<pre><code>lax_or_strict_schema(schema)\n</code></pre> <p>LaxOrStrict will use the strict branch for serialization internally, unless it was overridden here.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def lax_or_strict_schema(self, schema: core_schema.LaxOrStrictSchema) -&gt; JsonSchemaValue:\n\"\"\"LaxOrStrict will use the strict branch for serialization internally,\n    unless it was overridden here.\n    \"\"\"\n    # TODO: Need to read the default value off of model config or whatever\n    use_strict = schema.get('strict', False)  # TODO: replace this default False\n    # If your JSON schema fails to generate it is probably\n    # because one of the following two branches failed.\n    if use_strict:\n        return self.generate_inner(schema['strict_schema'])\n    else:\n        return self.generate_inner(schema['lax_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.list_schema","title":"list_schema","text":"<pre><code>list_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>List</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.ListSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def list_schema(self, schema: core_schema.ListSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `List` value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    items_schema = {} if 'items_schema' not in schema else self.generate_inner(schema['items_schema'])\n    json_schema = {'type': 'array', 'items': items_schema}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.literal_schema","title":"literal_schema","text":"<pre><code>literal_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>Literal</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.LiteralSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def literal_schema(self, schema: core_schema.LiteralSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `Literal` value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    expected = [v.value if isinstance(v, Enum) else v for v in schema['expected']]\n\n    if len(expected) == 1:\n        return {'const': expected[0]}\n    else:\n        return {'enum': expected}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.none_schema","title":"none_schema","text":"<pre><code>none_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>None</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.NoneSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def none_schema(self, schema: core_schema.NoneSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `None` value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'null'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.render_warning_message","title":"render_warning_message","text":"<pre><code>render_warning_message(kind, detail)\n</code></pre> <p>This method is responsible for ignoring warnings as desired, and for formatting the warning messages.</p> <p>You can override the value of <code>ignored_warning_kinds</code> in a subclass of GenerateJsonSchema to modify what warnings are generated. If you want more control, you can override this method; just return None in situations where you don't want warnings to be emitted.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def render_warning_message(self, kind: JsonSchemaWarningKind, detail: str) -&gt; str | None:\n\"\"\"This method is responsible for ignoring warnings as desired, and for formatting the warning messages.\n\n    You can override the value of `ignored_warning_kinds` in a subclass of GenerateJsonSchema\n    to modify what warnings are generated. If you want more control, you can override this method;\n    just return None in situations where you don't want warnings to be emitted.\n    \"\"\"\n    if kind in self.ignored_warning_kinds:\n        return None\n    return f'{detail} [{kind}]'\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.resolve_collisions","title":"resolve_collisions","text":"<pre><code>resolve_collisions(json_schema)\n</code></pre> <p>This function ensures that any defs_ref's that were involved in collisions (due to simplification of the core_ref) get updated, even if they were the first occurrence of the colliding defs_ref.</p> <p>This is intended to prevent confusion where the type that gets the \"shortened\" ref depends on the order in which the types were visited.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def resolve_collisions(self, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n\"\"\"This function ensures that any defs_ref's that were involved in collisions\n    (due to simplification of the core_ref) get updated, even if they were the\n    first occurrence of the colliding defs_ref.\n\n    This is intended to prevent confusion where the type that gets the \"shortened\"\n    ref depends on the order in which the types were visited.\n    \"\"\"\n    made_changes = True\n\n    # Note that because the defs ref choices eventually produce values that use the IDs and\n    # should _never_ collide, it should not be possible for this while loop to run forever\n    while made_changes:\n        made_changes = False\n\n        for defs_ref, core_mode_ref in self.defs_to_core_refs.items():\n            if defs_ref not in self.collisions:\n                continue\n\n            for choice in self.defs_ref_fallbacks[core_mode_ref]:\n                if choice == defs_ref or choice in self.collisions:\n                    continue\n\n                if self.defs_to_core_refs.get(choice, core_mode_ref) == core_mode_ref:\n                    json_schema = self.change_defs_ref(defs_ref, choice, json_schema)\n                    made_changes = True\n                    break\n                else:\n                    self.collisions.add(choice)\n\n            if made_changes:\n                break\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.resolve_schema_to_update","title":"resolve_schema_to_update","text":"<pre><code>resolve_schema_to_update(json_schema)\n</code></pre> <p>Resolve a JsonSchemaValue to the non-ref schema if it is a $ref schema</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def resolve_schema_to_update(self, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n\"\"\"Resolve a JsonSchemaValue to the non-ref schema if it is a $ref schema\"\"\"\n    if '$ref' in json_schema:\n        schema_to_update = self.get_schema_from_definitions(JsonRef(json_schema['$ref']))\n        if schema_to_update is None:\n            raise RuntimeError(f'Cannot update undefined schema for $ref={json_schema[\"$ref\"]}')\n        return self.resolve_schema_to_update(schema_to_update)\n    else:\n        schema_to_update = json_schema\n    return schema_to_update\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.set_schema","title":"set_schema","text":"<pre><code>set_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>Set</code> schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.SetSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def set_schema(self, schema: core_schema.SetSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `Set` schema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self._common_set_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.str_schema","title":"str_schema","text":"<pre><code>str_schema(schema)\n</code></pre> <p>Returns a schema that matches a string value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.StringSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def str_schema(self, schema: core_schema.StringSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a string value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.string)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.time_schema","title":"time_schema","text":"<pre><code>time_schema(schema)\n</code></pre> <p>Returns a schema that matches a time value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.TimeSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def time_schema(self, schema: core_schema.TimeSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a time value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'time'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.timedelta_schema","title":"timedelta_schema","text":"<pre><code>timedelta_schema(schema)\n</code></pre> <p>Returns a schema that matches a <code>timedelta</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.TimedeltaSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def timedelta_schema(self, schema: core_schema.TimedeltaSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a `timedelta` value.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'duration'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tuple_positional_schema","title":"tuple_positional_schema","text":"<pre><code>tuple_positional_schema(schema)\n</code></pre> <p>Returns a schema that matches a tuple of schemas.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.TuplePositionalSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def tuple_positional_schema(self, schema: core_schema.TuplePositionalSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a tuple of schemas.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: JsonSchemaValue = {'type': 'array'}\n    json_schema['minItems'] = len(schema['items_schema'])\n    prefixItems = [self.generate_inner(item) for item in schema['items_schema']]\n    if prefixItems:\n        json_schema['prefixItems'] = prefixItems\n    if 'extra_schema' in schema:\n        json_schema['items'] = self.generate_inner(schema['extra_schema'])\n    else:\n        json_schema['maxItems'] = len(schema['items_schema'])\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tuple_variable_schema","title":"tuple_variable_schema","text":"<pre><code>tuple_variable_schema(schema)\n</code></pre> <p>Returns a schema that matches a tuple of a given schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>core_schema.TupleVariableSchema</code> <p>The schema.</p> required <p>Returns:</p> Name Type Description <code>JsonSchemaValue</code> <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def tuple_variable_schema(self, schema: core_schema.TupleVariableSchema) -&gt; JsonSchemaValue:\n\"\"\"Returns a schema that matches a tuple of a given schema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        JsonSchemaValue: The generated JSON schema.\n    \"\"\"\n    items_schema = {} if 'items_schema' not in schema else self.generate_inner(schema['items_schema'])\n    json_schema = {'type': 'array', 'items': items_schema}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.update_with_validations","title":"update_with_validations","text":"<pre><code>update_with_validations(json_schema, core_schema, mapping)\n</code></pre> <p>Update the json_schema with the corresponding validations specified in the core_schema, using the provided mapping to translate keys in core_schema to the appropriate keys for a JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def update_with_validations(\n    self, json_schema: JsonSchemaValue, core_schema: CoreSchema, mapping: dict[str, str]\n) -&gt; None:\n\"\"\"Update the json_schema with the corresponding validations specified in the core_schema,\n    using the provided mapping to translate keys in core_schema to the appropriate keys for a JSON schema.\n    \"\"\"\n    for core_key, json_schema_key in mapping.items():\n        if core_key in core_schema:\n            json_schema[json_schema_key] = core_schema[core_key]  # type: ignore[literal-required]\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.PydanticJsonSchemaWarning","title":"PydanticJsonSchemaWarning","text":"<p>         Bases: <code>UserWarning</code></p> <p>This class is used to emit warnings produced during JSON schema generation. See the <code>GenerateJsonSchema.emit_warning</code> and <code>GenerateJsonSchema.render_warning_message</code> methods for more details; these can be overridden to control warning behavior.</p>"},{"location":"api/json_schema/#pydantic.json_schema.WithJsonSchema","title":"WithJsonSchema","text":"<p>Add this as an annotation on a field to override the (base) JSON schema that would be generated for that field. This provides a way to set a JSON schema for types that would otherwise raise errors when producing a JSON schema, such as Callable, or types that have an is-instance core schema, without needing to go so far as creating a custom subclass of pydantic.json_schema.GenerateJsonSchema. Note that any modifications to the schema that would normally be made (such as setting the title for model fields) will still be performed.</p> <p>If <code>mode</code> is set this will only apply to that schema generation mode, allowing you to set different json schemas for validation and serialization.</p>"},{"location":"api/json_schema/#pydantic.json_schema.model_json_schema","title":"model_json_schema","text":"<pre><code>model_json_schema(\n    cls,\n    by_alias=True,\n    ref_template=DEFAULT_REF_TEMPLATE,\n    schema_generator=GenerateJsonSchema,\n    mode=\"validation\",\n)\n</code></pre> <p>Utility function to generate a JSON Schema for a model.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def model_json_schema(\n    cls: type[BaseModel] | type[PydanticDataclass],\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n\"\"\"Utility function to generate a JSON Schema for a model.\"\"\"\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n    return schema_generator_instance.generate(cls.__pydantic_core_schema__, mode=mode)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.models_json_schema","title":"models_json_schema","text":"<pre><code>models_json_schema(\n    models,\n    *,\n    by_alias=True,\n    title=None,\n    description=None,\n    ref_template=DEFAULT_REF_TEMPLATE,\n    schema_generator=GenerateJsonSchema\n)\n</code></pre> <p>Utility function to generate a JSON Schema for multiple models.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>Sequence[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode]]</code> <p>A sequence of tuples of the form (model, mode).</p> required <code>by_alias</code> <code>bool</code> <p>Whether field aliases should be used as keys in the generated JSON Schema.</p> <code>True</code> <code>title</code> <code>str | None</code> <p>The title of the generated JSON Schema.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>The description of the generated JSON Schema.</p> <code>None</code> <code>ref_template</code> <code>str</code> <p>The reference template to use for generating JSON Schema references.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The schema generator to use for generating the JSON Schema.</p> <code>GenerateJsonSchema</code> <p>Returns:</p> Type Description <code>tuple[dict[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode], DefsRef], JsonSchemaValue]</code> <p>A 2-tuple, where: - The first element is a dictionary whose keys are tuples of a JSON schema key type and mode, and     whose values are <code>DefsRef</code>. - The second element is the generated JSON Schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def models_json_schema(\n    models: Sequence[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode]],\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n) -&gt; tuple[dict[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode], DefsRef], JsonSchemaValue]:\n\"\"\"Utility function to generate a JSON Schema for multiple models.\n\n    Args:\n        models: A sequence of tuples of the form (model, mode).\n        by_alias: Whether field aliases should be used as keys in the generated JSON Schema.\n        title: The title of the generated JSON Schema.\n        description: The description of the generated JSON Schema.\n        ref_template: The reference template to use for generating JSON Schema references.\n        schema_generator: The schema generator to use for generating the JSON Schema.\n\n    Returns:\n        A 2-tuple, where:\n            - The first element is a dictionary whose keys are tuples of a JSON schema key type and mode, and\n                whose values are `DefsRef`.\n            - The second element is the generated JSON Schema.\n    \"\"\"\n    instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n    inputs = [(m, mode, m.__pydantic_core_schema__) for m, mode in models]\n    key_map, definitions = instance.generate_definitions(inputs)\n\n    json_schema: dict[str, Any] = {}\n    if definitions:\n        json_schema['$defs'] = definitions\n    if title:\n        json_schema['title'] = title\n    if description:\n        json_schema['description'] = description\n\n    return key_map, json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.update_json_schema","title":"update_json_schema","text":"<pre><code>update_json_schema(schema, updates)\n</code></pre> <p>Update a JSON schema by providing a dictionary of updates.</p> <p>This function sets the provided key-value pairs in the schema and returns the updated schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>JsonSchemaValue</code> <p>The JSON schema to update.</p> required <code>updates</code> <code>dict[str, Any]</code> <p>A dictionary of key-value pairs to set in the schema.</p> required <p>Returns:</p> Name Type Description <code>JsonSchemaValue</code> <code>JsonSchemaValue</code> <p>The updated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def update_json_schema(schema: JsonSchemaValue, updates: dict[str, Any]) -&gt; JsonSchemaValue:\n\"\"\"Update a JSON schema by providing a dictionary of updates.\n\n    This function sets the provided key-value pairs in the schema and returns the updated schema.\n\n    Args:\n        schema (JsonSchemaValue): The JSON schema to update.\n        updates (dict[str, Any]): A dictionary of key-value pairs to set in the schema.\n\n    Returns:\n        JsonSchemaValue: The updated JSON schema.\n    \"\"\"\n    schema.update(updates)\n    return schema\n</code></pre>"},{"location":"api/main/","title":"pydantic","text":"<p>Logic for creating models.</p>"},{"location":"api/main/#pydantic.main.BaseModel","title":"BaseModel","text":"<pre><code>BaseModel(__pydantic_self__, **data)\n</code></pre> <p>A base model class for creating Pydantic models.</p> <ul> <li><code>model_fields</code> is a class attribute that contains the fields defined on the model in Pydantic V2.     This replaces <code>Model.__fields__</code> from Pydantic V1.</li> <li><code>__pydantic_decorators__</code> contains the decorators defined on the model in Pydantic V2. This replaces     <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</li> </ul> <p>Attributes:</p> Name Type Description <code>model_fields</code> <code>typing.ClassVar[dict[str, FieldInfo]]</code> <p>Fields in the model.</p> <code>model_config</code> <p>Configuration settings for the model.</p> <code>__pydantic_validator__</code> <code>typing.ClassVar[SchemaValidator]</code> <p>Validator for checking schema validity.</p> <code>__pydantic_core_schema__</code> <code>typing.ClassVar[CoreSchema]</code> <p>Schema for representing the model's core.</p> <code>__pydantic_serializer__</code> <code>typing.ClassVar[SchemaSerializer]</code> <p>Serializer for the schema.</p> <code>__pydantic_decorators__</code> <code>typing.ClassVar[_decorators.DecoratorInfos]</code> <p>Metadata for <code>@field_validator</code>, <code>@root_validator</code>, and <code>@serializer</code> decorators.</p> <code>__signature__</code> <code>typing.ClassVar[Signature]</code> <p>Signature for instantiating the model.</p> <code>__private_attributes__</code> <code>typing.ClassVar[dict[str, ModelPrivateAttr]]</code> <p>Private attributes of the model.</p> <code>__class_vars__</code> <code>typing.ClassVar[set[str]]</code> <p>Class variables of the model.</p> <code>__pydantic_fields_set__</code> <code>set[str]</code> <p>Set of fields in the model.</p> <code>__pydantic_extra__</code> <code>dict[str, Any] | None</code> <p>Extra fields in the model.</p> <code>__pydantic_private__</code> <code>dict[str, Any] | None</code> <p>Private fields in the model.</p> <code>__pydantic_generic_metadata__</code> <code>typing.ClassVar[_generics.PydanticGenericMetadata]</code> <p>Metadata for generic models.</p> <code>__pydantic_parent_namespace__</code> <code>typing.ClassVar[dict[str, Any] | None]</code> <p>Parent namespace of the model.</p> <code>__pydantic_custom_init__</code> <code>typing.ClassVar[bool]</code> <p>Custom init of the model.</p> <code>__pydantic_post_init__</code> <code>typing.ClassVar[None | Literal['model_post_init']]</code> <p>Post init of the model.</p> <code>__pydantic_complete__</code> <p>Whether model building is completed.</p> <code>__pydantic_root_model__</code> <code>typing.ClassVar[bool]</code> <p>Whether the model is a RootModel.</p> <p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p> <p>Uses something other than <code>self</code> for the first arg to allow \"self\" as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(__pydantic_self__, **data: Any) -&gt; None:  # type: ignore\n\"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises ValidationError if the input data cannot be parsed to form a valid model.\n\n    Uses something other than `self` for the first arg to allow \"self\" as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_computed_fields","title":"model_computed_fields  <code>property</code>","text":"<pre><code>model_computed_fields: dict[str, ComputedFieldInfo]\n</code></pre> <p>Get the computed fields of this model instance.</p> <p>Returns:</p> Type Description <code>dict[str, ComputedFieldInfo]</code> <p>A dictionary of computed field names and their corresponding <code>ComputedFieldInfo</code> objects.</p>"},{"location":"api/main/#pydantic.main.BaseModel.model_extra","title":"model_extra  <code>property</code>","text":"<pre><code>model_extra: dict[str, Any] | None\n</code></pre> <p>Get extra fields set during validation.</p> <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>A dictionary of extra fields, or <code>None</code> if <code>config.extra</code> is not set to <code>\"allow\"</code>.</p>"},{"location":"api/main/#pydantic.main.BaseModel.model_fields_set","title":"model_fields_set  <code>property</code>","text":"<pre><code>model_fields_set: set[str]\n</code></pre> <p>Returns the set of fields that have been set on this model instance.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>A set of strings representing the fields that have been set, i.e. that were not filled from defaults.</p>"},{"location":"api/main/#pydantic.main.BaseModel.copy","title":"copy","text":"<pre><code>copy(\n    *, include=None, exclude=None, update=None, deep=False\n)\n</code></pre> <p>Returns a copy of the model.</p> <p>This method is now deprecated; use <code>model_copy</code> instead. If you need <code>include</code> or <code>exclude</code>, use:</p> <pre><code>data = self.model_dump(include=include, exclude=exclude, round_trip=True)\ndata = {**data, **(update or {})}\ncopied = self.model_validate(data)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>include</code> <code>AbstractSetIntStr | MappingIntStrAny | None</code> <p>Optional set or mapping specifying which fields to include in the copied model.</p> <code>None</code> <code>exclude</code> <code>AbstractSetIntStr | MappingIntStrAny | None</code> <p>Optional set or mapping specifying which fields to exclude in the copied model.</p> <code>None</code> <code>update</code> <code>typing.Dict[str, Any] | None</code> <p>Optional dictionary of field-value pairs to override field values in the copied model.</p> <code>None</code> <code>deep</code> <code>bool</code> <p>If True, the values of fields that are Pydantic models will be deep copied.</p> <code>False</code> <p>Returns:</p> Type Description <code>Model</code> <p>A copy of the model with included, excluded and updated fields as specified.</p> Source code in <code>pydantic/main.py</code> <pre><code>@typing_extensions.deprecated('The copy method is deprecated; use `model_copy` instead.')\ndef copy(\n    self: Model,\n    *,\n    include: AbstractSetIntStr | MappingIntStrAny | None = None,\n    exclude: AbstractSetIntStr | MappingIntStrAny | None = None,\n    update: typing.Dict[str, Any] | None = None,  # noqa UP006\n    deep: bool = False,\n) -&gt; Model:  # pragma: no cover\n\"\"\"Returns a copy of the model.\n\n    This method is now deprecated; use `model_copy` instead. If you need `include` or `exclude`, use:\n\n    ```py\n    data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n    data = {**data, **(update or {})}\n    copied = self.model_validate(data)\n    ```\n\n    Args:\n        include: Optional set or mapping\n            specifying which fields to include in the copied model.\n        exclude: Optional set or mapping\n            specifying which fields to exclude in the copied model.\n        update: Optional dictionary of field-value pairs to override field values\n            in the copied model.\n        deep: If True, the values of fields that are Pydantic models will be deep copied.\n\n    Returns:\n        A copy of the model with included, excluded and updated fields as specified.\n    \"\"\"\n    warnings.warn(\n        'The `copy` method is deprecated; use `model_copy` instead. '\n        'See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`.',\n        DeprecationWarning,\n    )\n\n    values = dict(\n        _deprecated_copy_internals._iter(  # type: ignore\n            self, to_dict=False, by_alias=False, include=include, exclude=exclude, exclude_unset=False\n        ),\n        **(update or {}),\n    )\n    if self.__pydantic_private__ is None:\n        private = None\n    else:\n        private = {k: v for k, v in self.__pydantic_private__.items() if v is not PydanticUndefined}\n\n    if self.__pydantic_extra__ is None:\n        extra: dict[str, Any] | None = None\n    else:\n        extra = self.__pydantic_extra__.copy()\n        for k in list(self.__pydantic_extra__):\n            if k not in values:  # k was in the exclude\n                extra.pop(k)\n        for k in list(values):\n            if k in self.__pydantic_extra__:  # k must have come from extra\n                extra[k] = values.pop(k)\n\n    # new `__pydantic_fields_set__` can have unset optional fields with a set value in `update` kwarg\n    if update:\n        fields_set = self.__pydantic_fields_set__ | update.keys()\n    else:\n        fields_set = set(self.__pydantic_fields_set__)\n\n    # removing excluded fields from `__pydantic_fields_set__`\n    if exclude:\n        fields_set -= set(exclude)\n\n    return _deprecated_copy_internals._copy_and_set_values(self, values, fields_set, extra, private, deep=deep)\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_construct","title":"model_construct  <code>classmethod</code>","text":"<pre><code>model_construct(_fields_set=None, **values)\n</code></pre> <p>Creates a new instance of the <code>Model</code> class with validated data.</p> <p>Creates a new model setting <code>__dict__</code> and <code>__pydantic_fields_set__</code> from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if <code>Config.extra = 'allow'</code> was set since it adds all passed values</p> <p>Parameters:</p> Name Type Description Default <code>_fields_set</code> <code>set[str] | None</code> <p>The set of field names accepted for the Model instance.</p> <code>None</code> <code>values</code> <code>Any</code> <p>Trusted or pre-validated data dictionary.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Model</code> <p>A new instance of the <code>Model</code> class with validated data.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_construct(cls: type[Model], _fields_set: set[str] | None = None, **values: Any) -&gt; Model:\n\"\"\"Creates a new instance of the `Model` class with validated data.\n\n    Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n    Default values are respected, but no other validation is performed.\n    Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n\n    Args:\n        _fields_set: The set of field names accepted for the Model instance.\n        values: Trusted or pre-validated data dictionary.\n\n    Returns:\n        A new instance of the `Model` class with validated data.\n    \"\"\"\n    m = cls.__new__(cls)\n    fields_values: dict[str, Any] = {}\n    defaults: dict[str, Any] = {}  # keeping this separate from `fields_values` helps us compute `_fields_set`\n    for name, field in cls.model_fields.items():\n        if field.alias and field.alias in values:\n            fields_values[name] = values.pop(field.alias)\n        elif name in values:\n            fields_values[name] = values.pop(name)\n        elif not field.is_required():\n            defaults[name] = field.get_default(call_default_factory=True)\n    if _fields_set is None:\n        _fields_set = set(fields_values.keys())\n    fields_values.update(defaults)\n\n    _extra: dict[str, Any] | None = None\n    if cls.model_config.get('extra') == 'allow':\n        _extra = {}\n        for k, v in values.items():\n            _extra[k] = v\n    else:\n        fields_values.update(values)\n    _object_setattr(m, '__dict__', fields_values)\n    _object_setattr(m, '__pydantic_fields_set__', _fields_set)\n    _object_setattr(m, '__pydantic_extra__', _extra)\n\n    if cls.__pydantic_post_init__:\n        m.model_post_init(None)\n    else:\n        # Note: if there are any private attributes, cls.__pydantic_post_init__ would exist\n        # Since it doesn't, that means that `__pydantic_private__` should be set to None\n        _object_setattr(m, '__pydantic_private__', None)\n\n    return m\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_copy","title":"model_copy","text":"<pre><code>model_copy(*, update=None, deep=False)\n</code></pre> <p>Returns a copy of the model.</p> <p>Parameters:</p> Name Type Description Default <code>update</code> <code>dict[str, Any] | None</code> <p>Values to change/add in the new model. Note: the data is not validated before creating the new model. You should trust this data.</p> <code>None</code> <code>deep</code> <code>bool</code> <p>Set to <code>True</code> to make a deep copy of the model.</p> <code>False</code> <p>Returns:</p> Type Description <code>Model</code> <p>New model instance.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_copy(self: Model, *, update: dict[str, Any] | None = None, deep: bool = False) -&gt; Model:\n\"\"\"Returns a copy of the model.\n\n    Args:\n        update: Values to change/add in the new model. Note: the data is not validated\n            before creating the new model. You should trust this data.\n        deep: Set to `True` to make a deep copy of the model.\n\n    Returns:\n        New model instance.\n    \"\"\"\n    copied = self.__deepcopy__() if deep else self.__copy__()\n    if update:\n        if self.model_config.get('extra') == 'allow':\n            for k, v in update.items():\n                if k in self.model_fields:\n                    copied.__dict__[k] = v\n                else:\n                    if copied.__pydantic_extra__ is None:\n                        copied.__pydantic_extra__ = {}\n                    copied.__pydantic_extra__[k] = v\n        else:\n            copied.__dict__.update(update)\n        copied.__pydantic_fields_set__.update(update.keys())\n    return copied\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_dump","title":"model_dump","text":"<pre><code>model_dump(\n    *,\n    mode=\"python\",\n    include=None,\n    exclude=None,\n    by_alias=False,\n    exclude_unset=False,\n    exclude_defaults=False,\n    exclude_none=False,\n    round_trip=False,\n    warnings=True\n)\n</code></pre> <p>Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['json', 'python'] | str</code> <p>The mode in which <code>to_python</code> should run. If mode is 'json', the dictionary will only contain JSON serializable types. If mode is 'python', the dictionary may contain any Python objects.</p> <code>'python'</code> <code>include</code> <code>IncEx</code> <p>A list of fields to include in the output.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>A list of fields to exclude from the output.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the field's alias in the dictionary key if defined.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that are unset or None from the output.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are set to their default value from the output.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code> from the output.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and deserialization round-trip support.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to log warnings when invalid fields are encountered.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary representation of the model.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_dump(\n    self,\n    *,\n    mode: Literal['json', 'python'] | str = 'python',\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; dict[str, Any]:\n\"\"\"Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n    Args:\n        mode: The mode in which `to_python` should run.\n            If mode is 'json', the dictionary will only contain JSON serializable types.\n            If mode is 'python', the dictionary may contain any Python objects.\n        include: A list of fields to include in the output.\n        exclude: A list of fields to exclude from the output.\n        by_alias: Whether to use the field's alias in the dictionary key if defined.\n        exclude_unset: Whether to exclude fields that are unset or None from the output.\n        exclude_defaults: Whether to exclude fields that are set to their default value from the output.\n        exclude_none: Whether to exclude fields that have a value of `None` from the output.\n        round_trip: Whether to enable serialization and deserialization round-trip support.\n        warnings: Whether to log warnings when invalid fields are encountered.\n\n    Returns:\n        A dictionary representation of the model.\n    \"\"\"\n    return self.__pydantic_serializer__.to_python(\n        self,\n        mode=mode,\n        by_alias=by_alias,\n        include=include,\n        exclude=exclude,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n    )\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(\n    *,\n    indent=None,\n    include=None,\n    exclude=None,\n    by_alias=False,\n    exclude_unset=False,\n    exclude_defaults=False,\n    exclude_none=False,\n    round_trip=False,\n    warnings=True\n)\n</code></pre> <p>Generates a JSON representation of the model using Pydantic's <code>to_json</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int | None</code> <p>Indentation to use in the JSON output. If None is passed, the output will be compact.</p> <code>None</code> <code>include</code> <code>IncEx</code> <p>Field(s) to include in the JSON output. Can take either a string or set of strings.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>Field(s) to exclude from the JSON output. Can take either a string or set of strings.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to serialize using field aliases.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that have the default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to use serialization/deserialization between JSON and class instance.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to show any warnings that occurred during serialization.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string representation of the model.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_dump_json(\n    self,\n    *,\n    indent: int | None = None,\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; str:\n\"\"\"Generates a JSON representation of the model using Pydantic's `to_json` method.\n\n    Args:\n        indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n        include: Field(s) to include in the JSON output. Can take either a string or set of strings.\n        exclude: Field(s) to exclude from the JSON output. Can take either a string or set of strings.\n        by_alias: Whether to serialize using field aliases.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that have the default value.\n        exclude_none: Whether to exclude fields that have a value of `None`.\n        round_trip: Whether to use serialization/deserialization between JSON and class instance.\n        warnings: Whether to show any warnings that occurred during serialization.\n\n    Returns:\n        A JSON string representation of the model.\n    \"\"\"\n    return self.__pydantic_serializer__.to_json(\n        self,\n        indent=indent,\n        include=include,\n        exclude=exclude,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n    ).decode()\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_json_schema","title":"model_json_schema  <code>classmethod</code>","text":"<pre><code>model_json_schema(\n    by_alias=True,\n    ref_template=DEFAULT_REF_TEMPLATE,\n    schema_generator=GenerateJsonSchema,\n    mode=\"validation\",\n)\n</code></pre> <p>Generates a JSON schema for a model class.</p> <p>To override the logic used to generate the JSON schema, you can create a subclass of <code>GenerateJsonSchema</code> with your desired modifications, then override this method on a custom base class and set the default value of <code>schema_generator</code> to be your subclass.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether to use attribute aliases or not.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The reference template.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The JSON schema generator.</p> <code>GenerateJsonSchema</code> <code>mode</code> <code>JsonSchemaMode</code> <p>The mode in which to generate the schema.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The JSON schema for the given model class.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_json_schema(\n    cls,\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n\"\"\"Generates a JSON schema for a model class.\n\n    To override the logic used to generate the JSON schema, you can create a subclass of `GenerateJsonSchema`\n    with your desired modifications, then override this method on a custom base class and set the default\n    value of `schema_generator` to be your subclass.\n\n    Args:\n        by_alias: Whether to use attribute aliases or not.\n        ref_template: The reference template.\n        schema_generator: The JSON schema generator.\n        mode: The mode in which to generate the schema.\n\n    Returns:\n        The JSON schema for the given model class.\n    \"\"\"\n    return model_json_schema(\n        cls, by_alias=by_alias, ref_template=ref_template, schema_generator=schema_generator, mode=mode\n    )\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_parametrized_name","title":"model_parametrized_name  <code>classmethod</code>","text":"<pre><code>model_parametrized_name(params)\n</code></pre> <p>Compute the class name for parametrizations of generic classes.</p> <p>This method can be overridden to achieve a custom naming scheme for generic BaseModels.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple[type[Any], ...]</code> <p>Tuple of types of the class. Given a generic class <code>Model</code> with 2 type variables and a concrete model <code>Model[str, int]</code>, the value <code>(str, int)</code> would be passed to <code>params</code>.</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representing the new class where <code>params</code> are passed to <code>cls</code> as type variables.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Raised when trying to generate concrete names for non-generic models.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_parametrized_name(cls, params: tuple[type[Any], ...]) -&gt; str:\n\"\"\"Compute the class name for parametrizations of generic classes.\n\n    This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n\n    Args:\n        params: Tuple of types of the class. Given a generic class\n            `Model` with 2 type variables and a concrete model `Model[str, int]`,\n            the value `(str, int)` would be passed to `params`.\n\n    Returns:\n        String representing the new class where `params` are passed to `cls` as type variables.\n\n    Raises:\n        TypeError: Raised when trying to generate concrete names for non-generic models.\n    \"\"\"\n    if not issubclass(cls, typing.Generic):  # type: ignore[arg-type]\n        raise TypeError('Concrete names should only be generated for generic models.')\n\n    # Any strings received should represent forward references, so we handle them specially below.\n    # If we eventually move toward wrapping them in a ForwardRef in __class_getitem__ in the future,\n    # we may be able to remove this special case.\n    param_names = [param if isinstance(param, str) else _repr.display_as_type(param) for param in params]\n    params_component = ', '.join(param_names)\n    return f'{cls.__name__}[{params_component}]'\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context)\n</code></pre> <p>Override this method to perform additional initialization after <code>__init__</code> and <code>model_construct</code>. This is useful if you want to do some validation that requires the entire model to be initialized.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n\"\"\"Override this method to perform additional initialization after `__init__` and `model_construct`.\n    This is useful if you want to do some validation that requires the entire model to be initialized.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_rebuild","title":"model_rebuild  <code>classmethod</code>","text":"<pre><code>model_rebuild(\n    *,\n    force=False,\n    raise_errors=True,\n    _parent_namespace_depth=2,\n    _types_namespace=None\n)\n</code></pre> <p>Try to rebuild the pydantic-core schema for the model.</p> <p>This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.</p> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>Whether to force the rebuilding of the model schema, defaults to <code>False</code>.</p> <code>False</code> <code>raise_errors</code> <code>bool</code> <p>Whether to raise errors, defaults to <code>True</code>.</p> <code>True</code> <code>_parent_namespace_depth</code> <code>int</code> <p>The depth level of the parent namespace, defaults to 2.</p> <code>2</code> <code>_types_namespace</code> <code>dict[str, Any] | None</code> <p>The types namespace, defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>Returns <code>None</code> if the schema is already \"complete\" and rebuilding was not required.</p> <code>bool | None</code> <p>If rebuilding was required, returns <code>True</code> if rebuilding was successful, otherwise <code>False</code>.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_rebuild(\n    cls,\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None,\n) -&gt; bool | None:\n\"\"\"Try to rebuild the pydantic-core schema for the model.\n\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n    the initial attempt to build the schema, and automatic rebuilding fails.\n\n    Args:\n        force: Whether to force the rebuilding of the model schema, defaults to `False`.\n        raise_errors: Whether to raise errors, defaults to `True`.\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n        _types_namespace: The types namespace, defaults to `None`.\n\n    Returns:\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n    \"\"\"\n    if not force and cls.__pydantic_complete__:\n        return None\n    else:\n        if _types_namespace is not None:\n            types_namespace: dict[str, Any] | None = _types_namespace.copy()\n        else:\n            if _parent_namespace_depth &gt; 0:\n                frame_parent_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth) or {}\n                cls_parent_ns = cls.__pydantic_parent_namespace__ or {}\n                cls.__pydantic_parent_namespace__ = {**cls_parent_ns, **frame_parent_ns}\n\n            types_namespace = cls.__pydantic_parent_namespace__\n\n            types_namespace = _typing_extra.get_cls_types_namespace(cls, types_namespace)\n        return _model_construction.complete_model_class(\n            cls,\n            cls.__name__,\n            _config.ConfigWrapper(cls.model_config, check=False),\n            raise_errors=raise_errors,\n            types_namespace=types_namespace,\n        )\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(\n    obj, *, strict=None, from_attributes=None, context=None\n)\n</code></pre> <p>Validate a pydantic model instance.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to raise an exception on invalid fields.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to extract data from object attributes.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the object could not be validated.</p> <p>Returns:</p> Type Description <code>Model</code> <p>The validated model instance.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_validate(\n    cls: type[Model],\n    obj: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; Model:\n\"\"\"Validate a pydantic model instance.\n\n    Args:\n        obj: The object to validate.\n        strict: Whether to raise an exception on invalid fields.\n        from_attributes: Whether to extract data from object attributes.\n        context: Additional context to pass to the validator.\n\n    Raises:\n        ValidationError: If the object could not be validated.\n\n    Returns:\n        The validated model instance.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    return cls.__pydantic_validator__.validate_python(\n        obj, strict=strict, from_attributes=from_attributes, context=context\n    )\n</code></pre>"},{"location":"api/main/#pydantic.main.BaseModel.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(\n    json_data, *, strict=None, context=None\n)\n</code></pre> <p>Validate the given JSON data against the Pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str | bytes | bytearray</code> <p>The JSON data to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to enforce types strictly.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Extra variables to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Model</code> <p>The validated Pydantic model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>json_data</code> is not a JSON string.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_validate_json(\n    cls: type[Model],\n    json_data: str | bytes | bytearray,\n    *,\n    strict: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; Model:\n\"\"\"Validate the given JSON data against the Pydantic model.\n\n    Args:\n        json_data: The JSON data to validate.\n        strict: Whether to enforce types strictly.\n        context: Extra variables to pass to the validator.\n\n    Returns:\n        The validated Pydantic model.\n\n    Raises:\n        ValueError: If `json_data` is not a JSON string.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)\n</code></pre>"},{"location":"api/main/#pydantic.main.create_model","title":"create_model","text":"<pre><code>create_model(\n    __model_name,\n    *,\n    __config__=None,\n    __base__=None,\n    __module__=__name__,\n    __validators__=None,\n    __cls_kwargs__=None,\n    __slots__=None,\n    **field_definitions\n)\n</code></pre> <p>Dynamically creates and returns a new Pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>__model_name</code> <code>str</code> <p>The name of the newly created model.</p> required <code>__config__</code> <code>ConfigDict | None</code> <p>The configuration of the new model.</p> <code>None</code> <code>__base__</code> <code>type[Model] | tuple[type[Model], ...] | None</code> <p>The base class for the new model.</p> <code>None</code> <code>__module__</code> <code>str</code> <p>The name of the module that the model belongs to.</p> <code>__name__</code> <code>__validators__</code> <code>dict[str, AnyClassMethod] | None</code> <p>A dictionary of methods that validate fields.</p> <code>None</code> <code>__cls_kwargs__</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments for class creation.</p> <code>None</code> <code>__slots__</code> <code>tuple[str, ...] | None</code> <p>Deprecated. Should not be passed to <code>create_model</code>.</p> <code>None</code> <code>**field_definitions</code> <code>Any</code> <p>Attributes of the new model. They should be passed in the format: <code>&lt;name&gt;=(&lt;type&gt;, &lt;default value&gt;)</code> or <code>&lt;name&gt;=&lt;default value&gt;</code>. For more complex cases, they can be passed in the format: <code>&lt;name&gt;=&lt;Field&gt;</code> or <code>&lt;name&gt;=(&lt;type&gt;, &lt;FieldInfo&gt;)</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>type[Model]</code> <p>The newly created model.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>If <code>__base__</code> and <code>__config__</code> are both passed.</p> Source code in <code>pydantic/main.py</code> <pre><code>def create_model(\n    __model_name: str,\n    *,\n    __config__: ConfigDict | None = None,\n    __base__: type[Model] | tuple[type[Model], ...] | None = None,\n    __module__: str = __name__,\n    __validators__: dict[str, AnyClassMethod] | None = None,\n    __cls_kwargs__: dict[str, Any] | None = None,\n    __slots__: tuple[str, ...] | None = None,\n    **field_definitions: Any,\n) -&gt; type[Model]:\n\"\"\"Dynamically creates and returns a new Pydantic model.\n\n    Args:\n        __model_name: The name of the newly created model.\n        __config__: The configuration of the new model.\n        __base__: The base class for the new model.\n        __module__: The name of the module that the model belongs to.\n        __validators__: A dictionary of methods that validate\n            fields.\n        __cls_kwargs__: A dictionary of keyword arguments for class creation.\n        __slots__: Deprecated. Should not be passed to `create_model`.\n        **field_definitions: Attributes of the new model. They should be passed in the format:\n            `&lt;name&gt;=(&lt;type&gt;, &lt;default value&gt;)` or `&lt;name&gt;=&lt;default value&gt;`. For more complex cases, they can be\n            passed in the format: `&lt;name&gt;=&lt;Field&gt;` or `&lt;name&gt;=(&lt;type&gt;, &lt;FieldInfo&gt;)`.\n\n    Returns:\n        The newly created model.\n\n    Raises:\n        PydanticUserError: If `__base__` and `__config__` are both passed.\n    \"\"\"\n    if __slots__ is not None:\n        # __slots__ will be ignored from here on\n        warnings.warn('__slots__ should not be passed to create_model', RuntimeWarning)\n\n    if __base__ is not None:\n        if __config__ is not None:\n            raise PydanticUserError(\n                'to avoid confusion `__config__` and `__base__` cannot be used together',\n                code='create-model-config-base',\n            )\n        if not isinstance(__base__, tuple):\n            __base__ = (__base__,)\n    else:\n        __base__ = (typing.cast(typing.Type['Model'], BaseModel),)\n\n    __cls_kwargs__ = __cls_kwargs__ or {}\n\n    fields = {}\n    annotations = {}\n\n    for f_name, f_def in field_definitions.items():\n        if not _fields.is_valid_field_name(f_name):\n            warnings.warn(f'fields may not start with an underscore, ignoring \"{f_name}\"', RuntimeWarning)\n        if isinstance(f_def, tuple):\n            f_def = typing.cast('tuple[str, Any]', f_def)\n            try:\n                f_annotation, f_value = f_def\n            except ValueError as e:\n                raise PydanticUserError(\n                    'Field definitions should either be a `(&lt;type&gt;, &lt;default&gt;)`.',\n                    code='create-model-field-definitions',\n                ) from e\n        else:\n            f_annotation, f_value = None, f_def\n\n        if f_annotation:\n            annotations[f_name] = f_annotation\n        fields[f_name] = f_value\n\n    namespace: dict[str, Any] = {'__annotations__': annotations, '__module__': __module__}\n    if __validators__:\n        namespace.update(__validators__)\n    namespace.update(fields)\n    if __config__:\n        namespace['model_config'] = _config.ConfigWrapper(__config__).config_dict\n    resolved_bases = types.resolve_bases(__base__)\n    meta, ns, kwds = types.prepare_class(__model_name, resolved_bases, kwds=__cls_kwargs__)\n    if resolved_bases is not __base__:\n        ns['__orig_bases__'] = __base__\n    namespace.update(ns)\n    return meta(__model_name, resolved_bases, namespace, __pydantic_reset_parent_namespace__=False, **kwds)\n</code></pre>"},{"location":"api/mypy/","title":"pydantic.mypy","text":""},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer","title":"PydanticModelTransformer","text":"<pre><code>PydanticModelTransformer(ctx, plugin_config)\n</code></pre> Source code in <code>pydantic/mypy.py</code> <pre><code>def __init__(self, ctx: ClassDefContext, plugin_config: PydanticPluginConfig) -&gt; None:\n    self._ctx = ctx\n    self.plugin_config = plugin_config\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.add_initializer","title":"add_initializer","text":"<pre><code>add_initializer(fields, config)\n</code></pre> <p>Adds a fields-aware <code>__init__</code> method to the class.</p> <p>The added <code>__init__</code> will be annotated with types vs. all <code>Any</code> depending on the plugin settings.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def add_initializer(self, fields: list[PydanticModelField], config: ModelConfigData) -&gt; None:\n\"\"\"Adds a fields-aware `__init__` method to the class.\n\n    The added `__init__` will be annotated with types vs. all `Any` depending on the plugin settings.\n    \"\"\"\n    ctx = self._ctx\n    typed = self.plugin_config.init_typed\n    use_alias = config.populate_by_name is not True\n    force_all_optional = bool(config.has_alias_generator and not config.populate_by_name)\n    init_arguments = self.get_field_arguments(\n        fields, typed=typed, force_all_optional=force_all_optional, use_alias=use_alias\n    )\n    if not self.should_init_forbid_extra(fields, config):\n        var = Var('kwargs')\n        init_arguments.append(Argument(var, AnyType(TypeOfAny.explicit), None, ARG_STAR2))\n\n    if '__init__' not in ctx.cls.info.names:\n        add_method(ctx, '__init__', init_arguments, NoneType())\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.add_model_construct_method","title":"add_model_construct_method","text":"<pre><code>add_model_construct_method(fields)\n</code></pre> <p>Adds a fully typed <code>model_construct</code> classmethod to the class.</p> <p>Similar to the fields-aware init method, but always uses the field names (not aliases), and does not treat settings fields as optional.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def add_model_construct_method(self, fields: list[PydanticModelField]) -&gt; None:\n\"\"\"Adds a fully typed `model_construct` classmethod to the class.\n\n    Similar to the fields-aware __init__ method, but always uses the field names (not aliases),\n    and does not treat settings fields as optional.\n    \"\"\"\n    ctx = self._ctx\n    set_str = ctx.api.named_type(f'{BUILTINS_NAME}.set', [ctx.api.named_type(f'{BUILTINS_NAME}.str')])\n    optional_set_str = UnionType([set_str, NoneType()])\n    fields_set_argument = Argument(Var('_fields_set', optional_set_str), optional_set_str, None, ARG_OPT)\n    construct_arguments = self.get_field_arguments(fields, typed=True, force_all_optional=False, use_alias=False)\n    construct_arguments = [fields_set_argument] + construct_arguments\n\n    obj_type = ctx.api.named_type(f'{BUILTINS_NAME}.object')\n    self_tvar_name = '_PydanticBaseModel'  # Make sure it does not conflict with other names in the class\n    tvar_fullname = ctx.cls.fullname + '.' + self_tvar_name\n    # requires mypy&gt;0.910\n    if MYPY_VERSION_TUPLE &gt;= (1, 4):\n        self_type = TypeVarType(\n            self_tvar_name, tvar_fullname, -1, [], obj_type, AnyType(TypeOfAny.from_omitted_generics)\n        )\n        self_tvar_expr = TypeVarExpr(\n            self_tvar_name, tvar_fullname, [], obj_type, AnyType(TypeOfAny.from_omitted_generics)\n        )\n    else:\n        self_type = TypeVarDef(self_tvar_name, tvar_fullname, -1, [], obj_type)\n        self_tvar_expr = TypeVarExpr(self_tvar_name, tvar_fullname, [], obj_type)\n    ctx.cls.info.names[self_tvar_name] = SymbolTableNode(MDEF, self_tvar_expr)\n\n    add_method(\n        ctx,\n        'model_construct',\n        construct_arguments,\n        return_type=self_type,\n        self_type=self_type,\n        tvar_def=self_type,\n        is_classmethod=True,\n    )\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.adjust_validator_signatures","title":"adjust_validator_signatures","text":"<pre><code>adjust_validator_signatures()\n</code></pre> <p>When we decorate a function <code>f</code> with <code>pydantic.validator(...)</code>, <code>pydantic.field_validator</code> or <code>pydantic.serializer(...)</code>, mypy sees <code>f</code> as a regular method taking a <code>self</code> instance, even though pydantic internally wraps <code>f</code> with <code>classmethod</code> if necessary.</p> <p>Teach mypy this by marking any function whose outermost decorator is a <code>validator()</code>, <code>field_validator()</code> or <code>serializer()</code> call as a <code>classmethod</code>.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def adjust_validator_signatures(self) -&gt; None:\n\"\"\"When we decorate a function `f` with `pydantic.validator(...)`, `pydantic.field_validator`\n    or `pydantic.serializer(...)`, mypy sees `f` as a regular method taking a `self` instance,\n    even though pydantic internally wraps `f` with `classmethod` if necessary.\n\n    Teach mypy this by marking any function whose outermost decorator is a `validator()`,\n    `field_validator()` or `serializer()` call as a `classmethod`.\n    \"\"\"\n    for name, sym in self._ctx.cls.info.names.items():\n        if isinstance(sym.node, Decorator):\n            first_dec = sym.node.original_decorators[0]\n            if (\n                isinstance(first_dec, CallExpr)\n                and isinstance(first_dec.callee, NameExpr)\n                and first_dec.callee.fullname in DECORATOR_FULLNAMES\n            ):\n                sym.node.func.is_class = True\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.collect_config","title":"collect_config","text":"<pre><code>collect_config()\n</code></pre> <p>Collects the values of the config attributes that are used by the plugin, accounting for parent classes.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def collect_config(self) -&gt; ModelConfigData:  # noqa: C901 (ignore complexity)\n\"\"\"Collects the values of the config attributes that are used by the plugin, accounting for parent classes.\"\"\"\n    ctx = self._ctx\n    cls = ctx.cls\n    config = ModelConfigData()\n\n    has_config_kwargs = False\n    has_config_from_namespace = False\n\n    for name, expr in cls.keywords.items():\n        config_data = self.get_config_update(name, expr)\n        if config_data:\n            has_config_kwargs = True\n            config.update(config_data)\n\n    for stmt in cls.defs.body:\n        if not isinstance(stmt, (AssignmentStmt, ClassDef)):\n            continue\n\n        if isinstance(stmt, AssignmentStmt):\n            lhs = stmt.lvalues[0]\n            if not isinstance(lhs, NameExpr) or lhs.name != 'model_config' or not isinstance(stmt.rvalue, CallExpr):\n                continue\n            for arg_name, arg in zip(stmt.rvalue.arg_names, stmt.rvalue.args):\n                if arg_name is None:\n                    continue\n                config.update(self.get_config_update(arg_name, arg))\n\n        if isinstance(stmt, ClassDef):\n            if stmt.name != 'Config':  # 'deprecated' Config-class\n                continue\n            for substmt in stmt.defs.body:\n                if not isinstance(substmt, AssignmentStmt):\n                    continue\n                lhs = substmt.lvalues[0]\n                if not isinstance(lhs, NameExpr):\n                    continue\n                config.update(self.get_config_update(lhs.name, substmt.rvalue))\n\n        if has_config_kwargs:\n            ctx.api.fail(\n                'Specifying config in two places is ambiguous, use either Config attribute or class kwargs',\n                cls,\n            )\n            break\n\n        has_config_from_namespace = True\n\n    if has_config_kwargs or has_config_from_namespace:\n        if (\n            config.has_alias_generator\n            and not config.populate_by_name\n            and self.plugin_config.warn_required_dynamic_aliases\n        ):\n            error_required_dynamic_aliases(ctx.api, stmt)\n    for info in cls.info.mro[1:]:  # 0 is the current class\n        if METADATA_KEY not in info.metadata:\n            continue\n\n        # Each class depends on the set of fields in its ancestors\n        ctx.api.add_plugin_dependency(make_wildcard_trigger(get_fullname(info)))\n        for name, value in info.metadata[METADATA_KEY]['config'].items():\n            config.setdefault(name, value)\n    return config\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.collect_fields","title":"collect_fields","text":"<pre><code>collect_fields(model_config)\n</code></pre> <p>Collects the fields for the model, accounting for parent classes.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def collect_fields(self, model_config: ModelConfigData) -&gt; list[PydanticModelField]:\n\"\"\"Collects the fields for the model, accounting for parent classes.\"\"\"\n    # First, collect fields belonging to the current class.\n    ctx = self._ctx\n    cls = self._ctx.cls\n    fields: list[PydanticModelField] = []\n    known_fields: set[str] = set()\n    for stmt in cls.defs.body:\n        maybe_field = self.collect_field_from_stmt(stmt, model_config)\n        if maybe_field is not None:\n            fields.append(maybe_field)\n            known_fields.add(maybe_field.name)\n\n    all_fields = fields.copy()\n    for info in cls.info.mro[1:]:  # 0 is the current class, -2 is BaseModel, -1 is object\n        if METADATA_KEY not in info.metadata:\n            continue\n\n        superclass_fields = []\n        # Each class depends on the set of fields in its ancestors\n        ctx.api.add_plugin_dependency(make_wildcard_trigger(get_fullname(info)))\n\n        for name, data in info.metadata[METADATA_KEY]['fields'].items():\n            if name not in known_fields:\n                field = PydanticModelField.deserialize(info, data)\n                known_fields.add(name)\n                superclass_fields.append(field)\n            else:\n                (field,) = (a for a in all_fields if a.name == name)\n                all_fields.remove(field)\n                superclass_fields.append(field)\n        all_fields = superclass_fields + all_fields\n    return all_fields\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.get_alias_info","title":"get_alias_info  <code>staticmethod</code>","text":"<pre><code>get_alias_info(stmt)\n</code></pre> <p>Returns a pair (alias, has_dynamic_alias), extracted from the declaration of the field defined in <code>stmt</code>.</p> <p><code>has_dynamic_alias</code> is True if and only if an alias is provided, but not as a string literal. If <code>has_dynamic_alias</code> is True, <code>alias</code> will be None.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>@staticmethod\ndef get_alias_info(stmt: AssignmentStmt) -&gt; tuple[str | None, bool]:\n\"\"\"Returns a pair (alias, has_dynamic_alias), extracted from the declaration of the field defined in `stmt`.\n\n    `has_dynamic_alias` is True if and only if an alias is provided, but not as a string literal.\n    If `has_dynamic_alias` is True, `alias` will be None.\n    \"\"\"\n    expr = stmt.rvalue\n    if isinstance(expr, TempNode):\n        # TempNode means annotation-only\n        return None, False\n\n    if not (\n        isinstance(expr, CallExpr) and isinstance(expr.callee, RefExpr) and expr.callee.fullname == FIELD_FULLNAME\n    ):\n        # Assigned value is not a call to pydantic.fields.Field\n        return None, False\n\n    for i, arg_name in enumerate(expr.arg_names):\n        if arg_name != 'alias':\n            continue\n        arg = expr.args[i]\n        if isinstance(arg, StrExpr):\n            return arg.value, False\n        else:\n            return None, True\n    return None, False\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.get_config_update","title":"get_config_update","text":"<pre><code>get_config_update(name, arg)\n</code></pre> <p>Determines the config update due to a single kwarg in the ConfigDict definition.</p> <p>Warns if a tracked config attribute is set to a value the plugin doesn't know how to interpret (e.g., an int)</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def get_config_update(self, name: str, arg: Expression) -&gt; ModelConfigData | None:\n\"\"\"Determines the config update due to a single kwarg in the ConfigDict definition.\n\n    Warns if a tracked config attribute is set to a value the plugin doesn't know how to interpret (e.g., an int)\n    \"\"\"\n    if name not in self.tracked_config_fields:\n        return None\n    if name == 'extra':\n        if isinstance(arg, StrExpr):\n            forbid_extra = arg.value == 'forbid'\n        elif isinstance(arg, MemberExpr):\n            forbid_extra = arg.name == 'forbid'\n        else:\n            error_invalid_config_value(name, self._ctx.api, arg)\n            return None\n        return ModelConfigData(forbid_extra=forbid_extra)\n    if name == 'alias_generator':\n        has_alias_generator = True\n        if isinstance(arg, NameExpr) and arg.fullname == 'builtins.None':\n            has_alias_generator = False\n        return ModelConfigData(has_alias_generator=has_alias_generator)\n    if isinstance(arg, NameExpr) and arg.fullname in ('builtins.True', 'builtins.False'):\n        return ModelConfigData(**{name: arg.fullname == 'builtins.True'})\n    error_invalid_config_value(name, self._ctx.api, arg)\n    return None\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.get_field_arguments","title":"get_field_arguments","text":"<pre><code>get_field_arguments(\n    fields, typed, force_all_optional, use_alias\n)\n</code></pre> <p>Helper function used during the construction of the <code>__init__</code> and <code>model_construct</code> method signatures.</p> <p>Returns a list of mypy Argument instances for use in the generated signatures.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def get_field_arguments(\n    self, fields: list[PydanticModelField], typed: bool, force_all_optional: bool, use_alias: bool\n) -&gt; list[Argument]:\n\"\"\"Helper function used during the construction of the `__init__` and `model_construct` method signatures.\n\n    Returns a list of mypy Argument instances for use in the generated signatures.\n    \"\"\"\n    info = self._ctx.cls.info\n    arguments = [\n        field.to_argument(info, typed=typed, force_optional=force_all_optional, use_alias=use_alias)\n        for field in fields\n        if not (use_alias and field.has_dynamic_alias)\n    ]\n    return arguments\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.get_is_required","title":"get_is_required  <code>staticmethod</code>","text":"<pre><code>get_is_required(stmt, lhs)\n</code></pre> <p>Returns a boolean indicating whether the field defined in <code>stmt</code> is a required field.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>@staticmethod\ndef get_is_required(cls: ClassDef, stmt: AssignmentStmt, lhs: NameExpr) -&gt; bool:\n\"\"\"Returns a boolean indicating whether the field defined in `stmt` is a required field.\"\"\"\n    expr = stmt.rvalue\n    if isinstance(expr, TempNode):\n        # TempNode means annotation-only, so only non-required if Optional\n        value_type = get_proper_type(cls.info[lhs.name].type)\n        if isinstance(value_type, UnionType) and any(isinstance(item, NoneType) for item in value_type.items):\n            # Annotated as Optional, or otherwise having NoneType in the union\n            return False\n        return True\n    if isinstance(expr, CallExpr) and isinstance(expr.callee, RefExpr) and expr.callee.fullname == FIELD_FULLNAME:\n        # The \"default value\" is a call to `Field`; at this point, the field is\n        # only required if default is Ellipsis (i.e., `field_name: Annotation = Field(...)`) or if default_factory\n        # is specified.\n        for arg, name in zip(expr.args, expr.arg_names):\n            # If name is None, then this arg is the default because it is the only positional argument.\n            if name is None or name == 'default':\n                return arg.__class__ is EllipsisExpr\n            if name == 'default_factory':\n                return False\n        return True\n    # Only required if the \"default value\" is Ellipsis (i.e., `field_name: Annotation = ...`)\n    return isinstance(expr, EllipsisExpr)\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.is_dynamic_alias_present","title":"is_dynamic_alias_present  <code>staticmethod</code>","text":"<pre><code>is_dynamic_alias_present(fields, has_alias_generator)\n</code></pre> <p>Returns whether any fields on the model have a \"dynamic alias\", i.e., an alias that cannot be determined during static analysis.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>@staticmethod\ndef is_dynamic_alias_present(fields: list[PydanticModelField], has_alias_generator: bool) -&gt; bool:\n\"\"\"Returns whether any fields on the model have a \"dynamic alias\", i.e., an alias that cannot be\n    determined during static analysis.\n    \"\"\"\n    for field in fields:\n        if field.has_dynamic_alias:\n            return True\n    if has_alias_generator:\n        for field in fields:\n            if field.alias is None:\n                return True\n    return False\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.set_frozen","title":"set_frozen","text":"<pre><code>set_frozen(fields, frozen)\n</code></pre> <p>Marks all fields as properties so that attempts to set them trigger mypy errors.</p> <p>This is the same approach used by the attrs and dataclasses plugins.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def set_frozen(self, fields: list[PydanticModelField], frozen: bool) -&gt; None:\n\"\"\"Marks all fields as properties so that attempts to set them trigger mypy errors.\n\n    This is the same approach used by the attrs and dataclasses plugins.\n    \"\"\"\n    ctx = self._ctx\n    info = ctx.cls.info\n    for field in fields:\n        sym_node = info.names.get(field.name)\n        if sym_node is not None:\n            var = sym_node.node\n            if isinstance(var, Var):\n                var.is_property = frozen\n            elif isinstance(var, PlaceholderNode) and not ctx.api.final_iteration:\n                # See https://github.com/pydantic/pydantic/issues/5191 to hit this branch for test coverage\n                ctx.api.defer()\n            else:  # pragma: no cover\n                # I don't know whether it's possible to hit this branch, but I've added it for safety\n                try:\n                    var_str = str(var)\n                except TypeError:\n                    # This happens for PlaceholderNode; perhaps it will happen for other types in the future..\n                    var_str = repr(var)\n                detail = f'sym_node.node: {var_str} (of type {var.__class__})'\n                error_unexpected_behavior(detail, ctx.api, ctx.cls)\n        else:\n            var = field.to_var(info, use_alias=False)\n            var.info = info\n            var.is_property = frozen\n            var._fullname = get_fullname(info) + '.' + get_name(var)\n            info.names[get_name(var)] = SymbolTableNode(MDEF, var)\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.should_init_forbid_extra","title":"should_init_forbid_extra","text":"<pre><code>should_init_forbid_extra(fields, config)\n</code></pre> <p>Indicates whether the generated <code>__init__</code> should get a <code>**kwargs</code> at the end of its signature.</p> <p>We disallow arbitrary kwargs if the extra config setting is \"forbid\", or if the plugin config says to, unless a required dynamic alias is present (since then we can't determine a valid signature).</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def should_init_forbid_extra(self, fields: list[PydanticModelField], config: ModelConfigData) -&gt; bool:\n\"\"\"Indicates whether the generated `__init__` should get a `**kwargs` at the end of its signature.\n\n    We disallow arbitrary kwargs if the extra config setting is \"forbid\", or if the plugin config says to,\n    *unless* a required dynamic alias is present (since then we can't determine a valid signature).\n    \"\"\"\n    if not config.populate_by_name:\n        if self.is_dynamic_alias_present(fields, bool(config.has_alias_generator)):\n            return False\n    if config.forbid_extra:\n        return True\n    return self.plugin_config.init_forbid_extra\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticModelTransformer.transform","title":"transform","text":"<pre><code>transform()\n</code></pre> <p>Configures the BaseModel subclass according to the plugin settings.</p> <p>In particular: * determines the model config and fields, * adds a fields-aware signature for the initializer and construct methods * freezes the class if frozen = True * stores the fields, config, and if the class is settings in the mypy metadata for access by subclasses</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def transform(self) -&gt; None:\n\"\"\"Configures the BaseModel subclass according to the plugin settings.\n\n    In particular:\n    * determines the model config and fields,\n    * adds a fields-aware signature for the initializer and construct methods\n    * freezes the class if frozen = True\n    * stores the fields, config, and if the class is settings in the mypy metadata for access by subclasses\n    \"\"\"\n    ctx = self._ctx\n    info = ctx.cls.info\n\n    self.adjust_validator_signatures()\n    config = self.collect_config()\n    fields = self.collect_fields(config)\n    self.add_initializer(fields, config)\n    self.add_model_construct_method(fields)\n    self.set_frozen(fields, frozen=config.frozen is True)\n    info.metadata[METADATA_KEY] = {\n        'fields': {field.name: field.serialize() for field in fields},\n        'config': config.set_values_dict(),\n    }\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticPlugin","title":"PydanticPlugin","text":"<pre><code>PydanticPlugin(options)\n</code></pre> <p>         Bases: <code>Plugin</code></p> Source code in <code>pydantic/mypy.py</code> <pre><code>def __init__(self, options: Options) -&gt; None:\n    self.plugin_config = PydanticPluginConfig(options)\n    self._plugin_data = self.plugin_config.to_data()\n    super().__init__(options)\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticPlugin.get_class_decorator_hook","title":"get_class_decorator_hook","text":"<pre><code>get_class_decorator_hook(fullname)\n</code></pre> <p>Mark pydantic.dataclasses as dataclass.</p> <p>Mypy version 1.1.1 added support for <code>@dataclass_transform</code> decorator.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def get_class_decorator_hook(self, fullname: str) -&gt; Callable[[ClassDefContext], None] | None:\n\"\"\"Mark pydantic.dataclasses as dataclass.\n\n    Mypy version 1.1.1 added support for `@dataclass_transform` decorator.\n    \"\"\"\n    if fullname == DATACLASS_FULLNAME and MYPY_VERSION_TUPLE &lt; (1, 1):\n        return dataclasses.dataclass_class_maker_callback  # type: ignore[return-value]\n    return None\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.PydanticPlugin.report_config_data","title":"report_config_data","text":"<pre><code>report_config_data(ctx)\n</code></pre> <p>Return all plugin config data.</p> <p>Used by mypy to determine if cache needs to be discarded.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def report_config_data(self, ctx: ReportConfigContext) -&gt; dict[str, Any]:\n\"\"\"Return all plugin config data.\n\n    Used by mypy to determine if cache needs to be discarded.\n    \"\"\"\n    return self._plugin_data\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.add_method","title":"add_method","text":"<pre><code>add_method(\n    ctx,\n    name,\n    args,\n    return_type,\n    self_type=None,\n    tvar_def=None,\n    is_classmethod=False,\n    is_new=False,\n)\n</code></pre> <p>Adds a new method to a class.</p> <p>This can be dropped if/when https://github.com/python/mypy/issues/7301 is merged</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def add_method(\n    ctx: ClassDefContext,\n    name: str,\n    args: list[Argument],\n    return_type: Type,\n    self_type: Type | None = None,\n    tvar_def: TypeVarDef | None = None,\n    is_classmethod: bool = False,\n    is_new: bool = False,\n    # is_staticmethod: bool = False,\n) -&gt; None:\n\"\"\"Adds a new method to a class.\n\n    This can be dropped if/when https://github.com/python/mypy/issues/7301 is merged\n    \"\"\"\n    info = ctx.cls.info\n\n    # First remove any previously generated methods with the same name\n    # to avoid clashes and problems in the semantic analyzer.\n    if name in info.names:\n        sym = info.names[name]\n        if sym.plugin_generated and isinstance(sym.node, FuncDef):\n            ctx.cls.defs.body.remove(sym.node)  # pragma: no cover\n\n    self_type = self_type or fill_typevars(info)\n    if is_classmethod or is_new:\n        first = [Argument(Var('_cls'), TypeType.make_normalized(self_type), None, ARG_POS)]\n    # elif is_staticmethod:\n    #     first = []\n    else:\n        self_type = self_type or fill_typevars(info)\n        first = [Argument(Var('__pydantic_self__'), self_type, None, ARG_POS)]\n    args = first + args\n    arg_types, arg_names, arg_kinds = [], [], []\n    for arg in args:\n        assert arg.type_annotation, 'All arguments must be fully typed.'\n        arg_types.append(arg.type_annotation)\n        arg_names.append(get_name(arg.variable))\n        arg_kinds.append(arg.kind)\n\n    function_type = ctx.api.named_type(f'{BUILTINS_NAME}.function')\n    signature = CallableType(arg_types, arg_kinds, arg_names, return_type, function_type)\n    if tvar_def:\n        signature.variables = [tvar_def]\n\n    func = FuncDef(name, args, Block([PassStmt()]))\n    func.info = info\n    func.type = set_callable_name(signature, func)\n    func.is_class = is_classmethod\n    # func.is_static = is_staticmethod\n    func._fullname = get_fullname(info) + '.' + name\n    func.line = info.line\n\n    # NOTE: we would like the plugin generated node to dominate, but we still\n    # need to keep any existing definitions so they get semantically analyzed.\n    if name in info.names:\n        # Get a nice unique name instead.\n        r_name = get_unique_redefinition_name(name, info.names)\n        info.names[r_name] = info.names[name]\n\n    if is_classmethod:  # or is_staticmethod:\n        func.is_decorated = True\n        v = Var(name, func.type)\n        v.info = info\n        v._fullname = func._fullname\n        # if is_classmethod:\n        v.is_classmethod = True\n        dec = Decorator(func, [NameExpr('classmethod')], v)\n        # else:\n        #     v.is_staticmethod = True\n        #     dec = Decorator(func, [NameExpr('staticmethod')], v)\n\n        dec.line = info.line\n        sym = SymbolTableNode(MDEF, dec)\n    else:\n        sym = SymbolTableNode(MDEF, func)\n    sym.plugin_generated = True\n\n    info.names[name] = sym\n    info.defn.defs.body.append(func)\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.from_attributes_callback","title":"from_attributes_callback","text":"<pre><code>from_attributes_callback(ctx)\n</code></pre> <p>Raise an error if from_attributes is not enabled.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def from_attributes_callback(ctx: MethodContext) -&gt; Type:\n\"\"\"Raise an error if from_attributes is not enabled.\"\"\"\n    model_type: Instance\n    ctx_type = ctx.type\n    if isinstance(ctx_type, TypeType):\n        ctx_type = ctx_type.item\n    if isinstance(ctx_type, CallableType) and isinstance(ctx_type.ret_type, Instance):\n        model_type = ctx_type.ret_type  # called on the class\n    elif isinstance(ctx_type, Instance):\n        model_type = ctx_type  # called on an instance (unusual, but still valid)\n    else:  # pragma: no cover\n        detail = f'ctx.type: {ctx_type} (of type {ctx_type.__class__.__name__})'\n        error_unexpected_behavior(detail, ctx.api, ctx.context)\n        return ctx.default_return_type\n    pydantic_metadata = model_type.type.metadata.get(METADATA_KEY)\n    if pydantic_metadata is None:\n        return ctx.default_return_type\n    from_attributes = pydantic_metadata.get('config', {}).get('from_attributes')\n    if from_attributes is not True:\n        error_from_attributes(get_name(model_type.type), ctx.api, ctx.context)\n    return ctx.default_return_type\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.get_fullname","title":"get_fullname","text":"<pre><code>get_fullname(x)\n</code></pre> <p>Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def get_fullname(x: FuncBase | SymbolNode) -&gt; str:\n\"\"\"Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.\"\"\"\n    fn = x.fullname\n    if callable(fn):  # pragma: no cover\n        return fn()\n    return fn\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.get_name","title":"get_name","text":"<pre><code>get_name(x)\n</code></pre> <p>Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def get_name(x: FuncBase | SymbolNode) -&gt; str:\n\"\"\"Used for compatibility with mypy 0.740; can be dropped once support for 0.740 is dropped.\"\"\"\n    fn = x.name\n    if callable(fn):  # pragma: no cover\n        return fn()\n    return fn\n</code></pre>"},{"location":"api/mypy/#pydantic.mypy.plugin","title":"plugin","text":"<pre><code>plugin(version)\n</code></pre> <p><code>version</code> is the mypy version string.</p> <p>We might want to use this to print a warning if the mypy version being used is newer, or especially older, than we expect (or need).</p> Source code in <code>pydantic/mypy.py</code> <pre><code>def plugin(version: str) -&gt; type[Plugin]:\n\"\"\"`version` is the mypy version string.\n\n    We might want to use this to print a warning if the mypy version being used is\n    newer, or especially older, than we expect (or need).\n    \"\"\"\n    return PydanticPlugin\n</code></pre>"},{"location":"api/networks/","title":"pydantic.networks","text":"<p>The networks module contains types for common network-related fields.</p>"},{"location":"api/networks/#pydantic.networks.AmqpDsn","title":"AmqpDsn  <code>module-attribute</code>","text":"<pre><code>AmqpDsn = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"amqp\", \"amqps\"])\n]\n</code></pre> <p>A type that will accept any AMQP DSN.</p>"},{"location":"api/networks/#pydantic.networks.AnyHttpUrl","title":"AnyHttpUrl  <code>module-attribute</code>","text":"<pre><code>AnyHttpUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"http\", \"https\"])\n]\n</code></pre> <p>A type that will accept any http or https URL.</p>"},{"location":"api/networks/#pydantic.networks.AnyUrl","title":"AnyUrl  <code>module-attribute</code>","text":"<pre><code>AnyUrl = Url\n</code></pre> <p>Base type for all URLs.</p>"},{"location":"api/networks/#pydantic.networks.CockroachDsn","title":"CockroachDsn  <code>module-attribute</code>","text":"<pre><code>CockroachDsn = Annotated[\n    Url,\n    UrlConstraints(\n        host_required=True,\n        allowed_schemes=[\n            \"cockroachdb\",\n            \"cockroachdb+psycopg2\",\n            \"cockroachdb+asyncpg\",\n        ],\n    ),\n]\n</code></pre> <p>A type that will accept any Cockroach DSN.</p>"},{"location":"api/networks/#pydantic.networks.FileUrl","title":"FileUrl  <code>module-attribute</code>","text":"<pre><code>FileUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"file\"])\n]\n</code></pre> <p>A type that will accept any file URL.</p>"},{"location":"api/networks/#pydantic.networks.HttpUrl","title":"HttpUrl  <code>module-attribute</code>","text":"<pre><code>HttpUrl = Annotated[\n    Url,\n    UrlConstraints(\n        max_length=2083, allowed_schemes=[\"http\", \"https\"]\n    ),\n]\n</code></pre> <p>A type that will accept any http or https URL with a max length of 2083 characters.</p>"},{"location":"api/networks/#pydantic.networks.KafkaDsn","title":"KafkaDsn  <code>module-attribute</code>","text":"<pre><code>KafkaDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\"kafka\"],\n        default_host=\"localhost\",\n        default_port=9092,\n    ),\n]\n</code></pre> <p>A type that will accept any Kafka DSN.</p>"},{"location":"api/networks/#pydantic.networks.MariaDBDsn","title":"MariaDBDsn  <code>module-attribute</code>","text":"<pre><code>MariaDBDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\n            \"mariadb\",\n            \"mariadb+mariadbconnector\",\n            \"mariadb+pymysql\",\n        ],\n        default_port=3306,\n    ),\n]\n</code></pre> <p>A type that will accept any MariaDB DSN.</p>"},{"location":"api/networks/#pydantic.networks.MongoDsn","title":"MongoDsn  <code>module-attribute</code>","text":"<pre><code>MongoDsn = Annotated[\n    MultiHostUrl,\n    UrlConstraints(\n        allowed_schemes=[\"mongodb\", \"mongodb+srv\"],\n        default_port=27017,\n    ),\n]\n</code></pre> <p>A type that will accept any MongoDB DSN.</p>"},{"location":"api/networks/#pydantic.networks.MySQLDsn","title":"MySQLDsn  <code>module-attribute</code>","text":"<pre><code>MySQLDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\n            \"mysql\",\n            \"mysql+mysqlconnector\",\n            \"mysql+aiomysql\",\n            \"mysql+asyncmy\",\n            \"mysql+mysqldb\",\n            \"mysql+pymysql\",\n            \"mysql+cymysql\",\n            \"mysql+pyodbc\",\n        ],\n        default_port=3306,\n    ),\n]\n</code></pre> <p>A type that will accept any MySQL DSN.</p>"},{"location":"api/networks/#pydantic.networks.PostgresDsn","title":"PostgresDsn  <code>module-attribute</code>","text":"<pre><code>PostgresDsn = Annotated[\n    MultiHostUrl,\n    UrlConstraints(\n        host_required=True,\n        allowed_schemes=[\n            \"postgres\",\n            \"postgresql\",\n            \"postgresql+asyncpg\",\n            \"postgresql+pg8000\",\n            \"postgresql+psycopg\",\n            \"postgresql+psycopg2\",\n            \"postgresql+psycopg2cffi\",\n            \"postgresql+py-postgresql\",\n            \"postgresql+pygresql\",\n        ],\n    ),\n]\n</code></pre> <p>A type that will accept any Postgres DSN.</p>"},{"location":"api/networks/#pydantic.networks.RedisDsn","title":"RedisDsn  <code>module-attribute</code>","text":"<pre><code>RedisDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\"redis\", \"rediss\"],\n        default_host=\"localhost\",\n        default_port=6379,\n        default_path=\"/0\",\n    ),\n]\n</code></pre> <p>A type that will accept any Redis DSN.</p>"},{"location":"api/networks/#pydantic.networks.EmailStr","title":"EmailStr","text":"<p>Validate email addresses.</p> Example <pre><code>from pydantic import BaseModel, EmailStr\n\nclass Model(BaseModel):\n    email: EmailStr\n\nprint(Model(email='contact@mail.com'))\n# &gt; email='contact@mail.com'\n</code></pre>"},{"location":"api/networks/#pydantic.networks.IPvAnyAddress","title":"IPvAnyAddress","text":"<p>Validate an IPv4 or IPv6 address.</p>"},{"location":"api/networks/#pydantic.networks.IPvAnyInterface","title":"IPvAnyInterface","text":"<p>Validate an IPv4 or IPv6 interface.</p>"},{"location":"api/networks/#pydantic.networks.IPvAnyNetwork","title":"IPvAnyNetwork","text":"<p>Validate an IPv4 or IPv6 network.</p>"},{"location":"api/networks/#pydantic.networks.NameEmail","title":"NameEmail","text":"<pre><code>NameEmail(name, email)\n</code></pre> <p>         Bases: <code>_repr.Representation</code></p> <p>Validate a name and email address combination.</p> Example <pre><code>from pydantic import BaseModel, NameEmail\n\nclass User(BaseModel):\n    email: NameEmail\n\nprint(User(email='John Doe &lt;john.doe@mail.com&gt;'))\n#&gt; email=NameEmail(name='John Doe', email='john.doe@mail.com')\n</code></pre> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name.</p> <code>email</code> <p>The email address.</p> Source code in <code>pydantic/networks.py</code> <pre><code>def __init__(self, name: str, email: str):\n    self.name = name\n    self.email = email\n</code></pre>"},{"location":"api/networks/#pydantic.networks.UrlConstraints","title":"UrlConstraints  <code>dataclass</code>","text":"<p>         Bases: <code>_fields.PydanticMetadata</code></p> <p>Url constraints.</p> <p>Attributes:</p> Name Type Description <code>max_length</code> <code>int | None</code> <p>The maximum length of the url. Defaults to <code>None</code>.</p> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed schemes. Defaults to <code>None</code>.</p> <code>host_required</code> <code>bool | None</code> <p>Whether the host is required. Defaults to <code>None</code>.</p> <code>default_host</code> <code>str | None</code> <p>The default host. Defaults to <code>None</code>.</p> <code>default_port</code> <code>int | None</code> <p>The default port. Defaults to <code>None</code>.</p> <code>default_path</code> <code>str | None</code> <p>The default path. Defaults to <code>None</code>.</p>"},{"location":"api/networks/#pydantic.networks.validate_email","title":"validate_email","text":"<pre><code>validate_email(value)\n</code></pre> <p>Email address validation using https://pypi.org/project/email-validator/.</p> Note <p>Note that:</p> <ul> <li>Raw IP address (literal) domain parts are not allowed.</li> <li>\"John Doe local_part@domain.com\" style \"pretty\" email addresses are processed.</li> <li>Spaces are striped from the beginning and end of addresses, but no error is raised.</li> </ul> Source code in <code>pydantic/networks.py</code> <pre><code>def validate_email(value: str) -&gt; tuple[str, str]:\n\"\"\"Email address validation using https://pypi.org/project/email-validator/.\n\n    Note:\n        Note that:\n\n        * Raw IP address (literal) domain parts are not allowed.\n        * \"John Doe &lt;local_part@domain.com&gt;\" style \"pretty\" email addresses are processed.\n        * Spaces are striped from the beginning and end of addresses, but no error is raised.\n    \"\"\"\n    if email_validator is None:\n        import_email_validator()\n\n    m = pretty_email_regex.fullmatch(value)\n    name: str | None = None\n    if m:\n        unquoted_name, quoted_name, value = m.groups()\n        name = unquoted_name or quoted_name\n\n    email = value.strip()\n\n    try:\n        parts = email_validator.validate_email(email, check_deliverability=False)\n    except email_validator.EmailNotValidError as e:\n        raise PydanticCustomError(\n            'value_error', 'value is not a valid email address: {reason}', {'reason': str(e.args[0])}\n        ) from e\n\n    email = parts.normalized\n    assert email is not None\n    name = name or parts.local_part\n    return name, email\n</code></pre>"},{"location":"api/pydantic_core_init/","title":"pydantic_core","text":""},{"location":"api/pydantic_core_init/#pydantic_core.ArgsKwargs","title":"ArgsKwargs","text":"<pre><code>ArgsKwargs(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.MultiHostUrl","title":"MultiHostUrl","text":"<pre><code>MultiHostUrl(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.PydanticCustomError","title":"PydanticCustomError","text":"<pre><code>PydanticCustomError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.PydanticCustomError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.PydanticKnownError","title":"PydanticKnownError","text":"<pre><code>PydanticKnownError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.PydanticKnownError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.PydanticOmit","title":"PydanticOmit","text":"<pre><code>PydanticOmit(*args, **kwargs)\n</code></pre> <p>         Bases: <code>Exception</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.PydanticOmit.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.PydanticSerializationError","title":"PydanticSerializationError","text":"<pre><code>PydanticSerializationError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.PydanticSerializationError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.PydanticSerializationUnexpectedValue","title":"PydanticSerializationUnexpectedValue","text":"<pre><code>PydanticSerializationUnexpectedValue(*args, **kwargs)\n</code></pre> <p>         Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.PydanticSerializationUnexpectedValue.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.SchemaError","title":"SchemaError","text":"<pre><code>SchemaError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>Exception</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.SchemaError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.SchemaError","title":"SchemaError","text":"<pre><code>SchemaError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>Exception</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.SchemaError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.SchemaSerializer","title":"SchemaSerializer","text":"<pre><code>SchemaSerializer(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.SchemaValidator","title":"SchemaValidator","text":"<pre><code>SchemaValidator(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.Some","title":"Some","text":"<pre><code>Some(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.Url","title":"Url","text":"<pre><code>Url(*args, **kwargs)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.ValidationError","title":"ValidationError","text":"<pre><code>ValidationError(*args, **kwargs)\n</code></pre> <p>         Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.ValidationError.from_exception_data","title":"from_exception_data  <code>staticmethod</code>","text":"<pre><code>from_exception_data(\n    title, line_errors, error_mode=None, hide_input=False\n)\n</code></pre> <p>Provisory constructor for a Validation Error. This API will probably change and be deprecated in the the future; we will make it easier and more powerful to construct and use ValidationErrors, but we cannot do that before our initial Pydantic V2 release. So if you use this method please be aware that it may change or be removed before Pydantic V3.</p>"},{"location":"api/pydantic_core_init/#pydantic_core._pydantic_core.ValidationError.with_traceback","title":"with_traceback  <code>method descriptor</code>","text":"<pre><code>with_traceback()\n</code></pre> <p>Exception.with_traceback(tb) -- set self.traceback to tb and return self.</p>"},{"location":"api/pydantic_core_init/#pydantic_core.to_json","title":"to_json  <code>builtin</code>","text":"<pre><code>to_json(\n    value,\n    *,\n    indent=None,\n    include=None,\n    exclude=None,\n    by_alias=True,\n    exclude_none=False,\n    round_trip=False,\n    timedelta_mode=None,\n    bytes_mode=None,\n    serialize_unknown=False,\n    fallback=None\n)\n</code></pre>"},{"location":"api/pydantic_core_init/#pydantic_core.to_jsonable_python","title":"to_jsonable_python  <code>builtin</code>","text":"<pre><code>to_jsonable_python(\n    value,\n    *,\n    include=None,\n    exclude=None,\n    by_alias=True,\n    exclude_none=False,\n    round_trip=False,\n    timedelta_mode=None,\n    bytes_mode=None,\n    serialize_unknown=False,\n    fallback=None\n)\n</code></pre>"},{"location":"api/pydantic_core_schema/","title":"pydantic_core.core_schema","text":""},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.WhenUsed","title":"WhenUsed  <code>module-attribute</code>","text":"<pre><code>WhenUsed = Literal[\n    \"always\", \"unless-none\", \"json\", \"json-unless-none\"\n]\n</code></pre> <p>Values have the following meanings: * <code>'always'</code> means always use * <code>'unless-none'</code> means use unless the value is <code>None</code> * <code>'json'</code> means use when serializing to JSON * <code>'json-unless-none'</code> means use when serializing to JSON and the value is not <code>None</code></p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.FieldValidationInfo","title":"FieldValidationInfo","text":"<p>         Bases: <code>ValidationInfo</code>, <code>Protocol</code></p> <p>Argument passed to model field validation functions.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.FieldValidationInfo.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>All of the fields and data being validated for this model.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.FieldValidationInfo.field_name","title":"field_name  <code>property</code>","text":"<pre><code>field_name: str\n</code></pre> <p>The name of the current field being validated if this validator is attached to a model field.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo","title":"ValidationInfo","text":"<p>         Bases: <code>Protocol</code></p> <p>Argument passed to validation functions.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.config","title":"config  <code>property</code>","text":"<pre><code>config: CoreConfig | None\n</code></pre> <p>The CoreConfig that applies to this validation.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.context","title":"context  <code>property</code>","text":"<pre><code>context: Dict[str, Any]\n</code></pre> <p>Current validation context.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.mode","title":"mode  <code>property</code>","text":"<pre><code>mode: Literal['python', 'json']\n</code></pre> <p>The type of input data we are currently validating</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.any_schema","title":"any_schema","text":"<pre><code>any_schema(*, ref=None, metadata=None, serialization=None)\n</code></pre> <p>Returns a schema that matches any value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.any_schema()\nv = SchemaValidator(schema)\nassert v.validate_python(1) == 1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def any_schema(*, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -&gt; AnySchema:\n\"\"\"\n    Returns a schema that matches any value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.any_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='any', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.arguments_parameter","title":"arguments_parameter","text":"<pre><code>arguments_parameter(name, schema, *, mode=None, alias=None)\n</code></pre> <p>Returns a schema that matches an argument parameter, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nschema = core_schema.arguments_schema([param])\nv = SchemaValidator(schema)\nassert v.validate_python(('hello',)) == (('hello',), {})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to use for the argument parameter</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the argument parameter</p> required <code>mode</code> <code>Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None</code> <p>The mode to use for the argument parameter</p> <code>None</code> <code>alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias to use for the argument parameter</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def arguments_parameter(\n    name: str,\n    schema: CoreSchema,\n    *,\n    mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None = None,\n    alias: str | list[str | int] | list[list[str | int]] | None = None,\n) -&gt; ArgumentsParameter:\n\"\"\"\n    Returns a schema that matches an argument parameter, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello',)) == (('hello',), {})\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        mode: The mode to use for the argument parameter\n        alias: The alias to use for the argument parameter\n    \"\"\"\n    return dict_not_none(name=name, schema=schema, mode=mode, alias=alias)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.arguments_schema","title":"arguments_schema","text":"<pre><code>arguments_schema(\n    arguments,\n    *,\n    populate_by_name=None,\n    var_args_schema=None,\n    var_kwargs_schema=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches an arguments schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam_a = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nparam_b = core_schema.arguments_parameter(\n    name='b', schema=core_schema.bool_schema(), mode='positional_only'\n)\nschema = core_schema.arguments_schema([param_a, param_b])\nv = SchemaValidator(schema)\nassert v.validate_python(('hello', True)) == (('hello', True), {})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>list[ArgumentsParameter]</code> <p>The arguments to use for the arguments schema</p> required <code>populate_by_name</code> <code>bool | None</code> <p>Whether to populate by name</p> <code>None</code> <code>var_args_schema</code> <code>CoreSchema | None</code> <p>The variable args schema to use for the arguments schema</p> <code>None</code> <code>var_kwargs_schema</code> <code>CoreSchema | None</code> <p>The variable kwargs schema to use for the arguments schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def arguments_schema(\n    arguments: list[ArgumentsParameter],\n    *,\n    populate_by_name: bool | None = None,\n    var_args_schema: CoreSchema | None = None,\n    var_kwargs_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; ArgumentsSchema:\n\"\"\"\n    Returns a schema that matches an arguments schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param_a, param_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello', True)) == (('hello', True), {})\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        populate_by_name: Whether to populate by name\n        var_args_schema: The variable args schema to use for the arguments schema\n        var_kwargs_schema: The variable kwargs schema to use for the arguments schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='arguments',\n        arguments_schema=arguments,\n        populate_by_name=populate_by_name,\n        var_args_schema=var_args_schema,\n        var_kwargs_schema=var_kwargs_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.bool_schema","title":"bool_schema","text":"<pre><code>bool_schema(\n    strict=None, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that matches a bool value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.bool_schema()\nv = SchemaValidator(schema)\nassert v.validate_python('True') is True\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a bool or a value that can be converted to a bool</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def bool_schema(\n    strict: bool | None = None, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -&gt; BoolSchema:\n\"\"\"\n    Returns a schema that matches a bool value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bool_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python('True') is True\n    ```\n\n    Args:\n        strict: Whether the value should be a bool or a value that can be converted to a bool\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='bool', strict=strict, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.bytes_schema","title":"bytes_schema","text":"<pre><code>bytes_schema(\n    *,\n    max_length=None,\n    min_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a bytes value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.bytes_schema(max_length=10, min_length=2)\nv = SchemaValidator(schema)\nassert v.validate_python(b'hello') == b'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The value must be at most this length</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be at least this length</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a bytes or a value that can be converted to a bytes</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def bytes_schema(\n    *,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; BytesSchema:\n\"\"\"\n    Returns a schema that matches a bytes value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bytes_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python(b'hello') == b'hello'\n    ```\n\n    Args:\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strict: Whether the value should be a bytes or a value that can be converted to a bytes\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='bytes',\n        max_length=max_length,\n        min_length=min_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.call_schema","title":"call_schema","text":"<pre><code>call_schema(\n    arguments,\n    function,\n    *,\n    function_name=None,\n    return_schema=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches an arguments schema, then calls a function, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam_a = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nparam_b = core_schema.arguments_parameter(\n    name='b', schema=core_schema.bool_schema(), mode='positional_only'\n)\nargs_schema = core_schema.arguments_schema([param_a, param_b])\n\nschema = core_schema.call_schema(\n    arguments=args_schema,\n    function=lambda a, b: a + str(not b),\n    return_schema=core_schema.str_schema(),\n)\nv = SchemaValidator(schema)\nassert v.validate_python((('hello', True))) == 'helloFalse'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>CoreSchema</code> <p>The arguments to use for the arguments schema</p> required <code>function</code> <code>Callable[..., Any]</code> <p>The function to use for the call schema</p> required <code>function_name</code> <code>str | None</code> <p>The function name to use for the call schema, if not provided <code>function.__name__</code> is used</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>The return schema to use for the call schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def call_schema(\n    arguments: CoreSchema,\n    function: Callable[..., Any],\n    *,\n    function_name: str | None = None,\n    return_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; CallSchema:\n\"\"\"\n    Returns a schema that matches an arguments schema, then calls a function, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    args_schema = core_schema.arguments_schema([param_a, param_b])\n\n    schema = core_schema.call_schema(\n        arguments=args_schema,\n        function=lambda a, b: a + str(not b),\n        return_schema=core_schema.str_schema(),\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((('hello', True))) == 'helloFalse'\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        function: The function to use for the call schema\n        function_name: The function name to use for the call schema, if not provided `function.__name__` is used\n        return_schema: The return schema to use for the call schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='call',\n        arguments_schema=arguments,\n        function=function,\n        function_name=function_name,\n        return_schema=return_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.callable_schema","title":"callable_schema","text":"<pre><code>callable_schema(\n    *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that checks if a value is callable, equivalent to python's <code>callable</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.callable_schema()\nv = SchemaValidator(schema)\nv.validate_python(min)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def callable_schema(\n    *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -&gt; CallableSchema:\n\"\"\"\n    Returns a schema that checks if a value is callable, equivalent to python's `callable` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.callable_schema()\n    v = SchemaValidator(schema)\n    v.validate_python(min)\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='callable', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.chain_schema","title":"chain_schema","text":"<pre><code>chain_schema(\n    steps, *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that chains the provided validation schemas, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + ' world'\n\nfn_schema = core_schema.general_plain_validator_function(function=fn)\nschema = core_schema.chain_schema(\n    [fn_schema, fn_schema, fn_schema, core_schema.str_schema()]\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello world world world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>steps</code> <code>list[CoreSchema]</code> <p>The schemas to chain</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def chain_schema(\n    steps: list[CoreSchema], *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -&gt; ChainSchema:\n\"\"\"\n    Returns a schema that chains the provided validation schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + ' world'\n\n    fn_schema = core_schema.general_plain_validator_function(function=fn)\n    schema = core_schema.chain_schema(\n        [fn_schema, fn_schema, fn_schema, core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello world world world'\n    ```\n\n    Args:\n        steps: The schemas to chain\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='chain', steps=steps, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.computed_field","title":"computed_field","text":"<pre><code>computed_field(\n    property_name,\n    return_schema,\n    *,\n    alias=None,\n    metadata=None\n)\n</code></pre> <p>ComputedFields are properties of a model or dataclass that are included in serialization.</p> <p>Parameters:</p> Name Type Description Default <code>property_name</code> <code>str</code> <p>The name of the property on the model or dataclass</p> required <code>return_schema</code> <code>CoreSchema</code> <p>The schema used for the type returned by the computed field</p> required <code>alias</code> <code>str | None</code> <p>The name to use in the serialized output</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def computed_field(\n    property_name: str, return_schema: CoreSchema, *, alias: str | None = None, metadata: Any = None\n) -&gt; ComputedField:\n\"\"\"\n    ComputedFields are properties of a model or dataclass that are included in serialization.\n\n    Args:\n        property_name: The name of the property on the model or dataclass\n        return_schema: The schema used for the type returned by the computed field\n        alias: The name to use in the serialized output\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return dict_not_none(\n        type='computed-field', property_name=property_name, return_schema=return_schema, alias=alias, metadata=metadata\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.custom_error_schema","title":"custom_error_schema","text":"<pre><code>custom_error_schema(\n    schema,\n    custom_error_type,\n    *,\n    custom_error_message=None,\n    custom_error_context=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a custom error value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.custom_error_schema(\n    schema=core_schema.int_schema(),\n    custom_error_type='MyError',\n    custom_error_message='Error msg',\n)\nv = SchemaValidator(schema)\nv.validate_python(1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the custom error schema</p> required <code>custom_error_type</code> <code>str</code> <p>The custom error type to use for the custom error schema</p> required <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use for the custom error schema</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, str | int | float] | None</code> <p>The custom error context to use for the custom error schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def custom_error_schema(\n    schema: CoreSchema,\n    custom_error_type: str,\n    *,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, str | int | float] | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; CustomErrorSchema:\n\"\"\"\n    Returns a schema that matches a custom error value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.custom_error_schema(\n        schema=core_schema.int_schema(),\n        custom_error_type='MyError',\n        custom_error_message='Error msg',\n    )\n    v = SchemaValidator(schema)\n    v.validate_python(1)\n    ```\n\n    Args:\n        schema: The schema to use for the custom error schema\n        custom_error_type: The custom error type to use for the custom error schema\n        custom_error_message: The custom error message to use for the custom error schema\n        custom_error_context: The custom error context to use for the custom error schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='custom-error',\n        schema=schema,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_args_schema","title":"dataclass_args_schema","text":"<pre><code>dataclass_args_schema(\n    dataclass_name,\n    fields,\n    *,\n    computed_fields=None,\n    populate_by_name=None,\n    collect_init_only=None,\n    ref=None,\n    metadata=None,\n    serialization=None,\n    extra_behavior=None\n)\n</code></pre> <p>Returns a schema for validating dataclass arguments, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nfield_a = core_schema.dataclass_field(\n    name='a', schema=core_schema.str_schema(), kw_only=False\n)\nfield_b = core_schema.dataclass_field(\n    name='b', schema=core_schema.bool_schema(), kw_only=False\n)\nschema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])\nv = SchemaValidator(schema)\nassert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataclass_name</code> <code>str</code> <p>The name of the dataclass being validated</p> required <code>fields</code> <code>list[DataclassField]</code> <p>The fields to use for the dataclass</p> required <code>computed_fields</code> <code>List[ComputedField] | None</code> <p>Computed fields to use when serializing the dataclass</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether to populate by name</p> <code>None</code> <code>collect_init_only</code> <code>bool | None</code> <p>Whether to collect init only fields into a dict to pass to <code>__post_init__</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>How to handle extra fields</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_args_schema(\n    dataclass_name: str,\n    fields: list[DataclassField],\n    *,\n    computed_fields: List[ComputedField] | None = None,\n    populate_by_name: bool | None = None,\n    collect_init_only: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n) -&gt; DataclassArgsSchema:\n\"\"\"\n    Returns a schema for validating dataclass arguments, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field_a = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    field_b = core_schema.dataclass_field(\n        name='b', schema=core_schema.bool_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)\n    ```\n\n    Args:\n        dataclass_name: The name of the dataclass being validated\n        fields: The fields to use for the dataclass\n        computed_fields: Computed fields to use when serializing the dataclass\n        populate_by_name: Whether to populate by name\n        collect_init_only: Whether to collect init only fields into a dict to pass to `__post_init__`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        extra_behavior: How to handle extra fields\n    \"\"\"\n    return dict_not_none(\n        type='dataclass-args',\n        dataclass_name=dataclass_name,\n        fields=fields,\n        computed_fields=computed_fields,\n        populate_by_name=populate_by_name,\n        collect_init_only=collect_init_only,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        extra_behavior=extra_behavior,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_field","title":"dataclass_field","text":"<pre><code>dataclass_field(\n    name,\n    schema,\n    *,\n    kw_only=None,\n    init_only=None,\n    validation_alias=None,\n    serialization_alias=None,\n    serialization_exclude=None,\n    metadata=None,\n    frozen=None\n)\n</code></pre> <p>Returns a schema for a dataclass field, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nfield = core_schema.dataclass_field(\n    name='a', schema=core_schema.str_schema(), kw_only=False\n)\nschema = core_schema.dataclass_args_schema('Foobar', [field])\nv = SchemaValidator(schema)\nassert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to use for the argument parameter</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the argument parameter</p> required <code>kw_only</code> <code>bool | None</code> <p>Whether the field can be set with a positional argument as well as a keyword argument</p> <code>None</code> <code>init_only</code> <code>bool | None</code> <p>Whether the field should be omitted  from <code>__dict__</code> and passed to <code>__post_init__</code></p> <code>None</code> <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_field(\n    name: str,\n    schema: CoreSchema,\n    *,\n    kw_only: bool | None = None,\n    init_only: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Any = None,\n    frozen: bool | None = None,\n) -&gt; DataclassField:\n\"\"\"\n    Returns a schema for a dataclass field, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        kw_only: Whether the field can be set with a positional argument as well as a keyword argument\n        init_only: Whether the field should be omitted  from `__dict__` and passed to `__post_init__`\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        frozen: Whether the field is frozen\n    \"\"\"\n    return dict_not_none(\n        type='dataclass-field',\n        name=name,\n        schema=schema,\n        kw_only=kw_only,\n        init_only=init_only,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n        frozen=frozen,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_schema","title":"dataclass_schema","text":"<pre><code>dataclass_schema(\n    cls,\n    schema,\n    fields,\n    *,\n    cls_name=None,\n    post_init=None,\n    revalidate_instances=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None,\n    frozen=None,\n    slots=None,\n    config=None\n)\n</code></pre> <p>Returns a schema for a dataclass. As with <code>ModelSchema</code>, this schema can only be used as a field within another schema, not as the root type.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The dataclass type, used to perform subclass checks</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the dataclass fields</p> required <code>fields</code> <code>List[str]</code> <p>Fields of the dataclass, this is used in serialization and in validation during re-validation and while validating assignment</p> required <code>cls_name</code> <code>str | None</code> <p>The name to use in error locs, etc; this is useful for generics (default: <code>cls.__name__</code>)</p> <code>None</code> <code>post_init</code> <code>bool | None</code> <p>Whether to call <code>__post_init__</code> after validation</p> <code>None</code> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances'] | None</code> <p>whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate_instances, else 'never'</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to require an exact instance of <code>cls</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the dataclass is frozen</p> <code>None</code> <code>slots</code> <code>bool | None</code> <p>Whether <code>slots=True</code> on the dataclass, means each field is assigned independently, rather than simply setting <code>__dict__</code>, default false</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    fields: List[str],\n    *,\n    cls_name: str | None = None,\n    post_init: bool | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    frozen: bool | None = None,\n    slots: bool | None = None,\n    config: CoreConfig | None = None,\n) -&gt; DataclassSchema:\n\"\"\"\n    Returns a schema for a dataclass. As with `ModelSchema`, this schema can only be used as a field within\n    another schema, not as the root type.\n\n    Args:\n        cls: The dataclass type, used to perform subclass checks\n        schema: The schema to use for the dataclass fields\n        fields: Fields of the dataclass, this is used in serialization and in validation during re-validation\n            and while validating assignment\n        cls_name: The name to use in error locs, etc; this is useful for generics (default: `cls.__name__`)\n        post_init: Whether to call `__post_init__` after validation\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether to require an exact instance of `cls`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        frozen: Whether the dataclass is frozen\n        slots: Whether `slots=True` on the dataclass, means each field is assigned independently, rather than\n            simply setting `__dict__`, default false\n    \"\"\"\n    return dict_not_none(\n        type='dataclass',\n        cls=cls,\n        fields=fields,\n        cls_name=cls_name,\n        schema=schema,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        frozen=frozen,\n        slots=slots,\n        config=config,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.date_schema","title":"date_schema","text":"<pre><code>date_schema(\n    *,\n    strict=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    now_op=None,\n    now_utc_offset=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a date value, e.g.:</p> <pre><code>from datetime import date\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))\nv = SchemaValidator(schema)\nassert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a date or a value that can be converted to a date</p> <code>None</code> <code>le</code> <code>date | None</code> <p>The value must be less than or equal to this date</p> <code>None</code> <code>ge</code> <code>date | None</code> <p>The value must be greater than or equal to this date</p> <code>None</code> <code>lt</code> <code>date | None</code> <p>The value must be strictly less than this date</p> <code>None</code> <code>gt</code> <code>date | None</code> <p>The value must be strictly greater than this date</p> <code>None</code> <code>now_op</code> <code>Literal['past', 'future'] | None</code> <p>The value must be in the past or future relative to the current date</p> <code>None</code> <code>now_utc_offset</code> <code>int | None</code> <p>The value must be in the past or future relative to the current date with this utc offset</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def date_schema(\n    *,\n    strict: bool | None = None,\n    le: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    gt: date | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    now_utc_offset: int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; DateSchema:\n\"\"\"\n    Returns a schema that matches a date value, e.g.:\n\n    ```py\n    from datetime import date\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))\n    v = SchemaValidator(schema)\n    assert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)\n    ```\n\n    Args:\n        strict: Whether the value should be a date or a value that can be converted to a date\n        le: The value must be less than or equal to this date\n        ge: The value must be greater than or equal to this date\n        lt: The value must be strictly less than this date\n        gt: The value must be strictly greater than this date\n        now_op: The value must be in the past or future relative to the current date\n        now_utc_offset: The value must be in the past or future relative to the current date with this utc offset\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='date',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        now_utc_offset=now_utc_offset,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.datetime_schema","title":"datetime_schema","text":"<pre><code>datetime_schema(\n    *,\n    strict=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    now_op=None,\n    tz_constraint=None,\n    now_utc_offset=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a datetime value, e.g.:</p> <pre><code>from datetime import datetime\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.datetime_schema()\nv = SchemaValidator(schema)\nnow = datetime.now()\nassert v.validate_python(str(now)) == now\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a datetime or a value that can be converted to a datetime</p> <code>None</code> <code>le</code> <code>datetime | None</code> <p>The value must be less than or equal to this datetime</p> <code>None</code> <code>ge</code> <code>datetime | None</code> <p>The value must be greater than or equal to this datetime</p> <code>None</code> <code>lt</code> <code>datetime | None</code> <p>The value must be strictly less than this datetime</p> <code>None</code> <code>gt</code> <code>datetime | None</code> <p>The value must be strictly greater than this datetime</p> <code>None</code> <code>now_op</code> <code>Literal['past', 'future'] | None</code> <p>The value must be in the past or future relative to the current datetime</p> <code>None</code> <code>tz_constraint</code> <code>Literal['aware', 'naive'] | int | None</code> <p>The value must be timezone aware or naive, or an int to indicate required tz offset TODO: use of a tzinfo where offset changes based on the datetime is not yet supported</p> <code>None</code> <code>now_utc_offset</code> <code>int | None</code> <p>The value must be in the past or future relative to the current datetime with this utc offset</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def datetime_schema(\n    *,\n    strict: bool | None = None,\n    le: datetime | None = None,\n    ge: datetime | None = None,\n    lt: datetime | None = None,\n    gt: datetime | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    now_utc_offset: int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; DatetimeSchema:\n\"\"\"\n    Returns a schema that matches a datetime value, e.g.:\n\n    ```py\n    from datetime import datetime\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.datetime_schema()\n    v = SchemaValidator(schema)\n    now = datetime.now()\n    assert v.validate_python(str(now)) == now\n    ```\n\n    Args:\n        strict: Whether the value should be a datetime or a value that can be converted to a datetime\n        le: The value must be less than or equal to this datetime\n        ge: The value must be greater than or equal to this datetime\n        lt: The value must be strictly less than this datetime\n        gt: The value must be strictly greater than this datetime\n        now_op: The value must be in the past or future relative to the current datetime\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported\n        now_utc_offset: The value must be in the past or future relative to the current datetime with this utc offset\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='datetime',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        tz_constraint=tz_constraint,\n        now_utc_offset=now_utc_offset,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.definition_reference_schema","title":"definition_reference_schema","text":"<pre><code>definition_reference_schema(\n    schema_ref, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive models and also when you want to define validators separately from the main schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema_definition = core_schema.definition_reference_schema('list-schema')\nschema = core_schema.list_schema(items_schema=schema_definition, ref='list-schema')\nv = SchemaValidator(schema)\nassert v.validate_python([[]]) == [[]]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema_ref</code> <code>str</code> <p>The schema ref to use for the definition reference schema</p> required <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def definition_reference_schema(\n    schema_ref: str, metadata: Any = None, serialization: SerSchema | None = None\n) -&gt; DefinitionReferenceSchema:\n\"\"\"\n    Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive\n    models and also when you want to define validators separately from the main schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema_definition = core_schema.definition_reference_schema('list-schema')\n    schema = core_schema.list_schema(items_schema=schema_definition, ref='list-schema')\n    v = SchemaValidator(schema)\n    assert v.validate_python([[]]) == [[]]\n    ```\n\n    Args:\n        schema_ref: The schema ref to use for the definition reference schema\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='definition-ref', schema_ref=schema_ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.definitions_schema","title":"definitions_schema","text":"<pre><code>definitions_schema(schema, definitions)\n</code></pre> <p>Build a schema that contains both an inner schema and a list of definitions which can be used within the inner schema.</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.definitions_schema(\n    core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n    [core_schema.int_schema(ref='foobar')],\n)\nv = SchemaValidator(schema)\nassert v.validate_python([1, 2, '3']) == [1, 2, 3]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The inner schema</p> required <code>definitions</code> <code>list[CoreSchema]</code> <p>List of definitions which can be referenced within inner schema</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def definitions_schema(schema: CoreSchema, definitions: list[CoreSchema]) -&gt; DefinitionsSchema:\n\"\"\"\n    Build a schema that contains both an inner schema and a list of definitions which can be used\n    within the inner schema.\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.definitions_schema(\n        core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n        [core_schema.int_schema(ref='foobar')],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python([1, 2, '3']) == [1, 2, 3]\n    ```\n\n    Args:\n        schema: The inner schema\n        definitions: List of definitions which can be referenced within inner schema\n    \"\"\"\n    return DefinitionsSchema(type='definitions', schema=schema, definitions=definitions)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dict_schema","title":"dict_schema","text":"<pre><code>dict_schema(\n    keys_schema=None,\n    values_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a dict value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.dict_schema(\n    keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>keys_schema</code> <code>CoreSchema | None</code> <p>The value must be a dict with keys that match this schema</p> <code>None</code> <code>values_schema</code> <code>CoreSchema | None</code> <p>The value must be a dict with values that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a dict with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a dict with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the keys and values should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dict_schema(\n    keys_schema: CoreSchema | None = None,\n    values_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; DictSchema:\n\"\"\"\n    Returns a schema that matches a dict value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.dict_schema(\n        keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}\n    ```\n\n    Args:\n        keys_schema: The value must be a dict with keys that match this schema\n        values_schema: The value must be a dict with values that match this schema\n        min_length: The value must be a dict with at least this many items\n        max_length: The value must be a dict with at most this many items\n        strict: Whether the keys and values should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='dict',\n        keys_schema=keys_schema,\n        values_schema=values_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.field_after_validator_function","title":"field_after_validator_function","text":"<pre><code>field_after_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function after validating the function is called with information about the field being validated, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.FieldValidationInfo) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return v + 'world'\n\nfunc_schema = core_schema.field_after_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>FieldValidatorFunction</code> <p>The validator function to call after the schema is validated</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate before the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def field_after_validator_function(\n    function: FieldValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; AfterValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function after validating the function is called with information\n    about the field being validated, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.FieldValidationInfo) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v + 'world'\n\n    func_schema = core_schema.field_after_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-after',\n        function={'type': 'field', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.field_before_validator_function","title":"field_before_validator_function","text":"<pre><code>field_before_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function before validating the function is called with information about the field being validated, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: bytes, info: core_schema.FieldValidationInfo) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return v.decode() + 'world'\n\nfunc_schema = core_schema.field_before_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>FieldValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def field_before_validator_function(\n    function: FieldValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; BeforeValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function before validating the function is called with information\n    about the field being validated, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes, info: core_schema.FieldValidationInfo) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v.decode() + 'world'\n\n    func_schema = core_schema.field_before_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-before',\n        function={'type': 'field', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.field_plain_validator_function","title":"field_plain_validator_function","text":"<pre><code>field_plain_validator_function(\n    function, *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that uses the provided function for validation, e.g.:</p> <pre><code>from typing import Any\nfrom pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: Any, info: core_schema.FieldValidationInfo) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return str(v) + 'world'\n\nfunc_schema = core_schema.field_plain_validator_function(function=fn)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': 'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>FieldValidatorFunction</code> <p>The validator function to call</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def field_plain_validator_function(\n    function: FieldValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; PlainValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that uses the provided function for validation, e.g.:\n\n    ```py\n    from typing import Any\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: Any, info: core_schema.FieldValidationInfo) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return str(v) + 'world'\n\n    func_schema = core_schema.field_plain_validator_function(function=fn)\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-plain',\n        function={'type': 'field', 'function': function},\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.field_wrap_validator_function","title":"field_wrap_validator_function","text":"<pre><code>field_wrap_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema applicable to fields which calls a function with a <code>validator</code> callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, field info is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(\n    v: bytes,\n    validator: core_schema.ValidatorFunctionWrapHandler,\n    info: core_schema.FieldValidationInfo,\n) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return validator(v) + 'world'\n\nfunc_schema = core_schema.field_wrap_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>FieldWrapValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def field_wrap_validator_function(\n    function: FieldWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; WrapValidatorFunctionSchema:\n\"\"\"\n    Returns a schema applicable to **fields**\n    which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, field info is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: bytes,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n        info: core_schema.FieldValidationInfo,\n    ) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return validator(v) + 'world'\n\n    func_schema = core_schema.field_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-wrap',\n        function={'type': 'field', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.float_schema","title":"float_schema","text":"<pre><code>float_schema(\n    *,\n    allow_inf_nan=None,\n    multiple_of=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a float value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.float_schema(le=0.8, ge=0.2)\nv = SchemaValidator(schema)\nassert v.validate_python('0.5') == 0.5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow inf and nan values</p> <code>None</code> <code>multiple_of</code> <code>float | None</code> <p>The value must be a multiple of this number</p> <code>None</code> <code>le</code> <code>float | None</code> <p>The value must be less than or equal to this number</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>The value must be greater than or equal to this number</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>The value must be strictly less than this number</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>The value must be strictly greater than this number</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a float or a value that can be converted to a float</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def float_schema(\n    *,\n    allow_inf_nan: bool | None = None,\n    multiple_of: float | None = None,\n    le: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    gt: float | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; FloatSchema:\n\"\"\"\n    Returns a schema that matches a float value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.float_schema(le=0.8, ge=0.2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('0.5') == 0.5\n    ```\n\n    Args:\n        allow_inf_nan: Whether to allow inf and nan values\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a float or a value that can be converted to a float\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='float',\n        allow_inf_nan=allow_inf_nan,\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.format_ser_schema","title":"format_ser_schema","text":"<pre><code>format_ser_schema(\n    formatting_string, *, when_used=\"json-unless-none\"\n)\n</code></pre> <p>Returns a schema for serialization using python's <code>format</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>formatting_string</code> <code>str</code> <p>String defining the format to use</p> required <code>when_used</code> <code>WhenUsed</code> <p>Same meaning as for [general_function_plain_ser_schema], but with a different default</p> <code>'json-unless-none'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def format_ser_schema(formatting_string: str, *, when_used: WhenUsed = 'json-unless-none') -&gt; FormatSerSchema:\n\"\"\"\n    Returns a schema for serialization using python's `format` method.\n\n    Args:\n        formatting_string: String defining the format to use\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    if when_used == 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return dict_not_none(type='format', formatting_string=formatting_string, when_used=when_used)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.frozenset_schema","title":"frozenset_schema","text":"<pre><code>frozenset_schema(\n    items_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a frozenset of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.frozenset_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a frozenset with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a frozenset with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a frozenset with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a frozenset with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def frozenset_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; FrozenSetSchema:\n\"\"\"\n    Returns a schema that matches a frozenset of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.frozenset_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})\n    ```\n\n    Args:\n        items_schema: The value must be a frozenset with items that match this schema\n        min_length: The value must be a frozenset with at least this many items\n        max_length: The value must be a frozenset with at most this many items\n        strict: The value must be a frozenset with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='frozenset',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.general_after_validator_function","title":"general_after_validator_function","text":"<pre><code>general_after_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function after validating the provided schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + 'world'\n\nschema = core_schema.general_after_validator_function(\n    schema=core_schema.str_schema(), function=fn\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to validate before the validator function</p> required <code>function</code> <code>GeneralValidatorFunction</code> <p>The validator function to call after the schema is validated</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def general_after_validator_function(\n    function: GeneralValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; AfterValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function after validating the provided schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.general_after_validator_function(\n        schema=core_schema.str_schema(), function=fn\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        schema: The schema to validate before the validator function\n        function: The validator function to call after the schema is validated\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-after',\n        function={'type': 'general', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.general_before_validator_function","title":"general_before_validator_function","text":"<pre><code>general_before_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function before validating the provided schema, e.g.:</p> <pre><code>from typing import Any\nfrom pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: Any, info: core_schema.ValidationInfo) -&gt; str:\n    v_str = str(v)\n    assert 'hello' in v_str\n    return v_str + 'world'\n\nschema = core_schema.general_before_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python(b'hello ') == \"b'hello 'world\"\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>GeneralValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def general_before_validator_function(\n    function: GeneralValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; BeforeValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function before validating the provided schema, e.g.:\n\n    ```py\n    from typing import Any\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: Any, info: core_schema.ValidationInfo) -&gt; str:\n        v_str = str(v)\n        assert 'hello' in v_str\n        return v_str + 'world'\n\n    schema = core_schema.general_before_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(b'hello ') == \"b'hello 'world\"\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-before',\n        function={'type': 'general', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.general_plain_validator_function","title":"general_plain_validator_function","text":"<pre><code>general_plain_validator_function(\n    function, *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that uses the provided function for validation, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + 'world'\n\nschema = core_schema.general_plain_validator_function(function=fn)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>GeneralValidatorFunction</code> <p>The validator function to call</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def general_plain_validator_function(\n    function: GeneralValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; PlainValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that uses the provided function for validation, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.general_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-plain',\n        function={'type': 'general', 'function': function},\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.general_wrap_validator_function","title":"general_wrap_validator_function","text":"<pre><code>general_wrap_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema which calls a function with a <code>validator</code> callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, general info is also passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(\n    v: str,\n    validator: core_schema.ValidatorFunctionWrapHandler,\n    info: core_schema.ValidationInfo,\n) -&gt; str:\n    return validator(input_value=v) + 'world'\n\nschema = core_schema.general_wrap_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>GeneralWrapValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def general_wrap_validator_function(\n    function: GeneralWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; WrapValidatorFunctionSchema:\n\"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, general info is also passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n        info: core_schema.ValidationInfo,\n    ) -&gt; str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.general_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-wrap',\n        function={'type': 'general', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.generator_schema","title":"generator_schema","text":"<pre><code>generator_schema(\n    items_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a generator value, e.g.:</p> <pre><code>from typing import Iterator\nfrom pydantic_core import SchemaValidator, core_schema\n\ndef gen() -&gt; Iterator[int]:\n    yield 1\n\nschema = core_schema.generator_schema(items_schema=core_schema.int_schema())\nv = SchemaValidator(schema)\nv.validate_python(gen())\n</code></pre> <p>Unlike other types, validated generators do not raise ValidationErrors eagerly, but instead will raise a ValidationError when a violating value is actually read from the generator. This is to ensure that \"validated\" generators retain the benefit of lazy evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a generator with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a generator that yields at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a generator that yields at most this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def generator_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; GeneratorSchema:\n\"\"\"\n    Returns a schema that matches a generator value, e.g.:\n\n    ```py\n    from typing import Iterator\n    from pydantic_core import SchemaValidator, core_schema\n\n    def gen() -&gt; Iterator[int]:\n        yield 1\n\n    schema = core_schema.generator_schema(items_schema=core_schema.int_schema())\n    v = SchemaValidator(schema)\n    v.validate_python(gen())\n    ```\n\n    Unlike other types, validated generators do not raise ValidationErrors eagerly,\n    but instead will raise a ValidationError when a violating value is actually read from the generator.\n    This is to ensure that \"validated\" generators retain the benefit of lazy evaluation.\n\n    Args:\n        items_schema: The value must be a generator with items that match this schema\n        min_length: The value must be a generator that yields at least this many items\n        max_length: The value must be a generator that yields at most this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='generator',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.int_schema","title":"int_schema","text":"<pre><code>int_schema(\n    *,\n    multiple_of=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a int value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.int_schema(multiple_of=2, le=6, ge=2)\nv = SchemaValidator(schema)\nassert v.validate_python('4') == 4\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>multiple_of</code> <code>int | None</code> <p>The value must be a multiple of this number</p> <code>None</code> <code>le</code> <code>int | None</code> <p>The value must be less than or equal to this number</p> <code>None</code> <code>ge</code> <code>int | None</code> <p>The value must be greater than or equal to this number</p> <code>None</code> <code>lt</code> <code>int | None</code> <p>The value must be strictly less than this number</p> <code>None</code> <code>gt</code> <code>int | None</code> <p>The value must be strictly greater than this number</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a int or a value that can be converted to a int</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def int_schema(\n    *,\n    multiple_of: int | None = None,\n    le: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    gt: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; IntSchema:\n\"\"\"\n    Returns a schema that matches a int value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.int_schema(multiple_of=2, le=6, ge=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('4') == 4\n    ```\n\n    Args:\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a int or a value that can be converted to a int\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='int',\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.is_instance_schema","title":"is_instance_schema","text":"<pre><code>is_instance_schema(\n    cls,\n    *,\n    cls_repr=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that checks if a value is an instance of a class, equivalent to python's <code>isinstnace</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nclass A:\n    pass\n\nschema = core_schema.is_instance_schema(cls=A)\nv = SchemaValidator(schema)\nv.validate_python(A())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Any</code> <p>The value must be an instance of this class</p> required <code>cls_repr</code> <code>str | None</code> <p>If provided this string is used in the validator name instead of <code>repr(cls)</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def is_instance_schema(\n    cls: Any,\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; IsInstanceSchema:\n\"\"\"\n    Returns a schema that checks if a value is an instance of a class, equivalent to python's `isinstnace` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    schema = core_schema.is_instance_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(A())\n    ```\n\n    Args:\n        cls: The value must be an instance of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='is-instance', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.is_subclass_schema","title":"is_subclass_schema","text":"<pre><code>is_subclass_schema(\n    cls,\n    *,\n    cls_repr=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that checks if a value is a subtype of a class, equivalent to python's <code>issubclass</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nclass A:\n    pass\n\nclass B(A):\n    pass\n\nschema = core_schema.is_subclass_schema(cls=A)\nv = SchemaValidator(schema)\nv.validate_python(B)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The value must be a subclass of this class</p> required <code>cls_repr</code> <code>str | None</code> <p>If provided this string is used in the validator name instead of <code>repr(cls)</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def is_subclass_schema(\n    cls: Type[Any],\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; IsInstanceSchema:\n\"\"\"\n    Returns a schema that checks if a value is a subtype of a class, equivalent to python's `issubclass` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    schema = core_schema.is_subclass_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(B)\n    ```\n\n    Args:\n        cls: The value must be a subclass of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='is-subclass', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.json_or_python_schema","title":"json_or_python_schema","text":"<pre><code>json_or_python_schema(\n    json_schema,\n    python_schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that uses the Json or Python schema depending on the input:</p> <pre><code>from pydantic_core import SchemaValidator, ValidationError, core_schema\n\nv = SchemaValidator(\n    core_schema.json_or_python_schema(\n        json_schema=core_schema.int_schema(),\n        python_schema=core_schema.int_schema(strict=True),\n    )\n)\n\nassert v.validate_json('\"123\"') == 123\n\ntry:\n    v.validate_python('123')\nexcept ValidationError:\n    pass\nelse:\n    raise AssertionError('Validation should have failed')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>CoreSchema</code> <p>The schema to use for Json inputs</p> required <code>python_schema</code> <code>CoreSchema</code> <p>The schema to use for Python inputs</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def json_or_python_schema(\n    json_schema: CoreSchema,\n    python_schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; JsonOrPythonSchema:\n\"\"\"\n    Returns a schema that uses the Json or Python schema depending on the input:\n\n    ```py\n    from pydantic_core import SchemaValidator, ValidationError, core_schema\n\n    v = SchemaValidator(\n        core_schema.json_or_python_schema(\n            json_schema=core_schema.int_schema(),\n            python_schema=core_schema.int_schema(strict=True),\n        )\n    )\n\n    assert v.validate_json('\"123\"') == 123\n\n    try:\n        v.validate_python('123')\n    except ValidationError:\n        pass\n    else:\n        raise AssertionError('Validation should have failed')\n    ```\n\n    Args:\n        json_schema: The schema to use for Json inputs\n        python_schema: The schema to use for Python inputs\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='json-or-python',\n        json_schema=json_schema,\n        python_schema=python_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.json_schema","title":"json_schema","text":"<pre><code>json_schema(\n    schema=None,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a JSON value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndict_schema = core_schema.model_fields_schema(\n    {\n        'field_a': core_schema.model_field(core_schema.str_schema()),\n        'field_b': core_schema.model_field(core_schema.bool_schema()),\n    },\n)\n\nclass MyModel:\n    __slots__ = (\n        '__dict__',\n        '__pydantic_fields_set__',\n        '__pydantic_extra__',\n        '__pydantic_private__',\n    )\n    field_a: str\n    field_b: bool\n\njson_schema = core_schema.json_schema(schema=dict_schema)\nschema = core_schema.model_schema(cls=MyModel, schema=json_schema)\nv = SchemaValidator(schema)\nm = v.validate_python('{\"field_a\": \"hello\", \"field_b\": true}')\nassert isinstance(m, MyModel)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema | None</code> <p>The schema to use for the JSON schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def json_schema(\n    schema: CoreSchema | None = None,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; JsonSchema:\n\"\"\"\n    Returns a schema that matches a JSON value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    dict_schema = core_schema.model_fields_schema(\n        {\n            'field_a': core_schema.model_field(core_schema.str_schema()),\n            'field_b': core_schema.model_field(core_schema.bool_schema()),\n        },\n    )\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n        field_a: str\n        field_b: bool\n\n    json_schema = core_schema.json_schema(schema=dict_schema)\n    schema = core_schema.model_schema(cls=MyModel, schema=json_schema)\n    v = SchemaValidator(schema)\n    m = v.validate_python('{\"field_a\": \"hello\", \"field_b\": true}')\n    assert isinstance(m, MyModel)\n    ```\n\n    Args:\n        schema: The schema to use for the JSON schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='json', schema=schema, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.lax_or_strict_schema","title":"lax_or_strict_schema","text":"<pre><code>lax_or_strict_schema(\n    lax_schema,\n    strict_schema,\n    *,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that uses the lax or strict schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + ' world'\n\nlax_schema = core_schema.int_schema(strict=False)\nstrict_schema = core_schema.int_schema(strict=True)\n\nschema = core_schema.lax_or_strict_schema(\n    lax_schema=lax_schema, strict_schema=strict_schema, strict=True\n)\nv = SchemaValidator(schema)\nassert v.validate_python(123) == 123\n\nschema = core_schema.lax_or_strict_schema(\n    lax_schema=lax_schema, strict_schema=strict_schema, strict=False\n)\nv = SchemaValidator(schema)\nassert v.validate_python('123') == 123\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>lax_schema</code> <code>CoreSchema</code> <p>The lax schema to use</p> required <code>strict_schema</code> <code>CoreSchema</code> <p>The strict schema to use</p> required <code>strict</code> <code>bool | None</code> <p>Whether the strict schema should be used</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def lax_or_strict_schema(\n    lax_schema: CoreSchema,\n    strict_schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; LaxOrStrictSchema:\n\"\"\"\n    Returns a schema that uses the lax or strict schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + ' world'\n\n    lax_schema = core_schema.int_schema(strict=False)\n    strict_schema = core_schema.int_schema(strict=True)\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=True\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(123) == 123\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=False\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('123') == 123\n    ```\n\n    Args:\n        lax_schema: The lax schema to use\n        strict_schema: The strict schema to use\n        strict: Whether the strict schema should be used\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='lax-or-strict',\n        lax_schema=lax_schema,\n        strict_schema=strict_schema,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.list_schema","title":"list_schema","text":"<pre><code>list_schema(\n    items_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a list value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)\nv = SchemaValidator(schema)\nassert v.validate_python(['4']) == [4]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a list of items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a list with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a list with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a list with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def list_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; ListSchema:\n\"\"\"\n    Returns a schema that matches a list value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)\n    v = SchemaValidator(schema)\n    assert v.validate_python(['4']) == [4]\n    ```\n\n    Args:\n        items_schema: The value must be a list of items that match this schema\n        min_length: The value must be a list with at least this many items\n        max_length: The value must be a list with at most this many items\n        strict: The value must be a list with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='list',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.literal_schema","title":"literal_schema","text":"<pre><code>literal_schema(\n    expected, *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that matches a literal value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.literal_schema(['hello', 'world'])\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expected</code> <code>list[Any]</code> <p>The value must be one of these values</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def literal_schema(\n    expected: list[Any], *, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None\n) -&gt; LiteralSchema:\n\"\"\"\n    Returns a schema that matches a literal value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.literal_schema(['hello', 'world'])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        expected: The value must be one of these values\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='literal', expected=expected, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_field","title":"model_field","text":"<pre><code>model_field(\n    schema,\n    *,\n    validation_alias=None,\n    serialization_alias=None,\n    serialization_exclude=None,\n    frozen=None,\n    metadata=None\n)\n</code></pre> <p>Returns a schema for a model field, e.g.:</p> <pre><code>from pydantic_core import core_schema\n\nfield = core_schema.model_field(schema=core_schema.int_schema())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the field</p> required <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_field(\n    schema: CoreSchema,\n    *,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    frozen: bool | None = None,\n    metadata: Any = None,\n) -&gt; ModelField:\n\"\"\"\n    Returns a schema for a model field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.model_field(schema=core_schema.int_schema())\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        frozen: Whether the field is frozen\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return dict_not_none(\n        type='model-field',\n        schema=schema,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        frozen=frozen,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_fields_schema","title":"model_fields_schema","text":"<pre><code>model_fields_schema(\n    fields,\n    *,\n    computed_fields=None,\n    strict=None,\n    extra_validator=None,\n    extra_behavior=None,\n    populate_by_name=None,\n    from_attributes=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a typed dict, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nwrapper_schema = core_schema.model_fields_schema(\n    {'a': core_schema.model_field(core_schema.str_schema())}\n)\nv = SchemaValidator(wrapper_schema)\nprint(v.validate_python({'a': 'hello'}))\n#&gt; ({'a': 'hello'}, None, {'a'})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Dict[str, ModelField]</code> <p>The fields to use for the typed dict</p> required <code>computed_fields</code> <code>list[ComputedField] | None</code> <p>Computed fields to use when serializing the model, only applies when directly inside a model</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the typed dict is strict</p> <code>None</code> <code>extra_validator</code> <code>CoreSchema | None</code> <p>The extra validator to use for the typed dict</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the typed dict</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether the typed dict should populate by name</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether the typed dict should be populated from attributes</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_fields_schema(\n    fields: Dict[str, ModelField],\n    *,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extra_validator: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    populate_by_name: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; ModelFieldsSchema:\n\"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    wrapper_schema = core_schema.model_fields_schema(\n        {'a': core_schema.model_field(core_schema.str_schema())}\n    )\n    v = SchemaValidator(wrapper_schema)\n    print(v.validate_python({'a': 'hello'}))\n    #&gt; ({'a': 'hello'}, None, {'a'})\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extra_validator: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        populate_by_name: Whether the typed dict should populate by name\n        from_attributes: Whether the typed dict should be populated from attributes\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='model-fields',\n        fields=fields,\n        computed_fields=computed_fields,\n        strict=strict,\n        extra_validator=extra_validator,\n        extra_behavior=extra_behavior,\n        populate_by_name=populate_by_name,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_schema","title":"model_schema","text":"<pre><code>model_schema(\n    cls,\n    schema,\n    *,\n    custom_init=None,\n    root_model=None,\n    post_init=None,\n    revalidate_instances=None,\n    strict=None,\n    frozen=None,\n    extra_behavior=None,\n    config=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>A model schema generally contains a typed-dict schema. It will run the typed dict validator, then create a new class and set the dict and fields set returned from the typed dict validator to <code>__dict__</code> and <code>__pydantic_fields_set__</code> respectively.</p> <p>Example:</p> <pre><code>from pydantic_core import CoreConfig, SchemaValidator, core_schema\n\nclass MyModel:\n    __slots__ = (\n        '__dict__',\n        '__pydantic_fields_set__',\n        '__pydantic_extra__',\n        '__pydantic_private__',\n    )\n\nschema = core_schema.model_schema(\n    cls=MyModel,\n    config=CoreConfig(str_max_length=5),\n    schema=core_schema.model_fields_schema(\n        fields={'a': core_schema.model_field(core_schema.str_schema())},\n    ),\n)\nv = SchemaValidator(schema)\nassert v.isinstance_python({'a': 'hello'}) is True\nassert v.isinstance_python({'a': 'too long'}) is False\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The class to use for the model</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the model</p> required <code>custom_init</code> <code>bool | None</code> <p>Whether the model has a custom init method</p> <code>None</code> <code>root_model</code> <code>bool | None</code> <p>Whether the model is a <code>RootModel</code></p> <code>None</code> <code>post_init</code> <code>str | None</code> <p>The call after init to use for the model</p> <code>None</code> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances'] | None</code> <p>whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate_instances, else 'never'</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the model is strict</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the model is frozen</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the model, used in serialization</p> <code>None</code> <code>config</code> <code>CoreConfig | None</code> <p>The config to use for the model</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    *,\n    custom_init: bool | None = None,\n    root_model: bool | None = None,\n    post_init: str | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    frozen: bool | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    config: CoreConfig | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; ModelSchema:\n\"\"\"\n    A model schema generally contains a typed-dict schema.\n    It will run the typed dict validator, then create a new class\n    and set the dict and fields set returned from the typed dict validator\n    to `__dict__` and `__pydantic_fields_set__` respectively.\n\n    Example:\n\n    ```py\n    from pydantic_core import CoreConfig, SchemaValidator, core_schema\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n\n    schema = core_schema.model_schema(\n        cls=MyModel,\n        config=CoreConfig(str_max_length=5),\n        schema=core_schema.model_fields_schema(\n            fields={'a': core_schema.model_field(core_schema.str_schema())},\n        ),\n    )\n    v = SchemaValidator(schema)\n    assert v.isinstance_python({'a': 'hello'}) is True\n    assert v.isinstance_python({'a': 'too long'}) is False\n    ```\n\n    Args:\n        cls: The class to use for the model\n        schema: The schema to use for the model\n        custom_init: Whether the model has a custom init method\n        root_model: Whether the model is a `RootModel`\n        post_init: The call after init to use for the model\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether the model is strict\n        frozen: Whether the model is frozen\n        extra_behavior: The extra behavior to use for the model, used in serialization\n        config: The config to use for the model\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='model',\n        cls=cls,\n        schema=schema,\n        custom_init=custom_init,\n        root_model=root_model,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        frozen=frozen,\n        extra_behavior=extra_behavior,\n        config=config,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_ser_schema","title":"model_ser_schema","text":"<pre><code>model_ser_schema(cls, schema)\n</code></pre> <p>Returns a schema for serialization using a model.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The expected class type, used to generate warnings if the wrong type is passed</p> required <code>schema</code> <code>CoreSchema</code> <p>Internal schema to use to serialize the model dict</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_ser_schema(cls: Type[Any], schema: CoreSchema) -&gt; ModelSerSchema:\n\"\"\"\n    Returns a schema for serialization using a model.\n\n    Args:\n        cls: The expected class type, used to generate warnings if the wrong type is passed\n        schema: Internal schema to use to serialize the model dict\n    \"\"\"\n    return ModelSerSchema(type='model', cls=cls, schema=schema)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.multi_host_url_schema","title":"multi_host_url_schema","text":"<pre><code>multi_host_url_schema(\n    *,\n    max_length=None,\n    allowed_schemes=None,\n    host_required=None,\n    default_host=None,\n    default_port=None,\n    default_path=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a URL value with possibly multiple hosts, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.multi_host_url_schema()\nv = SchemaValidator(schema)\nprint(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))\n#&gt; redis://localhost,0.0.0.0,127.0.0.1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The maximum length of the URL</p> <code>None</code> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed URL schemes</p> <code>None</code> <code>host_required</code> <code>bool | None</code> <p>Whether the URL must have a host</p> <code>None</code> <code>default_host</code> <code>str | None</code> <p>The default host to use if the URL does not have a host</p> <code>None</code> <code>default_port</code> <code>int | None</code> <p>The default port to use if the URL does not have a port</p> <code>None</code> <code>default_path</code> <code>str | None</code> <p>The default path to use if the URL does not have a path</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to use strict URL parsing</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def multi_host_url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; MultiHostUrlSchema:\n\"\"\"\n    Returns a schema that matches a URL value with possibly multiple hosts, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.multi_host_url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))\n    #&gt; redis://localhost,0.0.0.0,127.0.0.1\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='multi-host-url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_after_validator_function","title":"no_info_after_validator_function","text":"<pre><code>no_info_after_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function after validating, no info is provided, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str) -&gt; str:\n    return v + 'world'\n\nfunc_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call after the schema is validated</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate before the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_after_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; AfterValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function after validating, no info is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -&gt; str:\n        return v + 'world'\n\n    func_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-after',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_before_validator_function","title":"no_info_before_validator_function","text":"<pre><code>no_info_before_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that calls a validator function before validating, no info is provided, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: bytes) -&gt; str:\n    return v.decode() + 'world'\n\nfunc_schema = core_schema.no_info_before_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_before_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; BeforeValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that calls a validator function before validating, no info is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes) -&gt; str:\n        return v.decode() + 'world'\n\n    func_schema = core_schema.no_info_before_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-before',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_plain_validator_function","title":"no_info_plain_validator_function","text":"<pre><code>no_info_plain_validator_function(\n    function, *, ref=None, metadata=None, serialization=None\n)\n</code></pre> <p>Returns a schema that uses the provided function for validation, no info is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str) -&gt; str:\n    assert 'hello' in v\n    return v + 'world'\n\nschema = core_schema.no_info_plain_validator_function(function=fn)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_plain_validator_function(\n    function: NoInfoValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; PlainValidatorFunctionSchema:\n\"\"\"\n    Returns a schema that uses the provided function for validation, no info is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -&gt; str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.no_info_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-plain',\n        function={'type': 'no-info', 'function': function},\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_wrap_validator_function","title":"no_info_wrap_validator_function","text":"<pre><code>no_info_wrap_validator_function(\n    function,\n    schema,\n    *,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema which calls a function with a <code>validator</code> callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, no info argument is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(\n    v: str,\n    validator: core_schema.ValidatorFunctionWrapHandler,\n) -&gt; str:\n    return validator(input_value=v) + 'world'\n\nschema = core_schema.no_info_wrap_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoWrapValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_wrap_validator_function(\n    function: NoInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; WrapValidatorFunctionSchema:\n\"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, no info argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n    ) -&gt; str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.no_info_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='function-wrap',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.none_schema","title":"none_schema","text":"<pre><code>none_schema(*, ref=None, metadata=None, serialization=None)\n</code></pre> <p>Returns a schema that matches a None value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.none_schema()\nv = SchemaValidator(schema)\nassert v.validate_python(None) is None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def none_schema(*, ref: str | None = None, metadata: Any = None, serialization: SerSchema | None = None) -&gt; NoneSchema:\n\"\"\"\n    Returns a schema that matches a None value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.none_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(type='none', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.nullable_schema","title":"nullable_schema","text":"<pre><code>nullable_schema(\n    schema,\n    *,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a nullable value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.nullable_schema(core_schema.str_schema())\nv = SchemaValidator(schema)\nassert v.validate_python(None) is None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to wrap</p> required <code>strict</code> <code>bool | None</code> <p>Whether the underlying schema should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def nullable_schema(\n    schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; NullableSchema:\n\"\"\"\n    Returns a schema that matches a nullable value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.nullable_schema(core_schema.str_schema())\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        schema: The schema to wrap\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='nullable', schema=schema, strict=strict, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.plain_serializer_function_ser_schema","title":"plain_serializer_function_ser_schema","text":"<pre><code>plain_serializer_function_ser_schema(\n    function,\n    *,\n    is_field_serializer=None,\n    info_arg=None,\n    return_schema=None,\n    when_used=\"always\"\n)\n</code></pre> <p>Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>SerializerFunction</code> <p>The function to use for serialization</p> required <code>is_field_serializer</code> <code>bool | None</code> <p>Whether the serializer is for a field, e.g. takes <code>model</code> as the first argument, and <code>info</code> includes <code>field_name</code></p> <code>None</code> <code>info_arg</code> <code>bool | None</code> <p>Whether the function takes an <code>__info</code> argument</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>Schema to use for serializing return value</p> <code>None</code> <code>when_used</code> <code>WhenUsed</code> <p>When the function should be called</p> <code>'always'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def plain_serializer_function_ser_schema(\n    function: SerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -&gt; PlainSerializerFunctionSerSchema:\n\"\"\"\n    Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `__info` argument\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return dict_not_none(\n        type='function-plain',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.set_schema","title":"set_schema","text":"<pre><code>set_schema(\n    items_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a set of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.set_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python({1, '2', 3}) == {1, 2, 3}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a set with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a set with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a set with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a set with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def set_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; SetSchema:\n\"\"\"\n    Returns a schema that matches a set of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.set_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({1, '2', 3}) == {1, 2, 3}\n    ```\n\n    Args:\n        items_schema: The value must be a set with items that match this schema\n        min_length: The value must be a set with at least this many items\n        max_length: The value must be a set with at most this many items\n        strict: The value must be a set with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='set',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.simple_ser_schema","title":"simple_ser_schema","text":"<pre><code>simple_ser_schema(type)\n</code></pre> <p>Returns a schema for serialization with a custom type.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>ExpectedSerializationTypes</code> <p>The type to use for serialization</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def simple_ser_schema(type: ExpectedSerializationTypes) -&gt; SimpleSerSchema:\n\"\"\"\n    Returns a schema for serialization with a custom type.\n\n    Args:\n        type: The type to use for serialization\n    \"\"\"\n    return SimpleSerSchema(type=type)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.str_schema","title":"str_schema","text":"<pre><code>str_schema(\n    *,\n    pattern=None,\n    max_length=None,\n    min_length=None,\n    strip_whitespace=None,\n    to_lower=None,\n    to_upper=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a string value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.str_schema(max_length=10, min_length=2)\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | None</code> <p>A regex pattern that the value must match</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be at most this length</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be at least this length</p> <code>None</code> <code>strip_whitespace</code> <code>bool | None</code> <p>Whether to strip whitespace from the value</p> <code>None</code> <code>to_lower</code> <code>bool | None</code> <p>Whether to convert the value to lowercase</p> <code>None</code> <code>to_upper</code> <code>bool | None</code> <p>Whether to convert the value to uppercase</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a string or a value that can be converted to a string</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def str_schema(\n    *,\n    pattern: str | None = None,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strip_whitespace: bool | None = None,\n    to_lower: bool | None = None,\n    to_upper: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; StringSchema:\n\"\"\"\n    Returns a schema that matches a string value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.str_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        pattern: A regex pattern that the value must match\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strip_whitespace: Whether to strip whitespace from the value\n        to_lower: Whether to convert the value to lowercase\n        to_upper: Whether to convert the value to uppercase\n        strict: Whether the value should be a string or a value that can be converted to a string\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='str',\n        pattern=pattern,\n        max_length=max_length,\n        min_length=min_length,\n        strip_whitespace=strip_whitespace,\n        to_lower=to_lower,\n        to_upper=to_upper,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tagged_union_schema","title":"tagged_union_schema","text":"<pre><code>tagged_union_schema(\n    choices,\n    discriminator,\n    *,\n    custom_error_type=None,\n    custom_error_message=None,\n    custom_error_context=None,\n    strict=None,\n    from_attributes=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a tagged union value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\napple_schema = core_schema.typed_dict_schema(\n    {\n        'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n        'bar': core_schema.typed_dict_field(core_schema.int_schema()),\n    }\n)\nbanana_schema = core_schema.typed_dict_schema(\n    {\n        'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n        'spam': core_schema.typed_dict_field(\n            core_schema.list_schema(items_schema=core_schema.int_schema())\n        ),\n    }\n)\nschema = core_schema.tagged_union_schema(\n    choices={\n        'apple': apple_schema,\n        'banana': banana_schema,\n    },\n    discriminator='foo',\n)\nv = SchemaValidator(schema)\nassert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\nassert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {\n    'foo': 'banana',\n    'spam': [1, 2, 3],\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>choices</code> <code>Dict[Hashable, CoreSchema]</code> <p>The schemas to match When retrieving a schema from <code>choices</code> using the discriminator value, if the value is a str, it should be fed back into the <code>choices</code> map until a schema is obtained (This approach is to prevent multiple ownership of a single schema in Rust)</p> required <code>discriminator</code> <code>str | list[str | int] | list[list[str | int]] | Callable[[Any], str | int | None]</code> <p>The discriminator to use to determine the schema to use * If <code>discriminator</code> is a str, it is the name of the attribute to use as the discriminator * If <code>discriminator</code> is a list of int/str, it should be used as a \"path\" to access the discriminator * If <code>discriminator</code> is a list of lists, each inner list is a path, and the first path that exists is used * If <code>discriminator</code> is a callable, it should return the discriminator when called on the value to validate;   the callable can return <code>None</code> to indicate that there is no matching discriminator present on the input</p> required <code>custom_error_type</code> <code>str | None</code> <p>The custom error type to use if the validation fails</p> <code>None</code> <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use if the validation fails</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, int | str | float] | None</code> <p>The custom error context to use if the validation fails</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schemas should be validated with strict mode</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to use the attributes of the object to retrieve the discriminator value</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tagged_union_schema(\n    choices: Dict[Hashable, CoreSchema],\n    discriminator: str | list[str | int] | list[list[str | int]] | Callable[[Any], str | int | None],\n    *,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, int | str | float] | None = None,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; TaggedUnionSchema:\n\"\"\"\n    Returns a schema that matches a tagged union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    apple_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'bar': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    banana_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'spam': core_schema.typed_dict_field(\n                core_schema.list_schema(items_schema=core_schema.int_schema())\n            ),\n        }\n    )\n    schema = core_schema.tagged_union_schema(\n        choices={\n            'apple': apple_schema,\n            'banana': banana_schema,\n        },\n        discriminator='foo',\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\n    assert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {\n        'foo': 'banana',\n        'spam': [1, 2, 3],\n    }\n    ```\n\n    Args:\n        choices: The schemas to match\n            When retrieving a schema from `choices` using the discriminator value, if the value is a str,\n            it should be fed back into the `choices` map until a schema is obtained\n            (This approach is to prevent multiple ownership of a single schema in Rust)\n        discriminator: The discriminator to use to determine the schema to use\n            * If `discriminator` is a str, it is the name of the attribute to use as the discriminator\n            * If `discriminator` is a list of int/str, it should be used as a \"path\" to access the discriminator\n            * If `discriminator` is a list of lists, each inner list is a path, and the first path that exists is used\n            * If `discriminator` is a callable, it should return the discriminator when called on the value to validate;\n              the callable can return `None` to indicate that there is no matching discriminator present on the input\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        strict: Whether the underlying schemas should be validated with strict mode\n        from_attributes: Whether to use the attributes of the object to retrieve the discriminator value\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='tagged-union',\n        choices=choices,\n        discriminator=discriminator,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        strict=strict,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.time_schema","title":"time_schema","text":"<pre><code>time_schema(\n    *,\n    strict=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    tz_constraint=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a time value, e.g.:</p> <pre><code>from datetime import time\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))\nv = SchemaValidator(schema)\nassert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a time or a value that can be converted to a time</p> <code>None</code> <code>le</code> <code>time | None</code> <p>The value must be less than or equal to this time</p> <code>None</code> <code>ge</code> <code>time | None</code> <p>The value must be greater than or equal to this time</p> <code>None</code> <code>lt</code> <code>time | None</code> <p>The value must be strictly less than this time</p> <code>None</code> <code>gt</code> <code>time | None</code> <p>The value must be strictly greater than this time</p> <code>None</code> <code>tz_constraint</code> <code>Literal['aware', 'naive'] | int | None</code> <p>The value must be timezone aware or naive, or an int to indicate required tz offset</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def time_schema(\n    *,\n    strict: bool | None = None,\n    le: time | None = None,\n    ge: time | None = None,\n    lt: time | None = None,\n    gt: time | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; TimeSchema:\n\"\"\"\n    Returns a schema that matches a time value, e.g.:\n\n    ```py\n    from datetime import time\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)\n    ```\n\n    Args:\n        strict: Whether the value should be a time or a value that can be converted to a time\n        le: The value must be less than or equal to this time\n        ge: The value must be greater than or equal to this time\n        lt: The value must be strictly less than this time\n        gt: The value must be strictly greater than this time\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='time',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        tz_constraint=tz_constraint,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.timedelta_schema","title":"timedelta_schema","text":"<pre><code>timedelta_schema(\n    *,\n    strict=None,\n    le=None,\n    ge=None,\n    lt=None,\n    gt=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a timedelta value, e.g.:</p> <pre><code>from datetime import timedelta\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))\nv = SchemaValidator(schema)\nassert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a timedelta or a value that can be converted to a timedelta</p> <code>None</code> <code>le</code> <code>timedelta | None</code> <p>The value must be less than or equal to this timedelta</p> <code>None</code> <code>ge</code> <code>timedelta | None</code> <p>The value must be greater than or equal to this timedelta</p> <code>None</code> <code>lt</code> <code>timedelta | None</code> <p>The value must be strictly less than this timedelta</p> <code>None</code> <code>gt</code> <code>timedelta | None</code> <p>The value must be strictly greater than this timedelta</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def timedelta_schema(\n    *,\n    strict: bool | None = None,\n    le: timedelta | None = None,\n    ge: timedelta | None = None,\n    lt: timedelta | None = None,\n    gt: timedelta | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; TimedeltaSchema:\n\"\"\"\n    Returns a schema that matches a timedelta value, e.g.:\n\n    ```py\n    from datetime import timedelta\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)\n    ```\n\n    Args:\n        strict: Whether the value should be a timedelta or a value that can be converted to a timedelta\n        le: The value must be less than or equal to this timedelta\n        ge: The value must be greater than or equal to this timedelta\n        lt: The value must be strictly less than this timedelta\n        gt: The value must be strictly greater than this timedelta\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='timedelta',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.to_string_ser_schema","title":"to_string_ser_schema","text":"<pre><code>to_string_ser_schema(*, when_used='json-unless-none')\n</code></pre> <p>Returns a schema for serialization using python's <code>str()</code> / <code>__str__</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>when_used</code> <code>WhenUsed</code> <p>Same meaning as for [general_function_plain_ser_schema], but with a different default</p> <code>'json-unless-none'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def to_string_ser_schema(*, when_used: WhenUsed = 'json-unless-none') -&gt; ToStringSerSchema:\n\"\"\"\n    Returns a schema for serialization using python's `str()` / `__str__` method.\n\n    Args:\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    s = dict(type='to-string')\n    if when_used != 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        s['when_used'] = when_used\n    return s  # type: ignore\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tuple_positional_schema","title":"tuple_positional_schema","text":"<pre><code>tuple_positional_schema(\n    items_schema,\n    *,\n    extra_schema=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a tuple of schemas, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.tuple_positional_schema(\n    [core_schema.int_schema(), core_schema.str_schema()]\n)\nv = SchemaValidator(schema)\nassert v.validate_python((1, 'hello')) == (1, 'hello')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>list[CoreSchema]</code> <p>The value must be a tuple with items that match these schemas</p> required <code>extra_schema</code> <code>CoreSchema | None</code> <p>The value must be a tuple with items that match this schema This was inspired by JSON schema's <code>prefixItems</code> and <code>items</code> fields. In python's <code>typing.Tuple</code>, you can't specify a type for \"extra\" items -- they must all be the same type if the length is variable. So this field won't be set from a <code>typing.Tuple</code> annotation on a pydantic model.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a tuple with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tuple_positional_schema(\n    items_schema: list[CoreSchema],\n    *,\n    extra_schema: CoreSchema | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; TuplePositionalSchema:\n\"\"\"\n    Returns a schema that matches a tuple of schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_positional_schema(\n        [core_schema.int_schema(), core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((1, 'hello')) == (1, 'hello')\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match these schemas\n        extra_schema: The value must be a tuple with items that match this schema\n            This was inspired by JSON schema's `prefixItems` and `items` fields.\n            In python's `typing.Tuple`, you can't specify a type for \"extra\" items -- they must all be the same type\n            if the length is variable. So this field won't be set from a `typing.Tuple` annotation on a pydantic model.\n        strict: The value must be a tuple with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='tuple-positional',\n        items_schema=items_schema,\n        extra_schema=extra_schema,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tuple_variable_schema","title":"tuple_variable_schema","text":"<pre><code>tuple_variable_schema(\n    items_schema=None,\n    *,\n    min_length=None,\n    max_length=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a tuple of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.tuple_variable_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python(('1', 2, 3)) == (1, 2, 3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a tuple with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a tuple with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a tuple with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a tuple with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tuple_variable_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; TupleVariableSchema:\n\"\"\"\n    Returns a schema that matches a tuple of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_variable_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(('1', 2, 3)) == (1, 2, 3)\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match this schema\n        min_length: The value must be a tuple with at least this many items\n        max_length: The value must be a tuple with at most this many items\n        strict: The value must be a tuple with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='tuple-variable',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.typed_dict_field","title":"typed_dict_field","text":"<pre><code>typed_dict_field(\n    schema,\n    *,\n    required=None,\n    validation_alias=None,\n    serialization_alias=None,\n    serialization_exclude=None,\n    metadata=None\n)\n</code></pre> <p>Returns a schema that matches a typed dict field, e.g.:</p> <pre><code>from pydantic_core import core_schema\n\nfield = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the field</p> required <code>required</code> <code>bool | None</code> <p>Whether the field is required</p> <code>None</code> <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def typed_dict_field(\n    schema: CoreSchema,\n    *,\n    required: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Any = None,\n) -&gt; TypedDictField:\n\"\"\"\n    Returns a schema that matches a typed dict field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        required: Whether the field is required\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return dict_not_none(\n        type='typed-dict-field',\n        schema=schema,\n        required=required,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.typed_dict_schema","title":"typed_dict_schema","text":"<pre><code>typed_dict_schema(\n    fields,\n    *,\n    computed_fields=None,\n    strict=None,\n    extra_validator=None,\n    extra_behavior=None,\n    total=None,\n    populate_by_name=None,\n    ref=None,\n    metadata=None,\n    serialization=None,\n    config=None\n)\n</code></pre> <p>Returns a schema that matches a typed dict, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nwrapper_schema = core_schema.typed_dict_schema(\n    {'a': core_schema.typed_dict_field(core_schema.str_schema())}\n)\nv = SchemaValidator(wrapper_schema)\nassert v.validate_python({'a': 'hello'}) == {'a': 'hello'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Dict[str, TypedDictField]</code> <p>The fields to use for the typed dict</p> required <code>computed_fields</code> <code>list[ComputedField] | None</code> <p>Computed fields to use when serializing the model, only applies when directly inside a model</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the typed dict is strict</p> <code>None</code> <code>extra_validator</code> <code>CoreSchema | None</code> <p>The extra validator to use for the typed dict</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the typed dict</p> <code>None</code> <code>total</code> <code>bool | None</code> <p>Whether the typed dict is total</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether the typed dict should populate by name</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def typed_dict_schema(\n    fields: Dict[str, TypedDictField],\n    *,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extra_validator: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    total: bool | None = None,\n    populate_by_name: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n    config: CoreConfig | None = None,\n) -&gt; TypedDictSchema:\n\"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(core_schema.str_schema())}\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({'a': 'hello'}) == {'a': 'hello'}\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extra_validator: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        total: Whether the typed dict is total\n        populate_by_name: Whether the typed dict should populate by name\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='typed-dict',\n        fields=fields,\n        computed_fields=computed_fields,\n        strict=strict,\n        extra_validator=extra_validator,\n        extra_behavior=extra_behavior,\n        total=total,\n        populate_by_name=populate_by_name,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        config=config,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.union_schema","title":"union_schema","text":"<pre><code>union_schema(\n    choices,\n    *,\n    auto_collapse=None,\n    custom_error_type=None,\n    custom_error_message=None,\n    custom_error_context=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a union value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\nassert v.validate_python(1) == 1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>choices</code> <code>list[CoreSchema]</code> <p>The schemas to match</p> required <code>auto_collapse</code> <code>bool | None</code> <p>whether to automatically collapse unions with one element to the inner validator, default true</p> <code>None</code> <code>custom_error_type</code> <code>str | None</code> <p>The custom error type to use if the validation fails</p> <code>None</code> <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use if the validation fails</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, str | int] | None</code> <p>The custom error context to use if the validation fails</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schemas should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def union_schema(\n    choices: list[CoreSchema],\n    *,\n    auto_collapse: bool | None = None,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, str | int] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; UnionSchema:\n\"\"\"\n    Returns a schema that matches a union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        choices: The schemas to match\n        auto_collapse: whether to automatically collapse unions with one element to the inner validator, default true\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        strict: Whether the underlying schemas should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='union',\n        choices=choices,\n        auto_collapse=auto_collapse,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.url_schema","title":"url_schema","text":"<pre><code>url_schema(\n    *,\n    max_length=None,\n    allowed_schemes=None,\n    host_required=None,\n    default_host=None,\n    default_port=None,\n    default_path=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that matches a URL value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.url_schema()\nv = SchemaValidator(schema)\nprint(v.validate_python('https://example.com'))\n#&gt; https://example.com/\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The maximum length of the URL</p> <code>None</code> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed URL schemes</p> <code>None</code> <code>host_required</code> <code>bool | None</code> <p>Whether the URL must have a host</p> <code>None</code> <code>default_host</code> <code>str | None</code> <p>The default host to use if the URL does not have a host</p> <code>None</code> <code>default_port</code> <code>int | None</code> <p>The default port to use if the URL does not have a port</p> <code>None</code> <code>default_path</code> <code>str | None</code> <p>The default path to use if the URL does not have a path</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to use strict URL parsing</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; UrlSchema:\n\"\"\"\n    Returns a schema that matches a URL value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('https://example.com'))\n    #&gt; https://example.com/\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return dict_not_none(\n        type='url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_default_schema","title":"with_default_schema","text":"<pre><code>with_default_schema(\n    schema,\n    *,\n    default=PydanticUndefined,\n    default_factory=None,\n    on_error=None,\n    validate_default=None,\n    strict=None,\n    ref=None,\n    metadata=None,\n    serialization=None\n)\n</code></pre> <p>Returns a schema that adds a default value to the given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')\nwrapper_schema = core_schema.typed_dict_schema(\n    {'a': core_schema.typed_dict_field(schema)}\n)\nv = SchemaValidator(wrapper_schema)\nassert v.validate_python({}) == v.validate_python({'a': 'hello'})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to add a default value to</p> required <code>default</code> <code>Any</code> <p>The default value to use</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>Callable[[], Any] | None</code> <p>A function that returns the default value to use</p> <code>None</code> <code>on_error</code> <code>Literal['raise', 'omit', 'default'] | None</code> <p>What to do if the schema validation fails. One of 'raise', 'omit', 'default'</p> <code>None</code> <code>validate_default</code> <code>bool | None</code> <p>Whether the default value should be validated</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schema should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Any</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_default_schema(\n    schema: CoreSchema,\n    *,\n    default: Any = PydanticUndefined,\n    default_factory: Callable[[], Any] | None = None,\n    on_error: Literal['raise', 'omit', 'default'] | None = None,\n    validate_default: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Any = None,\n    serialization: SerSchema | None = None,\n) -&gt; WithDefaultSchema:\n\"\"\"\n    Returns a schema that adds a default value to the given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(schema)}\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({}) == v.validate_python({'a': 'hello'})\n    ```\n\n    Args:\n        schema: The schema to add a default value to\n        default: The default value to use\n        default_factory: A function that returns the default value to use\n        on_error: What to do if the schema validation fails. One of 'raise', 'omit', 'default'\n        validate_default: Whether the default value should be validated\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    s = dict_not_none(\n        type='default',\n        schema=schema,\n        default_factory=default_factory,\n        on_error=on_error,\n        validate_default=validate_default,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n    if default is not PydanticUndefined:\n        s['default'] = default\n    return s\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.wrap_serializer_function_ser_schema","title":"wrap_serializer_function_ser_schema","text":"<pre><code>wrap_serializer_function_ser_schema(\n    function,\n    *,\n    is_field_serializer=None,\n    info_arg=None,\n    schema=None,\n    return_schema=None,\n    when_used=\"always\"\n)\n</code></pre> <p>Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WrapSerializerFunction</code> <p>The function to use for serialization</p> required <code>is_field_serializer</code> <code>bool | None</code> <p>Whether the serializer is for a field, e.g. takes <code>model</code> as the first argument, and <code>info</code> includes <code>field_name</code></p> <code>None</code> <code>info_arg</code> <code>bool | None</code> <p>Whether the function takes an <code>__info</code> argument</p> <code>None</code> <code>schema</code> <code>CoreSchema | None</code> <p>The schema to use for the inner serialization</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>Schema to use for serializing return value</p> <code>None</code> <code>when_used</code> <code>WhenUsed</code> <p>When the function should be called</p> <code>'always'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def wrap_serializer_function_ser_schema(\n    function: WrapSerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    schema: CoreSchema | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -&gt; WrapSerializerFunctionSerSchema:\n\"\"\"\n    Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `__info` argument\n        schema: The schema to use for the inner serialization\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return dict_not_none(\n        type='function-wrap',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        schema=schema,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/","title":"pydantic_extra_types.color","text":"<p>Color definitions are used as per the CSS3 CSS Color Module Level 3 specification.</p> <p>A few colors have multiple names referring to the sames colors, eg. <code>grey</code> and <code>gray</code> or <code>aqua</code> and <code>cyan</code>.</p> <p>In these cases the last color when sorted alphabetically takes preferences, eg. <code>Color((0, 255, 255)).as_named() == 'cyan'</code> because \"cyan\" comes after \"aqua\".</p>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color","title":"Color","text":"<pre><code>Color(value)\n</code></pre> <p>         Bases: <code>_repr.Representation</code></p> <p>Represents a color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def __init__(self, value: ColorType) -&gt; None:\n    self._rgba: RGBA\n    self._original: ColorType\n    if isinstance(value, (tuple, list)):\n        self._rgba = parse_tuple(value)\n    elif isinstance(value, str):\n        self._rgba = parse_str(value)\n    elif isinstance(value, Color):\n        self._rgba = value._rgba\n        value = value._original\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: value must be a tuple, list or string',\n        )\n\n    # if we've got here value must be a valid color\n    self._original = value\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hex","title":"as_hex","text":"<pre><code>as_hex()\n</code></pre> <p>Returns the hexadecimal representation of the color.</p> <p>Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string a \"short\" representation of the color is possible and whether there's an alpha channel.</p> <p>Returns:</p> Type Description <code>str</code> <p>The hexadecimal representation of the color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hex(self) -&gt; str:\n\"\"\"Returns the hexadecimal representation of the color.\n\n    Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string\n    a \"short\" representation of the color is possible and whether there's an alpha channel.\n\n    Returns:\n        The hexadecimal representation of the color.\n    \"\"\"\n    values = [float_to_255(c) for c in self._rgba[:3]]\n    if self._rgba.alpha is not None:\n        values.append(float_to_255(self._rgba.alpha))\n\n    as_hex = ''.join(f'{v:02x}' for v in values)\n    if all(c in repeat_colors for c in values):\n        as_hex = ''.join(as_hex[c] for c in range(0, len(as_hex), 2))\n    return '#' + as_hex\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hsl","title":"as_hsl","text":"<pre><code>as_hsl()\n</code></pre> <p>Color as an <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)</code> or <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hsl(self) -&gt; str:\n\"\"\"\n    Color as an `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)` or `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)` string.\n    \"\"\"\n    if self._rgba.alpha is None:\n        h, s, li = self.as_hsl_tuple(alpha=False)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%})'\n    else:\n        h, s, li, a = self.as_hsl_tuple(alpha=True)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%}, {round(a, 2)})'\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hsl_tuple","title":"as_hsl_tuple","text":"<pre><code>as_hsl_tuple(*, alpha=None)\n</code></pre> <p>Returns the color as an HSL or HSLA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>bool | None</code> <p>Whether to include the alpha channel.</p> <ul> <li><code>None</code> (default): Include the alpha channel only if it's set (e.g. not <code>None</code>).</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>HslColorTuple</code> <p>The color as a tuple of hue, saturation, lightness, and alpha (if included). All elements are in the range 0 to 1.</p> Note <p>This is HSL as used in HTML and most other places, not HLS as used in Python's <code>colorsys</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hsl_tuple(self, *, alpha: bool | None = None) -&gt; HslColorTuple:\n\"\"\"\n    Returns the color as an HSL or HSLA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel.\n\n            - `None` (default): Include the alpha channel only if it's set (e.g. not `None`).\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        The color as a tuple of hue, saturation, lightness, and alpha (if included).\n            All elements are in the range 0 to 1.\n\n    Note:\n        This is HSL as used in HTML and most other places, not HLS as used in Python's `colorsys`.\n    \"\"\"\n    h, l, s = rgb_to_hls(self._rgba.r, self._rgba.g, self._rgba.b)  # noqa: E741\n    if alpha is None:\n        if self._rgba.alpha is None:\n            return h, s, l\n        else:\n            return h, s, l, self._alpha_float()\n    if alpha:\n        return h, s, l, self._alpha_float()\n    else:\n        # alpha is False\n        return h, s, l\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_named","title":"as_named","text":"<pre><code>as_named(*, fallback=False)\n</code></pre> <p>Returns the name of the color if it can be found in <code>COLORS_BY_VALUE</code> dictionary, otherwise returns the hexadecimal representation of the color or raises <code>ValueError</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fallback</code> <code>bool</code> <p>If True, falls back to returning the hexadecimal representation of the color instead of raising a ValueError when no named color is found.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The name of the color, or the hexadecimal representation of the color.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When no named color is found and fallback is <code>False</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_named(self, *, fallback: bool = False) -&gt; str:\n\"\"\"\n    Returns the name of the color if it can be found in `COLORS_BY_VALUE` dictionary,\n    otherwise returns the hexadecimal representation of the color or raises `ValueError`.\n\n    Args:\n        fallback: If True, falls back to returning the hexadecimal representation of\n            the color instead of raising a ValueError when no named color is found.\n\n    Returns:\n        The name of the color, or the hexadecimal representation of the color.\n\n    Raises:\n        ValueError: When no named color is found and fallback is `False`.\n    \"\"\"\n    if self._rgba.alpha is None:\n        rgb = cast(Tuple[int, int, int], self.as_rgb_tuple())\n        try:\n            return COLORS_BY_VALUE[rgb]\n        except KeyError as e:\n            if fallback:\n                return self.as_hex()\n            else:\n                raise ValueError('no named color found, use fallback=True, as_hex() or as_rgb()') from e\n    else:\n        return self.as_hex()\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_rgb","title":"as_rgb","text":"<pre><code>as_rgb()\n</code></pre> <p>Color as an <code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code> or <code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_rgb(self) -&gt; str:\n\"\"\"\n    Color as an `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)` or `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)` string.\n    \"\"\"\n    if self._rgba.alpha is None:\n        return f'rgb({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)})'\n    else:\n        return (\n            f'rgba({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)}, '\n            f'{round(self._alpha_float(), 2)})'\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_rgb_tuple","title":"as_rgb_tuple","text":"<pre><code>as_rgb_tuple(*, alpha=None)\n</code></pre> <p>Returns the color as an RGB or RGBA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>bool | None</code> <p>Whether to include the alpha channel. There are three options for this input:</p> <ul> <li><code>None</code> (default): Include alpha only if it's set. (e.g. not <code>None</code>)</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>ColorTuple</code> <p>A tuple that contains the values of the red, green, and blue channels in the range 0 to 255. If alpha is included, it is in the range 0 to 1.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_rgb_tuple(self, *, alpha: bool | None = None) -&gt; ColorTuple:\n\"\"\"\n    Returns the color as an RGB or RGBA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel. There are three options for this input:\n\n            - `None` (default): Include alpha only if it's set. (e.g. not `None`)\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        A tuple that contains the values of the red, green, and blue channels in the range 0 to 255.\n            If alpha is included, it is in the range 0 to 1.\n    \"\"\"\n    r, g, b = (float_to_255(c) for c in self._rgba[:3])\n    if alpha is None:\n        if self._rgba.alpha is None:\n            return r, g, b\n        else:\n            return r, g, b, self._alpha_float()\n    elif alpha:\n        return r, g, b, self._alpha_float()\n    else:\n        # alpha is False\n        return r, g, b\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.original","title":"original","text":"<pre><code>original()\n</code></pre> <p>Original value passed to <code>Color</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def original(self) -&gt; ColorType:\n\"\"\"\n    Original value passed to `Color`.\n    \"\"\"\n    return self._original\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.RGBA","title":"RGBA","text":"<pre><code>RGBA(r, g, b, alpha)\n</code></pre> <p>Internal use only as a representation of a color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def __init__(self, r: float, g: float, b: float, alpha: float | None):\n    self.r = r\n    self.g = g\n    self.b = b\n    self.alpha = alpha\n\n    self._tuple: tuple[float, float, float, float | None] = (r, g, b, alpha)\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.float_to_255","title":"float_to_255","text":"<pre><code>float_to_255(c)\n</code></pre> <p>Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>float</code> <p>The float value to be converted. Must be between 0 and 1 (inclusive).</p> required <p>Returns:</p> Type Description <code>int</code> <p>The integer equivalent of the given float value rounded to the nearest whole number.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the given float value is outside the acceptable range of 0 to 1 (inclusive).</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def float_to_255(c: float) -&gt; int:\n\"\"\"\n    Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).\n\n    Args:\n        c: The float value to be converted. Must be between 0 and 1 (inclusive).\n\n    Returns:\n        The integer equivalent of the given float value rounded to the nearest whole number.\n\n    Raises:\n        ValueError: If the given float value is outside the acceptable range of 0 to 1 (inclusive).\n    \"\"\"\n    return int(round(c * 255))\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.ints_to_rgba","title":"ints_to_rgba","text":"<pre><code>ints_to_rgba(r, g, b, alpha=None)\n</code></pre> <p>Converts integer or string values for RGB color and an optional alpha value to an <code>RGBA</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>int | str</code> <p>An integer or string representing the red color value.</p> required <code>g</code> <code>int | str</code> <p>An integer or string representing the green color value.</p> required <code>b</code> <code>int | str</code> <p>An integer or string representing the blue color value.</p> required <code>alpha</code> <code>float | None</code> <p>A float representing the alpha value. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of the <code>RGBA</code> class with the corresponding color and alpha values.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def ints_to_rgba(\n    r: int | str,\n    g: int | str,\n    b: int | str,\n    alpha: float | None = None,\n) -&gt; RGBA:\n\"\"\"\n    Converts integer or string values for RGB color and an optional alpha value to an `RGBA` object.\n\n    Args:\n        r: An integer or string representing the red color value.\n        g: An integer or string representing the green color value.\n        b: An integer or string representing the blue color value.\n        alpha: A float representing the alpha value. Defaults to None.\n\n    Returns:\n        An instance of the `RGBA` class with the corresponding color and alpha values.\n    \"\"\"\n    return RGBA(\n        parse_color_value(r),\n        parse_color_value(g),\n        parse_color_value(b),\n        parse_float_alpha(alpha),\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_color_value","title":"parse_color_value","text":"<pre><code>parse_color_value(value, max_val=255)\n</code></pre> <p>Parse the color value provided and return a number between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | str</code> <p>An integer or string color value.</p> required <code>max_val</code> <code>int</code> <p>Maximum range value. Defaults to 255.</p> <code>255</code> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the value is not a valid color.</p> <p>Returns:</p> Type Description <code>float</code> <p>A number between 0 and 1.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_color_value(value: int | str, max_val: int = 255) -&gt; float:\n\"\"\"\n    Parse the color value provided and return a number between 0 and 1.\n\n    Args:\n        value: An integer or string color value.\n        max_val: Maximum range value. Defaults to 255.\n\n    Raises:\n        PydanticCustomError: If the value is not a valid color.\n\n    Returns:\n        A number between 0 and 1.\n    \"\"\"\n    try:\n        color = float(value)\n    except ValueError:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: color values must be a valid number',\n        )\n    if 0 &lt;= color &lt;= max_val:\n        return color / max_val\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: color values must be in the range 0 to {max_val}',\n            {'max_val': max_val},\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_float_alpha","title":"parse_float_alpha","text":"<pre><code>parse_float_alpha(value)\n</code></pre> <p>Parse an alpha value checking it's a valid float in the range 0 to 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>None | str | float | int</code> <p>The input value to parse.</p> required <p>Returns:</p> Type Description <code>float | None</code> <p>The parsed value as a float, or <code>None</code> if the value was None or equal 1.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the input value cannot be successfully parsed as a float in the expected range.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_float_alpha(value: None | str | float | int) -&gt; float | None:\n\"\"\"\n    Parse an alpha value checking it's a valid float in the range 0 to 1.\n\n    Args:\n        value: The input value to parse.\n\n    Returns:\n        The parsed value as a float, or `None` if the value was None or equal 1.\n\n    Raises:\n        PydanticCustomError: If the input value cannot be successfully parsed as a float in the expected range.\n    \"\"\"\n    if value is None:\n        return None\n    try:\n        if isinstance(value, str) and value.endswith('%'):\n            alpha = float(value[:-1]) / 100\n        else:\n            alpha = float(value)\n    except ValueError:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: alpha values must be a valid float',\n        )\n\n    if _utils.almost_equal_floats(alpha, 1):\n        return None\n    elif 0 &lt;= alpha &lt;= 1:\n        return alpha\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: alpha values must be in the range 0 to 1',\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_hsl","title":"parse_hsl","text":"<pre><code>parse_hsl(h, h_units, sat, light, alpha=None)\n</code></pre> <p>Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>str</code> <p>The hue value.</p> required <code>h_units</code> <code>str</code> <p>The unit for hue value.</p> required <code>sat</code> <code>str</code> <p>The saturation value.</p> required <code>light</code> <code>str</code> <p>The lightness value.</p> required <code>alpha</code> <code>float | None</code> <p>Alpha value.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of <code>RGBA</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: float | None = None) -&gt; RGBA:\n\"\"\"\n    Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.\n\n    Args:\n        h: The hue value.\n        h_units: The unit for hue value.\n        sat: The saturation value.\n        light: The lightness value.\n        alpha: Alpha value.\n\n    Returns:\n        An instance of `RGBA`.\n    \"\"\"\n    s_value, l_value = parse_color_value(sat, 100), parse_color_value(light, 100)\n\n    h_value = float(h)\n    if h_units in {None, 'deg'}:\n        h_value = h_value % 360 / 360\n    elif h_units == 'rad':\n        h_value = h_value % rads / rads\n    else:\n        # turns\n        h_value = h_value % 1\n\n    r, g, b = hls_to_rgb(h_value, l_value, s_value)\n    return RGBA(r, g, b, parse_float_alpha(alpha))\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_str","title":"parse_str","text":"<pre><code>parse_str(value)\n</code></pre> <p>Parse a string representing a color to an RGBA tuple.</p> <p>Possible formats for the input string include:</p> <ul> <li>named color, see <code>COLORS_BY_NAME</code></li> <li>hex short eg. <code>&lt;prefix&gt;fff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li>hex long eg. <code>&lt;prefix&gt;ffffff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li><code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code></li> <li><code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code></li> <li><code>transparent</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>A string representing a color.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input string cannot be parsed to an RGBA tuple.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_str(value: str) -&gt; RGBA:\n\"\"\"\n    Parse a string representing a color to an RGBA tuple.\n\n    Possible formats for the input string include:\n\n    * named color, see `COLORS_BY_NAME`\n    * hex short eg. `&lt;prefix&gt;fff` (prefix can be `#`, `0x` or nothing)\n    * hex long eg. `&lt;prefix&gt;ffffff` (prefix can be `#`, `0x` or nothing)\n    * `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)`\n    * `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)`\n    * `transparent`\n\n    Args:\n        value: A string representing a color.\n\n    Returns:\n        An `RGBA` tuple parsed from the input string.\n\n    Raises:\n        ValueError: If the input string cannot be parsed to an RGBA tuple.\n    \"\"\"\n    value_lower = value.lower()\n    try:\n        r, g, b = COLORS_BY_NAME[value_lower]\n    except KeyError:\n        pass\n    else:\n        return ints_to_rgba(r, g, b, None)\n\n    m = re.fullmatch(r_hex_short, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v * 2, 16) for v in rgb)\n        if a:\n            alpha: float | None = int(a * 2, 16) / 255\n        else:\n            alpha = None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_hex_long, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v, 16) for v in rgb)\n        if a:\n            alpha = int(a, 16) / 255\n        else:\n            alpha = None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_rgb, value_lower) or re.fullmatch(r_rgb_v4_style, value_lower)\n    if m:\n        return ints_to_rgba(*m.groups())  # type: ignore\n\n    m = re.fullmatch(r_hsl, value_lower) or re.fullmatch(r_hsl_v4_style, value_lower)\n    if m:\n        return parse_hsl(*m.groups())  # type: ignore\n\n    if value_lower == 'transparent':\n        return RGBA(0, 0, 0, 0)\n\n    raise PydanticCustomError(\n        'color_error',\n        'value is not a valid color: string not recognised as a valid color',\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_tuple","title":"parse_tuple","text":"<pre><code>parse_tuple(value)\n</code></pre> <p>Parse a tuple or list to get RGBA values.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>tuple[Any, ...]</code> <p>A tuple or list.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input tuple.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If tuple is not valid.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_tuple(value: tuple[Any, ...]) -&gt; RGBA:\n\"\"\"Parse a tuple or list to get RGBA values.\n\n    Args:\n        value: A tuple or list.\n\n    Returns:\n        An `RGBA` tuple parsed from the input tuple.\n\n    Raises:\n        PydanticCustomError: If tuple is not valid.\n    \"\"\"\n    if len(value) == 3:\n        r, g, b = (parse_color_value(v) for v in value)\n        return RGBA(r, g, b, None)\n    elif len(value) == 4:\n        r, g, b = (parse_color_value(v) for v in value[:3])\n        return RGBA(r, g, b, parse_float_alpha(value[3]))\n    else:\n        raise PydanticCustomError('color_error', 'value is not a valid color: tuples must have length 3 or 4')\n</code></pre>"},{"location":"api/pydantic_extra_types_country/","title":"pydantic_extra_types.country","text":"<p>Country definitions that are based on the ISO 3166 format Based on: https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes</p>"},{"location":"api/pydantic_extra_types_payment/","title":"pydantic_extra_types.payment","text":""},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber","title":"PaymentCardNumber","text":"<pre><code>PaymentCardNumber(card_number)\n</code></pre> <p>         Bases: <code>str</code></p> <p>Based on: https://en.wikipedia.org/wiki/Payment_card_number</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>def __init__(self, card_number: str):\n    self.validate_digits(card_number)\n\n    card_number = self.validate_luhn_check_digit(card_number)\n\n    self.bin = card_number[:6]\n    self.last4 = card_number[-4:]\n    self.brand = self.validate_brand(card_number)\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate_brand","title":"validate_brand  <code>staticmethod</code>","text":"<pre><code>validate_brand(card_number)\n</code></pre> <p>Validate length based on BIN for major brands: https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN)</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@staticmethod\ndef validate_brand(card_number: str) -&gt; PaymentCardBrand:\n\"\"\"\n    Validate length based on BIN for major brands:\n    https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN)\n    \"\"\"\n    if card_number[0] == '4':\n        brand = PaymentCardBrand.visa\n    elif 51 &lt;= int(card_number[:2]) &lt;= 55:\n        brand = PaymentCardBrand.mastercard\n    elif card_number[:2] in {'34', '37'}:\n        brand = PaymentCardBrand.amex\n    elif 2200 &lt;= int(card_number[:4]) &lt;= 2204:\n        brand = PaymentCardBrand.mir\n    else:\n        brand = PaymentCardBrand.other\n\n    required_length: None | int | str = None\n    if brand in PaymentCardBrand.mastercard:\n        required_length = 16\n        valid = len(card_number) == required_length\n    elif brand == PaymentCardBrand.visa:\n        required_length = '13, 16 or 19'\n        valid = len(card_number) in {13, 16, 19}\n    elif brand == PaymentCardBrand.amex:\n        required_length = 15\n        valid = len(card_number) == required_length\n    elif brand == PaymentCardBrand.mir:\n        required_length = 'in range from 16 to 19'\n        valid = len(card_number) in range(16, 20)\n    else:\n        valid = True\n\n    if not valid:\n        raise PydanticCustomError(\n            'payment_card_number_brand',\n            'Length for a {brand} card must be {required_length}',\n            {'brand': brand, 'required_length': required_length},\n        )\n    return brand\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate_luhn_check_digit","title":"validate_luhn_check_digit  <code>classmethod</code>","text":"<pre><code>validate_luhn_check_digit(card_number)\n</code></pre> <p>Based on: https://en.wikipedia.org/wiki/Luhn_algorithm</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@classmethod\ndef validate_luhn_check_digit(cls, card_number: str) -&gt; str:\n\"\"\"\n    Based on: https://en.wikipedia.org/wiki/Luhn_algorithm\n    \"\"\"\n    sum_ = int(card_number[-1])\n    length = len(card_number)\n    parity = length % 2\n    for i in range(length - 1):\n        digit = int(card_number[i])\n        if i % 2 == parity:\n            digit *= 2\n        if digit &gt; 9:\n            digit -= 9\n        sum_ += digit\n    valid = sum_ % 10 == 0\n    if not valid:\n        raise PydanticCustomError('payment_card_number_luhn', 'Card number is not luhn valid')\n    return card_number\n</code></pre>"},{"location":"api/pydantic_extra_types_phone_numbers/","title":"pydantic_extra_types.phone_numbers","text":""},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumber","title":"PhoneNumber","text":"<p>         Bases: <code>str</code></p> <p>An international phone number</p>"},{"location":"api/pydantic_extra_types_routing_number/","title":"pydantic_extra_types.routing_number","text":""},{"location":"api/pydantic_extra_types_routing_number/#pydantic_extra_types.routing_number.ABARoutingNumber","title":"ABARoutingNumber","text":"<pre><code>ABARoutingNumber(routing_number)\n</code></pre> <p>         Bases: <code>str</code></p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/routing_number.py</code> <pre><code>def __init__(self, routing_number: str):\n    self.validate_digits(routing_number)\n    self._routing_number = self.validate_routing_number(routing_number)\n</code></pre>"},{"location":"api/pydantic_extra_types_routing_number/#pydantic_extra_types.routing_number.ABARoutingNumber.validate_routing_number","title":"validate_routing_number  <code>classmethod</code>","text":"<pre><code>validate_routing_number(routing_number)\n</code></pre> <p>Check digit algorithm for ABA routing transit number. https://en.wikipedia.org/wiki/ABA_routing_transit_number#Check_digit https://www.routingnumber.com/</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/routing_number.py</code> <pre><code>@classmethod\ndef validate_routing_number(cls, routing_number: str) -&gt; str:\n\"\"\"\n    Check digit algorithm for ABA routing transit number.\n    https://en.wikipedia.org/wiki/ABA_routing_transit_number#Check_digit\n    https://www.routingnumber.com/\n    \"\"\"\n    checksum = (\n        3 * (sum(map(int, [routing_number[0], routing_number[3], routing_number[6]])))\n        + 7 * (sum(map(int, [routing_number[1], routing_number[4], routing_number[7]])))\n        + sum(map(int, [routing_number[2], routing_number[5], routing_number[8]]))\n    )\n    if checksum % 10 != 0:\n        raise PydanticCustomError('aba_routing_number', 'Incorrect ABA routing transit number')\n    return routing_number\n</code></pre>"},{"location":"api/pydantic_settings/","title":"pydantic_settings","text":""},{"location":"api/pydantic_settings/#pydantic_settings.BaseSettings","title":"BaseSettings","text":"<pre><code>BaseSettings(\n    __pydantic_self__,\n    _env_file=env_file_sentinel,\n    _env_file_encoding=None,\n    _env_nested_delimiter=None,\n    _secrets_dir=None,\n    **values\n)\n</code></pre> <p>         Bases: <code>BaseModel</code></p> <p>Base class for settings, allowing values to be overridden by environment variables.</p> <p>This is useful in production for secrets you do not wish to save in code, it plays nicely with docker(-compose), Heroku and any 12 factor app design.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/main.py</code> <pre><code>def __init__(\n    __pydantic_self__,\n    _env_file: DotenvType | None = env_file_sentinel,\n    _env_file_encoding: str | None = None,\n    _env_nested_delimiter: str | None = None,\n    _secrets_dir: str | Path | None = None,\n    **values: Any,\n) -&gt; None:\n    # Uses something other than `self` the first arg to allow \"self\" as a settable attribute\n    super().__init__(\n        **__pydantic_self__._settings_build_values(\n            values,\n            _env_file=_env_file,\n            _env_file_encoding=_env_file_encoding,\n            _env_nested_delimiter=_env_nested_delimiter,\n            _secrets_dir=_secrets_dir,\n        )\n    )\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource","title":"EnvSettingsSource","text":"<pre><code>EnvSettingsSource(\n    settings_cls,\n    env_nested_delimiter=None,\n    env_prefix_len=0,\n)\n</code></pre> <p>         Bases: <code>PydanticBaseEnvSettingsSource</code></p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    env_nested_delimiter: str | None = None,\n    env_prefix_len: int = 0,\n):\n    super().__init__(settings_cls)\n\n    self.env_nested_delimiter: str | None = env_nested_delimiter\n    self.env_prefix_len: int = env_prefix_len\n\n    self.env_vars: Mapping[str, str | None] = self._load_env_vars()\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.EnvSettingsSource.explode_env_vars","title":"explode_env_vars","text":"<pre><code>explode_env_vars(field_name, field, env_vars)\n</code></pre> <p>Process env_vars and extract the values of keys containing env_nested_delimiter into nested dictionaries.</p> <p>This is applied to a single field, hence filtering by env_var prefix.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def explode_env_vars(self, field_name: str, field: FieldInfo, env_vars: Mapping[str, str | None]) -&gt; dict[str, Any]:\n\"\"\"\n    Process env_vars and extract the values of keys containing env_nested_delimiter into nested dictionaries.\n\n    This is applied to a single field, hence filtering by env_var prefix.\n    \"\"\"\n    prefixes = [\n        f'{env_name}{self.env_nested_delimiter}' for _, env_name, _ in self._extract_field_info(field, field_name)\n    ]\n    result: dict[str, Any] = {}\n    for env_name, env_val in env_vars.items():\n        if not any(env_name.startswith(prefix) for prefix in prefixes):\n            continue\n        # we remove the prefix before splitting in case the prefix has characters in common with the delimiter\n        env_name_without_prefix = env_name[self.env_prefix_len :]\n        _, *keys, last_key = env_name_without_prefix.split(self.env_nested_delimiter)\n        env_var = result\n        target_field: FieldInfo | None = field\n        for key in keys:\n            target_field = self.next_field(target_field, key)\n            env_var = env_var.setdefault(key, {})\n\n        # get proper field with last_key\n        target_field = self.next_field(target_field, last_key)\n\n        # check if env_val maps to a complex field and if so, parse the env_val\n        if target_field and env_val:\n            is_complex, allow_json_failure = self._field_is_complex(target_field)\n            if is_complex:\n                try:\n                    env_val = json.loads(env_val)\n                except ValueError as e:\n                    if not allow_json_failure:\n                        raise e\n        env_var[last_key] = env_val\n\n    return result\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.EnvSettingsSource.next_field","title":"next_field  <code>staticmethod</code>","text":"<pre><code>next_field(field, key)\n</code></pre> <p>Find the field in a sub model by key(env name)</p> By having the following models <pre><code>class SubSubModel(BaseSettings):\n    dvals: Dict\n\nclass SubModel(BaseSettings):\n    vals: list[str]\n    sub_sub_model: SubSubModel\n\nclass Cfg(BaseSettings):\n    sub_model: SubModel\n</code></pre> Then <p>next_field(sub_model, 'vals') Returns the <code>vals</code> field of <code>SubModel</code> class next_field(sub_model, 'sub_sub_model') Returns <code>sub_sub_model</code> field of <code>SubModel</code> class</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@staticmethod\ndef next_field(field: FieldInfo | None, key: str) -&gt; FieldInfo | None:\n\"\"\"\n    Find the field in a sub model by key(env name)\n\n    By having the following models:\n\n        ```py\n        class SubSubModel(BaseSettings):\n            dvals: Dict\n\n        class SubModel(BaseSettings):\n            vals: list[str]\n            sub_sub_model: SubSubModel\n\n        class Cfg(BaseSettings):\n            sub_model: SubModel\n        ```\n\n    Then:\n        next_field(sub_model, 'vals') Returns the `vals` field of `SubModel` class\n        next_field(sub_model, 'sub_sub_model') Returns `sub_sub_model` field of `SubModel` class\n    \"\"\"\n    if not field or origin_is_union(get_origin(field.annotation)):\n        # no support for Unions of complex BaseSettings fields\n        return None\n    elif field.annotation and hasattr(field.annotation, 'model_fields') and field.annotation.model_fields.get(key):\n        return field.annotation.model_fields[key]\n\n    return None\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource","title":"PydanticBaseSettingsSource","text":"<pre><code>PydanticBaseSettingsSource(settings_cls)\n</code></pre> <p>         Bases: <code>ABC</code></p> <p>Abstract base class for settings sources, every settings source classes should inherit from it.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(self, settings_cls: type[BaseSettings]):\n    self.settings_cls = settings_cls\n    self.config = settings_cls.model_config\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.PydanticBaseSettingsSource.field_is_complex","title":"field_is_complex","text":"<pre><code>field_is_complex(field)\n</code></pre> <p>Checks whether a field is complex, in which case it will attempt to be parsed as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the field is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def field_is_complex(self, field: FieldInfo) -&gt; bool:\n\"\"\"\n    Checks whether a field is complex, in which case it will attempt to be parsed as JSON.\n\n    Args:\n        field (FieldInfo): The field.\n\n    Returns:\n        bool: Whether the field is complex.\n    \"\"\"\n    return _annotation_is_complex(field.annotation)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.PydanticBaseSettingsSource.get_field_value","title":"get_field_value  <code>abstractmethod</code>","text":"<pre><code>get_field_value(field, field_name)\n</code></pre> <p>Gets the value, the key for model creation, and a flag to determine whether value is complex.</p> <p>This is an abstract method that should be overrided in every settings source classes.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>field_name</code> <code>str</code> <p>The field name.</p> required <p>Returns:</p> Type Description <code>tuple[Any, str, bool]</code> <p>tuple[str, Any, bool]: The key, value and a flag to determine whether value is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@abstractmethod\ndef get_field_value(self, field: FieldInfo, field_name: str) -&gt; tuple[Any, str, bool]:\n\"\"\"\n    Gets the value, the key for model creation, and a flag to determine whether value is complex.\n\n    This is an abstract method that should be overrided in every settings source classes.\n\n    Args:\n        field (FieldInfo): The field.\n        field_name (str): The field name.\n\n    Returns:\n        tuple[str, Any, bool]: The key, value and a flag to determine whether value is complex.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.PydanticBaseSettingsSource.prepare_field_value","title":"prepare_field_value","text":"<pre><code>prepare_field_value(\n    field_name, field, value, value_is_complex\n)\n</code></pre> <p>Prepares the value of a field.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field name.</p> required <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>value</code> <code>Any</code> <p>The value of the field that has to be prepared.</p> required <code>value_is_complex</code> <code>bool</code> <p>A flag to determine whether value is complex.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The prepared value.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:\n\"\"\"\n    Prepares the value of a field.\n\n    Args:\n        field_name (str): The field name.\n        field (FieldInfo): The field.\n        value (Any): The value of the field that has to be prepared.\n        value_is_complex: A flag to determine whether value is complex.\n\n    Returns:\n        Any: The prepared value.\n    \"\"\"\n    if self.field_is_complex(field) or value_is_complex:\n        return json.loads(value)\n    return value\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.SecretsSettingsSource","title":"SecretsSettingsSource","text":"<pre><code>SecretsSettingsSource(settings_cls, secrets_dir)\n</code></pre> <p>         Bases: <code>PydanticBaseEnvSettingsSource</code></p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(self, settings_cls: type[BaseSettings], secrets_dir: str | Path | None):\n    self.secrets_dir = secrets_dir\n    super().__init__(settings_cls)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.sources.SecretsSettingsSource.find_case_path","title":"find_case_path  <code>classmethod</code>","text":"<pre><code>find_case_path(dir_path, file_name, case_sensitive)\n</code></pre> <p>Find a file within path's directory matching filename, optionally ignoring case.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@classmethod\ndef find_case_path(cls, dir_path: Path, file_name: str, case_sensitive: bool) -&gt; Path | None:\n\"\"\"\n    Find a file within path's directory matching filename, optionally ignoring case.\n    \"\"\"\n    for f in dir_path.iterdir():\n        if f.name == file_name:\n            return f\n        elif not case_sensitive and f.name.lower() == file_name.lower():\n            return f\n    return None\n</code></pre>"},{"location":"api/root_model/","title":"pydantic.root_model","text":"<p>RootModel class and type definitions.</p>"},{"location":"api/root_model/#pydantic.root_model.RootModel","title":"RootModel","text":"<pre><code>RootModel(__pydantic_self__, root=PydanticUndefined)\n</code></pre> <p>         Bases: <code>BaseModel</code>, <code>typing.Generic[RootModelRootType]</code></p> <p>A Pydantic <code>BaseModel</code> for the root object of the model.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>RootModelRootType</code> <p>The root object of the model.</p> <code>__pydantic_root_model__</code> <p>Whether the model is a RootModel.</p> <code>__pydantic_private__</code> <p>Private fields in the model.</p> <code>__pydantic_extra__</code> <p>Extra fields in the model.</p> Source code in <code>pydantic/root_model.py</code> <pre><code>def __init__(__pydantic_self__, root: RootModelRootType = PydanticUndefined) -&gt; None:  # type: ignore\n    __tracebackhide__ = True\n    __pydantic_self__.__pydantic_validator__.validate_python(root, self_instance=__pydantic_self__)\n</code></pre>"},{"location":"api/root_model/#pydantic.root_model.RootModel.model_construct","title":"model_construct  <code>classmethod</code>","text":"<pre><code>model_construct(root, _fields_set=None)\n</code></pre> <p>Create a new model using the provided root object and update fields set.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>RootModelRootType</code> <p>The root object of the model.</p> required <code>_fields_set</code> <code>set[str] | None</code> <p>The set of fields to be updated.</p> <code>None</code> <p>Returns:</p> Type Description <code>Model</code> <p>The new model.</p> <p>Raises:</p> Type Description <code>NotImplemented</code> <p>If the model is not a subclass of <code>RootModel</code>.</p> Source code in <code>pydantic/root_model.py</code> <pre><code>@classmethod\ndef model_construct(cls: type[Model], root: RootModelRootType, _fields_set: set[str] | None = None) -&gt; Model:\n\"\"\"Create a new model using the provided root object and update fields set.\n\n    Args:\n        root: The root object of the model.\n        _fields_set: The set of fields to be updated.\n\n    Returns:\n        The new model.\n\n    Raises:\n        NotImplemented: If the model is not a subclass of `RootModel`.\n    \"\"\"\n    return super().model_construct(root=root, _fields_set=_fields_set)\n</code></pre>"},{"location":"api/type_adapter/","title":"pydantic.type_adapter","text":"<p>A class representing the type adapter.</p>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter","title":"TypeAdapter","text":"<pre><code>TypeAdapter(type, *, config=None, _parent_depth=2)\n</code></pre> <p>         Bases: <code>Generic[T]</code></p> <p>A class representing the type adapter.</p> <p>A <code>TypeAdapter</code> instance exposes some of the functionality from <code>BaseModel</code> instance methods for types that do not have such methods (such as dataclasses, primitive types, and more).</p> <p>Note that <code>TypeAdapter</code> is not an actual type, so you cannot use it in type annotations.</p> <p>Attributes:</p> Name Type Description <code>core_schema</code> <p>The core schema for the type.</p> <code>validator</code> <p>The schema validator for the type.</p> <code>serializer</code> <p>The schema serializer for the type.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def __init__(self, type: Any, *, config: ConfigDict | None = None, _parent_depth: int = 2) -&gt; None:\n\"\"\"Initializes the TypeAdapter object.\"\"\"\n    config_wrapper = _config.ConfigWrapper(config)\n\n    try:\n        type_has_config = issubclass(type, BaseModel) or is_dataclass(type) or is_typeddict(type)\n    except TypeError:\n        # type is not a class\n        type_has_config = False\n\n    if type_has_config and config is not None:\n        raise PydanticUserError(\n            'Cannot use `config` when the type is a BaseModel, dataclass or TypedDict.'\n            ' These types can have their own config and setting the config via the `config`'\n            ' parameter to TypeAdapter will not override it, thus the `config` you passed to'\n            ' TypeAdapter becomes meaningless, which is probably not what you want.',\n            code='type-adapter-config-unused',\n        )\n\n    core_schema: CoreSchema\n    try:\n        core_schema = _getattr_no_parents(type, '__pydantic_core_schema__')\n    except AttributeError:\n        core_schema = _get_schema(type, config_wrapper, parent_depth=_parent_depth + 1)\n\n    core_schema = _core_utils.flatten_schema_defs(core_schema)\n    simplified_core_schema = _core_utils.inline_schema_defs(core_schema)\n\n    core_config = config_wrapper.core_config(None)\n    validator: SchemaValidator\n    try:\n        validator = _getattr_no_parents(type, '__pydantic_validator__')\n    except AttributeError:\n        validator = SchemaValidator(simplified_core_schema, core_config)\n\n    serializer: SchemaSerializer\n    try:\n        serializer = _getattr_no_parents(type, '__pydantic_serializer__')\n    except AttributeError:\n        serializer = SchemaSerializer(simplified_core_schema, core_config)\n\n    self.core_schema = core_schema\n    self.validator = validator\n    self.serializer = serializer\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.dump_json","title":"dump_json","text":"<pre><code>dump_json(\n    __instance,\n    *,\n    indent=None,\n    include=None,\n    exclude=None,\n    by_alias=False,\n    exclude_unset=False,\n    exclude_defaults=False,\n    exclude_none=False,\n    round_trip=False,\n    warnings=True\n)\n</code></pre> <p>Serialize an instance of the adapted type to JSON.</p> <p>Parameters:</p> Name Type Description Default <code>__instance</code> <code>T</code> <p>The instance to be serialized.</p> required <code>indent</code> <code>int | None</code> <p>Number of spaces for JSON indentation.</p> <code>None</code> <code>include</code> <code>IncEx | None</code> <p>Fields to include.</p> <code>None</code> <code>exclude</code> <code>IncEx | None</code> <p>Fields to exclude.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude unset fields.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields with default values.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields with a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to serialize and deserialize the instance to ensure round-tripping.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to emit serialization warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>bytes</code> <p>The JSON representation of the given instance as bytes.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def dump_json(\n    self,\n    __instance: T,\n    *,\n    indent: int | None = None,\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; bytes:\n\"\"\"Serialize an instance of the adapted type to JSON.\n\n    Args:\n        __instance: The instance to be serialized.\n        indent: Number of spaces for JSON indentation.\n        include: Fields to include.\n        exclude: Fields to exclude.\n        by_alias: Whether to use alias names for field names.\n        exclude_unset: Whether to exclude unset fields.\n        exclude_defaults: Whether to exclude fields with default values.\n        exclude_none: Whether to exclude fields with a value of `None`.\n        round_trip: Whether to serialize and deserialize the instance to ensure round-tripping.\n        warnings: Whether to emit serialization warnings.\n\n    Returns:\n        The JSON representation of the given instance as bytes.\n    \"\"\"\n    return self.serializer.to_json(\n        __instance,\n        indent=indent,\n        include=include,\n        exclude=exclude,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n    )\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.dump_python","title":"dump_python","text":"<pre><code>dump_python(\n    __instance,\n    *,\n    mode=\"python\",\n    include=None,\n    exclude=None,\n    by_alias=False,\n    exclude_unset=False,\n    exclude_defaults=False,\n    exclude_none=False,\n    round_trip=False,\n    warnings=True\n)\n</code></pre> <p>Dump an instance of the adapted type to a Python object.</p> <p>Parameters:</p> Name Type Description Default <code>__instance</code> <code>T</code> <p>The Python object to serialize.</p> required <code>mode</code> <code>Literal['json', 'python']</code> <p>The output format.</p> <code>'python'</code> <code>include</code> <code>IncEx | None</code> <p>Fields to include in the output.</p> <code>None</code> <code>exclude</code> <code>IncEx | None</code> <p>Fields to exclude from the output.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude unset fields.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields with default values.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields with None values.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to output the serialized data in a way that is compatible with deserialization.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to display serialization warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>Any</code> <p>The serialized object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def dump_python(\n    self,\n    __instance: T,\n    *,\n    mode: Literal['json', 'python'] = 'python',\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; Any:\n\"\"\"Dump an instance of the adapted type to a Python object.\n\n    Args:\n        __instance: The Python object to serialize.\n        mode: The output format.\n        include: Fields to include in the output.\n        exclude: Fields to exclude from the output.\n        by_alias: Whether to use alias names for field names.\n        exclude_unset: Whether to exclude unset fields.\n        exclude_defaults: Whether to exclude fields with default values.\n        exclude_none: Whether to exclude fields with None values.\n        round_trip: Whether to output the serialized data in a way that is compatible with deserialization.\n        warnings: Whether to display serialization warnings.\n\n    Returns:\n        The serialized object.\n    \"\"\"\n    return self.serializer.to_python(\n        __instance,\n        mode=mode,\n        by_alias=by_alias,\n        include=include,\n        exclude=exclude,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n    )\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.get_default_value","title":"get_default_value","text":"<pre><code>get_default_value(*, strict=None, context=None)\n</code></pre> <p>Get the default value for the wrapped type.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Some[T] | None</code> <p>The default value wrapped in a <code>Some</code> if there is one or None if not.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def get_default_value(self, *, strict: bool | None = None, context: dict[str, Any] | None = None) -&gt; Some[T] | None:\n\"\"\"Get the default value for the wrapped type.\n\n    Args:\n        strict: Whether to strictly check types.\n        context: Additional context to pass to the validator.\n\n    Returns:\n        The default value wrapped in a `Some` if there is one or None if not.\n    \"\"\"\n    return self.validator.get_default_value(strict=strict, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.json_schema","title":"json_schema","text":"<pre><code>json_schema(\n    *,\n    by_alias=True,\n    ref_template=DEFAULT_REF_TEMPLATE,\n    schema_generator=GenerateJsonSchema,\n    mode=\"validation\"\n)\n</code></pre> <p>Generate a JSON schema for the adapted type.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The format string used for generating $ref strings.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The generator class used for creating the schema.</p> <code>GenerateJsonSchema</code> <code>mode</code> <code>JsonSchemaMode</code> <p>The mode to use for schema generation.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The JSON schema for the model as a dictionary.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def json_schema(\n    self,\n    *,\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n\"\"\"Generate a JSON schema for the adapted type.\n\n    Args:\n        by_alias: Whether to use alias names for field names.\n        ref_template: The format string used for generating $ref strings.\n        schema_generator: The generator class used for creating the schema.\n        mode: The mode to use for schema generation.\n\n    Returns:\n        The JSON schema for the model as a dictionary.\n    \"\"\"\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n    return schema_generator_instance.generate(self.core_schema, mode=mode)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.json_schemas","title":"json_schemas  <code>staticmethod</code>","text":"<pre><code>json_schemas(\n    __inputs,\n    *,\n    by_alias=True,\n    title=None,\n    description=None,\n    ref_template=DEFAULT_REF_TEMPLATE,\n    schema_generator=GenerateJsonSchema\n)\n</code></pre> <p>Generate a JSON schema including definitions from multiple type adapters.</p> <p>Parameters:</p> Name Type Description Default <code>__inputs</code> <code>Iterable[tuple[JsonSchemaKeyT, JsonSchemaMode, TypeAdapter[Any]]]</code> <p>Inputs to schema generation. The first two items will form the keys of the (first) output mapping; the type adapters will provide the core schemas that get converted into definitions in the output JSON schema.</p> required <code>by_alias</code> <code>bool</code> <p>Whether to use alias names.</p> <code>True</code> <code>title</code> <code>str | None</code> <p>The title for the schema.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>The description for the schema.</p> <code>None</code> <code>ref_template</code> <code>str</code> <p>The format string used for generating $ref strings.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The generator class used for creating the schema.</p> <code>GenerateJsonSchema</code> <p>Returns:</p> Type Description <code>tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef], JsonSchemaValue]</code> <p>The first item contains the mapping of key + mode to a definitions reference, which will be a key of the $defs mapping in the JSON schema included as the second member of the returned tuple.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@staticmethod\ndef json_schemas(\n    __inputs: Iterable[tuple[JsonSchemaKeyT, JsonSchemaMode, TypeAdapter[Any]]],\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n) -&gt; tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef], JsonSchemaValue]:\n\"\"\"Generate a JSON schema including definitions from multiple type adapters.\n\n    Args:\n        __inputs: Inputs to schema generation. The first two items will form the keys of the (first)\n            output mapping; the type adapters will provide the core schemas that get converted into\n            definitions in the output JSON schema.\n        by_alias: Whether to use alias names.\n        title: The title for the schema.\n        description: The description for the schema.\n        ref_template: The format string used for generating $ref strings.\n        schema_generator: The generator class used for creating the schema.\n\n    Returns:\n        The first item contains the mapping of key + mode to a definitions reference, which will be a key\n            of the $defs mapping in the JSON schema included as the second member of the returned tuple.\n    \"\"\"\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n\n    inputs = [(key, mode, adapter.core_schema) for key, mode, adapter in __inputs]\n\n    key_map, definitions = schema_generator_instance.generate_definitions(inputs)\n\n    json_schema: dict[str, Any] = {}\n    if definitions:\n        json_schema['$defs'] = definitions\n    if title:\n        json_schema['title'] = title\n    if description:\n        json_schema['description'] = description\n\n    return key_map, json_schema\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_json","title":"validate_json","text":"<pre><code>validate_json(__data, *, strict=None, context=None)\n</code></pre> <p>Validate a JSON string or bytes against the model.</p> <p>Parameters:</p> Name Type Description Default <code>__data</code> <code>str | bytes</code> <p>The JSON data to validate against the model.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to use during validation.</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>The validated object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def validate_json(\n    self, __data: str | bytes, *, strict: bool | None = None, context: dict[str, Any] | None = None\n) -&gt; T:\n\"\"\"Validate a JSON string or bytes against the model.\n\n    Args:\n        __data: The JSON data to validate against the model.\n        strict: Whether to strictly check types.\n        context: Additional context to use during validation.\n\n    Returns:\n        The validated object.\n    \"\"\"\n    return self.validator.validate_json(__data, strict=strict, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_python","title":"validate_python","text":"<pre><code>validate_python(\n    __object,\n    *,\n    strict=None,\n    from_attributes=None,\n    context=None\n)\n</code></pre> <p>Validate a Python object against the model.</p> <p>Parameters:</p> Name Type Description Default <code>__object</code> <code>Any</code> <p>The Python object to validate against the model.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to extract data from object attributes.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>The validated object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def validate_python(\n    self,\n    __object: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; T:\n\"\"\"Validate a Python object against the model.\n\n    Args:\n        __object: The Python object to validate against the model.\n        strict: Whether to strictly check types.\n        from_attributes: Whether to extract data from object attributes.\n        context: Additional context to pass to the validator.\n\n    Returns:\n        The validated object.\n    \"\"\"\n    return self.validator.validate_python(__object, strict=strict, from_attributes=from_attributes, context=context)\n</code></pre>"},{"location":"api/types/","title":"pydantic.types","text":"<p>The types module contains custom types used by pydantic.</p>"},{"location":"api/types/#pydantic.types.DirectoryPath","title":"DirectoryPath  <code>module-attribute</code>","text":"<pre><code>DirectoryPath = Annotated[Path, PathType('dir')]\n</code></pre> <p>A path that must point to a directory.</p>"},{"location":"api/types/#pydantic.types.FilePath","title":"FilePath  <code>module-attribute</code>","text":"<pre><code>FilePath = Annotated[Path, PathType('file')]\n</code></pre> <p>A path that must point to a file.</p>"},{"location":"api/types/#pydantic.types.FiniteFloat","title":"FiniteFloat  <code>module-attribute</code>","text":"<pre><code>FiniteFloat = Annotated[float, AllowInfNan(False)]\n</code></pre> <p>A float that must be finite (not <code>-inf</code>, <code>inf</code>, or <code>nan</code>).</p>"},{"location":"api/types/#pydantic.types.NegativeFloat","title":"NegativeFloat  <code>module-attribute</code>","text":"<pre><code>NegativeFloat = Annotated[float, annotated_types.Lt(0)]\n</code></pre> <p>A float that must be less than zero.</p>"},{"location":"api/types/#pydantic.types.NegativeInt","title":"NegativeInt  <code>module-attribute</code>","text":"<pre><code>NegativeInt = Annotated[int, annotated_types.Lt(0)]\n</code></pre> <p>An integer that must be less than zero.</p>"},{"location":"api/types/#pydantic.types.NewPath","title":"NewPath  <code>module-attribute</code>","text":"<pre><code>NewPath = Annotated[Path, PathType('new')]\n</code></pre> <p>A path for a new file or directory that must not already exist.</p>"},{"location":"api/types/#pydantic.types.NonNegativeFloat","title":"NonNegativeFloat  <code>module-attribute</code>","text":"<pre><code>NonNegativeFloat = Annotated[float, annotated_types.Ge(0)]\n</code></pre> <p>A float that must be greater than or equal to zero.</p>"},{"location":"api/types/#pydantic.types.NonNegativeInt","title":"NonNegativeInt  <code>module-attribute</code>","text":"<pre><code>NonNegativeInt = Annotated[int, annotated_types.Ge(0)]\n</code></pre> <p>An integer that must be greater than or equal to zero.</p>"},{"location":"api/types/#pydantic.types.NonPositiveFloat","title":"NonPositiveFloat  <code>module-attribute</code>","text":"<pre><code>NonPositiveFloat = Annotated[float, annotated_types.Le(0)]\n</code></pre> <p>A float that must be less than or equal to zero.</p>"},{"location":"api/types/#pydantic.types.NonPositiveInt","title":"NonPositiveInt  <code>module-attribute</code>","text":"<pre><code>NonPositiveInt = Annotated[int, annotated_types.Le(0)]\n</code></pre> <p>An integer that must be less than or equal to zero.</p>"},{"location":"api/types/#pydantic.types.PositiveFloat","title":"PositiveFloat  <code>module-attribute</code>","text":"<pre><code>PositiveFloat = Annotated[float, annotated_types.Gt(0)]\n</code></pre> <p>A float that must be greater than zero.</p>"},{"location":"api/types/#pydantic.types.PositiveInt","title":"PositiveInt  <code>module-attribute</code>","text":"<pre><code>PositiveInt = Annotated[int, annotated_types.Gt(0)]\n</code></pre> <p>An integer that must be greater than zero.</p>"},{"location":"api/types/#pydantic.types.StrictBool","title":"StrictBool  <code>module-attribute</code>","text":"<pre><code>StrictBool = Annotated[bool, Strict()]\n</code></pre> <p>A boolean that must be either <code>True</code> or <code>False</code>.</p>"},{"location":"api/types/#pydantic.types.StrictBytes","title":"StrictBytes  <code>module-attribute</code>","text":"<pre><code>StrictBytes = Annotated[bytes, Strict()]\n</code></pre> <p>A bytes that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.StrictFloat","title":"StrictFloat  <code>module-attribute</code>","text":"<pre><code>StrictFloat = Annotated[float, Strict(True)]\n</code></pre> <p>A float that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.StrictInt","title":"StrictInt  <code>module-attribute</code>","text":"<pre><code>StrictInt = Annotated[int, Strict()]\n</code></pre> <p>An integer that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.StrictStr","title":"StrictStr  <code>module-attribute</code>","text":"<pre><code>StrictStr = Annotated[str, Strict()]\n</code></pre> <p>A string that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.UUID1","title":"UUID1  <code>module-attribute</code>","text":"<pre><code>UUID1 = Annotated[UUID, UuidVersion(1)]\n</code></pre> <p>A UUID1 annotated type.</p>"},{"location":"api/types/#pydantic.types.UUID3","title":"UUID3  <code>module-attribute</code>","text":"<pre><code>UUID3 = Annotated[UUID, UuidVersion(3)]\n</code></pre> <p>A UUID3 annotated type.</p>"},{"location":"api/types/#pydantic.types.UUID4","title":"UUID4  <code>module-attribute</code>","text":"<pre><code>UUID4 = Annotated[UUID, UuidVersion(4)]\n</code></pre> <p>A UUID4 annotated type.</p>"},{"location":"api/types/#pydantic.types.UUID5","title":"UUID5  <code>module-attribute</code>","text":"<pre><code>UUID5 = Annotated[UUID, UuidVersion(5)]\n</code></pre> <p>A UUID5 annotated type.</p>"},{"location":"api/types/#pydantic.types.AllowInfNan","title":"AllowInfNan  <code>dataclass</code>","text":"<p>         Bases: <code>_fields.PydanticMetadata</code></p> <p>A field metadata class to indicate that a field should allow <code>-inf</code>, <code>inf</code>, and <code>nan</code>.</p>"},{"location":"api/types/#pydantic.types.AwareDatetime","title":"AwareDatetime","text":"<p>A datetime that requires timezone info.</p>"},{"location":"api/types/#pydantic.types.Base64Encoder","title":"Base64Encoder","text":"<p>         Bases: <code>EncoderProtocol</code></p> <p>Base64 encoder.</p>"},{"location":"api/types/#pydantic.types.Base64Encoder.decode","title":"decode  <code>classmethod</code>","text":"<pre><code>decode(data)\n</code></pre> <p>Decode the data from base64 encoded bytes to original bytes data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The data to decode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The decoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef decode(cls, data: bytes) -&gt; bytes:\n\"\"\"Decode the data from base64 encoded bytes to original bytes data.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    try:\n        return base64.decodebytes(data)\n    except ValueError as e:\n        raise PydanticCustomError('base64_decode', \"Base64 decoding error: '{error}'\", {'error': str(e)})\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64Encoder.encode","title":"encode  <code>classmethod</code>","text":"<pre><code>encode(value)\n</code></pre> <p>Encode the data from bytes to a base64 encoded bytes.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bytes</code> <p>The data to encode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef encode(cls, value: bytes) -&gt; bytes:\n\"\"\"Encode the data from bytes to a base64 encoded bytes.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return base64.encodebytes(value)\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64Encoder.get_json_format","title":"get_json_format  <code>classmethod</code>","text":"<pre><code>get_json_format()\n</code></pre> <p>Get the JSON format for the encoded data.</p> <p>Returns:</p> Type Description <code>Literal['base64']</code> <p>The JSON format for the encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef get_json_format(cls) -&gt; Literal['base64']:\n\"\"\"Get the JSON format for the encoded data.\n\n    Returns:\n        The JSON format for the encoded data.\n    \"\"\"\n    return 'base64'\n</code></pre>"},{"location":"api/types/#pydantic.types.ByteSize","title":"ByteSize","text":"<p>         Bases: <code>int</code></p> <p>Converts a bytes string with units to the number of bytes.</p>"},{"location":"api/types/#pydantic.types.ByteSize.human_readable","title":"human_readable","text":"<pre><code>human_readable(decimal=False)\n</code></pre> <p>Converts a byte size to a human readable string.</p> <p>Parameters:</p> Name Type Description Default <code>decimal</code> <code>bool</code> <p>If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units (e.g. 1024 bytes per KiB).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A human readable string representation of the byte size.</p> Source code in <code>pydantic/types.py</code> <pre><code>def human_readable(self, decimal: bool = False) -&gt; str:\n\"\"\"Converts a byte size to a human readable string.\n\n    Args:\n        decimal: If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units\n            (e.g. 1024 bytes per KiB).\n\n    Returns:\n        A human readable string representation of the byte size.\n    \"\"\"\n    if decimal:\n        divisor = 1000\n        units = 'B', 'KB', 'MB', 'GB', 'TB', 'PB'\n        final_unit = 'EB'\n    else:\n        divisor = 1024\n        units = 'B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB'\n        final_unit = 'EiB'\n\n    num = float(self)\n    for unit in units:\n        if abs(num) &lt; divisor:\n            if unit == 'B':\n                return f'{num:0.0f}{unit}'\n            else:\n                return f'{num:0.1f}{unit}'\n        num /= divisor\n\n    return f'{num:0.1f}{final_unit}'\n</code></pre>"},{"location":"api/types/#pydantic.types.ByteSize.to","title":"to","text":"<pre><code>to(unit)\n</code></pre> <p>Converts a byte size to another unit.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>str</code> <p>The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EiB, KiB, MiB, GiB, TiB, PiB, EiB.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The byte size in the new unit.</p> Source code in <code>pydantic/types.py</code> <pre><code>def to(self, unit: str) -&gt; float:\n\"\"\"Converts a byte size to another unit.\n\n    Args:\n        unit: The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EiB,\n            KiB, MiB, GiB, TiB, PiB, EiB.\n\n    Returns:\n        The byte size in the new unit.\n    \"\"\"\n    try:\n        unit_div = BYTE_SIZES[unit.lower()]\n    except KeyError:\n        raise PydanticCustomError('byte_size_unit', 'Could not interpret byte unit: {unit}', {'unit': unit})\n\n    return self / unit_div\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedBytes","title":"EncodedBytes","text":"<p>A bytes type that is encoded and decoded using the specified encoder.</p>"},{"location":"api/types/#pydantic.types.EncodedBytes.decode","title":"decode","text":"<pre><code>decode(data, _)\n</code></pre> <p>Decode the data using the specified encoder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The data to decode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The decoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>def decode(self, data: bytes, _: core_schema.ValidationInfo) -&gt; bytes:\n\"\"\"Decode the data using the specified encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    return self.encoder.decode(data)\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedBytes.encode","title":"encode","text":"<pre><code>encode(value)\n</code></pre> <p>Encode the data using the specified encoder.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bytes</code> <p>The data to encode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>def encode(self, value: bytes) -&gt; bytes:\n\"\"\"Encode the data using the specified encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return self.encoder.encode(value)\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedStr","title":"EncodedStr","text":"<p>         Bases: <code>EncodedBytes</code></p> <p>A str type that is encoded and decoded using the specified encoder.</p>"},{"location":"api/types/#pydantic.types.EncodedStr.decode_str","title":"decode_str","text":"<pre><code>decode_str(data, _)\n</code></pre> <p>Decode the data using the specified encoder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The data to decode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The decoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>def decode_str(self, data: bytes, _: core_schema.ValidationInfo) -&gt; str:\n\"\"\"Decode the data using the specified encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    return data.decode()\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedStr.encode_str","title":"encode_str","text":"<pre><code>encode_str(value)\n</code></pre> <p>Encode the data using the specified encoder.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The data to encode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>def encode_str(self, value: str) -&gt; str:\n\"\"\"Encode the data using the specified encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return super().encode(value=value.encode()).decode()\n</code></pre>"},{"location":"api/types/#pydantic.types.EncoderProtocol","title":"EncoderProtocol","text":"<p>         Bases: <code>Protocol</code></p> <p>Protocol for encoding and decoding data to and from bytes.</p>"},{"location":"api/types/#pydantic.types.EncoderProtocol.decode","title":"decode  <code>classmethod</code>","text":"<pre><code>decode(data)\n</code></pre> <p>Decode the data using the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>The data to decode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The decoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef decode(cls, data: bytes) -&gt; bytes:\n\"\"\"Decode the data using the encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/types/#pydantic.types.EncoderProtocol.encode","title":"encode  <code>classmethod</code>","text":"<pre><code>encode(value)\n</code></pre> <p>Encode the data using the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bytes</code> <p>The data to encode.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef encode(cls, value: bytes) -&gt; bytes:\n\"\"\"Encode the data using the encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/types/#pydantic.types.EncoderProtocol.get_json_format","title":"get_json_format  <code>classmethod</code>","text":"<pre><code>get_json_format()\n</code></pre> <p>Get the JSON format for the encoded data.</p> <p>Returns:</p> Type Description <code>str</code> <p>The JSON format for the encoded data.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef get_json_format(cls) -&gt; str:\n\"\"\"Get the JSON format for the encoded data.\n\n    Returns:\n        The JSON format for the encoded data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/types/#pydantic.types.FutureDate","title":"FutureDate","text":"<p>A date in the future.</p>"},{"location":"api/types/#pydantic.types.FutureDatetime","title":"FutureDatetime","text":"<p>A datetime that must be in the future.</p>"},{"location":"api/types/#pydantic.types.ImportString","title":"ImportString","text":"<p>A type that can be used to import a type from a string.</p> Example <pre><code>from datetime import date\nfrom typing import Type\n\nfrom pydantic import BaseModel, ImportString\n\n\nclass Foo(BaseModel):\n    call_date: ImportString[Type[date]]\n\n\nfoo = Foo(call_date=\"datetime.date\")\nassert foo.call_date(2021, 1, 1) == date(2021, 1, 1)\n</code></pre>"},{"location":"api/types/#pydantic.types.Json","title":"Json","text":"<p>A special type wrapper which loads JSON before parsing.</p>"},{"location":"api/types/#pydantic.types.NaiveDatetime","title":"NaiveDatetime","text":"<p>A datetime that doesn't require timezone info.</p>"},{"location":"api/types/#pydantic.types.PastDate","title":"PastDate","text":"<p>A date in the past.</p>"},{"location":"api/types/#pydantic.types.PastDatetime","title":"PastDatetime","text":"<p>A datetime that must be in the past.</p>"},{"location":"api/types/#pydantic.types.PaymentCardNumber","title":"PaymentCardNumber","text":"<pre><code>PaymentCardNumber(card_number)\n</code></pre> <p>         Bases: <code>str</code></p> <p>Based on: https://en.wikipedia.org/wiki/Payment_card_number.</p> Source code in <code>pydantic/types.py</code> <pre><code>def __init__(self, card_number: str):\n    self.validate_digits(card_number)\n\n    card_number = self.validate_luhn_check_digit(card_number)\n\n    self.bin = card_number[:6]\n    self.last4 = card_number[-4:]\n    self.brand = self.validate_brand(card_number)\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.masked","title":"masked  <code>property</code>","text":"<pre><code>masked: str\n</code></pre> <p>Mask all but the last 4 digits of the card number.</p> <p>Returns:</p> Type Description <code>str</code> <p>A masked card number string.</p>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate","title":"validate  <code>classmethod</code>","text":"<pre><code>validate(__input_value, _)\n</code></pre> <p>Validate the card number and return a <code>PaymentCardNumber</code> instance.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate(cls, __input_value: str, _: core_schema.ValidationInfo) -&gt; PaymentCardNumber:\n\"\"\"Validate the card number and return a `PaymentCardNumber` instance.\"\"\"\n    return cls(__input_value)\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_brand","title":"validate_brand  <code>staticmethod</code>","text":"<pre><code>validate_brand(card_number)\n</code></pre> <p>Validate length based on BIN for major brands: https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN).</p> Source code in <code>pydantic/types.py</code> <pre><code>@staticmethod\ndef validate_brand(card_number: str) -&gt; PaymentCardBrand:\n\"\"\"Validate length based on BIN for major brands:\n    https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN).\n    \"\"\"\n    if card_number[0] == '4':\n        brand = PaymentCardBrand.visa\n    elif 51 &lt;= int(card_number[:2]) &lt;= 55:\n        brand = PaymentCardBrand.mastercard\n    elif card_number[:2] in {'34', '37'}:\n        brand = PaymentCardBrand.amex\n    else:\n        brand = PaymentCardBrand.other\n\n    required_length: None | int | str = None\n    if brand in PaymentCardBrand.mastercard:\n        required_length = 16\n        valid = len(card_number) == required_length\n    elif brand == PaymentCardBrand.visa:\n        required_length = '13, 16 or 19'\n        valid = len(card_number) in {13, 16, 19}\n    elif brand == PaymentCardBrand.amex:\n        required_length = 15\n        valid = len(card_number) == required_length\n    else:\n        valid = True\n\n    if not valid:\n        raise PydanticCustomError(\n            'payment_card_number_brand',\n            'Length for a {brand} card must be {required_length}',\n            {'brand': brand, 'required_length': required_length},\n        )\n    return brand\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_digits","title":"validate_digits  <code>classmethod</code>","text":"<pre><code>validate_digits(card_number)\n</code></pre> <p>Validate that the card number is all digits.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate_digits(cls, card_number: str) -&gt; None:\n\"\"\"Validate that the card number is all digits.\"\"\"\n    if not card_number.isdigit():\n        raise PydanticCustomError('payment_card_number_digits', 'Card number is not all digits')\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_luhn_check_digit","title":"validate_luhn_check_digit  <code>classmethod</code>","text":"<pre><code>validate_luhn_check_digit(card_number)\n</code></pre> <p>Based on: https://en.wikipedia.org/wiki/Luhn_algorithm.</p> Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate_luhn_check_digit(cls, card_number: str) -&gt; str:\n\"\"\"Based on: https://en.wikipedia.org/wiki/Luhn_algorithm.\"\"\"\n    sum_ = int(card_number[-1])\n    length = len(card_number)\n    parity = length % 2\n    for i in range(length - 1):\n        digit = int(card_number[i])\n        if i % 2 == parity:\n            digit *= 2\n        if digit &gt; 9:\n            digit -= 9\n        sum_ += digit\n    valid = sum_ % 10 == 0\n    if not valid:\n        raise PydanticCustomError('payment_card_number_luhn', 'Card number is not luhn valid')\n    return card_number\n</code></pre>"},{"location":"api/types/#pydantic.types.SecretBytes","title":"SecretBytes","text":"<p>         Bases: <code>_SecretField[bytes]</code></p> <p>A bytes that is displayed as <code>**********</code> in reprs and can be used for passwords.</p>"},{"location":"api/types/#pydantic.types.SecretStr","title":"SecretStr","text":"<p>         Bases: <code>_SecretField[str]</code></p> <p>A string that is displayed as <code>**********</code> in reprs and can be used for passwords.</p> Example <pre><code>from pydantic import BaseModel, SecretStr\n\nclass User(BaseModel):\n    username: str\n    password: SecretStr\n\nuser = User(username='scolvin', password='password1')\n\nprint(user)\n#&gt; username='scolvin' password=SecretStr('**********')\nprint(user.password.get_secret_value())\n#&gt; password1\n</code></pre>"},{"location":"api/types/#pydantic.types.Strict","title":"Strict  <code>dataclass</code>","text":"<p>         Bases: <code>_fields.PydanticMetadata</code></p> <p>A field metadata class to indicate that a field should be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.TransformSchema","title":"TransformSchema","text":"<p>An annotation that can be used to apply a transform to a core schema.</p>"},{"location":"api/types/#pydantic.types.conbytes","title":"conbytes","text":"<pre><code>conbytes(*, min_length=None, max_length=None, strict=None)\n</code></pre> <p>A wrapper around <code>bytes</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>min_length</code> <code>int | None</code> <p>The minimum length of the bytes.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the bytes.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to validate the bytes in strict mode.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[bytes]</code> <p>The wrapped bytes type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conbytes(\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n) -&gt; type[bytes]:\n\"\"\"A wrapper around `bytes` that allows for additional constraints.\n\n    Args:\n        min_length: The minimum length of the bytes.\n        max_length: The maximum length of the bytes.\n        strict: Whether to validate the bytes in strict mode.\n\n    Returns:\n        The wrapped bytes type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        bytes,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Len(min_length or 0, max_length),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.condate","title":"condate","text":"<pre><code>condate(*, strict=None, gt=None, ge=None, lt=None, le=None)\n</code></pre> <p>A wrapper for date that adds constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the date value in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>date | None</code> <p>The value must be greater than this. Defaults to <code>None</code>.</p> <code>None</code> <code>ge</code> <code>date | None</code> <p>The value must be greater than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>lt</code> <code>date | None</code> <p>The value must be less than this. Defaults to <code>None</code>.</p> <code>None</code> <code>le</code> <code>date | None</code> <p>The value must be less than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[date]</code> <p>A date type with the specified constraints.</p> Source code in <code>pydantic/types.py</code> <pre><code>def condate(\n    *,\n    strict: bool | None = None,\n    gt: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    le: date | None = None,\n) -&gt; type[date]:\n\"\"\"A wrapper for date that adds constraints.\n\n    Args:\n        strict: Whether to validate the date value in strict mode. Defaults to `None`.\n        gt: The value must be greater than this. Defaults to `None`.\n        ge: The value must be greater than or equal to this. Defaults to `None`.\n        lt: The value must be less than this. Defaults to `None`.\n        le: The value must be less than or equal to this. Defaults to `None`.\n\n    Returns:\n        A date type with the specified constraints.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        date,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.condecimal","title":"condecimal","text":"<pre><code>condecimal(\n    *,\n    strict=None,\n    gt=None,\n    ge=None,\n    lt=None,\n    le=None,\n    multiple_of=None,\n    max_digits=None,\n    decimal_places=None,\n    allow_inf_nan=None\n)\n</code></pre> <p>A wrapper around Decimal that adds validation.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the value in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>int | Decimal | None</code> <p>The value must be greater than this. Defaults to <code>None</code>.</p> <code>None</code> <code>ge</code> <code>int | Decimal | None</code> <p>The value must be greater than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>lt</code> <code>int | Decimal | None</code> <p>The value must be less than this. Defaults to <code>None</code>.</p> <code>None</code> <code>le</code> <code>int | Decimal | None</code> <p>The value must be less than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>multiple_of</code> <code>int | Decimal | None</code> <p>The value must be a multiple of this. Defaults to <code>None</code>.</p> <code>None</code> <code>max_digits</code> <code>int | None</code> <p>The maximum number of digits. Defaults to <code>None</code>.</p> <code>None</code> <code>decimal_places</code> <code>int | None</code> <p>The number of decimal places. Defaults to <code>None</code>.</p> <code>None</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow infinity and NaN. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>pydantic/types.py</code> <pre><code>def condecimal(\n    *,\n    strict: bool | None = None,\n    gt: int | Decimal | None = None,\n    ge: int | Decimal | None = None,\n    lt: int | Decimal | None = None,\n    le: int | Decimal | None = None,\n    multiple_of: int | Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    allow_inf_nan: bool | None = None,\n) -&gt; type[Decimal]:\n\"\"\"A wrapper around Decimal that adds validation.\n\n    Args:\n        strict: Whether to validate the value in strict mode. Defaults to `None`.\n        gt: The value must be greater than this. Defaults to `None`.\n        ge: The value must be greater than or equal to this. Defaults to `None`.\n        lt: The value must be less than this. Defaults to `None`.\n        le: The value must be less than or equal to this. Defaults to `None`.\n        multiple_of: The value must be a multiple of this. Defaults to `None`.\n        max_digits: The maximum number of digits. Defaults to `None`.\n        decimal_places: The number of decimal places. Defaults to `None`.\n        allow_inf_nan: Whether to allow infinity and NaN. Defaults to `None`.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        Decimal,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n        _fields.PydanticGeneralMetadata(max_digits=max_digits, decimal_places=decimal_places),\n        AllowInfNan(allow_inf_nan) if allow_inf_nan is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.confloat","title":"confloat","text":"<pre><code>confloat(\n    *,\n    strict=None,\n    gt=None,\n    ge=None,\n    lt=None,\n    le=None,\n    multiple_of=None,\n    allow_inf_nan=None\n)\n</code></pre> <p>A wrapper around <code>float</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the float in strict mode.</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>The value must be greater than this.</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>The value must be greater than or equal to this.</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>The value must be less than this.</p> <code>None</code> <code>le</code> <code>float | None</code> <p>The value must be less than or equal to this.</p> <code>None</code> <code>multiple_of</code> <code>float | None</code> <p>The value must be a multiple of this.</p> <code>None</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow <code>-inf</code>, <code>inf</code>, and <code>nan</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[float]</code> <p>The wrapped float type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def confloat(\n    *,\n    strict: bool | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    multiple_of: float | None = None,\n    allow_inf_nan: bool | None = None,\n) -&gt; type[float]:\n\"\"\"A wrapper around `float` that allows for additional constraints.\n\n    Args:\n        strict: Whether to validate the float in strict mode.\n        gt: The value must be greater than this.\n        ge: The value must be greater than or equal to this.\n        lt: The value must be less than this.\n        le: The value must be less than or equal to this.\n        multiple_of: The value must be a multiple of this.\n        allow_inf_nan: Whether to allow `-inf`, `inf`, and `nan`.\n\n    Returns:\n        The wrapped float type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        float,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n        AllowInfNan(allow_inf_nan) if allow_inf_nan is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.confrozenset","title":"confrozenset","text":"<pre><code>confrozenset(\n    item_type, *, min_length=None, max_length=None\n)\n</code></pre> <p>A wrapper around <code>typing.FrozenSet</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[HashableItemType]</code> <p>The type of the items in the frozenset.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the frozenset.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the frozenset.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[frozenset[HashableItemType]]</code> <p>The wrapped frozenset type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def confrozenset(\n    item_type: type[HashableItemType], *, min_length: int | None = None, max_length: int | None = None\n) -&gt; type[frozenset[HashableItemType]]:\n\"\"\"A wrapper around `typing.FrozenSet` that allows for additional constraints.\n\n    Args:\n        item_type: The type of the items in the frozenset.\n        min_length: The minimum length of the frozenset.\n        max_length: The maximum length of the frozenset.\n\n    Returns:\n        The wrapped frozenset type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        FrozenSet[item_type],  # type: ignore[valid-type]\n        annotated_types.Len(min_length or 0, max_length),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.conint","title":"conint","text":"<pre><code>conint(\n    *,\n    strict=None,\n    gt=None,\n    ge=None,\n    lt=None,\n    le=None,\n    multiple_of=None\n)\n</code></pre> <p>A wrapper around <code>int</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the integer in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>int | None</code> <p>The value must be greater than this.</p> <code>None</code> <code>ge</code> <code>int | None</code> <p>The value must be greater than or equal to this.</p> <code>None</code> <code>lt</code> <code>int | None</code> <p>The value must be less than this.</p> <code>None</code> <code>le</code> <code>int | None</code> <p>The value must be less than or equal to this.</p> <code>None</code> <code>multiple_of</code> <code>int | None</code> <p>The value must be a multiple of this.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[int]</code> <p>The wrapped integer type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conint(\n    *,\n    strict: bool | None = None,\n    gt: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    le: int | None = None,\n    multiple_of: int | None = None,\n) -&gt; type[int]:\n\"\"\"A wrapper around `int` that allows for additional constraints.\n\n    Args:\n        strict: Whether to validate the integer in strict mode. Defaults to `None`.\n        gt: The value must be greater than this.\n        ge: The value must be greater than or equal to this.\n        lt: The value must be less than this.\n        le: The value must be less than or equal to this.\n        multiple_of: The value must be a multiple of this.\n\n    Returns:\n        The wrapped integer type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        int,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.conlist","title":"conlist","text":"<pre><code>conlist(\n    item_type,\n    *,\n    min_length=None,\n    max_length=None,\n    unique_items=None\n)\n</code></pre> <p>A wrapper around typing.List that adds validation.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[AnyItemType]</code> <p>The type of the items in the list.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the list. Defaults to None.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the list. Defaults to None.</p> <code>None</code> <code>unique_items</code> <code>bool | None</code> <p>Whether the items in the list must be unique. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[list[AnyItemType]]</code> <p>The wrapped list type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conlist(\n    item_type: type[AnyItemType],\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    unique_items: bool | None = None,\n) -&gt; type[list[AnyItemType]]:\n\"\"\"A wrapper around typing.List that adds validation.\n\n    Args:\n        item_type: The type of the items in the list.\n        min_length: The minimum length of the list. Defaults to None.\n        max_length: The maximum length of the list. Defaults to None.\n        unique_items: Whether the items in the list must be unique. Defaults to None.\n\n    Returns:\n        The wrapped list type.\n    \"\"\"\n    if unique_items is not None:\n        raise PydanticUserError(\n            (\n                '`unique_items` is removed, use `Set` instead'\n                '(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)'\n            ),\n            code='removed-kwargs',\n        )\n    return Annotated[  # type: ignore[return-value]\n        List[item_type],  # type: ignore[valid-type]\n        annotated_types.Len(min_length or 0, max_length),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.conset","title":"conset","text":"<pre><code>conset(item_type, *, min_length=None, max_length=None)\n</code></pre> <p>A wrapper around <code>typing.Set</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[HashableItemType]</code> <p>The type of the items in the set.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the set.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the set.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[set[HashableItemType]]</code> <p>The wrapped set type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conset(\n    item_type: type[HashableItemType], *, min_length: int | None = None, max_length: int | None = None\n) -&gt; type[set[HashableItemType]]:\n\"\"\"A wrapper around `typing.Set` that allows for additional constraints.\n\n    Args:\n        item_type: The type of the items in the set.\n        min_length: The minimum length of the set.\n        max_length: The maximum length of the set.\n\n    Returns:\n        The wrapped set type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        Set[item_type], annotated_types.Len(min_length or 0, max_length)  # type: ignore[valid-type]\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.constr","title":"constr","text":"<pre><code>constr(\n    *,\n    strip_whitespace=None,\n    to_upper=None,\n    to_lower=None,\n    strict=None,\n    min_length=None,\n    max_length=None,\n    pattern=None\n)\n</code></pre> <p>A wrapper around <code>str</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strip_whitespace</code> <code>bool | None</code> <p>Whether to strip whitespace from the string.</p> <code>None</code> <code>to_upper</code> <code>bool | None</code> <p>Whether to convert the string to uppercase.</p> <code>None</code> <code>to_lower</code> <code>bool | None</code> <p>Whether to convert the string to lowercase.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to validate the string in strict mode.</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The minimum length of the string.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the string.</p> <code>None</code> <code>pattern</code> <code>str | None</code> <p>A regex pattern that the string must match.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[str]</code> <p>The wrapped string type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def constr(\n    *,\n    strip_whitespace: bool | None = None,\n    to_upper: bool | None = None,\n    to_lower: bool | None = None,\n    strict: bool | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n) -&gt; type[str]:\n\"\"\"A wrapper around `str` that allows for additional constraints.\n\n    Args:\n        strip_whitespace: Whether to strip whitespace from the string.\n        to_upper: Whether to convert the string to uppercase.\n        to_lower: Whether to convert the string to lowercase.\n        strict: Whether to validate the string in strict mode.\n        min_length: The minimum length of the string.\n        max_length: The maximum length of the string.\n        pattern: A regex pattern that the string must match.\n\n    Returns:\n        The wrapped string type.\n    \"\"\"\n    return Annotated[  # type: ignore[return-value]\n        str,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Len(min_length or 0, max_length),\n        _fields.PydanticGeneralMetadata(\n            strip_whitespace=strip_whitespace,\n            to_upper=to_upper,\n            to_lower=to_lower,\n            pattern=pattern,\n        ),\n    ]\n</code></pre>"},{"location":"api/validate_call/","title":"pydantic.validate_call","text":"<p>Decorators for validating function calls.</p>"},{"location":"api/validate_call/#pydantic.validate_call.validate_call","title":"validate_call","text":"<pre><code>validate_call(\n    __func=None, *, config=None, validate_return=False\n)\n</code></pre> <p>Returns a decorated version of the function that validates the arguments and, optionally, the return value.</p> <p>Parameters:</p> Name Type Description Default <code>__func</code> <code>AnyCallableT | None</code> <p>The function to be decorated.</p> <code>None</code> <code>config</code> <code>ConfigDict | None</code> <p>The configuration dictionary.</p> <code>None</code> <code>validate_return</code> <code>bool</code> <p>Whether to validate the return value.</p> <code>False</code> <p>Returns:</p> Type Description <code>AnyCallableT | Callable[[AnyCallableT], AnyCallableT]</code> <p>The decorated function.</p> Source code in <code>pydantic/validate_call.py</code> <pre><code>def validate_call(\n    __func: AnyCallableT | None = None,\n    *,\n    config: ConfigDict | None = None,\n    validate_return: bool = False,\n) -&gt; AnyCallableT | Callable[[AnyCallableT], AnyCallableT]:\n\"\"\"Returns a decorated version of the function that validates the arguments and, optionally, the return value.\n\n    Args:\n        __func: The function to be decorated.\n        config: The configuration dictionary.\n        validate_return: Whether to validate the return value.\n\n    Returns:\n        The decorated function.\n    \"\"\"\n\n    def validate(function: AnyCallableT) -&gt; AnyCallableT:\n        return _validate_call.ValidateCallWrapper(function, config, validate_return)  # type: ignore\n\n    if __func:\n        return validate(__func)\n    else:\n        return validate\n</code></pre>"},{"location":"api/version/","title":"pydantic.version","text":"<p>The <code>version</code> module holds the version information for Pydantic.</p>"},{"location":"api/version/#pydantic.version.VERSION","title":"VERSION  <code>module-attribute</code>","text":"<pre><code>VERSION = '2.0b3'\n</code></pre> <p>The version of Pydantic.</p>"},{"location":"api/version/#pydantic.version.version_info","title":"version_info","text":"<pre><code>version_info()\n</code></pre> <p>Return complete version information for Pydantic and its dependencies.</p> Source code in <code>pydantic/version.py</code> <pre><code>def version_info() -&gt; str:\n\"\"\"Return complete version information for Pydantic and its dependencies.\"\"\"\n    import platform\n    import sys\n    from importlib import import_module\n    from pathlib import Path\n\n    import pydantic_core._pydantic_core as pdc\n\n    optional_deps = []\n    for p in 'devtools', 'email-validator', 'typing-extensions':\n        try:\n            import_module(p.replace('-', '_'))\n        except ImportError:  # pragma: no cover\n            continue\n        optional_deps.append(p)\n\n    info = {\n        'pydantic version': VERSION,\n        'pydantic-core version': f'{pdc.__version__} {pdc.build_profile} build profile',\n        'install path': Path(__file__).resolve().parent,\n        'python version': sys.version,\n        'platform': platform.platform(),\n        'optional deps. installed': optional_deps,\n    }\n    return '\\n'.join('{:&gt;30} {}'.format(k + ':', str(v).replace('\\n', ' ')) for k, v in info.items())\n</code></pre>"},{"location":"blog/pydantic-v2-alpha/","title":"Pydantic V2 Pre Release","text":"<p>Terrence Dorsey &amp; Samuel Colvin \u2022\u00a0    \u2022\u00a0    \u2022\u00a0    April 3, 2023 \u2022\u00a0    8 min read</p> <p>We're excited to announce the first alpha release of Pydantic V2!</p> <p>This first Pydantic V2 alpha is no April Fool's joke \u2014 for a start we missed our April 1st target date . After a year's work, we invite you to explore the improvements we've made and give us your feedback. We look forward to hearing your thoughts and working together to improve the library.</p> <p>For many of you, Pydantic is already a key part of your Python toolkit and needs no introduction \u2014 we hope you'll find the improvements and additions in Pydantic V2 useful.</p> <p>If you're new to Pydantic: Pydantic is an open-source Python library that provides powerful data parsing and validation \u2014 including type coercion and useful error messages when typing issues arise \u2014 and settings management capabilities. See the docs for examples of Pydantic at work.</p>"},{"location":"blog/pydantic-v2-alpha/#getting-started-with-the-pydantic-v2-alpha","title":"Getting started with the Pydantic V2 alpha","text":"<p>Your feedback will be a critical part of ensuring that we have made the right tradeoffs with the API changes in V2.</p> <p>To get started with the Pydantic V2 alpha, install it from PyPI. We recommend using a virtual environment to isolate your testing environment:</p> <pre><code>pip install --pre -U \"pydantic&gt;=2.0a1\"\n</code></pre> <p>Note that there are still some rough edges and incomplete features, and while trying out the Pydantic V2 alpha releases you may experience errors. We encourage you to try out the alpha releases in a test environment and not in production. Some features are still in development, and we will continue to make changes to the API.</p> <p>If you do encounter any issues, please create an issue in GitHub using the <code>bug V2</code> label. This will help us to actively monitor and track errors, and to continue to improve the library\u2019s performance.</p> <p>This will be the first of several upcoming alpha releases. As you evaluate our changes and enhancements, we encourage you to share your feedback with us.</p> <p>Please let us know:</p> <ul> <li>If you don't like the changes, so we can make sure Pydantic remains a library you enjoy using.</li> <li>If this breaks your usage of Pydantic so we can fix it, or at least describe a migration path.</li> </ul> <p>Thank you for your support, and we look forward to your feedback.</p>"},{"location":"blog/pydantic-v2-alpha/#headlines","title":"Headlines","text":"<p>Here are some of the most interesting new features in the current Pydantic V2 alpha release. For background on plans behind these features, see the earlier Pydantic V2 Plan blog post.</p> <p>The biggest change to Pydantic V2 is <code>pydantic-core</code> \u2014 all validation logic has been rewritten in Rust and moved to a separate package, <code>pydantic-core</code>. This has a number of big advantages:</p> <ul> <li>Performance - Pydantic V2 is 5-50x faster than Pydantic V1.</li> <li>Safety &amp; maintainability - We've made changes to the architecture that we think will help us maintain Pydantic V2 with far fewer bugs in the long term.</li> </ul> <p>With the use of <code>pydantic-core</code>, the majority of the logic in the Pydantic library is dedicated to generating \"pydantic core schema\" \u2014 the schema used define the behaviour of the new, high-performance <code>pydantic-core</code> validators and serializers.</p>"},{"location":"blog/pydantic-v2-alpha/#ready-for-experimentation","title":"Ready for experimentation","text":"<ul> <li>BaseModel - the core of validation in Pydantic V1 remains, albeit with new method names.</li> <li>Dataclasses - Pydantic dataclasses are improved and ready to test.</li> <li>Serialization - dumping/serialization/marshalling is significantly more flexible, and ready to test.</li> <li>Strict mode - one of the biggest additions in Pydantic V2 is strict mode, which is ready to test.</li> <li>JSON Schema - generation of JSON Schema is much improved and ready to test.</li> <li>Generic Models - are much improved and ready to test.</li> <li>Recursive Models - and validation of recursive data structures is much improved and ready to test.</li> <li>Custom Types - custom types have a new interface and are ready to test.</li> <li>Custom Field Modifiers - used via <code>Annotated[]</code> are working and in use in Pydantic itself.</li> <li>Validation without a BaseModel - the new <code>TypeAdapter</code> class allows validation without the need for a <code>BaseModel</code> class, and it's ready to test.</li> <li>TypedDict - we now have full support for <code>TypedDict</code> via <code>TypeAdapter</code>, it's ready to test.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#still-under-construction","title":"Still under construction","text":"<ul> <li>Documentation - we're working hard on full documentation for V2, but it's not ready yet.</li> <li>Conversion Table - a big addition to the documentation will be a conversion table showing how types are coerced, this is a WIP.</li> <li>BaseSettings - <code>BaseSettings</code> will move to a separate <code>pydantic-settings</code> package, it's not yet ready to test.   Notice: since <code>pydantic-settings</code> is not yet ready to release, there's no support for <code>BaseSettings</code> in the first alpha release.</li> <li>validate_arguments - the <code>validate_arguments</code> decorator remains and is working, but hasn't been updated yet.</li> <li>Hypothesis Plugin - the Hypothesis plugin is yet to be updated.</li> <li>computed fields - we know a lot of people are waiting for this, we will include it in Pydantic V2.</li> <li>Error messages - could use some love, and links to docs in error messages are still to be added.</li> <li>Migration Guide - we have some pointers below, but this needs completing.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#migration-guide","title":"Migration Guide","text":"<p>Please note: this is just the beginning of a migration guide. We'll work hard up to the final release to prepare a full migration guide, but for now the following pointers should be some help while experimenting with V2.</p>"},{"location":"blog/pydantic-v2-alpha/#changes-to-basemodel","title":"Changes to BaseModel","text":"<ul> <li>Various method names have been changed; <code>BaseModel</code> methods all start with <code>model_</code> now.   Where possible, we have retained the old method names to help ease migration, but calling them will result in <code>DeprecationWarning</code>s.</li> <li>Some of the built-in data loading functionality has been slated for removal.     In particular, <code>parse_raw</code> and <code>parse_file</code> are now deprecated. You should load the data and then pass it to <code>model_validate</code>.</li> <li>The <code>from_orm</code> method has been removed; you can now just use <code>model_validate</code> (equivalent to <code>parse_obj</code> from Pydantic V1) to achieve something similar,   as long as you've set <code>from_attributes=True</code> in the model config.</li> <li>The <code>__eq__</code> method has changed for models; models are no longer considered equal to the dicts.</li> <li>Custom <code>__init__</code> overrides won't be called. This should be replaced with a <code>@root_validator</code>.</li> <li>Due to inconsistency with the rest of the library, we have removed the special behavior of models   using the <code>__root__</code> field, and have disallowed the use of an attribute with this name to prevent confusion.   However, you can achieve equivalent behavior with a \"standard\" field name through the use of <code>@root_validator</code>,   <code>@model_serializer</code>, and <code>__pydantic_modify_json_schema__</code>. You can see an example of this   here.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-pydantic-dataclasses","title":"Changes to Pydantic Dataclasses","text":"<ul> <li>The <code>__post_init__</code> in Pydantic dataclasses will now be called after validation, rather than before.</li> <li>We no longer support <code>extra='allow'</code> for Pydantic dataclasses, where extra attributes passed to the initializer would be   stored as extra fields on the dataclass. <code>extra='ignore'</code> is still supported for the purposes of allowing extra fields while parsing data; they just aren't stored.</li> <li><code>__post_init_post_parse__</code> has been removed.</li> <li>Nested dataclasses no longer accept tuples as input, only dict.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-config","title":"Changes to Config","text":"<ul> <li>To specify config on a model, it is now deprecated to create a class called <code>Config</code> in the namespace of the parent <code>BaseModel</code> subclass.   Instead, you just need to set a class attribute called <code>model_config</code> to be a dict with the key/value pairs you want to be used as the config.</li> </ul> <p>The following config settings have been removed:</p> <ul> <li><code>allow_mutation</code> \u2014 this has been removed. You should be able to use frozen equivalently (inverse of current use).</li> <li><code>error_msg_templates</code>.</li> <li><code>fields</code> \u2014 this was the source of various bugs, so has been removed. You should be able to use <code>Annotated</code> on fields to modify them as desired.</li> <li><code>getter_dict</code> \u2014 <code>orm_mode</code> has been removed, and this implementation detail is no longer necessary.</li> <li><code>schema_extra</code> \u2014 you should now use the <code>json_schema_extra</code> keyword argument to <code>pydantic.Field</code>.</li> <li><code>smart_union</code>.</li> <li><code>underscore_attrs_are_private</code> \u2014 the Pydantic V2 behavior is now the same as if this was always set to <code>True</code> in Pydantic V1.</li> </ul> <p>The following config settings have been renamed:</p> <ul> <li><code>allow_population_by_field_name</code> \u2192 <code>populate_by_name</code></li> <li><code>anystr_lower</code> \u2192 <code>str_to_lower</code></li> <li><code>anystr_strip_whitespace</code> \u2192 <code>str_strip_whitespace</code></li> <li><code>anystr_upper</code> \u2192 <code>str_to_upper</code></li> <li><code>keep_untouched</code> \u2192 <code>ignored_types</code></li> <li><code>max_anystr_length</code> \u2192 <code>str_max_length</code></li> <li><code>min_anystr_length</code> \u2192 <code>str_min_length</code></li> <li><code>orm_mode</code> \u2192 <code>from_attributes</code></li> <li><code>validate_all</code> \u2192 <code>validate_default</code></li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-validators","title":"Changes to Validators","text":"<ul> <li>Raising a <code>TypeError</code> inside a validator no longer produces a <code>ValidationError</code>, but just raises the <code>TypeError</code> directly.   This was necessary to prevent certain common bugs (such as calling functions with invalid signatures) from   being unintentionally converted into <code>ValidationError</code> and displayed to users.   If you really want <code>TypeError</code> to be converted to a <code>ValidationError</code> you should use a <code>try: except:</code> block that will catch it and do the conversion.</li> <li><code>each_item</code> validators are deprecated and should be replaced with a type annotation using <code>Annotated</code> to apply a validator   or with a validator that operates on all items at the top level.</li> <li>Changes to <code>@validator</code>-decorated function signatures.</li> <li>The <code>stricturl</code> type has been removed.</li> <li>Root validators can no longer be run with <code>skip_on_failure=False</code>.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-validation-of-specific-types","title":"Changes to Validation of specific types","text":"<ul> <li>Integers outside the valid range of 64 bit integers will cause <code>ValidationError</code>s during parsing.   To work around this, use an <code>IsInstance</code> validator (more details to come).</li> <li>Subclasses of built-ins won't validate into their subclass types; you'll need to use an <code>IsInstance</code> validator to validate these types.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-generic-models","title":"Changes to Generic models","text":"<ul> <li>While it does not raise an error at runtime yet, subclass checks for parametrized generics should no longer be used.   These will result in <code>TypeError</code>s and we can't promise they will work forever. However, it will be okay to do subclass checks against non-parametrized generic models</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#other-changes","title":"Other changes","text":"<ul> <li><code>GetterDict</code> has been removed, as it was just an implementation detail for <code>orm_mode</code>, which has been removed.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#typeadapter","title":"TypeAdapter","text":"<p>Pydantic V1 didn't have good support for validation or serializing non-<code>BaseModel</code>. To work with them you had to create a \"root\" model or use the utility functions in <code>pydantic.tools</code> (<code>parse_obj_as</code> and <code>schema_of</code>). In Pydantic V2 this is a lot easier: the <code>TypeAdapter</code> class lets you build an object that behaves almost like a <code>BaseModel</code> class which you can use for a lot of the use cases of root models and as a complete replacement for <code>parse_obj_as</code> and <code>schema_of</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\nvalidator = TypeAdapter(List[int])\nassert validator.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(validator.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <pre><code>from pydantic import TypeAdapter\n\nvalidator = TypeAdapter(list[int])\nassert validator.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(validator.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <p>Note that this API is provisional and may change before the final release of Pydantic V2.</p>"},{"location":"blog/pydantic-v2/","title":"Pydantic V2 Plan","text":"<p>Samuel Colvin \u2022\u00a0    \u2022\u00a0    \u2022\u00a0    Jul 10, 2022 \u2022\u00a0    25 min read</p> <p>Updated late 10 Jul 2022, see pydantic#4226.</p> <p>I've spoken to quite a few people about pydantic V2, and mention it in passing even more.</p> <p>I owe people a proper explanation of the plan for V2:</p> <ul> <li>What we will add</li> <li>What we will remove</li> <li>What we will change</li> <li>How I'm intending to go about completing it and getting it released</li> <li>Some idea of timeframe </li> </ul> <p>Here goes...</p> <p>Enormous thanks to Eric Jolibois, Laurence Watson, Sebasti\u00e1n Ram\u00edrez, Adrian Garcia Badaracco, Tom Hamilton Stubber, Zac Hatfield-Dodds, Tom &amp; Hasan Ramezani for reviewing this blog post, putting up with (and correcting) my horrible typos and making great suggestions that have made this post and Pydantic V2 materially better.</p>"},{"location":"blog/pydantic-v2/#plan-timeframe","title":"Plan &amp; Timeframe","text":"<p>I'm currently taking a kind of sabbatical after leaving my last job to get pydantic V2 released. Why? I ask myself that question quite often. I'm very proud of how much pydantic is used, but I'm less proud of its internals. Since it's something people seem to care about and use quite a lot (26m downloads a month, used by 72k public repos, 10k stars). I want it to be as good as possible.</p> <p>While I'm on the subject of why, how and my odd sabbatical: if you work for a large company who use pydantic a lot, you might encourage the company to sponsor me a meaningful amount, like Salesforce did (if your organisation is not open to donations, I can also offer consulting services). This is not charity, recruitment or marketing - the argument should be about how much the company will save if pydantic is 10x faster, more stable and more powerful - it would be worth paying me 10% of that to make it happen.</p> <p>Before pydantic V2 can be released, we need to release pydantic V1.10 - there are lots of changes in the main branch of pydantic contributed by the community, it's only fair to provide a release including those changes, many of them will remain unchanged for V2, the rest will act as a requirement to make sure pydantic V2 includes the capabilities they implemented.</p> <p>The basic road map for me is as follows:</p> <ol> <li>Implement a few more features in pydantic-core, and release a first version, see below</li> <li>Work on getting pydantic V1.10 out - basically merge all open PRs that are finished</li> <li>Release pydantic V1.10</li> <li>Delete all stale PRs which didn't make it into V1.10, apologise profusely to their authors who put their valuable    time into pydantic only to have their PRs closed     (and explain when and how they can rebase and recreate the PR)</li> <li>Rename <code>master</code> to <code>main</code>, seems like a good time to do this</li> <li>Change the main branch of pydantic to target V2</li> <li>Start tearing pydantic code apart and see how many existing tests can be made to pass</li> <li>Rinse, repeat</li> <li>Release pydantic V2 </li> </ol> <p>Plan is to have all this done by the end of October, definitely by the end of the year.</p>"},{"location":"blog/pydantic-v2/#breaking-changes-compatibility","title":"Breaking Changes &amp; Compatibility","text":"<p>While we'll do our best to avoid breaking changes, some things will break.</p> <p>As per the greatest pun in modern TV history.</p> <p>You can't make a Tomelette without breaking some Greggs.</p> <p>Where possible, if breaking changes are unavoidable, we'll try to provide warnings or errors to make sure those changes are obvious to developers.</p>"},{"location":"blog/pydantic-v2/#motivation-pydantic-core","title":"Motivation &amp; <code>pydantic-core</code>","text":"<p>Since pydantic's initial release, with the help of wonderful contributors Eric Jolibois, Sebasti\u00e1n Ram\u00edrez, David Montague and many others, the package and its usage have grown enormously. The core logic however has remained mostly unchanged since the initial experiment. It's old, it smells, it needs to be rebuilt.</p> <p>The release of version 2 is an opportunity to rebuild pydantic and correct many things that don't make sense - to make pydantic amazing .</p> <p>The core validation logic of pydantic V2 will be performed by a separate package pydantic-core which I've been building over the last few months. pydantic-core is written in Rust using the excellent pyo3 library which provides rust bindings for python.</p> <p>The motivation for building pydantic-core in Rust is as follows:</p> <ol> <li>Performance, see below</li> <li>Recursion and code separation - with no stack and little-to-no overhead for extra function calls,    Rust allows pydantic-core to be implemented as a tree of small validators which call each other,    making code easier to understand and extend without harming performance</li> <li>Safety and complexity - pydantic-core is a fairly complex piece of code which has to draw distinctions    between many different errors, Rust is great in situations like this,    it should minimise bugs () and allow the codebase to be extended for a long time to come</li> </ol> <p>Note</p> <p>The python interface to pydantic shouldn't change as a result of using pydantic-core, instead pydantic will use type annotations to build a schema for pydantic-core to use.</p> <p>pydantic-core is usable now, albeit with an unintuitive API, if you're interested, please give it a try.</p> <p>pydantic-core provides validators for common data types, see a list here. Other, less commonly used data types will be supported via validator functions implemented in pydantic, in Python.</p> <p>See pydantic-core#153 for a summary of what needs to be completed before its first release.</p>"},{"location":"blog/pydantic-v2/#headlines","title":"Headlines","text":"<p>Here are some of the biggest changes expected in V2.</p>"},{"location":"blog/pydantic-v2/#performance","title":"Performance","text":"<p>As a result of the move to Rust for the validation logic (and significant improvements in how validation objects are structured) pydantic V2 will be significantly faster than pydantic V1.</p> <p>Looking at the pydantic-core benchmarks today, pydantic V2 is between 4x and 50x faster than pydantic V1.9.1.</p> <p>In general, pydantic V2 is about 17x faster than V1 when validating a model containing a range of common fields.</p>"},{"location":"blog/pydantic-v2/#strict-mode","title":"Strict Mode","text":"<p>People have long complained about pydantic for coercing data instead of throwing an error. E.g. input to an <code>int</code> field could be <code>123</code> or the string <code>\"123\"</code> which would be converted to <code>123</code> While this is very useful in many scenarios (think: URL parameters, environment variables, user input), there are some situations where it's not desirable.</p> <p>pydantic-core comes with \"strict mode\" built in. With this, only the exact data type is allowed, e.g. passing <code>\"123\"</code> to an <code>int</code> field would result in a validation error.</p> <p>This will allow pydantic V2 to offer a <code>strict</code> switch which can be set on either a model or a field.</p>"},{"location":"blog/pydantic-v2/#formalised-conversion-table","title":"Formalised Conversion Table","text":"<p>As well as complaints about coercion, another legitimate complaint was inconsistency around data conversion.</p> <p>In pydantic V2, the following principle will govern when data should be converted in \"lax mode\" (<code>strict=False</code>):</p> <p>If the input data has a SINGLE and INTUITIVE representation, in the field's type, AND no data is lost during the conversion, then the data will be converted; otherwise a validation error is raised. There is one exception to this rule: string fields - virtually all data has an intuitive representation as a string (e.g. <code>repr()</code> and <code>str()</code>), therefore a custom rule is required: only <code>str</code>, <code>bytes</code> and <code>bytearray</code> are valid as inputs to string fields.</p> <p>Some examples of what that means in practice:</p> Field Type Input Single &amp; Intuitive R. All Data Preserved Result <code>int</code> <code>\"123\"</code> Convert <code>int</code> <code>123.0</code> Convert <code>int</code> <code>123.1</code> Error <code>date</code> <code>\"2020-01-01\"</code> Convert <code>date</code> <code>\"2020-01-01T00:00:00\"</code> Convert <code>date</code> <code>\"2020-01-01T12:00:00\"</code> Error <code>int</code> <code>b\"1\"</code> Error <p>(For the last case converting <code>bytes</code> to an <code>int</code> could reasonably mean <code>int(bytes_data.decode())</code> or <code>int.from_bytes(b'1', 'big/little')</code>, hence an error)</p> <p>In addition to the general rule, we'll provide a conversion table which defines exactly what data will be allowed to which field types. See the table below for a start on this.</p>"},{"location":"blog/pydantic-v2/#built-in-json-support","title":"Built in JSON support","text":"<p>pydantic-core can parse JSON directly into a model or output type, this both improves performance and avoids issue with strictness - e.g. if you have a strict model with a <code>datetime</code> field, the input must be a <code>datetime</code> object, but clearly that makes no sense when parsing JSON which has no <code>datatime</code> type. Same with <code>bytes</code> and many other types.</p> <p>Pydantic V2 will therefore allow some conversion when validating JSON directly, even in strict mode (e.g. <code>ISO8601 string -&gt; datetime</code>, <code>str -&gt; bytes</code>) even though this would not be allowed when validating a python object.</p> <p>In future direct validation of JSON will also allow:</p> <ul> <li>parsing in a separate thread while starting validation in the main thread</li> <li>line numbers from JSON to be included in the validation errors</li> </ul> <p>(These features will not be included in V2, but instead will hopefully be added later.)</p> <p>Note</p> <p>Pydantic has always had special support for JSON, that is not going to change.</p> <p>While in theory other formats could be specifically supported, the overheads and development time are significant and I don't think there's another format that's used widely enough to be worth specific logic. Other formats can be parsed to python then validated, similarly when serializing, data can be exported to a python object, then serialized, see below.</p>"},{"location":"blog/pydantic-v2/#validation-without-a-model","title":"Validation without a Model","text":"<p>In pydantic V1 the core of all validation was a pydantic model, this led to a significant performance penalty and extra complexity when the output data type was not a model.</p> <p>pydantic-core operates on a tree of validators with no \"model\" type required at the base of that tree. It can therefore validate a single <code>string</code> or <code>datetime</code> value, a <code>TypedDict</code> or a <code>Model</code> equally easily.</p> <p>This feature will provide significant addition performance improvements in scenarios like:</p> <ul> <li>Adding validation to <code>dataclasses</code></li> <li>Validating URL arguments, query strings, headers, etc. in FastAPI</li> <li>Adding validation to <code>TypedDict</code></li> <li>Function argument validation</li> <li>Adding validation to your custom classes, decorators...</li> </ul> <p>In effect - anywhere where you don't care about a traditional model class instance.</p> <p>We'll need to add standalone methods for generating JSON Schema and dumping these objects to JSON, etc.</p>"},{"location":"blog/pydantic-v2/#required-vs-nullable-cleanup","title":"Required vs. Nullable Cleanup","text":"<p>Pydantic previously had a somewhat confused idea about \"required\" vs. \"nullable\". This mostly resulted from my misgivings about marking a field as <code>Optional[int]</code> but requiring a value to be provided but allowing it to be <code>None</code> - I didn't like using the word \"optional\" in relation to a field which was not optional.</p> <p>In pydantic V2, pydantic will move to match dataclasses, thus:</p> Required vs. Nullable<pre><code>from pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    f1: str  # required, cannot be None\n    f2: str | None  # required, can be None - same as Optional[str] / Union[str, None]\n    f3: str | None = None  # not required, can be None\n    f4: str = 'Foobar'  # not required, but cannot be None\n</code></pre>"},{"location":"blog/pydantic-v2/#validator-function-improvements","title":"Validator Function Improvements","text":"<p>This is one of the changes in pydantic V2 that I'm most excited about, I've been talking about something like this for a long time, see pydantic#1984, but couldn't find a way to do this until now.</p> <p>Fields which use a function for validation can be any of the following types:</p> <ul> <li>function before mode - where the function is called before the inner validator is called</li> <li>function after mode - where the function is called after the inner validator is called</li> <li>plain mode - where there's no inner validator</li> <li>wrap mode - where the function takes a reference to a function which calls the inner validator,   and can therefore modify the input before inner validation, modify the output after inner validation, conditionally   not call the inner validator or catch errors from the inner validator and return a default value, or change the error</li> </ul> <p>An example how a wrap validator might look:</p> Wrap mode validator function<pre><code>from datetime import datetime\nfrom pydantic import BaseModel, ValidationError, validator\n\n\nclass MyModel(BaseModel):\n    timestamp: datetime\n\n    @validator('timestamp', mode='wrap')\n    def validate_timestamp(cls, v, handler):\n        if v == 'now':\n            # we don't want to bother with further validation,\n            # just return the new value\n            return datetime.now()\n        try:\n            return handler(v)\n        except ValidationError:\n            # validation failed, in this case we want to\n            # return a default value\n            return datetime(2000, 1, 1)\n</code></pre> <p>As well as being powerful, this provides a great \"escape hatch\" when pydantic validation doesn't do what you need.</p>"},{"location":"blog/pydantic-v2/#more-powerful-aliases","title":"More powerful alias(es)","text":"<p>pydantic-core can support alias \"paths\" as well as simple string aliases to flatten data as it's validated.</p> <p>Best demonstrated with an example:</p> Alias paths<pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    bar: str = Field(aliases=[['baz', 2, 'qux']])\n\n\ndata = {\n    'baz': [\n        {'qux': 'a'},\n        {'qux': 'b'},\n        {'qux': 'c'},\n        {'qux': 'd'},\n    ]\n}\n\nfoo = Foo(**data)\nassert foo.bar == 'c'\n</code></pre> <p><code>aliases</code> is a list of lists because multiple paths can be provided, if so they're tried in turn until a value is found.</p> <p>Tagged unions will use the same logic as <code>aliases</code> meaning nested attributes can be used to select a schema to validate against.</p>"},{"location":"blog/pydantic-v2/#improvements-to-dumpingserializationexport","title":"Improvements to Dumping/Serialization/Export","text":"<p>(I haven't worked on this yet, so these ideas are only provisional)</p> <p>There has long been a debate about how to handle converting data when extracting it from a model. One of the features people have long requested is the ability to convert data to JSON compliant types while converting a model to a dict.</p> <p>My plan is to move data export into pydantic-core, with that, one implementation can support all export modes without compromising (and hopefully significantly improving) performance.</p> <p>I see four different export/serialization scenarios:</p> <ol> <li>Extracting the field values of a model with no conversion, effectively <code>model.__dict__</code> but with the current filtering    logic provided by <code>.dict()</code></li> <li>Extracting the field values of a model recursively (effectively what <code>.dict()</code> does now) - sub-models are converted to    dicts, but other fields remain unchanged.</li> <li>Extracting data and converting at the same time (e.g. to JSON compliant types)</li> <li>Serializing data straight to JSON</li> </ol> <p>I think all 4 modes can be supported in a single implementation, with a kind of \"3.5\" mode where a python function is used to convert the data as the user wishes.</p> <p>The current <code>include</code> and <code>exclude</code> logic is extremely complicated, but hopefully it won't be too hard to translate it to Rust.</p> <p>We should also add support for <code>validate_alias</code> and <code>dump_alias</code> as well as the standard <code>alias</code> to allow for customising field keys.</p>"},{"location":"blog/pydantic-v2/#validation-context","title":"Validation Context","text":"<p>Pydantic V2 will add a new optional <code>context</code> argument to <code>model_validate</code> and <code>model_validate_json</code> which will allow you to pass information not available when creating a model to validators. See pydantic#1549 for motivation.</p> <p>Here's an example of <code>context</code> might be used:</p> Context during Validation<pre><code>from pydantic import BaseModel, EmailStr, validator\n\n\nclass User(BaseModel):\n    email: EmailStr\n    home_country: str\n\n    @validator('home_country')\n    def check_home_country(cls, v, context):\n        if v not in context['countries']:\n            raise ValueError('invalid country choice')\n        return v\n\n\nasync def add_user(post_data: bytes):\n    countries = set(await db_connection.fetch_all('select code from country'))\n    user = User.model_validate_json(post_data, context={'countries': countries})\n    ...\n</code></pre> <p>Note</p> <p>We (actually mostly Sebasti\u00e1n ) will have to make some changes to FastAPI to fully leverage <code>context</code> as we'd need some kind of dependency injection to build context before validation so models can still be passed as arguments to views. I'm sure he'll be game.</p> <p>Warning</p> <p>Although this will make it slightly easier to run synchronous IO (HTTP requests, DB. queries, etc.) from within validators, I strongly advise you keep IO separate from validation - do it before and use context, do it afterwards, avoid where possible making queries inside validation.</p>"},{"location":"blog/pydantic-v2/#model-namespace-cleanup","title":"Model Namespace Cleanup","text":"<p>For years I've wanted to clean up the model namespace, see pydantic#1001. This would avoid confusing gotchas when field names clash with methods on a model, it would also make it safer to add more methods to a model without risking new clashes.</p> <p>After much deliberation (and even giving a lightning talk at the python language submit about alternatives, see this discussion). I've decided to go with the simplest and clearest approach, at the expense of a bit more typing:</p> <p>All methods on models will start with <code>model_</code>, fields' names will not be allowed to start with <code>\"model\"</code> (aliases can be used if required).</p> <p>This will mean <code>BaseModel</code> will have roughly the following signature.</p> New BaseModel methods<pre><code>class BaseModel:\n    model_fields: List[FieldInfo]\n\"\"\"previously `__fields__`, although the format will change a lot\"\"\"\n    @classmethod\n    def model_validate(cls, data: Any, *, context=None) -&gt; Self:  # (1)\n\"\"\"\n        previously `parse_obj()`, validate data\n        \"\"\"\n    @classmethod\n    def model_validate_json(\n        cls,\n        data: str | bytes | bytearray,\n        *,\n        context=None\n    ) -&gt; Self:\n\"\"\"\n        previously `parse_raw(..., content_type='application/json')`\n        validate data from JSON\n        \"\"\"\n    @classmethod\n    def model_is_instance(cls, data: Any, *, context=None) -&gt; bool: # (2)\n\"\"\"\n        new, check if data is value for the model\n        \"\"\"\n    @classmethod\n    def model_is_instance_json(\n        cls,\n        data: str | bytes | bytearray,\n        *,\n        context=None\n    ) -&gt; bool:\n\"\"\"\n        Same as `model_is_instance`, but from JSON\n        \"\"\"\n    def model_dump(\n        self,\n        include: ... = None,\n        exclude: ... = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        mode: Literal['unchanged', 'dicts', 'json-compliant'] = 'unchanged',\n        converter: Callable[[Any], Any] | None = None\n    ) -&gt; Any:\n\"\"\"\n        previously `dict()`, as before\n        with new `mode` argument\n        \"\"\"\n    def model_dump_json(self, ...) -&gt; str:\n\"\"\"\n        previously `json()`, arguments as above\n        effectively equivalent to `json.dump(self.model_dump(..., mode='json'))`,\n        but more performant\n        \"\"\"\n    def model_json_schema(self, ...) -&gt; dict[str, Any]:\n\"\"\"\n        previously `schema()`, arguments roughly as before\n        JSON schema as a dict\n        \"\"\"\n    def model_update_forward_refs(self) -&gt; None:\n\"\"\"\n        previously `update_forward_refs()`, update forward references\n        \"\"\"\n    @classmethod\n    def model_construct(\n        self,\n        _fields_set: set[str] | None = None,\n        **values: Any\n    ) -&gt; Self:\n\"\"\"\n        previously `construct()`, arguments roughly as before\n        construct a model with no validation\n        \"\"\"\n    @classmethod\n    def model_customize_schema(cls, schema: dict[str, Any]) -&gt; dict[str, Any]:\n\"\"\"\n        new, way to customize validation,\n        e.g. if you wanted to alter how the model validates certain types,\n        or add validation for a specific type without custom types or\n        decorated validators\n        \"\"\"\n    class ModelConfig:\n\"\"\"\n        previously `Config`, configuration class for models\n        \"\"\"\n</code></pre> <ol> <li>see Validation Context for more information on <code>context</code></li> <li>see <code>is_instance</code> checks</li> </ol> <p>The following methods will be removed:</p> <ul> <li><code>.parse_file()</code> - was a mistake, should never have been in pydantic</li> <li><code>.parse_raw()</code> - partially replaced by <code>.model_validate_json()</code>, the other functionality was a mistake</li> <li><code>.from_orm()</code> - the functionality has been moved to config, see other improvements below</li> <li><code>.schema_json()</code> - mostly since it causes confusion between pydantic validation schema and JSON schema,   and can be replaced with just <code>json.dumps(m.model_json_schema())</code></li> <li><code>.copy()</code> instead we'll implement <code>__copy__</code> and let people use the <code>copy</code> module   (this removes some functionality) from <code>copy()</code> but there are bugs and ambiguities with the functionality anyway</li> </ul>"},{"location":"blog/pydantic-v2/#strict-api-api-documentation","title":"Strict API &amp; API documentation","text":"<p>When preparing for pydantic V2, we'll make a strict distinction between the public API and private functions &amp; classes. Private objects will be clearly identified as private via a <code>_internal</code> sub package to discourage use.</p> <p>The public API will have API documentation. I've recently been working with the wonderful mkdocstrings package for both dirty-equals and watchfiles documentation. I intend to use <code>mkdocstrings</code> to generate complete API documentation for V2.</p> <p>This wouldn't replace the current example-based somewhat informal documentation style but instead will augment it.</p>"},{"location":"blog/pydantic-v2/#error-descriptions","title":"Error descriptions","text":"<p>The way line errors (the individual errors within a <code>ValidationError</code>) are built has become much more sophisticated in pydantic-core.</p> <p>There's a well-defined set of error codes and messages.</p> <p>More will be added when other types are validated via pure python validators in pydantic.</p> <p>I would like to add a dedicated section to the documentation with extra information for each type of error.</p> <p>This would be another key in a line error: <code>documentation</code>, which would link to the appropriate section in the docs.</p> <p>Thus, errors might look like:</p> Line Errors Example<pre><code>[\n    {\n        'kind': 'greater_than_equal',\n        'loc': ['age'],\n        'message': 'Value must be greater than or equal to 18',\n        'input_value': 11,\n        'context': {'ge': 18},\n        'documentation': 'https://pydantic.dev/errors/#greater_than_equal',\n    },\n    {\n        'kind': 'bool_parsing',\n        'loc': ['is_developer'],\n        'message': 'Value must be a valid boolean, unable to interpret input',\n        'input_value': 'foobar',\n        'documentation': 'https://pydantic.dev/errors/#bool_parsing',\n    },\n]\n</code></pre> <p>I own the <code>pydantic.dev</code> domain and will use it for at least these errors so that even if the docs URL changes, the error will still link to the correct documentation. If developers don't want to show these errors to users, they can always process the errors list and filter out items from each error they don't need or want.</p>"},{"location":"blog/pydantic-v2/#no-pure-python-implementation","title":"No pure python implementation","text":"<p>Since pydantic-core is written in Rust, and I have absolutely no intention of rewriting it in python, pydantic V2 will only work where a binary package can be installed.</p> <p>pydantic-core will provide binaries in PyPI for (at least):</p> <ul> <li>Linux: <code>x86_64</code>, <code>aarch64</code>, <code>i686</code>, <code>armv7l</code>, <code>musl-x86_64</code> &amp; <code>musl-aarch64</code></li> <li>MacOS: <code>x86_64</code> &amp; <code>arm64</code> (except python 3.7)</li> <li>Windows: <code>amd64</code> &amp; <code>win32</code></li> <li>Web Assembly: <code>wasm32</code>   (pydantic-core is already   compiled for wasm32 using emscripten and unit tests pass, except where cpython itself has   problems)</li> </ul> <p>Binaries for pypy are a work in progress and will be added if possible, see pydantic-core#154.</p> <p>Other binaries can be added provided they can be (cross-)compiled on github actions. If no binary is available from PyPI, pydantic-core can be compiled from source if Rust stable is available.</p> <p>The only place where I know this will cause problems is Raspberry Pi, which is a mess when it comes to packages written in Rust for Python. Effectively, until that's fixed you'll likely have to install pydantic with <code>pip install -i https://pypi.org/simple/ pydantic</code>.</p>"},{"location":"blog/pydantic-v2/#pydantic-becomes-a-pure-python-package","title":"Pydantic becomes a pure python package","text":"<p>Pydantic V1.X is a pure python code base but is compiled with cython to provide some performance improvements. Since the \"hot\" code is moved to pydantic-core, pydantic itself can go back to being a pure python package.</p> <p>This should significantly reduce the size of the pydantic package and make unit tests of pydantic much faster. In addition:</p> <ul> <li>some constraints on pydantic code can be removed once it no-longer has to be compilable with cython</li> <li>debugging will be easier as you'll be able to drop straight into the pydantic codebase as you can with other,   pure python packages</li> </ul> <p>Some pieces of edge logic could get a little slower as they're no longer compiled.</p>"},{"location":"blog/pydantic-v2/#is_instance-like-checks","title":"<code>is_instance</code> like checks","text":"<p>Strict mode also means it makes sense to provide an <code>is_instance</code> method on models which effectively run validation then throws away the result while avoiding the (admittedly small) overhead of creating and raising an error or returning the validation result.</p> <p>To be clear, this isn't a real <code>isinstance</code> call, rather it is equivalent to</p> is_instance<pre><code>class BaseModel:\n    ...\n\n    @classmethod\n    def model_is_instance(cls, data: Any) -&gt; bool:\n        try:\n            cls(**data)\n        except ValidationError:\n            return False\n        else:\n            return True\n</code></pre>"},{"location":"blog/pydantic-v2/#im-dropping-the-word-parse-and-just-using-validate","title":"I'm dropping the word \"parse\" and just using \"validate\"","text":"<p>Partly due to the issues with the lack of strict mode, I've gone back and forth between using the terms \"parse\" and \"validate\" for what pydantic does.</p> <p>While pydantic is not simply a validation library (and I'm sure some would argue validation is not strictly what it does), most people use the word \"validation\".</p> <p>It's time to stop fighting that, and use consistent names.</p> <p>The word \"parse\" will no longer be used except when talking about JSON parsing, see model methods above.</p>"},{"location":"blog/pydantic-v2/#changes-to-custom-field-types","title":"Changes to custom field types","text":"<p>Since the core structure of validators has changed from \"a list of validators to call one after another\" to \"a tree of validators which call each other\", the <code>__get_validators__</code> way of defining custom field types no longer makes sense.</p> <p>Instead, we'll look for the attribute <code>__pydantic_validation_schema__</code> which must be a pydantic-core compliant schema for validating data to this field type (the <code>function</code> item can be a string, if so a function of that name will be taken from the class, see <code>'validate'</code> below).</p> <p>Here's an example of how a custom field type could be defined:</p> New custom field types<pre><code>from pydantic import ValidationSchema\n\n\nclass Foobar:\n    def __init__(self, value: str):\n        self.value = value\n\n    __pydantic_validation_schema__: ValidationSchema = {\n        'type': 'function',\n        'mode': 'after',\n        'function': 'validate',\n        'schema': {'type': 'str'},\n    }\n\n    @classmethod\n    def validate(cls, value):\n        if 'foobar' in value:\n            return Foobar(value)\n        else:\n            raise ValueError('expected foobar')\n</code></pre> <p>What's going on here: <code>__pydantic_validation_schema__</code> defines a schema which effectively says:</p> <p>Validate input data as a string, then call the <code>validate</code> function with that string, use the returned value as the final result of validation.</p> <p><code>ValidationSchema</code> is just an alias to <code>pydantic_core.Schema</code> which is a type defining the schema for validation schemas.</p> <p>Note</p> <p>pydantic-core schema has full type definitions although since the type is recursive, mypy can't provide static type analysis, pyright however can.</p> <p>We can probably provide one or more helper functions to make <code>__pydantic_validation_schema__</code> easier to generate.</p>"},{"location":"blog/pydantic-v2/#other-improvements","title":"Other Improvements","text":"<p>Some other things which will also change, IMHO for the better:</p> <ol> <li>Recursive models with cyclic references - although recursive models were supported by pydantic V1,    data with cyclic references caused recursion errors, in pydantic-core cyclic references are correctly detected    and a validation error is raised</li> <li>The reason I've been so keen to get pydantic-core to compile and run with wasm is that I want all examples    in the docs of pydantic V2 to be editable and runnable in the browser</li> <li>Full support for <code>TypedDict</code>, including <code>total=False</code> - e.g. omitted keys,    providing validation schema to a <code>TypedDict</code> field/item will use <code>Annotated</code>, e.g. <code>Annotated[str, Field(strict=True)]</code></li> <li><code>from_orm</code> has become <code>from_attributes</code> and is now defined at schema generation time    (either via model config or field config)</li> <li><code>input_value</code> has been added to each line error in a <code>ValidationError</code>, making errors easier to understand,    and more comprehensive details of errors to be provided to end users,    pydantic#784</li> <li><code>on_error</code> logic in a schema which allows either a default value to be used in the event of an error,    or that value to be omitted (in the case of a <code>total=False</code> <code>TypedDict</code>),    pydantic-core#151</li> <li><code>datetime</code>, <code>date</code>, <code>time</code> &amp; <code>timedelta</code> validation is improved, see the    speedate Rust library I built specifically for this purpose for more details</li> <li>Powerful \"priority\" system for optionally merging or overriding config in sub-models for nested schemas</li> <li>Pydantic will support annotated-types,    so you can do stuff like <code>Annotated[set[int], Len(0, 10)]</code> or <code>Name = Annotated[str, Len(1, 1024)]</code></li> <li>A single decorator for general usage - we should add a <code>validate</code> decorator which can be used:</li> <li>on functions (replacing <code>validate_arguments</code>)</li> <li>on dataclasses, <code>pydantic.dataclasses.dataclass</code> will become an alias of this</li> <li>on <code>TypedDict</code>s</li> <li>On any supported type, e.g. <code>Union[...]</code>, <code>Dict[str, Thing]</code></li> <li>On Custom field types - e.g. anything with a <code>__pydantic_schema__</code> attribute</li> <li>Easier validation error creation, I've often found myself wanting to raise <code>ValidationError</code>s outside     models, particularly in FastAPI     (here     is one method I've used), we should provide utilities to generate these errors</li> <li>Improve the performance of <code>__eq__</code> on models</li> <li>Computed fields, these having been an idea for a long time in pydantic - we should get them right</li> <li>Model validation that avoids instances of subclasses leaking data (particularly important for FastAPI),     see pydantic-core#155</li> <li>We'll now follow semvar properly and avoid breaking changes between minor versions,     as a result, major versions will become more common</li> <li>Improve generics to use <code>M(Basemodel, Generic[T])</code> instead of <code>M(GenericModel, Generic[T])</code> - e.g. <code>GenericModel</code>     can be removed; this results from no-longer needing to compile pydantic code with cython</li> </ol>"},{"location":"blog/pydantic-v2/#removed-features-limitations","title":"Removed Features &amp; Limitations","text":"<p>The emoji here is just for variation, I'm not frowning about any of this, these changes are either good IMHO (will make pydantic cleaner, easier to learn and easier to maintain) or irrelevant to 99.9+% of users.</p> <ol> <li><code>__root__</code> custom root models are no longer necessary since validation on any supported data type is allowed    without a model</li> <li><code>.parse_file()</code> and <code>.parse_raw()</code>, partially replaced with <code>.model_validate_json()</code>,    see model methods</li> <li><code>.schema_json()</code> &amp; <code>.copy()</code>, see model methods</li> <li><code>TypeError</code> are no longer considered as validation errors, but rather as internal errors, this is to better    catch errors in argument names in function validators.</li> <li>Subclasses of builtin types like <code>str</code>, <code>bytes</code> and <code>int</code> are coerced to their parent builtin type,    this is a limitation of how pydantic-core converts these types to Rust types during validation, if you have a    specific need to keep the type, you can use wrap validators or custom type validation as described above</li> <li>integers are represented in rust code as <code>i64</code>, meaning if you want to use ints where <code>abs(v) &gt; 2^63 \u2212 1</code>    (9,223,372,036,854,775,807), you'll need to use a wrap validator and your own logic</li> <li>Settings Management ??? - I definitely don't want to    remove the functionality, but it's something of a historical curiosity that it lives within pydantic,    perhaps it should move to a separate package, perhaps installable alongside pydantic with    <code>pip install pydantic[settings]</code>?</li> <li>The following <code>Config</code> properties will be removed:</li> <li><code>fields</code> - it's very old (it pre-dates <code>Field</code>), can be removed</li> <li><code>allow_mutation</code> will be removed, instead <code>frozen</code> will be used</li> <li><code>error_msg_templates</code>, it's not properly documented anyway, error messages can be customized with external logic if required</li> <li><code>getter_dict</code> - pydantic-core has hardcoded <code>from_attributes</code> logic</li> <li><code>json_loads</code> - again this is hard coded in pydantic-core</li> <li><code>json_dumps</code> - possibly</li> <li><code>json_encoders</code> - see the export \"mode\" discussion above</li> <li><code>underscore_attrs_are_private</code> we should just choose a sensible default</li> <li><code>smart_union</code> - all unions are now \"smart\"</li> <li><code>dict(model)</code> functionality should be removed, there's a much clearer distinction now that in 2017 when I    implemented this between a model and a dict</li> </ol>"},{"location":"blog/pydantic-v2/#features-remaining","title":"Features Remaining","text":"<p>The following features will remain (mostly) unchanged:</p> <ul> <li>JSONSchema, internally this will need to change a lot, but hopefully the external interface will remain unchanged</li> <li><code>dataclass</code> support, again internals might change, but not the external interface</li> <li><code>validate_arguments</code>, might be renamed, but otherwise remain</li> <li>hypothesis plugin, might be able to improve this as part of the general cleanup</li> </ul>"},{"location":"blog/pydantic-v2/#questions","title":"Questions","text":"<p>I hope the explanation above is useful. I'm sure people will have questions and feedback; I'm aware I've skipped over some features with limited detail (this post is already fairly long ).</p> <p>To allow feedback without being overwhelmed, I've created a \"Pydantic V2\" category for discussions on github - please feel free to create a discussion if you have any questions or suggestions. We will endeavour to read and respond to everyone.</p>"},{"location":"blog/pydantic-v2/#implementation-details","title":"Implementation Details","text":"<p>(This is yet to be built, so these are nascent ideas which might change)</p> <p>At the center of pydantic v2 will be a <code>PydanticValidator</code> class which looks roughly like this (note: this is just pseudo-code, it's not even valid python and is only supposed to be used to demonstrate the idea):</p> PydanticValidator<pre><code># type identifying data which has been validated,\n# as per pydantic-core, this can include \"fields_set\" data\nValidData = ...\n\n# any type we can perform validation for\nAnyOutputType = ...\n\nclass PydanticValidator:\n    def __init__(self, output_type: AnyOutputType, config: Config):\n        ...\n    def validate(self, input_data: Any) -&gt; ValidData:\n        ...\n    def validate_json(self, input_data: str | bytes | bytearray) -&gt; ValidData:\n        ...\n    def is_instance(self, input_data: Any) -&gt; bool:\n        ...\n    def is_instance_json(self, input_data: str | bytes | bytearray) -&gt; bool:\n        ...\n    def json_schema(self) -&gt; dict:\n        ...\n    def dump(\n        self,\n        data: ValidData,\n        include: ... = None,\n        exclude: ... = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        mode: Literal['unchanged', 'dicts', 'json-compliant'] = 'unchanged',\n        converter: Callable[[Any], Any] | None = None\n    ) -&gt; Any:\n        ...\n    def dump_json(self, ...) -&gt; str:\n        ...\n</code></pre> <p>This could be used directly, but more commonly will be used by the following:</p> <ul> <li><code>BaseModel</code></li> <li>the <code>validate</code> decorator described above</li> <li><code>pydantic.dataclasses.dataclass</code> (which might be an alias of <code>validate</code>)</li> <li>generics</li> </ul> <p>The aim will be to get pydantic V2 to a place were the vast majority of tests continue to pass unchanged.</p> <p>Thereby guaranteeing (as much as possible) that the external interface to pydantic and its behaviour are unchanged.</p>"},{"location":"blog/pydantic-v2/#conversion-table","title":"Conversion Table","text":"<p>The table below provisionally defines what input value types are allowed to which field types.</p> <p>An updated and complete version of this table is available in V2 conversion table.</p> <p>Note</p> <p>Some type conversion shown here is a significant departure from existing behavior, we may have to provide a config flag for backwards compatibility for a few of them, however pydantic V2 cannot be entirely backward compatible, see pydantic-core#152.</p> Field Type Input Mode Input Source Conditions <code>str</code> <code>str</code> both python, JSON - <code>str</code> <code>bytes</code> lax python assumes UTF-8, error on unicode decoding error <code>str</code> <code>bytearray</code> lax python assumes UTF-8, error on unicode decoding error <code>bytes</code> <code>bytes</code> both python - <code>bytes</code> <code>str</code> both JSON - <code>bytes</code> <code>str</code> lax python - <code>bytes</code> <code>bytearray</code> lax python - <code>int</code> <code>int</code> strict python, JSON max abs value 2^64 - <code>i64</code> is used internally, <code>bool</code> explicitly forbidden <code>int</code> <code>int</code> lax python, JSON <code>i64</code> <code>int</code> <code>float</code> lax python, JSON <code>i64</code>, must be exact int, e.g. <code>f % 1 == 0</code>, <code>nan</code>, <code>inf</code> raise errors <code>int</code> <code>Decimal</code> lax python, JSON <code>i64</code>, must be exact int, e.g. <code>f % 1 == 0</code> <code>int</code> <code>bool</code> lax python, JSON - <code>int</code> <code>str</code> lax python, JSON <code>i64</code>, must be numeric only, e.g. <code>[0-9]+</code> <code>float</code> <code>float</code> strict python, JSON <code>bool</code> explicitly forbidden <code>float</code> <code>float</code> lax python, JSON - <code>float</code> <code>int</code> lax python, JSON - <code>float</code> <code>str</code> lax python, JSON must match <code>[0-9]+(\\.[0-9]+)?</code> <code>float</code> <code>Decimal</code> lax python - <code>float</code> <code>bool</code> lax python, JSON - <code>bool</code> <code>bool</code> both python, JSON - <code>bool</code> <code>int</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>float</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>Decimal</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>str</code> lax python, JSON allowed: <code>'f', 'n', 'no', 'off', 'false', 't', 'y', 'on', 'yes', 'true'</code> <code>None</code> <code>None</code> both python, JSON - <code>date</code> <code>date</code> both python - <code>date</code> <code>datetime</code> lax python must be exact date, eg. no H, M, S, f <code>date</code> <code>str</code> both JSON format <code>YYYY-MM-DD</code> <code>date</code> <code>str</code> lax python format <code>YYYY-MM-DD</code> <code>date</code> <code>bytes</code> lax python format <code>YYYY-MM-DD</code> (UTF-8) <code>date</code> <code>int</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date <code>date</code> <code>float</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date <code>datetime</code> <code>datetime</code> both python - <code>datetime</code> <code>date</code> lax python - <code>datetime</code> <code>str</code> both JSON format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate <code>datetime</code> <code>str</code> lax python format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate <code>datetime</code> <code>bytes</code> lax python format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate, (UTF-8) <code>datetime</code> <code>int</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate <code>datetime</code> <code>float</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate <code>time</code> <code>time</code> both python - <code>time</code> <code>str</code> both JSON format <code>HH:MM:SS.FFFFFF</code> etc. see speedate <code>time</code> <code>str</code> lax python format <code>HH:MM:SS.FFFFFF</code> etc. see speedate <code>time</code> <code>bytes</code> lax python format <code>HH:MM:SS.FFFFFF</code> etc. see speedate, (UTF-8) <code>time</code> <code>int</code> lax python, JSON interpreted as seconds, range 0 - 86399 <code>time</code> <code>float</code> lax python, JSON interpreted as seconds, range 0 - 86399.9* <code>time</code> <code>Decimal</code> lax python, JSON interpreted as seconds, range 0 - 86399.9* <code>timedelta</code> <code>timedelta</code> both python - <code>timedelta</code> <code>str</code> both JSON format ISO8601 etc. see speedate <code>timedelta</code> <code>str</code> lax python format ISO8601 etc. see speedate <code>timedelta</code> <code>bytes</code> lax python format ISO8601 etc. see speedate, (UTF-8) <code>timedelta</code> <code>int</code> lax python, JSON interpreted as seconds <code>timedelta</code> <code>float</code> lax python, JSON interpreted as seconds <code>timedelta</code> <code>Decimal</code> lax python, JSON interpreted as seconds <code>dict</code> <code>dict</code> both python - <code>dict</code> <code>Object</code> both JSON - <code>dict</code> <code>mapping</code> lax python must implement the mapping interface and have an <code>items()</code> method <code>TypedDict</code> <code>dict</code> both python - <code>TypedDict</code> <code>Object</code> both JSON - <code>TypedDict</code> <code>Any</code> both python builtins not allowed, uses <code>getattr</code>, requires <code>from_attributes=True</code> <code>TypedDict</code> <code>mapping</code> lax python must implement the mapping interface and have an <code>items()</code> method <code>list</code> <code>list</code> both python - <code>list</code> <code>Array</code> both JSON - <code>list</code> <code>tuple</code> lax python - <code>list</code> <code>set</code> lax python - <code>list</code> <code>frozenset</code> lax python - <code>list</code> <code>dict_keys</code> lax python - <code>tuple</code> <code>tuple</code> both python - <code>tuple</code> <code>Array</code> both JSON - <code>tuple</code> <code>list</code> lax python - <code>tuple</code> <code>set</code> lax python - <code>tuple</code> <code>frozenset</code> lax python - <code>tuple</code> <code>dict_keys</code> lax python - <code>set</code> <code>set</code> both python - <code>set</code> <code>Array</code> both JSON - <code>set</code> <code>list</code> lax python - <code>set</code> <code>tuple</code> lax python - <code>set</code> <code>frozenset</code> lax python - <code>set</code> <code>dict_keys</code> lax python - <code>frozenset</code> <code>frozenset</code> both python - <code>frozenset</code> <code>Array</code> both JSON - <code>frozenset</code> <code>list</code> lax python - <code>frozenset</code> <code>tuple</code> lax python - <code>frozenset</code> <code>set</code> lax python - <code>frozenset</code> <code>dict_keys</code> lax python - <code>is_instance</code> <code>Any</code> both python <code>isinstance()</code> check returns <code>True</code> <code>is_instance</code> - both JSON never valid <code>callable</code> <code>Any</code> both python <code>callable()</code> check returns <code>True</code> <code>callable</code> - both JSON never valid <p>The <code>ModelClass</code> validator (use to create instances of a class) uses the <code>TypedDict</code> validator, then creates an instance with <code>__dict__</code> and <code>__fields_set__</code> set, so same rules apply as <code>TypedDict</code>.</p>"},{"location":"errors/errors/","title":"Error Handling","text":"<p>Pydantic will raise <code>ValidationError</code> whenever it finds an error in the data it's validating.</p> <p>Note</p> <p>Validation code should not raise <code>ValidationError</code> itself, but rather raise <code>ValueError</code>, <code>TypeError</code> or <code>AssertionError</code> (or subclasses of <code>ValueError</code> or <code>TypeError</code>) which will be caught and used to populate <code>ValidationError</code>.</p> <p>One exception will be raised regardless of the number of errors found, that <code>ValidationError</code> will contain information about all the errors and how they happened.</p> <p>You can access these errors in several ways:</p> Method Description <code>e.errors()</code> Returns a list of errors found in the input data. <code>e.error_count()</code> Returns the number of errors found in <code>errors</code>. <code>e.json()</code> Returns a JSON representation of <code>errors</code>. <code>str(e)</code> Returns a human-readable representation of the errors. <p>Each error object contains:</p> Property Description <code>ctx</code> An optional object which contains values required to render the error message. <code>input</code> The input provided for validation. <code>loc</code> The error's location as a list. <code>msg</code> A human-readable explanation of the error. <code>type</code> A computer-readable identifier of the error type. <code>url</code> The URL to further information about the error. <p>The first item in the <code>loc</code> list will be the field where the error occurred, and if the field is a sub-model, subsequent items will be present to indicate the nested location of the error.</p> <p>As a demonstration:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError, conint\n\n\nclass Location(BaseModel):\n    lat: float = 0.1\n    lng: float = 10.1\n\n\nclass Model(BaseModel):\n    is_required: float\n    gt_int: conint(gt=42)\n    list_of_ints: List[int] = None\n    a_float: float = None\n    recursive_model: Location = None\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n    recursive_model={'lat': 4.2, 'lng': 'New York'},\n    gt_int=21,\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    5 validation errors for Model\n    is_required\n      Field required [type=missing, input_value={'list_of_ints': ['1', 2,...ew York'}, 'gt_int': 21}, input_type=dict]\n    gt_int\n      Input should be greater than 42 [type=greater_than, input_value=21, input_type=int]\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='not a float', input_type=str]\n    recursive_model.lng\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='New York', input_type=str]\n    \"\"\"\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    # print(e.json())\n    # TODO set back to .json() once we add it\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('is_required',),\n            'msg': 'Field required',\n            'input': {\n                'list_of_ints': ['1', 2, 'bad'],\n                'a_float': 'not a float',\n                'recursive_model': {'lat': 4.2, 'lng': 'New York'},\n                'gt_int': 21,\n            },\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n        {\n            'type': 'greater_than',\n            'loc': ('gt_int',),\n            'msg': 'Input should be greater than 42',\n            'input': 21,\n            'ctx': {'gt': 42},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('list_of_ints', 2),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'bad',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('a_float',),\n            'msg': 'Input should be a valid number, unable to parse string as an number',\n            'input': 'not a float',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('recursive_model', 'lng'),\n            'msg': 'Input should be a valid number, unable to parse string as an number',\n            'input': 'New York',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n    ]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError, conint\n\n\nclass Location(BaseModel):\n    lat: float = 0.1\n    lng: float = 10.1\n\n\nclass Model(BaseModel):\n    is_required: float\n    gt_int: conint(gt=42)\n    list_of_ints: list[int] = None\n    a_float: float = None\n    recursive_model: Location = None\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n    recursive_model={'lat': 4.2, 'lng': 'New York'},\n    gt_int=21,\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    5 validation errors for Model\n    is_required\n      Field required [type=missing, input_value={'list_of_ints': ['1', 2,...ew York'}, 'gt_int': 21}, input_type=dict]\n    gt_int\n      Input should be greater than 42 [type=greater_than, input_value=21, input_type=int]\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='not a float', input_type=str]\n    recursive_model.lng\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='New York', input_type=str]\n    \"\"\"\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    # print(e.json())\n    # TODO set back to .json() once we add it\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('is_required',),\n            'msg': 'Field required',\n            'input': {\n                'list_of_ints': ['1', 2, 'bad'],\n                'a_float': 'not a float',\n                'recursive_model': {'lat': 4.2, 'lng': 'New York'},\n                'gt_int': 21,\n            },\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n        {\n            'type': 'greater_than',\n            'loc': ('gt_int',),\n            'msg': 'Input should be greater than 42',\n            'input': 21,\n            'ctx': {'gt': 42},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('list_of_ints', 2),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'bad',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('a_float',),\n            'msg': 'Input should be a valid number, unable to parse string as an number',\n            'input': 'not a float',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('recursive_model', 'lng'),\n            'msg': 'Input should be a valid number, unable to parse string as an number',\n            'input': 'New York',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n    ]\n    \"\"\"\n</code></pre>"},{"location":"errors/errors/#custom-errors","title":"Custom Errors","text":"<p>In your custom data types or validators you should use <code>ValueError</code> or <code>AssertionError</code> to raise errors.</p> <p>See validators for more details on use of the <code>@validator</code> decorator.</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    foo: str\n\n    @field_validator('foo')\n    def value_must_equal_bar(cls, v):\n        if v != 'bar':\n            raise ValueError('value must be \"bar\"')\n\n        return v\n\n\ntry:\n    Model(foo='ber')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    foo\n      Value error, value must be \"bar\" [type=value_error, input_value='ber', input_type=str]\n    \"\"\"\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'value_error',\n            'loc': ('foo',),\n            'msg': 'Value error, value must be \"bar\"',\n            'input': 'ber',\n            'ctx': {'error': 'value must be \"bar\"'},\n            'url': 'https://errors.pydantic.dev/2/v/value_error',\n        }\n    ]\n    \"\"\"\n</code></pre> <p>You can also define your own error classes, which can specify a custom error code, message template, and context:</p> <pre><code>from pydantic_core import PydanticCustomError\n\nfrom pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    foo: str\n\n    @field_validator('foo')\n    def value_must_equal_bar(cls, v):\n        if v != 'bar':\n            raise PydanticCustomError(\n                'not_a_bar',\n                'value is not \"bar\", got \"{wrong_value}\"',\n                dict(wrong_value=v),\n            )\n        return v\n\n\ntry:\n    Model(foo='ber')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    foo\n      value is not \"bar\", got \"ber\" [type=not_a_bar, input_value='ber', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"errors/errors/#error-messages","title":"Error messages","text":"<p>Pydantic attempts to provide useful default error messages for validation and usage errors.</p> <p>We've provided documentation for default error codes in the following sections:</p> <ul> <li>Validation Errors</li> <li>Usage Errors</li> </ul>"},{"location":"errors/errors/#customize-error-messages","title":"Customize error messages","text":"<p>You can customize error messages by creating a custom error handler.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Dict, List\n\nfrom pydantic_core import ErrorDetails\n\nfrom pydantic import BaseModel, HttpUrl, ValidationError\n\nCUSTOM_MESSAGES = {\n    'int_parsing': 'This is not an integer! \ud83e\udd26',\n    'url_scheme': 'Hey, use the right URL scheme! I wanted {expected_schemes}.',\n}\n\n\ndef convert_errors(\n    e: ValidationError, custom_messages: Dict[str, str]\n) -&gt; List[ErrorDetails]:\n    new_errors: List[ErrorDetails] = []\n    for error in e.errors():\n        custom_message = custom_messages.get(error['type'])\n        if custom_message:\n            ctx = error.get('ctx')\n            error['msg'] = custom_message.format(**ctx) if ctx else custom_message\n        new_errors.append(error)\n    return new_errors\n\n\nclass Model(BaseModel):\n    a: int\n    b: HttpUrl\n\n\ntry:\n    Model(a='wrong', b='ftp://example.com')\nexcept ValidationError as e:\n    errors = convert_errors(e, CUSTOM_MESSAGES)\n    print(errors)\n\"\"\"\n    [\n        {\n            'type': 'int_parsing',\n            'loc': ('a',),\n            'msg': 'This is not an integer! \ud83e\udd26',\n            'input': 'wrong',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'url_scheme',\n            'loc': ('b',),\n            'msg': \"Hey, use the right URL scheme! I wanted 'http' or 'https'.\",\n            'input': 'ftp://example.com',\n            'ctx': {'expected_schemes': \"'http' or 'https'\"},\n            'url': 'https://errors.pydantic.dev/2/v/url_scheme',\n        },\n    ]\n    \"\"\"\n</code></pre> <pre><code>from pydantic_core import ErrorDetails\n\nfrom pydantic import BaseModel, HttpUrl, ValidationError\n\nCUSTOM_MESSAGES = {\n    'int_parsing': 'This is not an integer! \ud83e\udd26',\n    'url_scheme': 'Hey, use the right URL scheme! I wanted {expected_schemes}.',\n}\n\n\ndef convert_errors(\n    e: ValidationError, custom_messages: dict[str, str]\n) -&gt; list[ErrorDetails]:\n    new_errors: list[ErrorDetails] = []\n    for error in e.errors():\n        custom_message = custom_messages.get(error['type'])\n        if custom_message:\n            ctx = error.get('ctx')\n            error['msg'] = custom_message.format(**ctx) if ctx else custom_message\n        new_errors.append(error)\n    return new_errors\n\n\nclass Model(BaseModel):\n    a: int\n    b: HttpUrl\n\n\ntry:\n    Model(a='wrong', b='ftp://example.com')\nexcept ValidationError as e:\n    errors = convert_errors(e, CUSTOM_MESSAGES)\n    print(errors)\n\"\"\"\n    [\n        {\n            'type': 'int_parsing',\n            'loc': ('a',),\n            'msg': 'This is not an integer! \ud83e\udd26',\n            'input': 'wrong',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'url_scheme',\n            'loc': ('b',),\n            'msg': \"Hey, use the right URL scheme! I wanted 'http' or 'https'.\",\n            'input': 'ftp://example.com',\n            'ctx': {'expected_schemes': \"'http' or 'https'\"},\n            'url': 'https://errors.pydantic.dev/2/v/url_scheme',\n        },\n    ]\n    \"\"\"\n</code></pre> <p>A common use case would be to translate error messages. For example, in the above example, we could translate the error messages replacing the <code>CUSTOM_MESSAGES</code> dictionary with a dictionary of translations.</p>"},{"location":"integrations/datamodel_code_generator/","title":"Code Generation with datamodel-code-generator","text":"<p>The datamodel-code-generator project is a library and command-line utility to generate pydantic models from just about any data source, including:</p> <ul> <li>OpenAPI 3 (YAML/JSON)</li> <li>JSON Schema</li> <li>JSON/YAML Data (which will converted to JSON Schema)</li> </ul> <p>Whenever you find yourself with any data convertible JSON but without pydantic models, this tool will allow you to generate type-safe model hierarchies on demand.</p>"},{"location":"integrations/datamodel_code_generator/#installation","title":"Installation","text":"<pre><code>pip install datamodel-code-generator\n</code></pre>"},{"location":"integrations/datamodel_code_generator/#example","title":"Example","text":"<p>In this case, datamodel-code-generator creates pydantic models from a JSON Schema file. <pre><code>datamodel-codegen  --input person.json --input-file-type jsonschema --output model.py\n</code></pre></p> <p>person.json: <pre><code>{\n\"$id\": \"person.json\",\n\"$schema\": \"http://json-schema.org/draft-07/schema#\",\n\"title\": \"Person\",\n\"type\": \"object\",\n\"properties\": {\n\"first_name\": {\n\"type\": \"string\",\n\"description\": \"The person's first name.\"\n},\n\"last_name\": {\n\"type\": \"string\",\n\"description\": \"The person's last name.\"\n},\n\"age\": {\n\"description\": \"Age in years.\",\n\"type\": \"integer\",\n\"minimum\": 0\n},\n\"pets\": {\n\"type\": \"array\",\n\"items\": [\n{\n\"$ref\": \"#/definitions/Pet\"\n}\n]\n},\n\"comment\": {\n\"type\": \"null\"\n}\n},\n\"required\": [\n\"first_name\",\n\"last_name\"\n],\n\"definitions\": {\n\"Pet\": {\n\"properties\": {\n\"name\": {\n\"type\": \"string\"\n},\n\"age\": {\n\"type\": \"integer\"\n}\n}\n}\n}\n}\n</code></pre></p> <p>model.py: <pre><code># generated by datamodel-codegen:\n#   filename:  person.json\n#   timestamp: 2020-05-19T15:07:31+00:00\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom pydantic import BaseModel, Field, conint\n\n\nclass Pet(BaseModel):\n    name: str | None = None\n    age: int | None = None\n\n\nclass Person(BaseModel):\n    first_name: str = Field(..., description=\"The person's first name.\")\n    last_name: str = Field(..., description=\"The person's last name.\")\n    age: conint(ge=0) | None = Field(None, description='Age in years.')\n    pets: list[Pet] | None = None\n    comment: Any | None = None\n</code></pre></p> <p>More information can be found on the official documentation</p>"},{"location":"integrations/devtools/","title":"devtools","text":"<p>Note</p> <p>Admission: I (the primary developer of Pydantic) also develop python-devtools.</p> <p>python-devtools (<code>pip install devtools</code>) provides a number of tools which are useful during Python development, including <code>debug()</code> an alternative to <code>print()</code> which formats output in a way which should be easier to read than <code>print</code> as well as giving information about which file/line the print statement is on and what value was printed.</p> <p>Pydantic integrates with devtools by implementing the <code>__pretty__</code> method on most public classes.</p> <p>In particular <code>debug()</code> is useful when inspecting models:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from datetime import datetime\nfrom typing import List\n\nfrom devtools import debug\n\nfrom pydantic import BaseModel\n\n\nclass Address(BaseModel):\n    street: str\n    country: str\n    lat: float\n    lng: float\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n    signup_ts: datetime\n    friends: List[int]\n    address: Address\n\n\nuser = User(\n    id='123',\n    name='John Doe',\n    signup_ts='2019-06-01 12:22',\n    friends=[1234, 4567, 7890],\n    address=dict(street='Testing', country='uk', lat=51.5, lng=0),\n)\ndebug(user)\nprint('\\nshould be much easier read than:\\n')\nprint('user:', user)\n</code></pre> <pre><code>from datetime import datetime\n\nfrom devtools import debug\n\nfrom pydantic import BaseModel\n\n\nclass Address(BaseModel):\n    street: str\n    country: str\n    lat: float\n    lng: float\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n    signup_ts: datetime\n    friends: list[int]\n    address: Address\n\n\nuser = User(\n    id='123',\n    name='John Doe',\n    signup_ts='2019-06-01 12:22',\n    friends=[1234, 4567, 7890],\n    address=dict(street='Testing', country='uk', lat=51.5, lng=0),\n)\ndebug(user)\nprint('\\nshould be much easier read than:\\n')\nprint('user:', user)\n</code></pre> <p>Will output in your terminal:</p> <pre><code>\ndevtools_example.py:31 &lt;module&gt;\n    user: User(\nid=123,\nname='John Doe',\nsignup_ts=datetime.datetime(2019, 6, 1, 12, 22),\nfriends=[\n1234,\n4567,\n7890,\n],\naddress=Address(\nstreet='Testing',\ncountry='uk',\nlat=51.5,\nlng=0.0,\n),\n) (User)\n\nshould be much easier read than:\n\nuser: id=123 name='John Doe' signup_ts=datetime.datetime(2019, 6, 1, 12, 22) friends=[1234, 4567, 7890] address=Address(street='Testing', country='uk', lat=51.5, lng=0.0)</code></pre>"},{"location":"integrations/hypothesis/","title":"Hypothesis","text":"<p>Hypothesis is the Python library for property-based testing. Hypothesis can infer how to construct type-annotated classes, and supports builtin types, many standard library types, and generic types from the <code>typing</code> and <code>typing_extensions</code> modules by default.</p> <p>Pydantic v2.0 drops built-in support for Hypothesis and no more ships with the integrated Hypothesis plugin.</p> <p>We are temporarily removing the Hypothesis plugin in favor of another mechanism discussed here - Way to communicate more information between libraries \u00b7 Issue #37 \u00b7 annotated-types/annotated-types. It is also possible that Hypothesis plugin will be back in Pydantic v2.0+ (see V2: hypothesis plugin rewrite \u00b7 Issue #4682 \u00b7 pydantic/pydantic).</p>"},{"location":"integrations/mypy/","title":"Mypy","text":"<p>Pydantic works well with mypy right out of the box.</p> <p>However, Pydantic also ships with a mypy plugin that adds a number of important pydantic-specific features to mypy that improve its ability to type-check your code.</p> <p>For example, consider the following script:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    age: int\n    first_name = 'John'\n    last_name: Optional[str] = None\n    signup_ts: Optional[datetime] = None\n    list_of_ints: List[int]\n\n\nm = Model(age=42, list_of_ints=[1, '2', b'3'])\nprint(m.middle_name)  # not a model field!\nModel()  # will raise a validation error for age and list_of_ints\n</code></pre> <pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    age: int\n    first_name = 'John'\n    last_name: Optional[str] = None\n    signup_ts: Optional[datetime] = None\n    list_of_ints: list[int]\n\n\nm = Model(age=42, list_of_ints=[1, '2', b'3'])\nprint(m.middle_name)  # not a model field!\nModel()  # will raise a validation error for age and list_of_ints\n</code></pre> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    age: int\n    first_name = 'John'\n    last_name: str | None = None\n    signup_ts: datetime | None = None\n    list_of_ints: list[int]\n\n\nm = Model(age=42, list_of_ints=[1, '2', b'3'])\nprint(m.middle_name)  # not a model field!\nModel()  # will raise a validation error for age and list_of_ints\n</code></pre> <p>Without any special configuration, mypy catches one of the errors:</p> <pre><code>13: error: \"Model\" has no attribute \"middle_name\"\n</code></pre> <p>But with the plugin enabled, it catches both: <pre><code>13: error: \"Model\" has no attribute \"middle_name\"\n16: error: Missing named argument \"age\" for \"Model\"\n16: error: Missing named argument \"list_of_ints\" for \"Model\"\n</code></pre></p> <p>With the pydantic mypy plugin, you can fearlessly refactor your models knowing mypy will catch any mistakes if your field names or types change.</p> <p>There are other benefits too! See below for more details.</p>"},{"location":"integrations/mypy/#using-mypy-without-the-plugin","title":"Using mypy without the plugin","text":"<p>You can run your code through mypy with:</p> <pre><code>mypy \\\n--ignore-missing-imports \\\n--follow-imports=skip \\\n--strict-optional \\\npydantic_mypy_test.py\n</code></pre>"},{"location":"integrations/mypy/#strict-optional","title":"Strict Optional","text":"<p>For your code to pass with <code>--strict-optional</code>, you need to to use <code>Optional[]</code> or an alias of <code>Optional[]</code> for all fields with <code>None</code> as the default. (This is standard with mypy.)</p> <p>Pydantic provides a few useful optional or union types:</p> <ul> <li><code>NoneStr</code> aka. <code>Optional[str]</code></li> <li><code>NoneBytes</code> aka. <code>Optional[bytes]</code></li> <li><code>StrBytes</code> aka. <code>Union[str, bytes]</code></li> <li><code>NoneStrBytes</code> aka. <code>Optional[StrBytes]</code></li> </ul> <p>If these aren't sufficient you can of course define your own.</p>"},{"location":"integrations/mypy/#other-pydantic-interfaces","title":"Other Pydantic interfaces","text":"<p>Pydantic dataclasses and the <code>validate_arguments</code> decorator should also work well with mypy.</p>"},{"location":"integrations/mypy/#mypy-plugin-capabilities","title":"Mypy Plugin Capabilities","text":""},{"location":"integrations/mypy/#generate-a-signature-for-model__init__","title":"Generate a signature for <code>Model.__init__</code>","text":"<ul> <li>Any required fields that don't have dynamically-determined aliases will be included as required   keyword arguments.</li> <li>If <code>Config.populate_by_name=True</code>, the generated signature will use the field names,   rather than aliases.</li> <li>If <code>Config.extra=\"forbid\"</code> and you don't make use of dynamically-determined aliases, the generated signature   will not allow unexpected inputs.</li> <li>Optional: If the <code>init_forbid_extra</code> plugin setting is set to <code>True</code>, unexpected inputs to   <code>__init__</code> will raise errors even if <code>Config.extra</code> is not <code>\"forbid\"</code>.</li> <li>Optional: If the <code>init_typed</code> plugin setting is set to <code>True</code>, the generated signature   will use the types of the model fields (otherwise they will be annotated as <code>Any</code> to allow parsing).</li> </ul>"},{"location":"integrations/mypy/#generate-a-typed-signature-for-modelmodel_construct","title":"Generate a typed signature for <code>Model.model_construct</code>","text":"<ul> <li>The <code>model_construct</code> method is an alternative to <code>__init__</code>   when input data is known to be valid and should not be parsed. Because this method performs no runtime validation,   static checking is important to detect errors.</li> </ul>"},{"location":"integrations/mypy/#respect-configallow_mutation","title":"Respect <code>Config.allow_mutation</code>","text":"<ul> <li>If <code>Config.allow_mutation</code> is <code>False</code>, you'll get a mypy error if you try to change   the value of a model field; cf. faux immutability.</li> </ul>"},{"location":"integrations/mypy/#respect-configfrom_attributes","title":"Respect <code>Config.from_attributes</code>","text":"<ul> <li>If <code>Config.from_attributes</code> is <code>False</code>, you'll get a mypy error if you try to call <code>.from_orm()</code>;   cf. ORM mode</li> </ul>"},{"location":"integrations/mypy/#generate-a-signature-for-dataclasses","title":"Generate a signature for <code>dataclasses</code>","text":"<ul> <li>classes decorated with <code>@pydantic.dataclasses.dataclass</code> are type checked the same as standard Python dataclasses</li> <li>The <code>@pydantic.dataclasses.dataclass</code> decorator accepts a <code>config</code> keyword argument which has the same meaning as the <code>Config</code> sub-class.</li> </ul>"},{"location":"integrations/mypy/#respect-the-type-of-the-fields-default-and-default_factory","title":"Respect the type of the <code>Field</code>'s <code>default</code> and <code>default_factory</code>","text":"<ul> <li>Field with both a <code>default</code> and a <code>default_factory</code> will result in an error during static checking.</li> <li>The type of the <code>default</code> and <code>default_factory</code> value must be compatible with the one of the field.</li> </ul>"},{"location":"integrations/mypy/#warn-about-the-use-of-untyped-fields","title":"Warn about the use of untyped fields","text":"<ul> <li>You'll get a mypy error any time you assign a public attribute on a model without annotating its type</li> <li>If your goal is to set a ClassVar, you should explicitly annotate the field using typing.ClassVar</li> </ul>"},{"location":"integrations/mypy/#optional-capabilities","title":"Optional Capabilities:","text":""},{"location":"integrations/mypy/#prevent-the-use-of-required-dynamic-aliases","title":"Prevent the use of required dynamic aliases","text":"<ul> <li>If the <code>warn_required_dynamic_aliases</code> plugin setting is set to <code>True</code>, you'll get a mypy   error any time you use a dynamically-determined alias or alias generator on a model with   <code>Config.populate_by_name=False</code>.</li> <li>This is important because if such aliases are present, mypy cannot properly type check calls to <code>__init__</code>.   In this case, it will default to treating all arguments as optional.</li> </ul>"},{"location":"integrations/mypy/#enabling-the-plugin","title":"Enabling the Plugin","text":"<p>To enable the plugin, just add <code>pydantic.mypy</code> to the list of plugins in your mypy config file (this could be <code>mypy.ini</code> or <code>setup.cfg</code>).</p> <p>To get started, all you need to do is create a <code>mypy.ini</code> file with following contents: <pre><code>[mypy]\nplugins = pydantic.mypy\n</code></pre></p> <p>The plugin is compatible with mypy versions <code>&gt;=0.930</code>.</p> <p>See the plugin configuration docs for more details.</p>"},{"location":"integrations/mypy/#configuring-the-plugin","title":"Configuring the Plugin","text":"<p>To change the values of the plugin settings, create a section in your mypy config file called <code>[pydantic-mypy]</code>, and add any key-value pairs for settings you want to override.</p> <p>A <code>mypy.ini</code> file with all plugin strictness flags enabled (and some other mypy strictness flags, too) might look like:</p> <pre><code>[mypy]\nplugins = pydantic.mypy\n\nfollow_imports = silent\nwarn_redundant_casts = True\nwarn_unused_ignores = True\ndisallow_any_generics = True\ncheck_untyped_defs = True\nno_implicit_reexport = True\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = True\n\n[pydantic-mypy]\ninit_forbid_extra = True\ninit_typed = True\nwarn_required_dynamic_aliases = True\n</code></pre> <p>As of <code>mypy&gt;=0.900</code>, mypy config may also be included in the <code>pyproject.toml</code> file rather than <code>mypy.ini</code>. The same configuration as above would be:</p> <pre><code>[tool.mypy]\nplugins = [\n\"pydantic.mypy\"\n]\n\nfollow_imports = \"silent\"\nwarn_redundant_casts = true\nwarn_unused_ignores = true\ndisallow_any_generics = true\ncheck_untyped_defs = true\nno_implicit_reexport = true\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = true\n\n[tool.pydantic-mypy]\ninit_forbid_extra = true\ninit_typed = true\nwarn_required_dynamic_aliases = true\n</code></pre>"},{"location":"integrations/pycharm/","title":"PyCharm","text":"<p>While pydantic will work well with any IDE out of the box, a PyCharm plugin offering improved pydantic integration is available on the JetBrains Plugins Repository for PyCharm. You can install the plugin for free from the plugin marketplace (PyCharm's Preferences -&gt; Plugin -&gt; Marketplace -&gt; search \"pydantic\").</p> <p>The plugin currently supports the following features:</p> <ul> <li>For <code>pydantic.BaseModel.__init__</code>:</li> <li>Inspection</li> <li>Autocompletion</li> <li> <p>Type-checking</p> </li> <li> <p>For fields of <code>pydantic.BaseModel</code>:</p> </li> <li>Refactor-renaming fields updates <code>__init__</code> calls, and affects sub- and super-classes</li> <li>Refactor-renaming <code>__init__</code> keyword arguments updates field names, and affects sub- and super-classes</li> </ul> <p>More information can be found on the official plugin page and Github repository.</p>"},{"location":"integrations/rich/","title":"Rich","text":"<p>Pydantic models may be printed with the Rich library which will add additional formatting and color to the output. Here's an example:</p> <p></p> <p>See the Rich documentation on pretty printing for more information.</p>"},{"location":"integrations/visual_studio_code/","title":"Visual Studio Code","text":"<p>Pydantic works well with any editor or IDE out of the box because it's made on top of standard Python type annotations.</p> <p>When using Visual Studio Code (VS Code), there are some additional editor features supported, comparable to the ones provided by the PyCharm plugin.</p> <p>This means that you will have autocompletion (or \"IntelliSense\") and error checks for types and required arguments even while creating new Pydantic model instances.</p> <p></p>"},{"location":"integrations/visual_studio_code/#configure-vs-code","title":"Configure VS Code","text":"<p>To take advantage of these features, you need to make sure you configure VS Code correctly, using the recommended settings.</p> <p>In case you have a different configuration, here's a short overview of the steps.</p>"},{"location":"integrations/visual_studio_code/#install-pylance","title":"Install Pylance","text":"<p>You should use the Pylance extension for VS Code. It is the recommended, next-generation, official VS Code plug-in for Python.</p> <p>Pylance is installed as part of the Python Extension for VS Code by default, so it should probably just work. Otherwise, you can double check it's installed and enabled in your editor.</p>"},{"location":"integrations/visual_studio_code/#configure-your-environment","title":"Configure your environment","text":"<p>Then you need to make sure your editor knows the Python environment (probably a virtual environment) for your Python project.</p> <p>This would be the environment in where you installed Pydantic.</p>"},{"location":"integrations/visual_studio_code/#configure-pylance","title":"Configure Pylance","text":"<p>With the default configurations, you will get support for autocompletion, but Pylance might not check for type errors.</p> <p>You can enable type error checks from Pylance with these steps:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Type Checking Mode</code></li> <li>You will find an option under <code>Python \u203a Analysis: Type Checking Mode</code></li> <li>Set it to <code>basic</code> or <code>strict</code> (by default it's <code>off</code>)</li> </ul> <p></p> <p>Now you will not only get autocompletion when creating new Pydantic model instances but also error checks for required arguments.</p> <p></p> <p>And you will also get error checks for invalid data types.</p> <p></p> <p>Technical Details</p> <p>Pylance is the VS Code extension, it's closed source, but free to use. Underneath, Pylance uses an open source tool (also from Microsoft) called Pyright that does all the heavy lifting.</p> <p>You can read more about it in the Pylance Frequently Asked Questions.</p>"},{"location":"integrations/visual_studio_code/#configure-mypy","title":"Configure mypy","text":"<p>You might also want to configure mypy in VS Code to get mypy error checks inline in your editor (alternatively/additionally to Pylance).</p> <p>This would include the errors detected by the Pydantic mypy plugin, if you configured it.</p> <p>To enable mypy in VS Code, do the following:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Mypy Enabled</code></li> <li>You will find an option under <code>Python \u203a Linting: Mypy Enabled</code></li> <li>Check the box (by default it's unchecked)</li> </ul> <p></p>"},{"location":"integrations/visual_studio_code/#tips-and-tricks","title":"Tips and tricks","text":"<p>Here are some additional tips and tricks to improve your developer experience when using VS Code with Pydantic.</p>"},{"location":"integrations/visual_studio_code/#strict-errors","title":"Strict errors","text":"<p>The way this additional editor support works is that Pylance will treat your Pydantic models as if they were Python's pure <code>dataclasses</code>.</p> <p>And it will show strict type error checks about the data types passed in arguments when creating a new Pydantic model instance.</p> <p>In this example you can see that it shows that a <code>str</code> of <code>'23'</code> is not a valid <code>int</code> for the argument <code>age</code>.</p> <p></p> <p>It would expect <code>age=23</code> instead of <code>age='23'</code>.</p> <p>Nevertheless, the design, and one of the main features of Pydantic, is that it is very lenient with data types.</p> <p>It will actually accept the <code>str</code> with value <code>'23'</code> and will convert it to an <code>int</code> with value <code>23</code>.</p> <p>These strict error checks are very useful most of the time and can help you detect many bugs early. But there are cases, like with <code>age='23'</code>, where they could be inconvenient by reporting a \"false positive\" error.</p> <p>This example above with <code>age='23'</code> is intentionally simple, to show the error and the differences in types.</p> <p>But more common cases where these strict errors would be inconvenient would be when using more sophisticated data types, like <code>int</code> values for <code>datetime</code> fields, or <code>dict</code> values for Pydantic sub-models.</p> <p>For example, this is valid for Pydantic:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nclass Quest(BaseModel):\n    title: str\nknight: Knight\nquest = Quest(\n    title='To seek the Holy Grail', knight={'title': 'Sir Lancelot', 'age': 23}\n)\n</code></pre> <p>The type of the field <code>knight</code> is declared with the class <code>Knight</code> (a Pydantic model) and the code is passing a literal <code>dict</code> instead. This is still valid for Pydantic, and the <code>dict</code> would be automatically converted to a <code>Knight</code> instance.</p> <p>Nevertheless, it would be detected as a type error:</p> <p></p> <p>In those cases, there are several ways to disable or ignore strict errors in very specific places, while still preserving them in the rest of the code.</p> <p>Below are several techniques to achieve it.</p>"},{"location":"integrations/visual_studio_code/#disable-type-checks-in-a-line","title":"Disable type checks in a line","text":"<p>You can disable the errors for a specific line using a comment of:</p> <pre><code># type: ignore\n</code></pre> <p>or (to be specific to pylance/pyright):</p> <pre><code># pyright: ignore\n</code></pre> <p>(pyright is the language server used by Pylance.).</p> <p>coming back to the example with <code>age='23'</code>, it would be:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nlancelot = Knight(title='Sir Lancelot', age='23')  # pyright: ignore\n</code></pre> <p>that way Pylance and mypy will ignore errors in that line.</p> <p>Pros: it's a simple change in that line to remove errors there.</p> <p>Cons: any other error in that line will also be omitted, including type checks, misspelled arguments, required arguments not provided, etc.</p>"},{"location":"integrations/visual_studio_code/#override-the-type-of-a-variable","title":"Override the type of a variable","text":"<p>You can also create a variable with the value you want to use and declare it's type explicitly with <code>Any</code>.</p> <pre><code>from typing import Any\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\nage_str: Any = '23'\nlancelot = Knight(title='Sir Lancelot', age=age_str)\n</code></pre> <p>that way Pylance and mypy will interpret the variable <code>age_str</code> as if they didn't know its type, instead of knowing it has a type of <code>str</code> when an <code>int</code> was expected (and then showing the corresponding error).</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments.</p> <p>Cons: it requires importing <code>Any</code> and a new variable in a new line for each argument that needs ignoring errors.</p>"},{"location":"integrations/visual_studio_code/#override-the-type-of-a-value-with-cast","title":"Override the type of a value with <code>cast</code>","text":"<p>The same idea from the previous example can be put on the same line with the help of <code>cast()</code>.</p> <p>This way, the type declaration of the value is overridden inline, without requiring another variable.</p> <pre><code>from typing import Any, cast\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\nlancelot = Knight(title='Sir Lancelot', age=cast(Any, '23'))\n</code></pre> <p><code>cast(Any, '23')</code> doesn't affect the value, it's still just <code>'23'</code>, but now Pylance and mypy will assume it is of type <code>Any</code>, which means, they will act as if they didn't know the type of the value.</p> <p>So, this is the equivalent of the previous example, without the additional variable.</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments. There's no need for additional variables.</p> <p>Cons: it requires importing <code>Any</code> and <code>cast</code>, and if you are not used to using <code>cast()</code>, it could seem strange at first.</p>"},{"location":"integrations/visual_studio_code/#config-in-class-arguments","title":"Config in class arguments","text":"<p>Pydantic has a rich set of Model Configurations available.</p> <p>These configurations can be set in an internal <code>class Config</code> on each model:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    model_config = dict(frozen=True)\n    title: str\n    age: int\n    color: str = 'blue'\n</code></pre> <p>or passed as keyword arguments when defining the model class:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel, frozen=True):\ntitle: str\n    age: int\n    color: str = 'blue'\n</code></pre> <p>The specific configuration <code>frozen</code> (in beta) has a special meaning.</p> <p>It prevents other code from changing a model instance once it's created, keeping it \"frozen\".</p> <p>When using the second version to declare <code>frozen=True</code> (with keyword arguments in the class definition), Pylance can use it to help you check in your code and detect errors when something is trying to set values in a model that is \"frozen\".</p> <p></p>"},{"location":"integrations/visual_studio_code/#adding-a-default-with-field","title":"Adding a default with <code>Field</code>","text":"<p>Pylance/pyright requires <code>default</code> to be a keyword argument to <code>Field</code> in order to infer that the field is optional.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Knight(BaseModel):\n    title: str = Field(default='Sir Lancelot')  # this is okay\n    age: int = Field(\n        23\n    )  # this works fine at runtime but will case an error for pyright\n\n\nlance = Knight()  # error: Argument missing for parameter \"age\"\n</code></pre> <p>This is a limitation of dataclass transforms and cannot be fixed in pydantic.</p>"},{"location":"integrations/visual_studio_code/#technical-details","title":"Technical Details","text":"<p>Warning</p> <p>As a Pydantic user, you don't need the details below. Feel free to skip the rest of this section.</p> <p>These details are only useful for other library authors, etc.</p> <p>This additional editor support works by implementing the proposed draft standard for Dataclass Transform.</p> <p>The proposed draft standard is written by Eric Traut, from the Microsoft team, the same author of the open source package Pyright (used by Pylance to provide Python support in VS Code).</p> <p>The intention of the standard is to provide a way for libraries like Pydantic and others to tell editors and tools that they (the editors) should treat these libraries (e.g. Pydantic) as if they were <code>dataclasses</code>, providing autocompletion, type checks, etc.</p> <p>The draft standard also includes an Alternate Form for early adopters, like Pydantic, to add support for it right away, even before the new draft standard is finished and approved.</p> <p>This new draft standard, with the Alternate Form, is already supported by Pyright, so it can be used via Pylance in VS Code.</p> <p>As it is being proposed as an official standard for Python, other editors can also easily add support for it.</p> <p>And authors of other libraries similar to Pydantic can also easily adopt the standard right away (using the \"Alternate Form\") and get the benefits of these additional editor features.</p>"},{"location":"usage/computed_fields/","title":"Computed fields","text":""},{"location":"usage/computed_fields/#field-with-computed-value-based-on-other-fields","title":"Field with computed value based on other fields","text":"<p>Computed fields allow <code>property</code> and <code>cached_property</code> to be included when serializing models or dataclasses.</p> <pre><code>from pydantic import BaseModel, computed_field\n\n\nclass Rectangle(BaseModel):\n    width: int\n    length: int\n\n    @computed_field\n    @property\n    def area(self) -&gt; int:\n        return self.width * self.length\n\n\nprint(Rectangle(width=3, length=2).model_dump())\n#&gt; {'width': 3, 'length': 2, 'area': 6}\n</code></pre> <p>If the <code>computed_field</code> decorator is applied to a bare function (e.g. a function without the <code>@property</code> or <code>@cached_property</code> decorator) it will wrap the function in <code>property</code> itself. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of <code>@property</code> is recommended.</p> <p>Mypy Warning</p> <p>Even with the <code>@property</code> or <code>@cached_property</code> applied to your function before <code>@computed_field</code>, mypy won't be happy because of this issue, you'll need to add <code># type: ignore[misc]</code> to the <code>@computed_field</code> line.</p> <p>In contract, pyright works nicely with <code>@computed_field</code>.</p> <pre><code>import random\nfrom functools import cached_property\n\nfrom pydantic import BaseModel, computed_field\n\n\nclass Square(BaseModel):\n    width: float\n\n    @computed_field\n    def area(self) -&gt; float:  # converted to a `property` by `computed_field`\n        return round(self.width**2, 2)\n\n    @area.setter\n    def area(self, new_area: float) -&gt; None:\n        self.width = new_area**0.5\n\n    @computed_field(alias='the magic number', repr=False)\n    @cached_property\n    def random_number(self) -&gt; int:\n        return random.randint(0, 1_000)\n\n\nsquare = Square(width=1.3)\n\n# `random_number` does not appear in representation\nprint(repr(square))\n#&gt; Square(width=1.3, area=1.69)\n\nprint(square.random_number)\n#&gt; 3\n\n# same random number as before (cached as expected)\nprint(square.model_dump())\n#&gt; {'width': 1.3, 'area': 1.69, 'random_number': 3}\n\nsquare.area = 4\n\nprint(square.model_dump_json(by_alias=True))\n#&gt; {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\n</code></pre>"},{"location":"usage/conversion_table/","title":"Conversion table","text":"Field Type Input Mode Input Source Conditions <code>str</code> <code>str</code> Strict Python &amp; JSON <code>str</code> <code>bytes</code> Lax Python Assumes UTF-8, error on unicode decoding error. <code>str</code> <code>bytearray</code> Lax Python Assumes UTF-8, error on unicode decoding error. <code>bytes</code> <code>bytes</code> Strict Python <code>bytes</code> <code>str</code> Strict JSON <code>bytes</code> <code>str</code> Lax Python <code>bytes</code> <code>bytearray</code> Lax Python <code>int</code> <code>int</code> Strict Python &amp; JSON Max abs value <code>2^64</code> - <code>i64</code> is used internally, <code>bool</code> explicitly forbidden. <code>int</code> <code>int</code> Lax Python &amp; JSON <code>i64</code>. Limits <code>numbers &gt; (2 ^ 63) - 1</code> to <code>(2 ^ 63) - 1</code>. <code>int</code> <code>float</code> Lax Python &amp; JSON <code>i64</code>, Must be exact int, e.g. <code>val % 1 == 0</code>, raises error for <code>nan</code>, <code>inf</code>. <code>int</code> <code>Decimal</code> Lax Python <code>i64</code>, Must be exact int, e.g. <code>val % 1 == 0</code>. <code>int</code> <code>bool</code> Lax Python &amp; JSON <code>int</code> <code>str</code> Lax Python &amp; JSON <code>i64</code>, Must be numeric only, e.g. <code>[0-9]+</code>. <code>int</code> <code>bytes</code> Lax Python <code>i64</code>, Must be numeric only, e.g. <code>[0-9]+</code>. <code>float</code> <code>float</code> Strict Python &amp; JSON <code>bool</code> explicitly forbidden. <code>float</code> <code>int</code> Strict Python &amp; JSON <code>float</code> <code>str</code> Lax Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>bytes</code> Lax Python Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>Decimal</code> Lax Python <code>float</code> <code>bool</code> Lax Python &amp; JSON <code>bool</code> <code>bool</code> Strict Python &amp; JSON <code>bool</code> <code>int</code> Lax Python &amp; JSON Allowed values: <code>0, 1</code>. <code>bool</code> <code>float</code> Lax Python &amp; JSON Allowed values: <code>0.0, 1.0</code>. <code>bool</code> <code>Decimal</code> Lax Python Allowed values: <code>Decimal(0), Decimal(1)</code>. <code>bool</code> <code>str</code> Lax Python &amp; JSON Allowed values: <code>'f'</code>, <code>'n'</code>, <code>'no'</code>, <code>'off'</code>, <code>'false'</code>, <code>'False'</code>, <code>'t'</code>, <code>'y'</code>, <code>'on'</code>, <code>'yes'</code>, <code>'true'</code>, <code>'True'</code>. <code>None</code> <code>None</code> Strict Python &amp; JSON <code>date</code> <code>date</code> Strict Python <code>date</code> <code>datetime</code> Lax Python Must be exact date, eg. no <code>H</code>, <code>M</code>, <code>S</code>, <code>f</code>. <code>date</code> <code>str</code> Lax Python &amp; JSON Format: <code>YYYY-MM-DD</code>. <code>date</code> <code>bytes</code> Lax Python Format: <code>YYYY-MM-DD</code> (UTF-8). <code>date</code> <code>int</code> Lax Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>float</code> Lax Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>Decimal</code> Lax Python Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>datetime</code> <code>datetime</code> Strict Python <code>datetime</code> <code>date</code> Lax Python <code>datetime</code> <code>str</code> Lax Python &amp; JSON Format: <code>YYYY-MM-DDTHH:MM:SS.f</code>. See speedate. <code>datetime</code> <code>bytes</code> Lax Python Format: <code>YYYY-MM-DDTHH:MM:SS.f</code>. See speedate, (UTF-8). <code>datetime</code> <code>int</code> Lax Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>float</code> Lax Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>Decimal</code> Lax Python Interpreted as seconds or ms from epoch, see speedate. <code>time</code> <code>time</code> Strict Python <code>time</code> <code>str</code> Lax Python &amp; JSON Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>bytes</code> Lax Python Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>int</code> Lax Python &amp; JSON Interpreted as seconds, range <code>0 - 86399</code>. <code>time</code> <code>float</code> Lax Python &amp; JSON Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>time</code> <code>Decimal</code> Lax Python Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>timedelta</code> <code>timedelta</code> Strict Python <code>timedelta</code> <code>str</code> Lax Python &amp; JSON Format: <code>ISO8601</code>. See speedate. <code>timedelta</code> <code>bytes</code> Lax Python Format: <code>ISO8601</code>. See speedate, (UTF-8). <code>timedelta</code> <code>int</code> Lax Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>float</code> Lax Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>Decimal</code> Lax Python Interpreted as seconds. <code>dict</code> <code>dict</code> Strict Python <code>dict</code> <code>Object</code> Strict JSON <code>dict</code> <code>Mapping</code> Lax Python Must implement the mapping interface and have an <code>items()</code> method. <code>TypedDict</code> <code>dict</code> Strict Python <code>TypedDict</code> <code>Object</code> Strict JSON <code>TypedDict</code> <code>Any</code> Strict Python <code>TypedDict</code> <code>Mapping</code> Lax Python Must implement the mapping interface and have an <code>items()</code> method. <code>list</code> <code>list</code> Strict Python <code>list</code> <code>Array</code> Strict JSON <code>list</code> <code>tuple</code> Lax Python <code>list</code> <code>set</code> Lax Python <code>list</code> <code>frozenset</code> Lax Python <code>list</code> <code>deque</code> Lax Python <code>list</code> <code>dict_keys</code> Lax Python <code>list</code> <code>dict_values</code> Lax Python <code>tuple</code> <code>tuple</code> Strict Python <code>tuple</code> <code>Array</code> Strict JSON <code>tuple</code> <code>list</code> Lax Python <code>tuple</code> <code>set</code> Lax Python <code>tuple</code> <code>frozenset</code> Lax Python <code>tuple</code> <code>deque</code> Lax Python <code>tuple</code> <code>dict_keys</code> Lax Python <code>tuple</code> <code>dict_values</code> Lax Python <code>set</code> <code>set</code> Strict Python <code>set</code> <code>Array</code> Strict JSON <code>set</code> <code>list</code> Lax Python <code>set</code> <code>tuple</code> Lax Python <code>set</code> <code>frozenset</code> Lax Python <code>set</code> <code>deque</code> Lax Python <code>set</code> <code>dict_keys</code> Lax Python <code>set</code> <code>dict_values</code> Lax Python <code>frozenset</code> <code>frozenset</code> Strict Python <code>frozenset</code> <code>Array</code> Strict JSON <code>frozenset</code> <code>list</code> Lax Python <code>frozenset</code> <code>tuple</code> Lax Python <code>frozenset</code> <code>set</code> Lax Python <code>frozenset</code> <code>deque</code> Lax Python <code>frozenset</code> <code>dict_keys</code> Lax Python <code>frozenset</code> <code>dict_values</code> Lax Python <code>isinstance</code> <code>Any</code> Strict Python <code>isinstance()</code> check returns <code>True</code>. <code>isinstance</code> <code>-</code> Strict JSON Never valid. <code>callable</code> <code>Any</code> Strict Python <code>callable()</code> check returns <code>True</code>. <code>callable</code> `` Strict JSON Never valid. <code>deque</code> <code>deque</code> Strict Python <code>deque</code> <code>Array</code> Strict Json <code>deque</code> <code>list</code> Lax Python <code>deque</code> <code>tuple</code> Lax Python <code>deque</code> <code>set</code> Lax Python <code>deque</code> <code>frozenset</code> Lax Python <code>Any</code> <code>Any</code> Strict Python &amp; JSON <code>NamedTuple</code> <code>NamedTuple</code> Strict Python <code>NamedTuple</code> <code>Array</code> Strict JSON <code>NamedTuple</code> <code>namedtuple</code> Strict Python <code>NamedTuple</code> <code>tuple</code> Strict Python <code>NamedTuple</code> <code>list</code> Strict Python <code>NamedTuple</code> <code>dict</code> Strict Python <code>namedtuple</code> <code>namedtuple</code> Strict Python <code>namedtuple</code> <code>Array</code> Strict JSON <code>namedtuple</code> <code>NamedTuple</code> Strict Python <code>namedtuple</code> <code>tuple</code> Strict Python <code>namedtuple</code> <code>list</code> Strict Python <code>namedtuple</code> <code>dict</code> Strict Python <code>Sequence</code> <code>list</code> Strict Python <code>Sequence</code> <code>Array</code> Strict JSON <code>Sequence</code> <code>tuple</code> Lax Python <code>Sequence</code> <code>deque</code> Lax Python <code>Iterable</code> <code>list</code> Strict Python <code>Iterable</code> <code>Array</code> Strict JSON <code>Iterable</code> <code>tuple</code> Strict Python <code>Iterable</code> <code>set</code> Strict Python <code>Iterable</code> <code>frozenset</code> Strict Python <code>Iterable</code> <code>deque</code> Strict Python <code>Type</code> <code>Type</code> Strict Python <code>Pattern</code> <code>str</code> Strict Python &amp; JSON Input should be a valid pattern. <code>Pattern</code> <code>bytes</code> Strict Python Input should be a valid pattern. <code>IPv4Address</code> <code>IPv4Address</code> Strict Python <code>IPv4Address</code> <code>IPv4Interface</code> Strict Python <code>IPv4Address</code> <code>str</code> Strict JSON <code>IPv4Address</code> <code>str</code> Lax Python &amp; JSON <code>IPv4Address</code> <code>bytes</code> Lax Python <code>IPv4Address</code> <code>int</code> Lax Python integer representing the IP address, should be less than <code>2**32</code> <code>IPv4Interface</code> <code>IPv4Interface</code> Strict Python <code>IPv4Interface</code> <code>str</code> Strict JSON <code>IPv4Interface</code> <code>IPv4Address</code> Lax Python &amp; JSON <code>IPv4Interface</code> <code>str</code> Lax Python &amp; JSON <code>IPv4Interface</code> <code>bytes</code> Lax Python <code>IPv4Interface</code> <code>tuple</code> Lax Python <code>IPv4Interface</code> <code>int</code> Lax Python integer representing the IP address, should be less than <code>2**32</code> <code>IPv4Network</code> <code>IPv4Network</code> Strict Python <code>IPv4Network</code> <code>str</code> Strict JSON <code>IPv4Network</code> <code>IPv4Address</code> Lax Python &amp; JSON <code>IPv4Network</code> <code>IPv4Interface</code> Lax Python &amp; JSON <code>IPv4Network</code> <code>str</code> Lax Python &amp; JSON <code>IPv4Network</code> <code>bytes</code> Lax Python <code>IPv4Network</code> <code>int</code> Lax Python integer representing the IP network, should be less than <code>2**32</code> <code>IPv6Address</code> <code>IPv6Address</code> Strict Python <code>IPv6Address</code> <code>IPv6Interface</code> Strict Python <code>IPv6Address</code> <code>str</code> Strict JSON <code>IPv6Address</code> <code>str</code> Lax Python &amp; JSON <code>IPv6Address</code> <code>bytes</code> Lax Python <code>IPv6Address</code> <code>int</code> Lax Python integer representing the IP address, should be less than <code>2**128</code> <code>IPv6Interface</code> <code>IPv6Interface</code> Strict Python <code>IPv6Interface</code> <code>str</code> Strict JSON <code>IPv6Interface</code> <code>IPv6Address</code> Lax Python &amp; JSON <code>IPv6Interface</code> <code>str</code> Lax Python &amp; JSON <code>IPv6Interface</code> <code>bytes</code> Lax Python <code>IPv6Interface</code> <code>tuple</code> Lax Python <code>IPv6Interface</code> <code>int</code> Lax Python integer representing the IP address, should be less than <code>2**128</code> <code>IPv6Network</code> <code>IPv6Network</code> Strict Python <code>IPv6Network</code> <code>str</code> Strict JSON <code>IPv6Network</code> <code>IPv6Address</code> Lax Python &amp; JSON <code>IPv6Network</code> <code>IPv6Interface</code> Lax Python &amp; JSON <code>IPv6Network</code> <code>str</code> Lax Python &amp; JSON <code>IPv6Network</code> <code>bytes</code> Lax Python <code>IPv6Network</code> <code>int</code> Lax Python integer representing the IP address, should be less than <code>2**128</code> <code>Enum</code> <code>Enum</code> Strict Python <code>Enum</code> <code>Any</code> Strict JSON Input value should be convertible to enum values. <code>Enum</code> <code>Any</code> Lax Python Input value should be convertible to enum values. <code>IntEnum</code> <code>IntEnum</code> Strict Python <code>IntEnum</code> <code>Any</code> Strict JSON Input value should be convertible to enum values. <code>IntEnum</code> <code>Any</code> Lax Python Input value should be convertible to enum values. <code>Decimal</code> <code>Decimal</code> Strict Python <code>Decimal</code> <code>int</code> Strict JSON <code>Decimal</code> <code>str</code> Strict JSON <code>Decimal</code> <code>float</code> Strict JSON <code>Decimal</code> <code>int</code> Lax Python &amp; JSON <code>Decimal</code> <code>str</code> Lax Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>Decimal</code> <code>float</code> Lax Python &amp; JSON <code>Path</code> <code>Path</code> Strict Python <code>Path</code> <code>str</code> Strict JSON <code>Path</code> <code>str</code> Lax Python <code>UUID</code> <code>UUID</code> Strict Python <code>UUID</code> <code>str</code> Strict JSON <code>UUID</code> <code>str</code> Lax Python <code>ByteSize</code> <code>str</code> Strict Python &amp; JSON <code>ByteSize</code> <code>int</code> Strict Python &amp; JSON <code>ByteSize</code> <code>float</code> Strict Python &amp; JSON <code>ByteSize</code> <code>Decimal</code> Strict Python"},{"location":"usage/dataclasses/","title":"Dataclasses","text":"<p>If you don't want to use pydantic's <code>BaseModel</code> you can instead get the same data validation on standard dataclasses (introduced in Python 3.7).</p> <pre><code>from datetime import datetime\n\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n\n\nuser = User(id='42', signup_ts='2032-06-21T12:00')\nprint(user)\n#&gt; User(id=42, name='John Doe', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\n</code></pre> <p>Note</p> <p>Keep in mind that <code>pydantic.dataclasses.dataclass</code> is not a replacement for <code>pydantic.BaseModel</code> (with a small difference in how initialization hooks work). <code>pydantic.dataclasses.dataclass</code> provides a similar functionality to <code>dataclasses.dataclass</code> with the addition of Pydantic validation. There are cases where subclassing <code>pydantic.BaseModel</code> is the better choice.</p> <p>For more information and discussion see pydantic/pydantic#710.</p> <p>You can use all the standard pydantic field types. Note, however, that arguments passed to constructor will be copied in order to perform validation and, where necessary coercion.</p> <p>The schema can be accessed by TypeAdapter. Also, fields that require a <code>default_factory</code> can be specified by either a <code>pydantic.Field</code> or a <code>dataclasses.field</code>.</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>import dataclasses\nfrom typing import List, Optional\n\nfrom pydantic import Field, TypeAdapter\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: List[int] = dataclasses.field(default_factory=lambda: [0])\n    age: Optional[int] = dataclasses.field(\n        default=None,\n        metadata=dict(title='The age of the user', description='do not lie!'),\n    )\n    height: Optional[int] = Field(None, title='The height in cm', ge=50, le=300)\n\n\nuser = User(id='42')\nprint(TypeAdapter(User).json_schema())\n\"\"\"\n{\n    'properties': {\n        'age': {\n            'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n            'default': None,\n            'description': 'do not lie!',\n            'title': 'The age of the user',\n        },\n        'friends': {'items': {'type': 'integer'}, 'title': 'Friends', 'type': 'array'},\n        'height': {\n            'anyOf': [\n                {'maximum': 300, 'minimum': 50, 'type': 'integer'},\n                {'type': 'null'},\n            ],\n            'default': None,\n            'title': 'The height in cm',\n        },\n        'id': {'title': 'Id', 'type': 'integer'},\n        'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'},\n    },\n    'required': ['id'],\n    'title': 'User',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <pre><code>import dataclasses\nfrom typing import Optional\n\nfrom pydantic import Field, TypeAdapter\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\n    age: Optional[int] = dataclasses.field(\n        default=None,\n        metadata=dict(title='The age of the user', description='do not lie!'),\n    )\n    height: Optional[int] = Field(None, title='The height in cm', ge=50, le=300)\n\n\nuser = User(id='42')\nprint(TypeAdapter(User).json_schema())\n\"\"\"\n{\n    'properties': {\n        'age': {\n            'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n            'default': None,\n            'description': 'do not lie!',\n            'title': 'The age of the user',\n        },\n        'friends': {'items': {'type': 'integer'}, 'title': 'Friends', 'type': 'array'},\n        'height': {\n            'anyOf': [\n                {'maximum': 300, 'minimum': 50, 'type': 'integer'},\n                {'type': 'null'},\n            ],\n            'default': None,\n            'title': 'The height in cm',\n        },\n        'id': {'title': 'Id', 'type': 'integer'},\n        'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'},\n    },\n    'required': ['id'],\n    'title': 'User',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <pre><code>import dataclasses\n\nfrom pydantic import Field, TypeAdapter\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\n    age: int | None = dataclasses.field(\n        default=None,\n        metadata=dict(title='The age of the user', description='do not lie!'),\n    )\n    height: int | None = Field(None, title='The height in cm', ge=50, le=300)\n\n\nuser = User(id='42')\nprint(TypeAdapter(User).json_schema())\n\"\"\"\n{\n    'properties': {\n        'age': {\n            'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n            'default': None,\n            'description': 'do not lie!',\n            'title': 'The age of the user',\n        },\n        'friends': {'items': {'type': 'integer'}, 'title': 'Friends', 'type': 'array'},\n        'height': {\n            'anyOf': [\n                {'maximum': 300, 'minimum': 50, 'type': 'integer'},\n                {'type': 'null'},\n            ],\n            'default': None,\n            'title': 'The height in cm',\n        },\n        'id': {'title': 'Id', 'type': 'integer'},\n        'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'},\n    },\n    'required': ['id'],\n    'title': 'User',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p><code>pydantic.dataclasses.dataclass</code>'s arguments are the same as the standard decorator, except one extra keyword argument <code>config</code> which has the same meaning as model_config.</p> <p>Warning</p> <p>After v1.2, The Mypy plugin must be installed to type check pydantic dataclasses.</p> <p>For more information about combining validators with dataclasses, see dataclass validators.</p>"},{"location":"usage/dataclasses/#dataclass-config","title":"Dataclass Config","text":"<p>If you want to modify the <code>config</code> like you would with a <code>BaseModel</code>, you have two options:</p> <pre><code>from pydantic import ConfigDict\nfrom pydantic.dataclasses import dataclass\n\n\n# Option 1 - use directly a dict\n# Note: `mypy` will still raise typo error\n@dataclass(config=dict(validate_assignment=True))  # (1)!\nclass MyDataclass1:\n    a: int\n\n\n# Option 2 - use `ConfigDict`\n# (same as before at runtime since it's a `TypedDict` but with intellisense)\n@dataclass(config=ConfigDict(validate_assignment=True))\nclass MyDataclass2:\n    a: int\n</code></pre> <ol> <li>You can read more about <code>validate_assignment</code> in model_config.</li> </ol> <p>Warning</p> <p>After v1.10, pydantic dataclasses support <code>Config.extra</code> but some default behaviour of stdlib dataclasses may prevail. For example, when <code>print</code>ing a pydantic dataclass with allowed extra fields, it will still use the <code>__str__</code> method of stdlib dataclass and show only the required fields. This may be improved further in the future.</p>"},{"location":"usage/dataclasses/#nested-dataclasses","title":"Nested dataclasses","text":"<p>Nested dataclasses are supported both in dataclasses and normal models.</p> <pre><code>from pydantic import AnyUrl\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass NavbarButton:\n    href: AnyUrl\n\n\n@dataclass\nclass Navbar:\n    button: NavbarButton\n\n\nnavbar = Navbar(button={'href': 'https://example.com'})\nprint(navbar)\n#&gt; Navbar(button=NavbarButton(href=Url('https://example.com/')))\n</code></pre> <p>Dataclasses attributes can be populated by tuples, dictionaries or instances of the dataclass itself.</p>"},{"location":"usage/dataclasses/#stdlib-dataclasses-and-pydantic-dataclasses","title":"Stdlib dataclasses and pydantic dataclasses","text":""},{"location":"usage/dataclasses/#inherit-from-stdlib-dataclasses","title":"Inherit from stdlib dataclasses","text":"<p>Stdlib dataclasses (nested or not) can also be inherited and pydantic will automatically validate all the inherited fields.</p> <pre><code>import dataclasses\n\nimport pydantic\n\n\n@dataclasses.dataclass\nclass Z:\n    z: int\n\n\n@dataclasses.dataclass\nclass Y(Z):\n    y: int = 0\n\n\n@pydantic.dataclasses.dataclass\nclass X(Y):\n    x: int = 0\n\n\nfoo = X(x=b'1', y='2', z='3')\nprint(foo)\n#&gt; X(z=3, y=2, x=1)\n\ntry:\n    X(z='pika')\nexcept pydantic.ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for X\n    z\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='pika', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/dataclasses/#use-of-stdlib-dataclasses-with-basemodel","title":"Use of stdlib dataclasses with <code>BaseModel</code>","text":"<p>Bear in mind that stdlib dataclasses (nested or not) are automatically converted into pydantic dataclasses when mixed with <code>BaseModel</code>! Furthermore the generated pydantic dataclass will have the exact same configuration (<code>order</code>, <code>frozen</code>, ...) as the original one.</p> Python 3.7 and abovePython 3.10 and above <pre><code>import dataclasses\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\n@dataclasses.dataclass(frozen=True)\nclass User:\n    name: str\n\n\n@dataclasses.dataclass\nclass File:\n    filename: str\n    last_modification_time: Optional[datetime] = None\n\n\nclass Foo(BaseModel):\n    file: File\n    user: Optional[User] = None\n\n\nfile = File(\n    filename=['not', 'a', 'string'],\n    last_modification_time='2020-01-01T00:00',\n)  # nothing is validated as expected\nprint(file)\n#&gt; File(filename=['not', 'a', 'string'], last_modification_time='2020-01-01T00:00')\n\ntry:\n    Foo(file=file)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Foo\n    file.filename\n      Input should be a valid string [type=string_type, input_value=['not', 'a', 'string'], input_type=list]\n    \"\"\"\n\nfoo = Foo(file=File(filename='myfile'), user=User(name='pika'))\ntry:\n    foo.user.name = 'bulbi'\nexcept dataclasses.FrozenInstanceError as e:\n    print(e)\n    #&gt; cannot assign to field 'name'\n</code></pre> <pre><code>import dataclasses\nfrom datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\n@dataclasses.dataclass(frozen=True)\nclass User:\n    name: str\n\n\n@dataclasses.dataclass\nclass File:\n    filename: str\n    last_modification_time: datetime | None = None\n\n\nclass Foo(BaseModel):\n    file: File\n    user: User | None = None\n\n\nfile = File(\n    filename=['not', 'a', 'string'],\n    last_modification_time='2020-01-01T00:00',\n)  # nothing is validated as expected\nprint(file)\n#&gt; File(filename=['not', 'a', 'string'], last_modification_time='2020-01-01T00:00')\n\ntry:\n    Foo(file=file)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Foo\n    file.filename\n      Input should be a valid string [type=string_type, input_value=['not', 'a', 'string'], input_type=list]\n    \"\"\"\n\nfoo = Foo(file=File(filename='myfile'), user=User(name='pika'))\ntry:\n    foo.user.name = 'bulbi'\nexcept dataclasses.FrozenInstanceError as e:\n    print(e)\n    #&gt; cannot assign to field 'name'\n</code></pre>"},{"location":"usage/dataclasses/#use-custom-types","title":"Use custom types","text":"<p>Since stdlib dataclasses are automatically converted to add validation using custom types may cause some unexpected behaviour. In this case you can simply add <code>arbitrary_types_allowed</code> in the config!</p> <pre><code>import dataclasses\n\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic.errors import PydanticSchemaGenerationError\n\n\nclass ArbitraryType:\n    def __init__(self, value):\n        self.value = value\n\n    def __repr__(self):\n        return f'ArbitraryType(value={self.value!r})'\n\n\n@dataclasses.dataclass\nclass DC:\n    a: ArbitraryType\n    b: str\n\n\n# valid as it is a builtin dataclass without validation\nmy_dc = DC(a=ArbitraryType(value=3), b='qwe')\n\ntry:\n\n    class Model(BaseModel):\n        dc: DC\n        other: str\n\n    Model(dc=my_dc, other='other')\nexcept PydanticSchemaGenerationError as e:  # invalid as it is now a pydantic dataclass\n    print(e.message)\n\"\"\"\n    Unable to generate pydantic-core schema for &lt;class '__main__.ArbitraryType'&gt;. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\n    If you got this error by calling handler(&lt;some type&gt;) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(&lt;some type&gt;)` since we do not call `__get_pydantic_core_schema__` on `&lt;some type&gt;` otherwise to avoid infinite recursion.\n    \"\"\"\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    dc: DC\n    other: str\n\n\nm = Model(dc=my_dc, other='other')\nprint(repr(m))\n#&gt; Model(dc=DC(a=ArbitraryType(value=3), b='qwe'), other='other')\n</code></pre>"},{"location":"usage/dataclasses/#initialize-hooks","title":"Initialize hooks","text":"<p>When you initialize a dataclass, it is possible to execute code before or after validation with the help of <code>model_validator</code> decorator.</p> Python 3.7 and abovePython 3.9 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Any, Dict\n\nfrom pydantic import model_validator\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Birth:\n    year: int\n    month: int\n    day: int\n\n\n@dataclass\nclass User:\n    birth: Birth\n\n    @model_validator(mode='before')\n    def pre_root(cls, values: Dict[str, Any]) -&gt; Dict[str, Any]:\n        print(values)\n        #&gt; ArgsKwargs((), {'birth': {'year': 1995, 'month': 3, 'day': 2}})\n        return values\n\n    @model_validator(mode='after')\n    def post_root(cls, values: Dict[str, Any]) -&gt; Dict[str, Any]:\n        print(values)\n        #&gt; User(birth=Birth(year=1995, month=3, day=2))\n        return values\n\n    def __post_init__(self):\n        print(self.birth)\n        #&gt; Birth(year=1995, month=3, day=2)\n\n\nuser = User(**{'birth': {'year': 1995, 'month': 3, 'day': 2}})\n</code></pre> <pre><code>from typing import Any\n\nfrom pydantic import model_validator\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Birth:\n    year: int\n    month: int\n    day: int\n\n\n@dataclass\nclass User:\n    birth: Birth\n\n    @model_validator(mode='before')\n    def pre_root(cls, values: dict[str, Any]) -&gt; dict[str, Any]:\n        print(values)\n        #&gt; ArgsKwargs((), {'birth': {'year': 1995, 'month': 3, 'day': 2}})\n        return values\n\n    @model_validator(mode='after')\n    def post_root(cls, values: dict[str, Any]) -&gt; dict[str, Any]:\n        print(values)\n        #&gt; User(birth=Birth(year=1995, month=3, day=2))\n        return values\n\n    def __post_init__(self):\n        print(self.birth)\n        #&gt; Birth(year=1995, month=3, day=2)\n\n\nuser = User(**{'birth': {'year': 1995, 'month': 3, 'day': 2}})\n</code></pre> <pre><code>from dataclasses import InitVar\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass PathData:\n    path: Path\n    base_path: InitVar[Optional[Path]]\n\n    def __post_init__(self, base_path):\n        print(f'Received path={self.path!r}, base_path={base_path!r}')\n        #&gt; Received path=PosixPath('world'), base_path=PosixPath('/hello')\n        if base_path is not None:\n            self.path = base_path / self.path\n\n\npath_data = PathData('world', base_path='/hello')\n# Received path='world', base_path='/hello'\nassert path_data.path == Path('/hello/world')\n</code></pre> <pre><code>from dataclasses import InitVar\nfrom pathlib import Path\n\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass PathData:\n    path: Path\n    base_path: InitVar[Path | None]\n\n    def __post_init__(self, base_path):\n        print(f'Received path={self.path!r}, base_path={base_path!r}')\n        #&gt; Received path=PosixPath('world'), base_path=PosixPath('/hello')\n        if base_path is not None:\n            self.path = base_path / self.path\n\n\npath_data = PathData('world', base_path='/hello')\n# Received path='world', base_path='/hello'\nassert path_data.path == Path('/hello/world')\n</code></pre>"},{"location":"usage/dataclasses/#difference-with-stdlib-dataclasses","title":"Difference with stdlib dataclasses","text":"<p>Note that the <code>dataclasses.dataclass</code> from Python stdlib implements only the <code>__post_init__</code> method since it doesn't run a validation step.</p> <p>When substituting usage of <code>dataclasses.dataclass</code> with <code>pydantic.dataclasses.dataclass</code>, it is recommended to move the code executed in the <code>__post_init__</code> to methods decorated with <code>model_validator</code>.</p>"},{"location":"usage/dataclasses/#json-dumping","title":"JSON dumping","text":"<p>Pydantic dataclasses do not feature a <code>.model_dump_json()</code> function. To dump them as JSON, you will need to make use of the RootModel as follows:</p> Python 3.7 and abovePython 3.9 and above <pre><code>import dataclasses\nfrom typing import List\n\nfrom pydantic import RootModel\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: List[int] = dataclasses.field(default_factory=lambda: [0])\n\n\nuser = User(id='42')\nprint(RootModel[User](User(id='42')).model_dump_json(indent=4))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"id\": 42,\n\"name\": \"John Doe\",\n\"friends\": [\n0\n]\n}\n</code></pre> <pre><code>import dataclasses\n\nfrom pydantic import RootModel\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\n\n\nuser = User(id='42')\nprint(RootModel[User](User(id='42')).model_dump_json(indent=4))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"id\": 42,\n\"name\": \"John Doe\",\n\"friends\": [\n0\n]\n}\n</code></pre>"},{"location":"usage/errors/","title":"Usage Errors","text":"<p>Pydantic attempts to provide useful errors. The following sections provide details on common errors developers may encounter when working with Pydantic, along with suggestions for addressing the error condition.</p>"},{"location":"usage/errors/#class-not-fully-defined","title":"Class not fully defined","text":"<p>This error is raised when a type referenced in an annotation of a pydantic-validated type (such as a subclass of <code>BaseModel</code>, or a pydantic <code>dataclass</code>) is not defined:</p> <pre><code>from typing import ForwardRef\n\nfrom pydantic import BaseModel, PydanticUserError\n\nUndefinedType = ForwardRef('UndefinedType')\n\n\nclass Foobar(BaseModel):\n    a: UndefinedType\n\n\ntry:\n    Foobar(a=1)\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'class-not-fully-defined'\n</code></pre> <p>Or when the type has been defined after usage:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, PydanticUserError\n\n\nclass Foo(BaseModel):\n    a: Optional['Bar'] = None\n\n\nclass Bar(BaseModel):\n    b: 'Foo'\n\n\ntry:\n    foo = Foo(a={'b': {'a': None}})\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'class-not-fully-defined'\n</code></pre> <p>For BaseModel subclasses, it can be fixed by defining the type and then calling <code>.model_rebuild()</code>:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: Optional['Bar'] = None\n\n\nclass Bar(BaseModel):\n    b: 'Foo'\n\n\nFoo.model_rebuild()\n\nfoo = Foo(a={'b': {'a': None}})\n</code></pre> <p>In other cases, the error message should indicate how to rebuild the class with the appropriate type defined.</p>"},{"location":"usage/errors/#custom-json-schema","title":"Custom JSON Schema","text":"<p>The <code>__modify_schema__</code> method is no longer supported in V2. You should use the <code>__get_pydantic_json_schema__</code> method instead.</p> <p>The <code>__modify_schema__</code> used to receive a single argument representing the JSON schema. See the example below:</p> Old way<pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        @classmethod\n        def __modify_schema__(cls, field_schema):\n            field_schema.update(examples='examples')\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'custom-json-schema'\n</code></pre> <p>The new method <code>__get_pydantic_json_schema__</code> receives two arguments: the first is a dictionary denoted as <code>CoreSchema</code>, and the second a callable <code>handler</code> that receives a <code>CoreSchema</code> as parameter, and returns a JSON schema. See the example below:</p> Python 3.7 and abovePython 3.9 and above New way<pre><code>from typing import Any, Dict\n\nfrom pydantic_core import CoreSchema\n\nfrom pydantic import BaseModel, GetJsonSchemaHandler\n\n\nclass Model(BaseModel):\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, core_schema: CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; Dict[str, Any]:\n        json_schema = super().__get_pydantic_json_schema__(core_schema, handler)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema.update(examples='examples')\n        return json_schema\n\n\nprint(Model.model_json_schema())\n#&gt; {'examples': 'examples', 'properties': {}, 'title': 'Model', 'type': 'object'}\n</code></pre> New way<pre><code>from typing import Any\n\nfrom pydantic_core import CoreSchema\n\nfrom pydantic import BaseModel, GetJsonSchemaHandler\n\n\nclass Model(BaseModel):\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, core_schema: CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; dict[str, Any]:\n        json_schema = super().__get_pydantic_json_schema__(core_schema, handler)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema.update(examples='examples')\n        return json_schema\n\n\nprint(Model.model_json_schema())\n#&gt; {'examples': 'examples', 'properties': {}, 'title': 'Model', 'type': 'object'}\n</code></pre>"},{"location":"usage/errors/#decorator-missing-field","title":"Decorator on missing field","text":"<p>This error is raised when you define a decorator with a field that is not valid.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator('b')\n        def check_b(cls, v: Any):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'decorator-missing-field'\n</code></pre> <p>You can use <code>check_fields=False</code> if you're inheriting from the model and intended this.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, create_model, field_validator\n\n\nclass Model(BaseModel):\n    @field_validator('a', check_fields=False)\n    def check_a(cls, v: Any):\n        return v\n\n\nmodel = create_model('FooModel', a=(str, 'cake'), __base__=Model)\n</code></pre>"},{"location":"usage/errors/#discriminator-no-field","title":"Discriminator no field","text":"<p>This error is raised when a model in discriminated unions doesn't define a discriminator field.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-no-field'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-no-field'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Cat | Dog = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-no-field'\n</code></pre>"},{"location":"usage/errors/#discriminator-alias-type","title":"Discriminator alias type","text":"<p>This error is raised when you define a non-string alias on a discriminator field.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import AliasChoices, BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias=AliasChoices('Pet', 'PET'))\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias-type'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import AliasChoices, BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias=AliasChoices('Pet', 'PET'))\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias-type'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import AliasChoices, BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias=AliasChoices('Pet', 'PET'))\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Cat | Dog = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias-type'\n</code></pre>"},{"location":"usage/errors/#discriminator-needs-literal","title":"Discriminator needs literal","text":"<p>This error is raised when you define a non-<code>Literal</code> type on a discriminator field.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: int\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-needs-literal'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: int\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-needs-literal'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: int\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Cat | Dog = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-needs-literal'\n</code></pre>"},{"location":"usage/errors/#discriminator-alias","title":"Discriminator alias","text":"<p>This error is raised when you define different aliases on discriminator fields.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias='PET')\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog'] = Field(validation_alias='Pet')\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias='PET')\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog'] = Field(validation_alias='Pet')\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias='PET')\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog'] = Field(validation_alias='Pet')\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Cat | Dog = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias'\n</code></pre>"},{"location":"usage/errors/#typed-dict-version","title":"<code>TypedDict</code> version","text":"<p>This error is raised when you use <code>typing_extensions.TypedDict</code> instead of <code>typing.TypedDict</code> on Python &lt; 3.11.</p>"},{"location":"usage/errors/#model-field-overridden","title":"Model parent field overridden","text":"<p>This error is raised when a field defined on a base class was overridden by a non-annotated attribute.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\n\nclass Foo(BaseModel):\n    a: float\n\n\ntry:\n\n    class Bar(Foo):\n        x: float = 12.3\n        a = 123.0\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-field-overridden'\n</code></pre>"},{"location":"usage/errors/#model-field-missing-annotation","title":"Model field missing annotation","text":"<p>This error is raised when a field doesn't have an annotation.</p> <pre><code>from pydantic import BaseModel, Field, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        a = Field('foobar')\n        b = None\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-field-missing-annotation'\n</code></pre> <p>If the field is not meant to be a field, you may be able to resolve the error by annotating it as a <code>ClassVar</code>:</p> <pre><code>from typing import ClassVar\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: ClassVar[str]\n</code></pre> <p>Or updating <code>model_config['ignored_types']</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass IgnoredType:\n    pass\n\n\nclass MyModel(BaseModel):\n    model_config = ConfigDict(ignored_types=(IgnoredType,))\n\n    _a = IgnoredType()\n    _b: int = IgnoredType()\n    _c: IgnoredType\n    _d: IgnoredType = IgnoredType()\n</code></pre>"},{"location":"usage/errors/#config-both","title":"<code>Config</code> and <code>model_config</code> both defined","text":"<p>This error is raised when <code>class Config</code> and <code>model_config</code> are used together.</p> <pre><code>from pydantic import BaseModel, ConfigDict, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        model_config = ConfigDict(from_attributes=True)\n\n        a: str\n\n        class Config:\n            from_attributes = True\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'config-both'\n</code></pre>"},{"location":"usage/errors/#removed-kwargs","title":"Keyword arguments removed","text":"<p>This error is raised when the keyword arguments are not available in Pydantic V2.</p> <p>For example, <code>regex</code> is removed from Pydantic V2:</p> <pre><code>from pydantic import BaseModel, Field, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        x: str = Field(regex='test')\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'removed-kwargs'\n</code></pre>"},{"location":"usage/errors/#invalid-for-json-schema","title":"JSON schema invalid type","text":"<p>This error is raised when Pydantic fails to generate a JSON schema for some <code>CoreSchema</code>.</p> <pre><code>from pydantic import BaseModel, ImportString, PydanticUserError\n\n\nclass Model(BaseModel):\n    a: ImportString\n\n\ntry:\n    Model.model_json_schema()\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'invalid-for-json-schema'\n</code></pre>"},{"location":"usage/errors/#json-schema-already-used","title":"JSON schema already used","text":"<p>This error is raised when the JSON schema generator has already been used to generate a JSON schema. You must create a new instance to generate a new JSON schema.</p>"},{"location":"usage/errors/#base-model-instantiated","title":"BaseModel instantiated","text":"<p>This error is raised when you instantiate <code>BaseModel</code> directly. Pydantic models should inherit from <code>BaseModel</code>.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n    BaseModel()\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'base-model-instantiated'\n</code></pre>"},{"location":"usage/errors/#undefined-annotation","title":"Undefined annotation","text":"<p>This error is raised when handling undefined annotations during <code>CoreSchema</code> generation.</p> <pre><code>from pydantic import BaseModel, PydanticUndefinedAnnotation\n\n\nclass Model(BaseModel):\n    a: 'B'  # noqa F821\n\n\ntry:\n    Model.model_rebuild()\nexcept PydanticUndefinedAnnotation as exc_info:\n    assert exc_info.code == 'undefined-annotation'\n</code></pre>"},{"location":"usage/errors/#schema-for-unknown-type","title":"Schema for unknown type","text":"<p>This error is raised when Pydantic fails to generate a <code>CoreSchema</code> for some type.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        x: 43 = 123\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'schema-for-unknown-type'\n</code></pre>"},{"location":"usage/errors/#import-error","title":"Import error","text":"<p>This error is raised when you try to import an object that was available in Pydantic V1, but has been removed in Pydantic V2.</p>"},{"location":"usage/errors/#create-model-field-definitions","title":"<code>create_model</code> field definitions","text":"<p>This error is raised when you provide field definitions input in <code>create_model</code> that is not valid.</p> <pre><code>from pydantic import PydanticUserError, create_model\n\ntry:\n    create_model('FooModel', foo=(str, 'default value', 'more'))\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'create-model-field-definitions'\n</code></pre>"},{"location":"usage/errors/#create-model-config-base","title":"<code>create_model</code> config base","text":"<p>This error is raised when you use both <code>__config__</code> and <code>__base__</code> together in <code>create_model</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, PydanticUserError, create_model\n\ntry:\n    config = ConfigDict(frozen=True)\n    model = create_model(\n        'FooModel', foo=(int, ...), __config__=config, __base__=BaseModel\n    )\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'create-model-config-base'\n</code></pre>"},{"location":"usage/errors/#validator-no-fields","title":"Validator with no fields","text":"<p>This error is raised when you use validator bare (with no fields).</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator\n        def checker(cls, v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-no-fields'\n</code></pre> <p>Validators should be used with fields and keyword arguments.</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    a: str\n\n    @field_validator('a')\n    def checker(cls, v):\n        return v\n</code></pre>"},{"location":"usage/errors/#validator-invalid-fields","title":"Invalid validator fields","text":"<p>This error is raised when you use a validator with non-string fields.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n        b: str\n\n        @field_validator(['a', 'b'])\n        def check_fields(cls, v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-invalid-fields'\n</code></pre> <p>Fields should be passed as separate string arguments:</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    a: str\n    b: str\n\n    @field_validator('a', 'b')\n    def check_fields(cls, v):\n        return v\n</code></pre>"},{"location":"usage/errors/#validator-instance-method","title":"Validator on instance method","text":"<p>This error is raised when you apply a validator on an instance method.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: int = 1\n\n        @field_validator('a')\n        def check_a(self, values):\n            return values\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-instance-method'\n</code></pre>"},{"location":"usage/errors/#root-validator-pre-skip","title":"Root validator, <code>pre</code>, <code>skip_on_failure</code>","text":"<p>If you use <code>@root_validator</code> with <code>pre=False</code> (the default) you MUST specify <code>skip_on_failure=True</code>. The <code>skip_on_failure=False</code> option is no longer available.</p> <p>If you were not trying to set <code>skip_on_failure=False</code>, you can safely set <code>skip_on_failure=True</code>. If you do, this root validator will no longer be called if validation fails for any of the fields.</p> <p>Please see the Migration Guide for more details.</p>"},{"location":"usage/errors/#model-serializer-instance-method","title":"<code>model_serializer</code> instance methods","text":"<p><code>@model_serializer</code> must be applied to instance methods.</p> <p>This error is raised when you apply <code>model_serializer</code> on an instance method without <code>self</code>:</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        def _serialize(slf, x, y, z):\n            return slf\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-instance-method'\n</code></pre> <p>Or on a class method:</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        @classmethod\n        def _serialize(self, x, y, z):\n            return self\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-instance-method'\n</code></pre>"},{"location":"usage/errors/#validator-field-config-info","title":"<code>validator</code>, <code>field</code>, <code>config</code>, and <code>info</code>","text":"<p>The <code>field</code> and <code>config</code> parameters are not available in Pydantic V2. Please use the <code>info</code> parameter instead.</p> <p>You can access the configuration via <code>info.config</code>, but it is a dictionary instead of an object like it was in Pydantic V1.</p> <p>The <code>field</code> argument is no longer available.</p>"},{"location":"usage/errors/#validator-v1-signature","title":"Pydantic V1 validator signature","text":"<p>This error is raised when you use an unsupported signature for Pydantic V1-style validator.</p> <pre><code>import warnings\n\nfrom pydantic import BaseModel, PydanticUserError, validator\n\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\ntry:\n\n    class Model(BaseModel):\n        a: int\n\n        @validator('a')\n        def check_a(cls, value, foo):\n            return value\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-v1-signature'\n</code></pre>"},{"location":"usage/errors/#validator-signature","title":"Unrecognized <code>field_validator</code> signature","text":"<p>This error is raised when a <code>field_validator</code> or <code>model_validator</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator('a')\n        @classmethod\n        def check_a(cls):\n            return 'a'\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-signature'\n</code></pre>"},{"location":"usage/errors/#field-serializer-signature","title":"Unrecognized <code>field_serializer</code> signature","text":"<p>This error is raised when the <code>field_serializer</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_serializer\n\ntry:\n\n    class Model(BaseModel):\n        x: int\n\n        @field_serializer('x')\n        def no_args():\n            return 'x'\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'field-serializer-signature'\n</code></pre> <p>Valid serializer signatures are:</p> <pre><code>from pydantic import model_serializer\n\n# an instance method with the default mode or `mode='plain'`\n@model_serializer('x')  # or @serialize('x', mode='plain')\ndef ser_x(self, value: Any, info: pydantic.FieldSerializationInfo): ...\n\n# a static method or free-standing function with the default mode or `mode='plain'`\n@model_serializer('x')  # or @serialize('x', mode='plain')\n@staticmethod\ndef ser_x(value: Any, info: pydantic.FieldSerializationInfo): ...\n# equivalent to\ndef ser_x(value: Any, info: pydantic.FieldSerializationInfo): ...\nserializer('x')(ser_x)\n\n# an instance method with `mode='wrap'`\n@model_serializer('x', mode='wrap')\ndef ser_x(self, value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ...\n\n# a static method or free-standing function with `mode='wrap'`\n@model_serializer('x', mode='wrap')\n@staticmethod\ndef ser_x(value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ...\n# equivalent to\ndef ser_x(value: Any, nxt: pydantic.SerializerFunctionWrapHandler, info: pydantic.FieldSerializationInfo): ...\nserializer('x')(ser_x)\n\nFor all of these, you can also choose to omit the `info` argument, for example:\n\n@model_serializer('x')\ndef ser_x(self, value: Any): ...\n\n@model_serializer('x', mode='wrap')\ndef ser_x(self, value: Any, handler: pydantic.SerializerFunctionWrapHandler): ...\n</code></pre>"},{"location":"usage/errors/#model-serializer-signature","title":"Unrecognized <code>model_serializer</code> signature","text":"<p>This error is raised when the <code>model_serializer</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        def _serialize(self, x, y, z):\n            return self\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-signature'\n</code></pre>"},{"location":"usage/errors/#multiple-field-serializers","title":"Multiple field serializers","text":"<p>This error is raised when multiple <code>model_serializer</code> functions are defined for a field.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        x: int\n        y: int\n\n        @field_serializer('x', 'y')\n        def serializer1(v):\n            return f'{v:,}'\n\n        @field_serializer('x')\n        def serializer2(v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'multiple-field-serializers'\n</code></pre>"},{"location":"usage/errors/#invalid_annotated_type","title":"Invalid annotated type","text":"<p>This error is raised when an annotation cannot annotate a type.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, FutureDate, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        foo: Annotated[str, FutureDate()]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'invalid_annotated_type'\n</code></pre> <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, FutureDate, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        foo: Annotated[str, FutureDate()]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'invalid_annotated_type'\n</code></pre>"},{"location":"usage/errors/#type-adapter-config-unused","title":"<code>config</code> is unused with TypeAdapter","text":"<p>You will get this error if you try to pass <code>config</code> to <code>TypeAdapter</code> when the type is a type that has it's own config that cannot be overridden (currently this is only <code>BaseModel</code>, <code>TypedDict</code> and <code>dataclass</code>):</p> Python 3.7 and abovePython 3.11 and above <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, PydanticUserError, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n\ntry:\n    TypeAdapter(MyTypedDict, config=ConfigDict(strict=True))\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'type-adapter-config-unused'\n</code></pre> <pre><code>from typing import TypedDict\n\nfrom pydantic import ConfigDict, PydanticUserError, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n\ntry:\n    TypeAdapter(MyTypedDict, config=ConfigDict(strict=True))\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'type-adapter-config-unused'\n</code></pre> <p>Instead you'll need to subclass the type and override or set the config on it:</p> Python 3.7 and abovePython 3.11 and above <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n    # or `model_config = ...` for BaseModel\n    __pydantic_config__ = ConfigDict(strict=True)\n\n\nTypeAdapter(MyTypedDict)  # ok\n</code></pre> <pre><code>from typing import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n    # or `model_config = ...` for BaseModel\n    __pydantic_config__ = ConfigDict(strict=True)\n\n\nTypeAdapter(MyTypedDict)  # ok\n</code></pre>"},{"location":"usage/exporting_models/","title":"Exporting models","text":"<p>Beyond accessing model attributes directly via their field names (e.g. <code>model.foobar</code>), models can be converted, dumped, serialized, and exported in a number of ways:</p>"},{"location":"usage/exporting_models/#modelmodel_dump","title":"<code>model.model_dump(...)</code>","text":"<p>This is the primary way of converting a model to a dictionary. Sub-models will be recursively converted to dictionaries.</p> <p>Note</p> <p>The one exception to sub-models being converted to dictionaries is that <code>RootModel</code> and its subclasses will have the <code>root</code> field value dumped directly, without a wrapping dictionary. This is also done recursively.</p> <p>See the API docs for <code>model_dump</code> for more information.</p> <p>Example:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Any, List, Optional\n\nfrom pydantic import BaseModel, Field, Json\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: Optional[float] = 1.1\n    foo: str = Field(serialization_alias='foo_alias')\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\n# returns a dictionary:\nprint(m.model_dump())\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(include={'foo', 'bar'}))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(exclude={'foo', 'bar'}))\n#&gt; {'banana': 3.14}\nprint(m.model_dump(by_alias=True))\n#&gt; {'banana': 3.14, 'foo_alias': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_unset=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=1.1, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_defaults=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_defaults=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=None, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_none=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\n\n\nclass Model(BaseModel):\n    x: List[Json[Any]]\n\n\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump())\n#&gt; {'x': [{'a': 1}, [1, 2]]}\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump(round_trip=True))\n#&gt; {'x': ['{\"a\":1}', '[1,2]']}\n</code></pre> <pre><code>from typing import Any, Optional\n\nfrom pydantic import BaseModel, Field, Json\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: Optional[float] = 1.1\n    foo: str = Field(serialization_alias='foo_alias')\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\n# returns a dictionary:\nprint(m.model_dump())\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(include={'foo', 'bar'}))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(exclude={'foo', 'bar'}))\n#&gt; {'banana': 3.14}\nprint(m.model_dump(by_alias=True))\n#&gt; {'banana': 3.14, 'foo_alias': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_unset=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=1.1, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_defaults=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_defaults=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=None, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_none=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\n\n\nclass Model(BaseModel):\n    x: list[Json[Any]]\n\n\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump())\n#&gt; {'x': [{'a': 1}, [1, 2]]}\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump(round_trip=True))\n#&gt; {'x': ['{\"a\":1}', '[1,2]']}\n</code></pre> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, Field, Json\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: float | None = 1.1\n    foo: str = Field(serialization_alias='foo_alias')\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\n# returns a dictionary:\nprint(m.model_dump())\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(include={'foo', 'bar'}))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(exclude={'foo', 'bar'}))\n#&gt; {'banana': 3.14}\nprint(m.model_dump(by_alias=True))\n#&gt; {'banana': 3.14, 'foo_alias': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_unset=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=1.1, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_defaults=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(exclude_defaults=True))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=None, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_none=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\n\n\nclass Model(BaseModel):\n    x: list[Json[Any]]\n\n\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump())\n#&gt; {'x': [{'a': 1}, [1, 2]]}\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump(round_trip=True))\n#&gt; {'x': ['{\"a\":1}', '[1,2]']}\n</code></pre>"},{"location":"usage/exporting_models/#modelmodel_dump_json","title":"<code>model.model_dump_json(...)</code>","text":"<p>The <code>.model_dump_json()</code> method serializes a model directly to a JSON-encoded string that is equivalent to the result produced by <code>.model_dump()</code>.</p> <p>See arguments for more information.</p> <p>Note</p> <p>Pydantic can serialize many commonly used types to JSON that would otherwise be incompatible with a simple <code>json.dumps(foobar)</code> (e.g. <code>datetime</code>, <code>date</code> or <code>UUID</code>) .</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    foo: datetime\n    bar: BarModel\n\n\nm = FooBarModel(foo=datetime(2032, 6, 1, 12, 13, 14), bar={'whatever': 123})\nprint(m.model_dump_json())\n#&gt; {\"foo\":\"2032-06-01T12:13:14\",\"bar\":{\"whatever\":123}}\nprint(m.model_dump_json(indent=2))\n\"\"\"\n{\n  \"foo\": \"2032-06-01T12:13:14\",\n  \"bar\": {\n    \"whatever\": 123\n  }\n}\n\"\"\"\n</code></pre>"},{"location":"usage/exporting_models/#dictmodel-and-iteration","title":"<code>dict(model)</code> and iteration","text":"<p>Pydantic models can also be converted to dictionaries using <code>dict(model)</code>, and you can also iterate over a model's fields using <code>for field_name, field_value in model:</code>. With this approach the raw field values are returned, so sub-models will not be converted to dictionaries.</p> <p>Example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: float\n    foo: str\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\nprint(dict(m))\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': BarModel(whatever=123)}\nfor name, value in m:\n    print(f'{name}: {value}')\n    #&gt; banana: 3.14\n    #&gt; foo: hello\n    #&gt; bar: whatever=123\n</code></pre> <p>Note also that <code>RootModel</code> does get converted to a dictionary with the key <code>'root'</code>.</p>"},{"location":"usage/exporting_models/#custom-serializers","title":"Custom serializers","text":"<p>Serialization can be customised on a field using the <code>@field_serializer</code> decorator, and on a model using the <code>@model_serializer</code> decorator.</p> <p>Here is an example:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from datetime import datetime, timedelta, timezone\nfrom typing import Any, Dict\n\nfrom pydantic import BaseModel, ConfigDict, field_serializer, model_serializer\n\n\nclass WithCustomEncoders(BaseModel):\n    model_config = ConfigDict(ser_json_timedelta='iso8601')\n\n    dt: datetime\n    diff: timedelta\n\n    @field_serializer('dt')\n    def serialize_dt(self, dt: datetime, _info):\n        return dt.timestamp()\n\n\nm = WithCustomEncoders(\n    dt=datetime(2032, 6, 1, tzinfo=timezone.utc), diff=timedelta(hours=100)\n)\nprint(m.model_dump_json())\n#&gt; {\"dt\":1969660800.0,\"diff\":\"P4DT14400S\"}\n\n\nclass Model(BaseModel):\n    x: str\n\n    @model_serializer\n    def ser_model(self) -&gt; Dict[str, Any]:\n        return {'x': f'serialized {self.x}'}\n\n\nprint(Model(x='test value').model_dump_json())\n#&gt; {\"x\":\"serialized test value\"}\n</code></pre> <pre><code>from datetime import datetime, timedelta, timezone\nfrom typing import Any\n\nfrom pydantic import BaseModel, ConfigDict, field_serializer, model_serializer\n\n\nclass WithCustomEncoders(BaseModel):\n    model_config = ConfigDict(ser_json_timedelta='iso8601')\n\n    dt: datetime\n    diff: timedelta\n\n    @field_serializer('dt')\n    def serialize_dt(self, dt: datetime, _info):\n        return dt.timestamp()\n\n\nm = WithCustomEncoders(\n    dt=datetime(2032, 6, 1, tzinfo=timezone.utc), diff=timedelta(hours=100)\n)\nprint(m.model_dump_json())\n#&gt; {\"dt\":1969660800.0,\"diff\":\"P4DT14400S\"}\n\n\nclass Model(BaseModel):\n    x: str\n\n    @model_serializer\n    def ser_model(self) -&gt; dict[str, Any]:\n        return {'x': f'serialized {self.x}'}\n\n\nprint(Model(x='test value').model_dump_json())\n#&gt; {\"x\":\"serialized test value\"}\n</code></pre>"},{"location":"usage/exporting_models/#serializing-subclasses","title":"Serializing subclasses","text":""},{"location":"usage/exporting_models/#subclasses-of-standard-types","title":"Subclasses of standard types","text":"<p>Subclasses of standard types are automatically dumped like their super-classes:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from datetime import date, timedelta\nfrom typing import Any, Type\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass DayThisYear(date):\n\"\"\"\n    Contrived example of a special type of date that\n    takes an int and interprets it as a day in the current year\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.general_after_validator_function(\n            cls.validate,\n            core_schema.int_schema(),\n            serialization=core_schema.format_ser_schema('%Y-%m-%d'),\n        )\n\n    @classmethod\n    def validate(cls, v: int, _info):\n        return date.today().replace(month=1, day=1) + timedelta(days=v)\n\n\nclass FooModel(BaseModel):\n    date: DayThisYear\n\n\nm = FooModel(date=300)\nprint(m.model_dump_json())\n#&gt; {\"date\":\"2023-10-28\"}\n</code></pre> <pre><code>from datetime import date, timedelta\nfrom typing import Any\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass DayThisYear(date):\n\"\"\"\n    Contrived example of a special type of date that\n    takes an int and interprets it as a day in the current year\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.general_after_validator_function(\n            cls.validate,\n            core_schema.int_schema(),\n            serialization=core_schema.format_ser_schema('%Y-%m-%d'),\n        )\n\n    @classmethod\n    def validate(cls, v: int, _info):\n        return date.today().replace(month=1, day=1) + timedelta(days=v)\n\n\nclass FooModel(BaseModel):\n    date: DayThisYear\n\n\nm = FooModel(date=300)\nprint(m.model_dump_json())\n#&gt; {\"date\":\"2023-10-28\"}\n</code></pre>"},{"location":"usage/exporting_models/#subclass-instances-for-fields-of-basemodel-dataclasses-typeddict","title":"Subclass instances for fields of BaseModel, dataclasses, TypedDict","text":"<p>When using fields whose annotations are themselves struct-like types (e.g., <code>BaseModel</code> subclasses, dataclasses, etc.), the default behavior is to serialize the attribute value as though it was an instance of the annotated type, even if it is a subclass. More specifically, only the fields from the annotated type will be included in the dumped object:</p> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    user: User\n\n\nuser = UserLogin(name='pydantic', password='hunter2')\n\nm = OuterModel(user=user)\nprint(m)\n#&gt; user=UserLogin(name='pydantic', password='hunter2')\nprint(m.model_dump())  # note: the password field is not included\n#&gt; {'user': {'name': 'pydantic'}}\n</code></pre> <p>Migration Warning</p> <p>This behavior is different from how things worked in Pydantic V1, where we would always include all (subclass) fields when recursively dumping models to dicts. The motivation behind this change in behavior is that it helps ensure that you know precisely which fields could be included when serializing, even if subclasses get passed when instantiating the object. In particular, this can help prevent surprises when adding sensitive information like secrets as fields of subclasses.</p>"},{"location":"usage/exporting_models/#serializing-with-duck-typing","title":"Serializing with duck-typing","text":"<p>If you want to preserve the old duck-typing serialization behavior, this can be done using <code>SerializeAsAny</code>:</p> <pre><code>from pydantic import BaseModel, SerializeAsAny\n\n\nclass User(BaseModel):\n    name: str\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    as_any: SerializeAsAny[User]\n    as_user: User\n\n\nuser = UserLogin(name='pydantic', password='password')\n\nprint(OuterModel(as_any=user, as_user=user).model_dump())\n\"\"\"\n{\n    'as_any': {'name': 'pydantic', 'password': 'password'},\n    'as_user': {'name': 'pydantic'},\n}\n\"\"\"\n</code></pre> <p>When a field is annotated as <code>SerializeAsAny[&lt;SomeType&gt;]</code>, the validation behavior will be the same as if it was annotated as <code>&lt;SomeType&gt;</code>, and type-checkers like mypy will treat the attribute as having the appropriate type as well. But when serializing, the field will be serialized as though the type hint for the field was <code>Any</code>, which is where the name comes from.</p>"},{"location":"usage/exporting_models/#pickledumpsmodel","title":"<code>pickle.dumps(model)</code>","text":"<p>Pydantic models support efficient pickling and unpickling.</p> <pre><code># TODO need to get pickling to work\nimport pickle\n\nfrom pydantic import BaseModel\n\n\nclass FooBarModel(BaseModel):\n    a: str\n    b: int\n\n\nm = FooBarModel(a='hello', b=123)\nprint(m)\n#&gt; a='hello' b=123\ndata = pickle.dumps(m)\nprint(data[:20])\n#&gt; b'\\x80\\x04\\x95\\x95\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main_'\nm2 = pickle.loads(data)\nprint(m2)\n#&gt; a='hello' b=123\n</code></pre>"},{"location":"usage/exporting_models/#advanced-include-and-exclude","title":"Advanced include and exclude","text":"<p>The <code>model_dump</code> and <code>model_dump_json</code> methods support <code>include</code> and <code>exclude</code> arguments which can either be sets or dictionaries. This allows nested selection of which fields to export:</p> <pre><code>from pydantic import BaseModel, SecretStr\n\n\nclass User(BaseModel):\n    id: int\n    username: str\n    password: SecretStr\n\n\nclass Transaction(BaseModel):\n    id: str\n    user: User\n    value: int\n\n\nt = Transaction(\n    id='1234567890',\n    user=User(id=42, username='JohnDoe', password='hashedpassword'),\n    value=9876543210,\n)\n\n# using a set:\nprint(t.model_dump(exclude={'user', 'value'}))\n#&gt; {'id': '1234567890'}\n\n# using a dict:\nprint(t.model_dump(exclude={'user': {'username', 'password'}, 'value': True}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n\nprint(t.model_dump(include={'id': True, 'user': {'id'}}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n</code></pre> <p>The <code>True</code> indicates that we want to exclude or include an entire key, just as if we included it in a set. This can be done at any depth level.</p> <p>Special care must be taken when including or excluding fields from a list or tuple of submodels or dictionaries. In this scenario, <code>model_dump</code> and related methods expect integer keys for element-wise inclusion or exclusion. To exclude a field from every member of a list or tuple, the dictionary key <code>'__all__'</code> can be used, as shown here:</p> Python 3.7 and abovePython 3.9 and above <pre><code>import datetime\nfrom typing import List\n\nfrom pydantic import BaseModel, SecretStr\n\n\nclass Country(BaseModel):\n    name: str\n    phone_code: int\n\n\nclass Address(BaseModel):\n    post_code: int\n    country: Country\n\n\nclass CardDetails(BaseModel):\n    number: SecretStr\n    expires: datetime.date\n\n\nclass Hobby(BaseModel):\n    name: str\n    info: str\n\n\nclass User(BaseModel):\n    first_name: str\n    second_name: str\n    address: Address\n    card_details: CardDetails\n    hobbies: List[Hobby]\n\n\nuser = User(\n    first_name='John',\n    second_name='Doe',\n    address=Address(post_code=123456, country=Country(name='USA', phone_code=1)),\n    card_details=CardDetails(\n        number='4212934504460000', expires=datetime.date(2020, 5, 1)\n    ),\n    hobbies=[\n        Hobby(name='Programming', info='Writing code and stuff'),\n        Hobby(name='Gaming', info='Hell Yeah!!!'),\n    ],\n)\n\nexclude_keys = {\n    'second_name': True,\n    'address': {'post_code': True, 'country': {'phone_code'}},\n    'card_details': True,\n    # You can exclude fields from specific members of a tuple/list by index:\n    'hobbies': {-1: {'info'}},\n}\n\ninclude_keys = {\n    'first_name': True,\n    'address': {'country': {'name'}},\n    'hobbies': {0: True, -1: {'name'}},\n}\n\n# would be the same as user.model_dump(exclude=exclude_keys) in this case:\nprint(user.model_dump(include=include_keys))\n\"\"\"\n{\n    'first_name': 'John',\n    'address': {'country': {'name': 'USA'}},\n    'hobbies': [\n        {'name': 'Programming', 'info': 'Writing code and stuff'},\n        {'name': 'Gaming'},\n    ],\n}\n\"\"\"\n\n# To exclude a field from all members of a nested list or tuple, use \"__all__\":\nprint(user.model_dump(exclude={'hobbies': {'__all__': {'info'}}}))\n\"\"\"\n{\n    'first_name': 'John',\n    'second_name': 'Doe',\n    'address': {'post_code': 123456, 'country': {'name': 'USA', 'phone_code': 1}},\n    'card_details': {\n        'number': SecretStr('**********'),\n        'expires': datetime.date(2020, 5, 1),\n    },\n    'hobbies': [{'name': 'Programming'}, {'name': 'Gaming'}],\n}\n\"\"\"\n</code></pre> <pre><code>import datetime\n\nfrom pydantic import BaseModel, SecretStr\n\n\nclass Country(BaseModel):\n    name: str\n    phone_code: int\n\n\nclass Address(BaseModel):\n    post_code: int\n    country: Country\n\n\nclass CardDetails(BaseModel):\n    number: SecretStr\n    expires: datetime.date\n\n\nclass Hobby(BaseModel):\n    name: str\n    info: str\n\n\nclass User(BaseModel):\n    first_name: str\n    second_name: str\n    address: Address\n    card_details: CardDetails\n    hobbies: list[Hobby]\n\n\nuser = User(\n    first_name='John',\n    second_name='Doe',\n    address=Address(post_code=123456, country=Country(name='USA', phone_code=1)),\n    card_details=CardDetails(\n        number='4212934504460000', expires=datetime.date(2020, 5, 1)\n    ),\n    hobbies=[\n        Hobby(name='Programming', info='Writing code and stuff'),\n        Hobby(name='Gaming', info='Hell Yeah!!!'),\n    ],\n)\n\nexclude_keys = {\n    'second_name': True,\n    'address': {'post_code': True, 'country': {'phone_code'}},\n    'card_details': True,\n    # You can exclude fields from specific members of a tuple/list by index:\n    'hobbies': {-1: {'info'}},\n}\n\ninclude_keys = {\n    'first_name': True,\n    'address': {'country': {'name'}},\n    'hobbies': {0: True, -1: {'name'}},\n}\n\n# would be the same as user.model_dump(exclude=exclude_keys) in this case:\nprint(user.model_dump(include=include_keys))\n\"\"\"\n{\n    'first_name': 'John',\n    'address': {'country': {'name': 'USA'}},\n    'hobbies': [\n        {'name': 'Programming', 'info': 'Writing code and stuff'},\n        {'name': 'Gaming'},\n    ],\n}\n\"\"\"\n\n# To exclude a field from all members of a nested list or tuple, use \"__all__\":\nprint(user.model_dump(exclude={'hobbies': {'__all__': {'info'}}}))\n\"\"\"\n{\n    'first_name': 'John',\n    'second_name': 'Doe',\n    'address': {'post_code': 123456, 'country': {'name': 'USA', 'phone_code': 1}},\n    'card_details': {\n        'number': SecretStr('**********'),\n        'expires': datetime.date(2020, 5, 1),\n    },\n    'hobbies': [{'name': 'Programming'}, {'name': 'Gaming'}],\n}\n\"\"\"\n</code></pre> <p>The same holds for the <code>model_dump_json</code> method.</p>"},{"location":"usage/exporting_models/#model-and-field-level-include-and-exclude","title":"Model- and field-level include and exclude","text":"<p>In addition to the explicit arguments <code>exclude</code> and <code>include</code> passed to <code>model_dump</code> and <code>model_dump_json</code> methods, we can also pass the <code>include</code>/<code>exclude</code> arguments directly to the <code>Field</code> constructor:</p> <pre><code>from pydantic import BaseModel, Field, SecretStr\n\n\nclass User(BaseModel):\n    id: int\n    username: str\n    password: SecretStr = Field(..., exclude=True)\n\n\nclass Transaction(BaseModel):\n    id: str\n    user: User = Field(exclude={'username'})\n    value: int = Field(exclude=True)\n\n\nt = Transaction(\n    id='1234567890',\n    user=User(id=42, username='JohnDoe', password='hashedpassword'),\n    value=9876543210,\n)\n\nprint(t.model_dump())\n#&gt; {'id': '1234567890'}\n# TODO: this is wrong! not all of \"user\" should be excluded\n# TODO: do we need to fix the type of the argument to Field? Or do we want to just remove that functionality?\n</code></pre> <p>Explicitly setting <code>exclude</code>/<code>include</code> on <code>model_dump</code> and <code>model_dump_json</code> takes priority over the <code>exclude</code>/<code>include</code> from the field constructor (i.e. <code>Field(..., exclude=True)</code>):</p> <p>Note that while merging settings, <code>exclude</code> entries are merged by computing the \"union\" of keys, while <code>include</code> entries are merged by computing the \"intersection\" of keys.</p> <p>The resulting merged exclude settings:</p> <pre><code>from pydantic import BaseModel, Field, SecretStr\n\n\nclass User(BaseModel):\n    id: int\n    username: str  # overridden by explicit exclude\n    password: SecretStr = Field(exclude=True)\n\n\nclass Transaction(BaseModel):\n    id: str\n    user: User\n    value: int\n\n\nt = Transaction(\n    id='1234567890',\n    user=User(id=42, username='JohnDoe', password='hashedpassword'),\n    value=9876543210,\n)\n\nprint(t.model_dump(exclude={'value': True, 'user': {'username'}}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n</code></pre> <p>are the same as using merged include settings as follows:</p> <pre><code>from pydantic import BaseModel, Field, SecretStr\n\n\nclass User(BaseModel):\n    id: int = Field(..., include=True)\n    username: str = Field(..., include=True)  # overridden by explicit include\n    password: SecretStr\n\n\nclass Transaction(BaseModel):\n    id: str\n    user: User\n    value: int\n\n\nt = Transaction(\n    id='1234567890',\n    user=User(id=42, username='JohnDoe', password='hashedpassword'),\n    value=9876543210,\n)\n\nprint(t.model_dump(include={'id': True, 'user': {'id'}}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n</code></pre>"},{"location":"usage/exporting_models/#model_copy","title":"<code>model_copy(...)</code>","text":"<p><code>model_copy()</code> allows models to be duplicated (with optional updates), which is particularly useful when working with frozen models. See the API docs for <code>model_copy</code> for more information.</p> <p>Example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: float\n    foo: str\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\nprint(m.model_copy(update={'banana': 0}))\n#&gt; banana=0 foo='hello' bar=BarModel(whatever=123)\nprint(id(m.bar) == id(m.model_copy().bar))\n#&gt; True\n# normal copy gives the same object reference for bar\nprint(id(m.bar) == id(m.model_copy(deep=True).bar))\n#&gt; False\n# deep copy gives a new object reference for `bar`\n</code></pre>"},{"location":"usage/fields/","title":"Fields","text":"<p>The <code>Field</code> function is used to customize and add metadata to fields of models.</p> <p>See the <code>Field</code> API reference for additional details.</p>"},{"location":"usage/fields/#default-values","title":"Default values","text":"<p>The <code>default</code> parameter is used to define a default value for a field.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(default='John Doe')\n\n\nuser = User()\nprint(user)\n#&gt; name='John Doe'\n</code></pre> <p>You can also use <code>default_factory</code> to define a callable that will be called to generate a default value.</p> <pre><code>from uuid import uuid4\n\nfrom pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    id: int = Field(default_factory=lambda: uuid4().hex)\n</code></pre> <p>Info</p> <p>The <code>default</code> and <code>default_factory</code> parameters are mutually exclusive.</p> <p>Note</p> <p>If you use <code>typing.Optional</code>, it doesn't mean that the field has a default value of <code>None</code>!</p>"},{"location":"usage/fields/#field-aliases","title":"Field aliases","text":"<p>For validation and serialization, you can define an alias for a field.</p> <p>There are three ways to define an alias:</p> <ul> <li><code>Field(..., alias='foo')</code></li> <li><code>Field(..., validation_alias='foo')</code></li> <li><code>Field(..., serialization_alias='foo')</code></li> </ul> <p>The <code>alias</code> parameter is used for both validation and serialization. If you want to use different aliases for validation and serialization respectively, you can use the<code>validation_alias</code> and <code>serialization_alias</code> parameters, which will apply only in their respective use cases.</p> <p>Here is some example usage of the <code>alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'username': 'johndoe'}\n</code></pre> <ol> <li>The alias <code>'username'</code> is used for instance creation and validation.</li> <li> <p>We are using <code>model_dump</code> to convert the model into a serializable format.</p> <p>You can see more details about <code>model_dump</code> in the API reference.</p> <p>Note that the <code>by_alias</code> keyword argument defaults to <code>False</code>, and must be specified explicitly to dump models using the field (serialization) aliases.</p> <p>When <code>by_alias=True</code>, the alias <code>'username'</code> is also used during serialization.</p> </li> </ol> <p>If you want to use an alias only for validation, you can use the <code>validation_alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., validation_alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'name': 'johndoe'}\n</code></pre> <ol> <li>The validation alias <code>'username'</code> is used during validation.</li> <li>The field name <code>'name'</code> is used during serialization.</li> </ol> <p>If you only want to define an alias for serialization, you can use the <code>serialization_alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., serialization_alias='username')\n\n\nuser = User(name='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'username': 'johndoe'}\n</code></pre> <ol> <li>The field name <code>'name'</code> is used for validation.</li> <li>The serialization alias <code>'username'</code> is used for serialization.</li> </ol> <p>In case you use <code>alias</code> together with <code>validation_alias</code> or <code>serialization_alias</code> at the same time, the <code>validation_alias</code> will have priority over <code>alias</code> for validation, and <code>serialization_alias</code> will have priority over <code>alias</code> for serialization.</p> <p>You can read more about Alias Precedence in the Model Config documentation.</p> VSCode and Pyright users <p>In VSCode, if you use the Pylance extension, you won't see a warning when instantiating a model using a field's alias:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\n</code></pre> <ol> <li>VSCode will NOT show a warning here.</li> </ol> <p>When the <code>'alias'</code> keyword argument is specified, even if you set <code>populate_by_name</code> to <code>True</code> in the Model Config, VSCode will show a warning when instantiating a model using the field name (though it will work at runtime) \u2014 in this case, <code>'name'</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(..., alias='username')\n\n\nuser = User(name='johndoe')  # (1)!\n</code></pre> <ol> <li>VSCode will show a warning here.</li> </ol> <p>To \"trick\" VSCode into preferring the field name, you can use the <code>str</code> function to wrap the alias value:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(..., alias='username')\n</code></pre> <p>This is discussed in more detail in this issue.</p>"},{"location":"usage/fields/#validation-alias","title":"Validation Alias","text":"<p>Even though Pydantic treats <code>alias</code> and <code>validation_alias</code> the same when creating model instances, VSCode will not use the <code>validation_alias</code> in the class initializer signature. If you want VSCode to use the <code>validation_alias</code> in the class initializer, you can instead specify both an <code>alias</code> and <code>serialization_alias</code>, as the <code>serialization_alias</code> will override the <code>alias</code> during serialization:</p> <p><pre><code>from pydantic import BaseModel, Field\n\n\nclass MyModel(BaseModel):\n    my_field: int = Field(..., validation_alias='myValidationAlias')\n</code></pre> with: <pre><code>from pydantic import BaseModel, Field\n\n\nclass MyModel(BaseModel):\n    my_field: int = Field(\n        ..., alias='myValidationAlias', serialization_alias='my_serialization_alias'\n    )\n\n\nm = MyModel(myValidationAlias=1)\nprint(m.model_dump(by_alias=True))\n#&gt; {'my_serialization_alias': 1}\n</code></pre></p> <p>All of the above will likely also apply to other tools that respect the <code>@typing.dataclass_transform</code> decorator, such as Pyright.</p>"},{"location":"usage/fields/#aliaspath-and-aliaschoices","title":"<code>AliasPath</code> and <code>AliasChoices</code>","text":"<p>Pydantic provides two special types for convenience when using <code>validation_alias</code>: <code>AliasPath</code> and <code>AliasChoices</code>.</p> <p>The <code>AliasPath</code> is used to specify a path to a field using aliases. For example:</p> <pre><code>from pydantic import BaseModel, Field, AliasPath\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasPath('names', 0))\n    last_name: str = Field(validation_alias=AliasPath('names', 1))\n\nuser = User.model_validate({'names': ['John', 'Doe']})  # (1)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre> <ol> <li> <p>We are using <code>model_validate</code> to validate a dictionary using the field aliases.</p> <p>You can see more details about <code>model_validate</code> in the API reference.</p> </li> </ol> <p>In the <code>'first_name'</code> field, we are using the alias <code>'names'</code> and the index <code>0</code> to specify the path to the first name. In the <code>'last_name'</code> field, we are using the alias <code>'names'</code> and the index <code>1</code> to specify the path to the last name.</p> <p><code>AliasChoices</code> is used to specify a choice of aliases. For example:</p> <pre><code>from pydantic import BaseModel, Field, AliasChoices\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasChoices('first_name', 'fname'))\n    last_name: str = Field(validation_alias=AliasChoices('last_name', 'lname'))\n\nuser = User.model_validate({'fname': 'John', 'lname': 'Doe'})  # (1)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'first_name': 'John', 'lname': 'Doe'})  # (2)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre> <ol> <li>We are using the second alias choice for both fields.</li> <li>We are using the first alias choice for the field <code>'first_name'</code> and the second alias choice    for the field <code>'last_name'</code>.</li> </ol> <p>You can also use <code>AliasChoices</code> with <code>AliasPath</code>:</p> <pre><code>from pydantic import BaseModel, Field, AliasPath, AliasChoices\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasChoices('first_name', AliasPath('names', 0)))\n    last_name: str = Field(validation_alias=AliasChoices('last_name', AliasPath('names', 1)))\n\n\nuser = User.model_validate({'first_name': 'John', 'last_name': 'Doe'})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'names': ['John', 'Doe']})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'names': ['John'], 'last_name': 'Doe'})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre>"},{"location":"usage/fields/#numeric-constraints","title":"Numeric Constraints","text":"<p>There are some keyword arguments that can be used to constrain numeric values:</p> <ul> <li><code>gt</code> - greater than</li> <li><code>lt</code> - less than</li> <li><code>ge</code> - greater than or equal to</li> <li><code>le</code> - less than or equal to</li> <li><code>multiple_of</code> - a multiple of the given number</li> <li><code>allow_inf_nan</code> - allow <code>'inf'</code>, <code>'-inf'</code>, <code>'nan'</code> values</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    positive: int = Field(gt=0)\n    non_negative: int = Field(ge=0)\n    negative: int = Field(lt=0)\n    non_positive: int = Field(le=0)\n    even: int = Field(multiple_of=2)\n    love_for_pydantic: float = Field(allow_inf_nan=True)\n\n\nfoo = Foo(\n    positive=1,\n    non_negative=0,\n    negative=-1,\n    non_positive=0,\n    even=2,\n    love_for_pydantic=float('inf'),\n)\nprint(foo)\n#&gt; positive=1 non_negative=0 negative=-1 non_positive=0 even=2 love_for_pydantic=inf\n</code></pre> JSON Schema <p>In the generated JSON schema:</p> <ul> <li><code>gt</code> and <code>lt</code> constraints will be translated to <code>exclusiveMinimum</code> and <code>exclusiveMaximum</code>.</li> <li><code>ge</code> and <code>le</code> constraints will be translated to <code>minimum</code> and <code>maximum</code>.</li> <li><code>multiple_of</code> constraint will be translated to <code>multipleOf</code>.</li> </ul> <p>The above snippet will generate the following JSON Schema:</p> <pre><code>{\n\"title\": \"Foo\",\n\"type\": \"object\",\n\"properties\": {\n\"positive\": {\n\"title\": \"Positive\",\n\"type\": \"integer\",\n\"exclusiveMinimum\": 0\n},\n\"non_negative\": {\n\"title\": \"Non Negative\",\n\"type\": \"integer\",\n\"minimum\": 0\n},\n\"negative\": {\n\"title\": \"Negative\",\n\"type\": \"integer\",\n\"exclusiveMaximum\": 0\n},\n\"non_positive\": {\n\"title\": \"Non Positive\",\n\"type\": \"integer\",\n\"maximum\": 0\n},\n\"even\": {\n\"title\": \"Even\",\n\"type\": \"integer\",\n\"multipleOf\": 2\n},\n\"love_for_pydantic\": {\n\"title\": \"Love For Pydantic\",\n\"type\": \"number\"\n}\n},\n\"required\": [\n\"positive\",\n\"non_negative\",\n\"negative\",\n\"non_positive\",\n\"even\",\n\"love_for_pydantic\"\n]\n}\n</code></pre> <p>See the JSON Schema Draft 2020-12 for more details.</p>"},{"location":"usage/fields/#string-constraints","title":"String Constraints","text":"<p>There are fields that can be used to constrain strings:</p> <ul> <li><code>min_length</code>: Minimum length of the string.</li> <li><code>max_length</code>: Maximum length of the string.</li> <li><code>pattern</code>: A regular expression that the string must match.</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    short: str = Field(min_length=3)\n    long: str = Field(max_length=10)\n    regex: str = Field(pattern=r'^\\d*$')  # (1)!\n\n\nfoo = Foo(short='foo', long='foobarbaz', regex='123')\nprint(foo)\n#&gt; short='foo' long='foobarbaz' regex='123'\n</code></pre> <ol> <li>Only digits are allowed.</li> </ol> JSON Schema <p>In the generated JSON schema:</p> <ul> <li><code>min_length</code> constraint will be translated to <code>minLength</code>.</li> <li><code>max_length</code> constraint will be translated to <code>maxLength</code>.</li> <li><code>pattern</code> constraint will be translated to <code>pattern</code>.</li> </ul> <p>The above snippet will generate the following JSON Schema:</p> <pre><code>{\n\"title\": \"Foo\",\n\"type\": \"object\",\n\"properties\": {\n\"short\": {\n\"title\": \"Short\",\n\"type\": \"string\",\n\"minLength\": 3\n},\n\"long\": {\n\"title\": \"Long\",\n\"type\": \"string\",\n\"maxLength\": 10\n},\n\"regex\": {\n\"title\": \"Regex\",\n\"type\": \"string\",\n\"pattern\": \"^\\\\d*$\"\n}\n},\n\"required\": [\n\"short\",\n\"long\",\n\"regex\"\n]\n}\n</code></pre>"},{"location":"usage/fields/#decimal-constraints","title":"Decimal Constraints","text":"<p>There are fields that can be used to constrain decimals:</p> <ul> <li><code>max_digits</code>: Maximum number of digits within the <code>Decimal</code>. It does not include a zero before the decimal point or   trailing decimal zeroes.</li> <li><code>decimal_places</code>: Maximum number of decimal places allowed. It does not include trailing decimal zeroes.</li> </ul> <p>Here's an example:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    precise: Decimal = Field(max_digits=5, decimal_places=2)\n\n\nfoo = Foo(precise=Decimal('123.45'))\nprint(foo)\n#&gt; precise=Decimal('123.45')\n</code></pre>"},{"location":"usage/fields/#dataclass-constraints","title":"Dataclass Constraints","text":"<p>There are fields that can be used to constrain dataclasses:</p> <ul> <li><code>init_var</code>: Whether the field should be seen as an init-only field in the dataclass.</li> <li><code>kw_only</code>: Whether the field should be a keyword-only argument in the constructor of the dataclass.</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Foo:\n    bar: str\n    baz: str = Field(init_var=True)\n    qux: str = Field(kw_only=True)\n\n\nclass Model(BaseModel):\n    foo: Foo\n\n\nmodel = Model(foo=Foo('bar', baz='baz', qux='qux'))\nprint(model.model_dump())  # (1)!\n#&gt; {'foo': {'bar': 'bar', 'qux': 'qux'}}\n</code></pre> <ol> <li>The <code>baz</code> field is not included in the <code>model_dump()</code> output, since it is an init-only field.</li> </ol>"},{"location":"usage/fields/#validate-default-values","title":"Validate Default Values","text":"<p>The parameter <code>validate_default</code> can be used to control whether the default value of the field should be validated.</p> <p>By default, the default value of the field is not validated.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass User(BaseModel):\n    age: int = Field(default='twelve', validate_default=True)\n\n\ntry:\n    user = User()\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    age\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='twelve', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/fields/#field-representation","title":"Field Representation","text":"<p>The parameter <code>repr</code> can be used to control whether the field should be included in the string representation of the model.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(repr=True)  # (1)!\n    age: int = Field(repr=False)\n\n\nuser = User(name='John', age=42)\nprint(user)\n#&gt; name='John'\n</code></pre> <ol> <li>This is the default value.</li> </ol>"},{"location":"usage/fields/#discriminator","title":"Discriminator","text":"<p>The parameter <code>discriminator</code> can be used to control the field that will be used to discriminate between different models in a union.</p> Python 3.8 and abovePython 3.10 and above <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    age: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    age: int\n\n\nclass Model(BaseModel):\n    pet: Union[Cat, Dog] = Field(discriminator='pet_type')\n\n\nprint(Model.model_validate({'pet': {'pet_type': 'cat', 'age': 12}}))  # (1)!\n#&gt; pet=Cat(pet_type='cat', age=12)\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    age: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    age: int\n\n\nclass Model(BaseModel):\n    pet: Cat | Dog = Field(discriminator='pet_type')\n\n\nprint(Model.model_validate({'pet': {'pet_type': 'cat', 'age': 12}}))  # (1)!\n#&gt; pet=Cat(pet_type='cat', age=12)\n</code></pre> <ol> <li>See more about Helper Functions in the Models page.</li> </ol> <p>See the Discriminated Unions for more details.</p>"},{"location":"usage/fields/#strict-mode","title":"Strict Mode","text":"<p>The parameter <code>strict</code> can be used to control whether the field should be validated in \"strict mode\".</p> <p>[TODO: Add a link to documentation about strict mode]</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(strict=True)  # (1)!\n    age: int = Field(strict=False)\n\n\nuser = User(name='John', age='42')  # (2)!\nprint(user)\n#&gt; name='John' age=42\n</code></pre> <ol> <li>This is the default value.</li> <li>The <code>age</code> field is not validated in the strict mode. Therefore, it can be assigned a string.</li> </ol>"},{"location":"usage/fields/#immutability","title":"Immutability","text":"<p>The parameter <code>frozen</code> is used to emulate the [frozen dataclass] behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability).</p> <p>See the frozen dataclass documentation for more details.</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field, ValidationError\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(validate_assignment=True)  # (1)!\n\n    name: str = Field(frozen=True)\n    age: int\n\n\nuser = User(name='John', age=42)\n\ntry:\n    user.name = 'Jane'  # (2)!\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    name\n      Field is frozen [type=frozen_field, input_value='Jane', input_type=str]\n    \"\"\"\n</code></pre> <ol> <li> <p>The <code>model_config</code> field is used to enable the validation of assignments.</p> <p>See the Validate Assignment section for more details.</p> </li> <li> <p>Since <code>validate_assignment</code> is enabled, and the <code>name</code> field is frozen, the assignment is not allowed.</p> </li> </ol>"},{"location":"usage/fields/#include-and-exclude","title":"Include and Exclude","text":"<p>The parameters <code>include</code> and <code>exclude</code> can be used to control which fields should be included or excluded from the model when exporting the model.</p> <p>See the following example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(exclude=True)\n\n\nuser = User(name='John', age=42)\nprint(user.model_dump())  # (1)!\n#&gt; {'name': 'John'}\n</code></pre> <ol> <li>The <code>age</code> field is not included in the <code>model_dump()</code> output, since it is excluded.</li> </ol> <p>See the Exporting Models section for more details.</p>"},{"location":"usage/fields/#customizing-json-schema","title":"Customizing JSON Schema","text":"<p>There are fields that exclusively to customise the generated JSON Schema:</p> <ul> <li><code>title</code>: The title of the field.</li> <li><code>description</code>: The description of the field.</li> <li><code>examples</code>: The examples of the field.</li> <li><code>json_schema_extra</code>: Extra JSON Schema properties to be added to the field.</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, EmailStr, Field, SecretStr\n\n\nclass User(BaseModel):\n    age: int = Field(description='Age of the user')\n    email: EmailStr = Field(examples=['marcelo@mail.com'])\n    name: str = Field(title='Username')\n    password: SecretStr = Field(\n        json_schema_extra={\n            'title': 'Password',\n            'description': 'Password of the user',\n            'examples': ['123456'],\n        }\n    )\n\n\nprint(User.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'age': {'description': 'Age of the user', 'title': 'Age', 'type': 'integer'},\n        'email': {\n            'examples': ['marcelo@mail.com'],\n            'format': 'email',\n            'title': 'Email',\n            'type': 'string',\n        },\n        'name': {'title': 'Username', 'type': 'string'},\n        'password': {\n            'description': 'Password of the user',\n            'examples': ['123456'],\n            'format': 'password',\n            'title': 'Password',\n            'type': 'string',\n            'writeOnly': True,\n        },\n    },\n    'required': ['age', 'email', 'name', 'password'],\n    'title': 'User',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p>TODO: Add <code>final</code>, and <code>alias_priority</code> parameters.</p>"},{"location":"usage/json_schema/","title":"JSON Schema","text":"<p>Pydantic allows auto creation of JSON Schemas from models:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>import json\nfrom enum import Enum\nfrom typing import Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: Union[float, None] = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n\"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Union[Gender, None], Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nprint(json.dumps(MainModel.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"FooBar\": {\n\"properties\": {\n\"count\": {\n\"title\": \"Count\",\n\"type\": \"integer\"\n},\n\"size\": {\n\"anyOf\": [\n{\n\"type\": \"number\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null,\n\"title\": \"Size\"\n}\n},\n\"required\": [\n\"count\"\n],\n\"title\": \"FooBar\",\n\"type\": \"object\"\n},\n\"Gender\": {\n\"enum\": [\n\"male\",\n\"female\",\n\"other\",\n\"not_given\"\n],\n\"title\": \"Gender\",\n\"type\": \"string\"\n}\n},\n\"description\": \"\\n    This is the description of the main model\\n    \",\n\"properties\": {\n\"Gender\": {\n\"anyOf\": [\n{\n\"$ref\": \"#/$defs/Gender\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null\n},\n\"foo_bar\": {\n\"$ref\": \"#/$defs/FooBar\"\n},\n\"snap\": {\n\"default\": 42,\n\"description\": \"this is the value of snap\",\n\"exclusiveMaximum\": 50,\n\"exclusiveMinimum\": 30,\n\"title\": \"The Snap\",\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"foo_bar\"\n],\n\"title\": \"Main\",\n\"type\": \"object\"\n}\n</code></pre> <pre><code>import json\nfrom enum import Enum\nfrom typing import Union\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: Union[float, None] = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n\"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Union[Gender, None], Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nprint(json.dumps(MainModel.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"FooBar\": {\n\"properties\": {\n\"count\": {\n\"title\": \"Count\",\n\"type\": \"integer\"\n},\n\"size\": {\n\"anyOf\": [\n{\n\"type\": \"number\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null,\n\"title\": \"Size\"\n}\n},\n\"required\": [\n\"count\"\n],\n\"title\": \"FooBar\",\n\"type\": \"object\"\n},\n\"Gender\": {\n\"enum\": [\n\"male\",\n\"female\",\n\"other\",\n\"not_given\"\n],\n\"title\": \"Gender\",\n\"type\": \"string\"\n}\n},\n\"description\": \"\\n    This is the description of the main model\\n    \",\n\"properties\": {\n\"Gender\": {\n\"anyOf\": [\n{\n\"$ref\": \"#/$defs/Gender\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null\n},\n\"foo_bar\": {\n\"$ref\": \"#/$defs/FooBar\"\n},\n\"snap\": {\n\"default\": 42,\n\"description\": \"this is the value of snap\",\n\"exclusiveMaximum\": 50,\n\"exclusiveMinimum\": 30,\n\"title\": \"The Snap\",\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"foo_bar\"\n],\n\"title\": \"Main\",\n\"type\": \"object\"\n}\n</code></pre> <pre><code>import json\nfrom enum import Enum\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: float | None = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n\"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Gender | None, Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nprint(json.dumps(MainModel.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"FooBar\": {\n\"properties\": {\n\"count\": {\n\"title\": \"Count\",\n\"type\": \"integer\"\n},\n\"size\": {\n\"anyOf\": [\n{\n\"type\": \"number\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null,\n\"title\": \"Size\"\n}\n},\n\"required\": [\n\"count\"\n],\n\"title\": \"FooBar\",\n\"type\": \"object\"\n},\n\"Gender\": {\n\"enum\": [\n\"male\",\n\"female\",\n\"other\",\n\"not_given\"\n],\n\"title\": \"Gender\",\n\"type\": \"string\"\n}\n},\n\"description\": \"\\n    This is the description of the main model\\n    \",\n\"properties\": {\n\"Gender\": {\n\"anyOf\": [\n{\n\"$ref\": \"#/$defs/Gender\"\n},\n{\n\"type\": \"null\"\n}\n],\n\"default\": null\n},\n\"foo_bar\": {\n\"$ref\": \"#/$defs/FooBar\"\n},\n\"snap\": {\n\"default\": 42,\n\"description\": \"this is the value of snap\",\n\"exclusiveMaximum\": 50,\n\"exclusiveMinimum\": 30,\n\"title\": \"The Snap\",\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"foo_bar\"\n],\n\"title\": \"Main\",\n\"type\": \"object\"\n}\n</code></pre> <p>The generated schemas are compliant with the specifications: JSON Schema Core, JSON Schema Validation and OpenAPI.</p> <p><code>BaseModel.model_json_schema</code> will return a dict of the schema, while <code>BaseModel.schema_json</code> will return a JSON string representation of that dict.</p> <p>Sub-models used are added to the <code>definitions</code> JSON attribute and referenced, as per the spec.</p> <p>All sub-models' (and their sub-models') schemas are put directly in a top-level <code>definitions</code> JSON key for easy re-use and reference.</p> <p>\"Sub-models\" with modifications (via the <code>Field</code> class) like a custom title, description or default value, are recursively included instead of referenced.</p> <p>The <code>description</code> for models is taken from either the docstring of the class or the argument <code>description</code> to the <code>Field</code> class.</p> <p>The schema is generated by default using aliases as keys, but it can be generated using model property names instead by calling <code>MainModel.model_json_schema/schema_json(by_alias=False)</code>.</p> <p>The format of <code>$ref</code>s (<code>\"#/definitions/FooBar\"</code> above) can be altered by calling <code>model_json_schema()</code> or <code>schema_json()</code> with the <code>ref_template</code> keyword argument, e.g. <code>ApplePie.model_json_schema(ref_template='/schemas/{model}.json#/')</code>, here <code>{model}</code> will be replaced with the model naming using <code>str.format()</code>.</p>"},{"location":"usage/json_schema/#getting-schema-of-a-specified-type","title":"Getting schema of a specified type","text":"<p>Pydantic includes two standalone utility functions <code>schema_of</code> and <code>schema_json_of</code> that can be used to apply the schema generation logic used for pydantic models in a more ad-hoc way. These functions behave similarly to <code>BaseModel.model_json_schema</code> and <code>BaseModel.schema_json</code>, but work with arbitrary pydantic-compatible types.</p> Python 3.8 and abovePython 3.9 and above <pre><code>from typing import Literal, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field, schema_json_of\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    cat_name: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    dog_name: str\n\n\nPet = Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n\nprint(schema_json_of(Pet, title='The Pet Schema', indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"Cat\": {\n\"properties\": {\n\"cat_name\": {\n\"title\": \"Cat Name\",\n\"type\": \"string\"\n},\n\"pet_type\": {\n\"const\": \"cat\",\n\"title\": \"Pet Type\"\n}\n},\n\"required\": [\n\"pet_type\",\n\"cat_name\"\n],\n\"title\": \"Cat\",\n\"type\": \"object\"\n},\n\"Dog\": {\n\"properties\": {\n\"dog_name\": {\n\"title\": \"Dog Name\",\n\"type\": \"string\"\n},\n\"pet_type\": {\n\"const\": \"dog\",\n\"title\": \"Pet Type\"\n}\n},\n\"required\": [\n\"pet_type\",\n\"dog_name\"\n],\n\"title\": \"Dog\",\n\"type\": \"object\"\n}\n},\n\"discriminator\": {\n\"mapping\": {\n\"cat\": \"#/$defs/Cat\",\n\"dog\": \"#/$defs/Dog\"\n},\n\"propertyName\": \"pet_type\"\n},\n\"oneOf\": [\n{\n\"$ref\": \"#/$defs/Cat\"\n},\n{\n\"$ref\": \"#/$defs/Dog\"\n}\n],\n\"title\": \"The Pet Schema\"\n}\n</code></pre> <pre><code>from typing import Literal, Union\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field, schema_json_of\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    cat_name: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    dog_name: str\n\n\nPet = Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n\nprint(schema_json_of(Pet, title='The Pet Schema', indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"Cat\": {\n\"properties\": {\n\"cat_name\": {\n\"title\": \"Cat Name\",\n\"type\": \"string\"\n},\n\"pet_type\": {\n\"const\": \"cat\",\n\"title\": \"Pet Type\"\n}\n},\n\"required\": [\n\"pet_type\",\n\"cat_name\"\n],\n\"title\": \"Cat\",\n\"type\": \"object\"\n},\n\"Dog\": {\n\"properties\": {\n\"dog_name\": {\n\"title\": \"Dog Name\",\n\"type\": \"string\"\n},\n\"pet_type\": {\n\"const\": \"dog\",\n\"title\": \"Pet Type\"\n}\n},\n\"required\": [\n\"pet_type\",\n\"dog_name\"\n],\n\"title\": \"Dog\",\n\"type\": \"object\"\n}\n},\n\"discriminator\": {\n\"mapping\": {\n\"cat\": \"#/$defs/Cat\",\n\"dog\": \"#/$defs/Dog\"\n},\n\"propertyName\": \"pet_type\"\n},\n\"oneOf\": [\n{\n\"$ref\": \"#/$defs/Cat\"\n},\n{\n\"$ref\": \"#/$defs/Dog\"\n}\n],\n\"title\": \"The Pet Schema\"\n}\n</code></pre>"},{"location":"usage/json_schema/#field-customization","title":"Field customization","text":"<p>Optionally, the <code>Field</code> function can be used to provide extra information about the field and validations. It has the following arguments:</p> <ul> <li><code>default</code>: (a positional argument) the default value of the field.     Since the <code>Field</code> replaces the field's default, this first argument can be used to set the default.     Use ellipsis (<code>...</code>) to indicate the field is required.</li> <li><code>default_factory</code>: a zero-argument callable that will be called when a default value is needed for this field.     Among other purposes, this can be used to set dynamic default values.     It is forbidden to set both <code>default</code> and <code>default_factory</code>.</li> <li><code>alias</code>: the public name of the field</li> <li><code>title</code>: if omitted, <code>field_name.title()</code> is used</li> <li><code>description</code>: if omitted and the annotation is a sub-model,     the docstring of the sub-model will be used</li> <li><code>exclude</code>: exclude this field when dumping (<code>.dict</code> and <code>.json</code>) the instance. The exact syntax and configuration options are described in details in the exporting models section.</li> <li><code>include</code>: include (only) this field when dumping (<code>.dict</code> and <code>.json</code>) the instance. The exact syntax and configuration options are described in details in the exporting models section.</li> <li><code>const</code>: this argument must be the same as the field's default value if present.</li> <li><code>gt</code>: for numeric values (<code>int</code>, <code>float</code>, <code>Decimal</code>), adds a validation of \"greater than\" and an annotation   of <code>exclusiveMinimum</code> to the JSON Schema</li> <li><code>ge</code>: for numeric values, this adds a validation of \"greater than or equal\" and an annotation of <code>minimum</code> to the   JSON Schema</li> <li><code>lt</code>: for numeric values, this adds a validation of \"less than\" and an annotation of <code>exclusiveMaximum</code> to the   JSON Schema</li> <li><code>le</code>: for numeric values, this adds a validation of \"less than or equal\" and an annotation of <code>maximum</code> to the   JSON Schema</li> <li><code>multiple_of</code>: for numeric values, this adds a validation of \"a multiple of\" and an annotation of <code>multipleOf</code> to the   JSON Schema</li> <li><code>max_digits</code>: for <code>Decimal</code> values, this adds a validation to have a maximum number of digits within the decimal. It   does not include a zero before the decimal point or trailing decimal zeroes.</li> <li><code>decimal_places</code>: for <code>Decimal</code> values, this adds a validation to have at most a number of decimal places allowed. It   does not include trailing decimal zeroes.</li> <li><code>min_items</code>: for list values, this adds a corresponding validation and an annotation of <code>minItems</code> to the   JSON Schema</li> <li><code>max_items</code>: for list values, this adds a corresponding validation and an annotation of <code>maxItems</code> to the   JSON Schema</li> <li><code>unique_items</code>: for list values, this adds a corresponding validation and an annotation of <code>uniqueItems</code> to the   JSON Schema</li> <li><code>min_length</code>: for string values, this adds a corresponding validation and an annotation of <code>minLength</code> to the   JSON Schema</li> <li><code>max_length</code>: for string values, this adds a corresponding validation and an annotation of <code>maxLength</code> to the   JSON Schema</li> <li><code>allow_mutation</code>: a boolean which defaults to <code>True</code>. When False, the field raises a <code>TypeError</code> if the field is   assigned on an instance.  The model config must set <code>validate_assignment</code> to <code>True</code> for this check to be performed.</li> <li><code>regex</code>: for string values, this adds a Regular Expression validation generated from the passed string and an   annotation of <code>pattern</code> to the JSON Schema \u2014 see note below for details</li> <li><code>repr</code>: a boolean which defaults to <code>True</code>. When False, the field shall be hidden from the object representation.</li> <li><code>**</code> any other keyword arguments (e.g. <code>examples</code>) will be added verbatim to the field's schema</li> </ul> <p>Note</p> <p>Pydantic validates strings using <code>re.match</code>, which treats regular expressions as implicitly anchored at the beginning. On the contrary, JSON Schema validators treat the <code>pattern</code> keyword as implicitly unanchored, more like what <code>re.search</code> does.</p> <p>For interoperability, depending on your desired behavior, either explicitly anchor your regular expressions with <code>^</code> (e.g. <code>^foo</code> to match any string starting with <code>foo</code>), or explicitly allow an arbitrary prefix with <code>.*?</code> (e.g. <code>.*?foo</code> to match any string containing the substring <code>foo</code>).</p> <p>See #1631 for a discussion of possible changes to Pydantic behavior in v2.</p> <p>Instead of using <code>Field</code>, the <code>fields</code> property of the Config class can be used to set all of the arguments above except <code>default</code>.</p>"},{"location":"usage/json_schema/#unenforced-field-constraints","title":"Unenforced Field constraints","text":"<p>If Pydantic finds constraints which are not being enforced, an error will be raised. If you want to force the constraint to appear in the schema, even though it's not being checked upon parsing, you can use variadic arguments to <code>Field()</code> with the raw schema attribute name:</p> <pre><code>from pydantic import BaseModel, Field, PositiveInt\n\ntry:\n    # this won't work since PositiveInt takes precedence over the\n    # constraints defined in Field meaning they're ignored\n    class Model(BaseModel):\n        foo: PositiveInt = Field(..., lt=10)\n\nexcept ValueError as e:\n    print(e)\n\n\n# if you find yourself needing this, an alternative is to declare\n# the constraints in Field (or you could use conint())\n# here both constraints will be enforced:\nclass ModelB(BaseModel):\n    # Here both constraints will be applied and the schema\n    # will be generated correctly\n    foo: int = Field(..., gt=0, lt=10)\n\n\nprint(ModelB.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'foo': {\n            'exclusiveMaximum': 10,\n            'exclusiveMinimum': 0,\n            'title': 'Foo',\n            'type': 'integer',\n        }\n    },\n    'required': ['foo'],\n    'title': 'ModelB',\n    'type': 'object',\n}\n\"\"\"\n</code></pre>"},{"location":"usage/json_schema/#typingannotated-fields","title":"typing.Annotated Fields","text":"<p>Rather than assigning a <code>Field</code> value, it can be specified in the type hint with <code>typing.Annotated</code>:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from uuid import uuid4\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    id: Annotated[str, Field(default_factory=lambda: uuid4().hex)]\n    name: Annotated[str, Field(max_length=256)] = 'Bar'\n</code></pre> <pre><code>from uuid import uuid4\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    id: Annotated[str, Field(default_factory=lambda: uuid4().hex)]\n    name: Annotated[str, Field(max_length=256)] = 'Bar'\n</code></pre> <p><code>Field</code> can only be supplied once per field - an error will be raised if used in <code>Annotated</code> and as the assigned value. Defaults can be set outside <code>Annotated</code> as the assigned value or with <code>Field.default_factory</code> inside <code>Annotated</code> - the <code>Field.default</code> argument is not supported inside <code>Annotated</code>.</p> <p>For versions of Python prior to 3.9, <code>typing_extensions.Annotated</code> can be used.</p>"},{"location":"usage/json_schema/#modifying-the-schema","title":"Modifying the schema","text":"<p>Custom types (used as <code>field_name: TheType</code> or <code>field_name: Annotated[TheType, ...]</code>) as well as Annotated metadata (used as <code>field_name: Annotated[int, SomeMetadata]</code>) can modify or override the generated schema by implementing <code>__get_pydantic_core_schema__</code>. This method receives two positional arguments:</p> <ol> <li>The type annotation that corresponds to this type (so in the case of <code>TheType[T][int]</code> it would be <code>TheType[int]</code>).</li> <li>A handler / callback to call the next implementer of <code>__get_pydantic_core_schema__</code>.</li> </ol> <p>The handler system works just like <code>mode='wrap'</code> validators. In this case the input is the type and the output is a <code>CoreSchema</code>.</p> <p>Here is an example of a custom type that overrides the generated core schema:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from dataclasses import dataclass\nfrom typing import Any, Dict, List, Type\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\n@dataclass\nclass CompressedString:\n    dictionary: Dict[int, str]\n    text: List[int]\n\n    def build(self) -&gt; str:\n        return ' '.join([self.dictionary[key] for key in self.text])\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        assert source is CompressedString\n        return core_schema.no_info_after_validator_function(\n            cls._validate,\n            core_schema.str_schema(),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                cls._serialize, info_arg=False, return_schema=core_schema.str_schema()\n            ),\n        )\n\n    @staticmethod\n    def _validate(value: str) -&gt; 'CompressedString':\n        inverse_dictionary: Dict[str, int] = {}\n        text: List[int] = []\n        for word in value.split(' '):\n            if word not in inverse_dictionary:\n                inverse_dictionary[word] = len(inverse_dictionary)\n            text.append(inverse_dictionary[word])\n        return CompressedString({v: k for k, v in inverse_dictionary.items()}, text)\n\n    @staticmethod\n    def _serialize(value: 'CompressedString') -&gt; str:\n        return value.build()\n\n\nclass MyModel(BaseModel):\n    value: CompressedString\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='fox fox fox dog fox'))\n#&gt; value=CompressedString(dictionary={0: 'fox', 1: 'dog'}, text=[0, 0, 0, 1, 0])\n\nprint(MyModel(value='fox fox fox dog fox').model_dump(mode='json'))\n#&gt; {'value': 'fox fox fox dog fox'}\n</code></pre> <pre><code>from dataclasses import dataclass\nfrom typing import Any\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\n@dataclass\nclass CompressedString:\n    dictionary: dict[int, str]\n    text: list[int]\n\n    def build(self) -&gt; str:\n        return ' '.join([self.dictionary[key] for key in self.text])\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        assert source is CompressedString\n        return core_schema.no_info_after_validator_function(\n            cls._validate,\n            core_schema.str_schema(),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                cls._serialize, info_arg=False, return_schema=core_schema.str_schema()\n            ),\n        )\n\n    @staticmethod\n    def _validate(value: str) -&gt; 'CompressedString':\n        inverse_dictionary: dict[str, int] = {}\n        text: list[int] = []\n        for word in value.split(' '):\n            if word not in inverse_dictionary:\n                inverse_dictionary[word] = len(inverse_dictionary)\n            text.append(inverse_dictionary[word])\n        return CompressedString({v: k for k, v in inverse_dictionary.items()}, text)\n\n    @staticmethod\n    def _serialize(value: 'CompressedString') -&gt; str:\n        return value.build()\n\n\nclass MyModel(BaseModel):\n    value: CompressedString\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='fox fox fox dog fox'))\n#&gt; value=CompressedString(dictionary={0: 'fox', 1: 'dog'}, text=[0, 0, 0, 1, 0])\n\nprint(MyModel(value='fox fox fox dog fox').model_dump(mode='json'))\n#&gt; {'value': 'fox fox fox dog fox'}\n</code></pre> <p>Since Pydantic would not know how to generate a schema for <code>CompressedString</code> if you call <code>handler(source)</code> in it's <code>__get_pydantic_core_schema__</code> method you would get a <code>pydantic.errors.PydanticSchemaGenerationError</code> error. This will be the case for most custom types so you almost never want to call into <code>handler</code> for custom types.</p> <p>The process for Annotated metadata is much the same except that you can generally call into <code>handler</code> to have Pydantic handle generating the schema.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from dataclasses import dataclass\nfrom typing import Any, Sequence, Type\n\nfrom pydantic_core import core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationError\n\n\n@dataclass\nclass RestrictCharacters:\n    alphabet: Sequence[str]\n\n    def __get_pydantic_core_schema__(\n        self, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if not self.alphabet:\n            raise ValueError('Alphabet may not be empty')\n        schema = handler(source)  # get the CoreSchema from the type / inner constraints\n        if schema['type'] != 'str':\n            raise TypeError('RestrictCharacters can only be applied to strings')\n        return core_schema.no_info_after_validator_function(\n            self.validate,\n            schema,\n        )\n\n    def validate(self, value: str) -&gt; str:\n        if any(c not in self.alphabet for c in value):\n            raise ValueError(f'{value!r} is not restricted to {self.alphabet!r}')\n        return value\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, RestrictCharacters('ABC')]\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='CBA'))\n#&gt; value='CBA'\n\ntry:\n    MyModel(value='XYZ')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    value\n      Value error, 'XYZ' is not restricted to 'ABC' [type=value_error, input_value='XYZ', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from dataclasses import dataclass\nfrom typing import Any\nfrom collections.abc import Sequence\n\nfrom pydantic_core import core_schema\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationError\n\n\n@dataclass\nclass RestrictCharacters:\n    alphabet: Sequence[str]\n\n    def __get_pydantic_core_schema__(\n        self, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if not self.alphabet:\n            raise ValueError('Alphabet may not be empty')\n        schema = handler(source)  # get the CoreSchema from the type / inner constraints\n        if schema['type'] != 'str':\n            raise TypeError('RestrictCharacters can only be applied to strings')\n        return core_schema.no_info_after_validator_function(\n            self.validate,\n            schema,\n        )\n\n    def validate(self, value: str) -&gt; str:\n        if any(c not in self.alphabet for c in value):\n            raise ValueError(f'{value!r} is not restricted to {self.alphabet!r}')\n        return value\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, RestrictCharacters('ABC')]\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='CBA'))\n#&gt; value='CBA'\n\ntry:\n    MyModel(value='XYZ')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    value\n      Value error, 'XYZ' is not restricted to 'ABC' [type=value_error, input_value='XYZ', input_type=str]\n    \"\"\"\n</code></pre> <p>So far we have been wrapping the schema, but if you just want to modify it or ignore it you can as well. To modify the schema first call the handler and then mutate the result:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, Type\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass SmallString:\n    def __get_pydantic_core_schema__(\n        self,\n        source: Type[Any],\n        handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        schema = handler(source)\n        assert schema['type'] == 'str'\n        schema['max_length'] = 10  # modify in place\n        return schema\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, SmallString()]\n\n\ntry:\n    MyModel(value='too long!!!!!')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    value\n      String should have at most 10 characters [type=string_too_long, input_value='too long!!!!!', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import Any\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass SmallString:\n    def __get_pydantic_core_schema__(\n        self,\n        source: type[Any],\n        handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        schema = handler(source)\n        assert schema['type'] == 'str'\n        schema['max_length'] = 10  # modify in place\n        return schema\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, SmallString()]\n\n\ntry:\n    MyModel(value='too long!!!!!')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    value\n      String should have at most 10 characters [type=string_too_long, input_value='too long!!!!!', input_type=str]\n    \"\"\"\n</code></pre> <p>To override the schema completely do not call the handler and return your own <code>CoreSchema</code>:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, Type\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass AllowAnySubclass:\n    def __get_pydantic_core_schema__(\n        self, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        # we can't call handler since it will fail for arbitrary types\n        def validate(value: Any) -&gt; Any:\n            if not isinstance(value, source):\n                raise ValueError(\n                    f'Expected an instance of {source}, got an instance of {type(value)}'\n                )\n\n        return core_schema.no_info_plain_validator_function(validate)\n\n\nclass Foo:\n    pass\n\n\nclass Model(BaseModel):\n    f: Annotated[Foo, AllowAnySubclass()]\n\n\nprint(Model(f=Foo()))\n#&gt; f=None\n\n\nclass NotFoo:\n    pass\n\n\ntry:\n    Model(f=NotFoo())\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    f\n      Value error, Expected an instance of &lt;class '__main__.Foo'&gt;, got an instance of &lt;class '__main__.NotFoo'&gt; [type=value_error, input_value=&lt;__main__.NotFoo object at 0x0123456789ab&gt;, input_type=NotFoo]\n    \"\"\"\n</code></pre> <pre><code>from typing import Any\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass AllowAnySubclass:\n    def __get_pydantic_core_schema__(\n        self, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        # we can't call handler since it will fail for arbitrary types\n        def validate(value: Any) -&gt; Any:\n            if not isinstance(value, source):\n                raise ValueError(\n                    f'Expected an instance of {source}, got an instance of {type(value)}'\n                )\n\n        return core_schema.no_info_plain_validator_function(validate)\n\n\nclass Foo:\n    pass\n\n\nclass Model(BaseModel):\n    f: Annotated[Foo, AllowAnySubclass()]\n\n\nprint(Model(f=Foo()))\n#&gt; f=None\n\n\nclass NotFoo:\n    pass\n\n\ntry:\n    Model(f=NotFoo())\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    f\n      Value error, Expected an instance of &lt;class '__main__.Foo'&gt;, got an instance of &lt;class '__main__.NotFoo'&gt; [type=value_error, input_value=&lt;__main__.NotFoo object at 0x0123456789ab&gt;, input_type=NotFoo]\n    \"\"\"\n</code></pre>"},{"location":"usage/json_schema/#json-schema-types","title":"JSON Schema Types","text":"<p>Types, custom field types, and constraints (like <code>max_length</code>) are mapped to the corresponding spec formats in the following priority order (when there is an equivalent available):</p> <ol> <li>JSON Schema Core</li> <li>JSON Schema Validation</li> <li>OpenAPI Data Types</li> <li>The standard <code>format</code> JSON field is used to define Pydantic extensions for more complex <code>string</code> sub-types.</li> </ol> <p>The field schema mapping from Python / Pydantic to JSON Schema is done as follows:</p>"},{"location":"usage/json_schema/#top-level-schema-generation","title":"Top-level schema generation","text":"<p>You can also generate a top-level JSON Schema that only includes a list of models and related sub-models in its <code>definitions</code>:</p> <pre><code>import json\n\nfrom pydantic import BaseModel\nfrom pydantic.json_schema import models_json_schema\n\n\nclass Foo(BaseModel):\n    a: str = None\n\n\nclass Model(BaseModel):\n    b: Foo\n\n\nclass Bar(BaseModel):\n    c: int\n\n\n_, top_level_schema = models_json_schema(\n    [(Model, 'validation'), (Bar, 'validation')], title='My Schema'\n)\nprint(json.dumps(top_level_schema, indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"Bar\": {\n\"properties\": {\n\"c\": {\n\"title\": \"C\",\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"c\"\n],\n\"title\": \"Bar\",\n\"type\": \"object\"\n},\n\"Foo\": {\n\"properties\": {\n\"a\": {\n\"default\": null,\n\"title\": \"A\",\n\"type\": \"string\"\n}\n},\n\"title\": \"Foo\",\n\"type\": \"object\"\n},\n\"Model\": {\n\"properties\": {\n\"b\": {\n\"$ref\": \"#/$defs/Foo\"\n}\n},\n\"required\": [\n\"b\"\n],\n\"title\": \"Model\",\n\"type\": \"object\"\n}\n},\n\"title\": \"My Schema\"\n}\n</code></pre>"},{"location":"usage/json_schema/#schema-customization","title":"Schema customization","text":"<p>You can customize the generated <code>$ref</code> JSON location: the definitions are always stored under the key <code>definitions</code>, but a specified prefix can be used for the references.</p> <p>This is useful if you need to extend or modify the JSON Schema default definitions location. E.g. with OpenAPI:</p> <pre><code>import json\n\nfrom pydantic import BaseModel\nfrom pydantic.type_adapter import TypeAdapter\n\n\nclass Foo(BaseModel):\n    a: int\n\n\nclass Model(BaseModel):\n    a: Foo\n\n\n# Default location for OpenAPI\n_, top_level_schema = TypeAdapter.json_schemas(\n    [(Model, 'validation', TypeAdapter(Model))],\n    ref_template='#/components/schemas/{model}',\n)\nprint(json.dumps(top_level_schema, indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"$defs\": {\n\"Foo\": {\n\"properties\": {\n\"a\": {\n\"title\": \"A\",\n\"type\": \"integer\"\n}\n},\n\"required\": [\n\"a\"\n],\n\"title\": \"Foo\",\n\"type\": \"object\"\n},\n\"Model\": {\n\"properties\": {\n\"a\": {\n\"$ref\": \"#/components/schemas/Foo\"\n}\n},\n\"required\": [\n\"a\"\n],\n\"title\": \"Model\",\n\"type\": \"object\"\n}\n}\n}\n</code></pre> <p>It's also possible to extend/override the generated JSON schema in a model.</p> <p>To do it, implement <code>__get_pydantic_json_schema__</code> on your model:</p> <p>For example, you could add <code>examples</code> to the JSON Schema:</p> <pre><code>import json\n\nfrom pydantic_core import CoreSchema\n\nfrom pydantic import BaseModel, GetJsonSchemaHandler\nfrom pydantic.json_schema import JsonSchemaValue\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, core_schema: CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        json_schema = handler(core_schema)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema['examples'] = [\n            {\n                'name': 'John Doe',\n                'age': 25,\n            }\n        ]\n        return json_schema\n\n\nprint(json.dumps(Person.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n\"examples\": [\n{\n\"age\": 25,\n\"name\": \"John Doe\"\n}\n],\n\"properties\": {\n\"age\": {\n\"title\": \"Age\",\n\"type\": \"integer\"\n},\n\"name\": {\n\"title\": \"Name\",\n\"type\": \"string\"\n}\n},\n\"required\": [\n\"name\",\n\"age\"\n],\n\"title\": \"Person\",\n\"type\": \"object\"\n}\n</code></pre> <p>Note that you must return a schema, even if you are just mutating it in-place.</p>"},{"location":"usage/model_config/","title":"Model Config","text":"<p>Behaviour of pydantic can be controlled via the <code>model_config</code> attribute on a <code>BaseModel</code>.</p> <p>Note</p> <p>Before v2.0, the <code>Config</code> class was used. This is still supported, but deprecated.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(str_max_length=10)\n\n    v: str\n\n\ntry:\n    m = Model(v='x' * 20)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    v\n      String should have at most 10 characters [type=string_too_long, input_value='xxxxxxxxxxxxxxxxxxxx', input_type=str]\n    \"\"\"\n</code></pre> <p>Also, you can specify config options as model class kwargs: <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel, extra='forbid'):  # (1)!\n    a: str\n\n\ntry:\n    Model(a='spam', b='oh no')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    b\n      Extra inputs are not permitted [type=extra_forbidden, input_value='oh no', input_type=str]\n    \"\"\"\n</code></pre></p> <ol> <li>See the Extra Attributes section for more details.</li> </ol> <p>Similarly, if using the <code>@dataclass</code> decorator from pydantic: <pre><code>from datetime import datetime\n\nfrom pydantic import ConfigDict, ValidationError\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass(config=ConfigDict(str_max_length=10, validate_assignment=True))  # (1)!\nclass User:\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n\n\nuser = User(id='42', signup_ts='2032-06-21T12:00')\ntry:\n    user.name = 'x' * 20\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    name\n      String should have at most 10 characters [type=string_too_long, input_value='xxxxxxxxxxxxxxxxxxxx', input_type=str]\n    \"\"\"\n</code></pre></p> <ol> <li> <p>If using the <code>dataclass</code> from the standard library, you should use <code>__pydantic_config__</code> instead.    See:</p> <pre><code>from dataclasses import dataclass\nfrom datetime import datetime\n\nfrom pydantic import ConfigDict\n\n\n@dataclass\nclass User:\n    __pydantic_config__ = ConfigDict(strict=True)\n\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n</code></pre> </li> </ol>"},{"location":"usage/model_config/#options","title":"Options","text":"<p>See the <code>ConfigDict</code> API documentation for the full list of settings.</p>"},{"location":"usage/model_config/#change-behaviour-globally","title":"Change behaviour globally","text":"<p>If you wish to change the behaviour of Pydantic globally, you can create your own custom <code>BaseModel</code> with custom <code>model_config</code> since the config is inherited:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Parent(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n\nclass Model(Parent):\n    x: str\n\n\nm = Model(x='foo', y='bar')\nprint(m.model_dump())\n#&gt; {'x': 'foo', 'y': 'bar'}\n</code></pre> <ol> <li>Since <code>Parent</code> is a subclass of <code>BaseModel</code>, it will inherit the <code>model_config</code> attribute.    This means that <code>Model</code> will have <code>extra='allow'</code> by default.</li> </ol> <p>If you add a <code>model_config</code> to the <code>Model</code> class, it will merge with the <code>model_config</code> from <code>Parent</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Parent(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n\nclass Model(Parent):\n    model_config = ConfigDict(str_to_lower=True)  # (1)!\n\n    x: str\n\n\nm = Model(x='FOO', y='bar')\nprint(m.model_dump())\n#&gt; {'x': 'foo', 'y': 'bar'}\nprint(m.model_config)\n#&gt; {'extra': 'allow', 'str_to_lower': True}\n</code></pre>"},{"location":"usage/model_config/#alias-generator","title":"Alias Generator","text":"<p>If data source field names do not match your code style (e. g. CamelCase fields), you can automatically generate aliases using <code>alias_generator</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\ndef to_camel(string: str) -&gt; str:\n    return ''.join(word.capitalize() for word in string.split('_'))\n\n\nclass Voice(BaseModel):\n    model_config = ConfigDict(alias_generator=to_camel)\n\n    name: str\n    language_code: str\n\n\nvoice = Voice(Name='Filiz', LanguageCode='tr-TR')\nprint(voice.language_code)\n#&gt; tr-TR\nprint(voice.model_dump(by_alias=True))\n#&gt; {'Name': 'Filiz', 'LanguageCode': 'tr-TR'}\n</code></pre> <p>Here camel case refers to \"upper camel case\" aka pascal case e.g. <code>CamelCase</code>. If you'd like instead to use lower camel case e.g. <code>camelCase</code>, instead use the <code>to_lower_camel</code> function.</p>"},{"location":"usage/model_config/#alias-precedence","title":"Alias Precedence","text":"<p>If you specify an <code>alias</code> on the <code>Field</code>, it will take precedence over the generated alias:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\ndef to_camel(string: str) -&gt; str:\n    return ''.join(word.capitalize() for word in string.split('_'))\n\n\nclass Voice(BaseModel):\n    model_config = ConfigDict(alias_generator=to_camel)\n\n    name: str\n    language_code: str = Field(alias='lang')\n\n\nvoice = Voice(Name='Filiz', lang='tr-TR')\nprint(voice.language_code)\n#&gt; tr-TR\nprint(voice.model_dump(by_alias=True))\n#&gt; {'Name': 'Filiz', 'lang': 'tr-TR'}\n</code></pre> <p>The same precedence applies to <code>validation_alias</code> and <code>serialization_alias</code>. See more about the different field aliases under field aliases.</p>"},{"location":"usage/model_config/#extra-attributes","title":"Extra Attributes","text":"<p>You can configure how pydantic handles the attributes that are not defined in the model:</p> <ul> <li><code>allow</code> - Allow any extra attributes.</li> <li><code>forbid</code> - Forbid any extra attributes.</li> <li><code>ignore</code> - Ignore any extra attributes.</li> </ul> <p>The default value is <code>'ignore'</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='ignore')  # (1)!\n\n    name: str\n\n\nuser = User(name='John Doe', age=20)  # (2)!\nprint(user)\n#&gt; name='John Doe'\n</code></pre> <ol> <li>This is the the default behaviour.</li> <li>The <code>age</code> argument is ignored.</li> </ol> <p>Instead, with <code>extra='allow'</code>, the <code>age</code> argument is included:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n    name: str\n\n\nuser = User(name='John Doe', age=20)  # (1)!\nprint(user)\n#&gt; name='John Doe' age=20\n</code></pre> <ol> <li>The <code>age</code> argument is included.</li> </ol> <p>With <code>extra='forbid'</code>, an error is raised:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='forbid')\n\n    name: str\n\n\ntry:\n    User(name='John Doe', age=20)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    age\n      Extra inputs are not permitted [type=extra_forbidden, input_value=20, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"usage/model_config/#populate-by-name","title":"Populate by Name","text":"<p>In case you set an alias, you can still populate the model by the original name.</p> <p>You need to set <code>populate_by_name=True</code> in the <code>model_config</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(alias='full_name')  # (1)!\n    age: int\n\n\nuser = User(full_name='John Doe', age=20)  # (2)!\nprint(user)\n#&gt; name='John Doe' age=20\nuser = User(name='John Doe', age=20)  # (3)!\nprint(user)\n#&gt; name='John Doe' age=20\n</code></pre> <ol> <li>The field <code>'name'</code> has an alias <code>'full_name'</code>.</li> <li>The model is populated by the alias <code>'full_name'</code>.</li> <li>The model is populated by the field name <code>'name'</code>.</li> </ol>"},{"location":"usage/model_config/#validate-assignment","title":"Validate Assignment","text":"<p>The default behavior of Pydantic is to validate the data when the model is created.</p> <p>In case the user changes the data after the model is created, the model is not revalidated.</p> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n\n\nuser = User(name='John Doe')  # (1)!\nprint(user)\n#&gt; name='John Doe'\nuser.name = 123  # (1)!\nprint(user)\n#&gt; name=123\n</code></pre> <ol> <li>The validation happens only when the model is created.</li> <li>The validation does not happen when the data is changed.</li> </ol> <p>In case you want to revalidate the model when the data is changed, you can use <code>validate_assignment=True</code>:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel, validate_assignment=True):  # (1)!\n    name: str\n\n\nuser = User(name='John Doe')  # (2)!\nprint(user)\n#&gt; name='John Doe'\ntry:\n    user.name = 123  # (3)!\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    name\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    \"\"\"\n</code></pre> <ol> <li>You can either use class keyword arguments, or <code>model_config</code> to set <code>validate_assignment=True</code>.</li> <li>The validation happens when the model is created.</li> <li>The validation also happens when the data is changed.</li> </ol>"},{"location":"usage/model_config/#revalidate-instances","title":"Revalidate instances","text":"<p>By default, model and dataclass instances are not revalidated during validation.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel, revalidate_instances='never'):  # (1)!\n    hobbies: List[str]\n\n\nclass SubUser(User):\n    sins: List[str]\n\n\nclass Transaction(BaseModel):\n    user: User\n\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]  # (2)!\nt = Transaction(user=my_user)  # (3)!\nprint(t)\n#&gt; user=User(hobbies=[1])\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)\n#&gt; user=SubUser(hobbies=['scuba diving'], sins=['lying'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'never'</code> by **default.</li> <li>The assignment is not validated, unless you set <code>validate_assignment</code> to <code>True</code> in the model's config.</li> <li>Since <code>revalidate_instances</code> is set to <code>never</code>, this is not revalidated.</li> </ol> <p>If you want to revalidate instances during validation, you can set <code>revalidate_instances</code> to <code>'always'</code> in the model's config.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel, revalidate_instances='always'):  # (1)!\n    hobbies: List[str]\n\n\nclass SubUser(User):\n    sins: List[str]\n\n\nclass Transaction(BaseModel):\n    user: User\n\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]\ntry:\n    t = Transaction(user=my_user)  # (2)!\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Transaction\n    user.hobbies.0\n      Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    \"\"\"\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)  # (3)!\n#&gt; user=User(hobbies=['scuba diving'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'always'</code>.</li> <li>The model is revalidated, since <code>revalidate_instances</code> is set to <code>'always'</code>.</li> <li>Using <code>'never'</code> we would have gotten <code>user=SubUser(hobbies=['scuba diving'], sins=['lying'])</code>.</li> </ol> <p>It's also possible to set <code>revalidate_instances</code> to <code>'subclass-instances'</code> to only revalidate instances of subclasses of the model.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel, revalidate_instances='subclass-instances'):  # (1)!\n    hobbies: List[str]\n\n\nclass SubUser(User):\n    sins: List[str]\n\n\nclass Transaction(BaseModel):\n    user: User\n\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]\nt = Transaction(user=my_user)  # (2)!\nprint(t)\n#&gt; user=User(hobbies=[1])\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)  # (3)!\n#&gt; user=User(hobbies=['scuba diving'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'subclass-instances'</code>.</li> <li>This is not revalidated, since <code>my_user</code> is not a subclass of <code>User</code>.</li> <li>Using <code>'never'</code> we would have gotten <code>user=SubUser(hobbies=['scuba diving'], sins=['lying'])</code>.</li> </ol>"},{"location":"usage/model_config/#arbitrary-types-allowed","title":"Arbitrary Types Allowed","text":"<p>You can allow arbitrary types using the <code>arbitrary_types_allowed</code> setting in the model's config:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\n# This is not a pydantic model, it's an arbitrary class\nclass Pet:\n    def __init__(self, name: str):\n        self.name = name\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    pet: Pet\n    owner: str\n\n\npet = Pet(name='Hedwig')\n# A simple check of instance type is used to validate the data\nmodel = Model(owner='Harry', pet=pet)\nprint(model)\n#&gt; pet=&lt;__main__.Pet object at 0x0123456789ab&gt; owner='Harry'\nprint(model.pet)\n#&gt; &lt;__main__.Pet object at 0x0123456789ab&gt;\nprint(model.pet.name)\n#&gt; Hedwig\nprint(type(model.pet))\n#&gt; &lt;class '__main__.Pet'&gt;\ntry:\n    # If the value is not an instance of the type, it's invalid\n    Model(owner='Harry', pet='Hedwig')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet\n      Input should be an instance of Pet [type=is_instance_of, input_value='Hedwig', input_type=str]\n    \"\"\"\n# Nothing in the instance of the arbitrary type is checked\n# Here name probably should have been a str, but it's not validated\npet2 = Pet(name=42)\nmodel2 = Model(owner='Harry', pet=pet2)\nprint(model2)\n#&gt; pet=&lt;__main__.Pet object at 0x0123456789ab&gt; owner='Harry'\nprint(model2.pet)\n#&gt; &lt;__main__.Pet object at 0x0123456789ab&gt;\nprint(model2.pet.name)\n#&gt; 42\nprint(type(model2.pet))\n#&gt; &lt;class '__main__.Pet'&gt;\n</code></pre>"},{"location":"usage/model_config/#protected-namespaces","title":"Protected Namespaces","text":"<p>Pydantic prevents collisions between model attributes and <code>BaseModel</code>'s own methods by namespacing them with the prefix <code>model_</code>.</p> <pre><code>from pydantic import BaseModel\n\ntry:\n\n    class Model(BaseModel):\n        model_prefixed_field: str\n\nexcept NameError as e:\n    print(e)\n    #&gt; Field \"model_prefixed_field\" has conflict with protected namespace \"model_\"\n</code></pre> <p>You can customize this behavior using the <code>protected_namespaces</code> setting:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\ntry:\n\n    class Model(BaseModel):\n        model_prefixed_field: str\n        also_protect_field: str\n\n        model_config = ConfigDict(protected_namespaces=('protect_me_', 'also_protect_'))\n\nexcept NameError as e:\n    print(e)\n    #&gt; Field \"also_protect_field\" has conflict with protected namespace \"also_protect_\"\n</code></pre>"},{"location":"usage/model_config/#hide-input-in-errors","title":"Hide Input in Errors","text":"<p>Pydantic shows the input value and type when it raises <code>ValidationError</code> during the validation.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: str\n\n\ntry:\n    Model(a=123)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    a\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    \"\"\"\n</code></pre> <p>You can hide the input value and type by setting the <code>hide_input_in_errors</code> config to <code>True</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    a: str\n\n    model_config = ConfigDict(hide_input_in_errors=True)\n\n\ntry:\n    Model(a=123)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    a\n      Input should be a valid string [type=string_type]\n    \"\"\"\n</code></pre>"},{"location":"usage/models/","title":"Models","text":"<p>The primary means of defining objects in Pydantic is via models. Models are simply classes which inherit from <code>BaseModel</code>.</p> <p>You can think of models as similar to types in strictly typed languages, or as the requirements of a single endpoint in an API.</p> <p>Untrusted data can be passed to a model and, after parsing and validation, Pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model.</p> <p>Note</p> <p>Pydantic is primarily a parsing and transformation library, not a validation library. Validation is a means to an end: building a model which conforms to the types and constraints provided.</p> <p>In other words, Pydantic guarantees the types and constraints of the output model, not the input data.</p> <p>This might sound like an esoteric distinction, but it is not. If you're unsure what this means or how it might affect your usage you should read the section about Data Conversion below.</p> <p>Although validation is not the main purpose of Pydantic, you can use this library for custom validation.</p>"},{"location":"usage/models/#basic-model-usage","title":"Basic model usage","text":"<pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'Jane Doe'\n</code></pre> <p>In this example, <code>User</code> is a model with two fields:</p> <ul> <li><code>id</code>, which is an integer and is required</li> <li><code>name</code>, which is a string and is not required (it has a default value).</li> </ul> <pre><code>user = User(id='123')\n</code></pre> <p>In this example, <code>user</code> is an instance of <code>User</code>. Initialisation of the object will perform all parsing and validation. If no <code>ValidationError</code> is raised, you know the resulting model instance is valid.</p> <pre><code>assert user.id == 123\nassert isinstance(user.id, int)\n# Note that '123' was coerced to an int and its value is 123\n</code></pre> <p>More details on pydantic's coercion logic can be found in Data Conversion. Fields of a model can be accessed as normal attributes of the user object. The string '123' has been cast to an int as per the field type.</p> <pre><code>assert user.name == 'Jane Doe'\n</code></pre> <p><code>name</code> wasn't set when <code>user</code> was initialised, so it has the default value.</p> <pre><code>assert user.model_fields_set == {'id'}\n</code></pre> <p>The fields which were supplied when user was initialised.</p> <pre><code>assert user.model_dump() == {'id': 123, 'name': 'Jane Doe'}\n</code></pre> <p>Either <code>.model_dump()</code> or <code>dict(user)</code> will provide a dict of fields, but <code>.model_dump()</code> can take numerous other arguments.</p> <pre><code>user.id = 321\nassert user.id == 321\n</code></pre> <p>This model is mutable so field values can be changed.</p>"},{"location":"usage/models/#model-methods-and-properties","title":"Model methods and properties","text":"<p>The example above only shows the tip of the iceberg of what models can do. Models possess the following methods and attributes:</p> <ul> <li><code>model_computed_fields</code>: a dictionary of the computed fields of this model instance.</li> <li><code>model_construct()</code>: a class method for creating models without running validation. See     Creating models without validation.</li> <li><code>model_copy()</code>: returns a copy (by default, shallow copy) of the model. See     Exporting models.</li> <li><code>model_dump()</code>: returns a dictionary of the model's fields and values. See     Exporting models.</li> <li><code>model_dump_json()</code>: returns a JSON string representation of <code>model_dump()</code>. See     Exporting models.</li> <li><code>model_extra</code>: get extra fields set during validation.</li> <li><code>model_fields_set</code>: set of fields which were set when the model instance was initialised.</li> <li><code>model_json_schema()</code>: returns a dictionary representing the model as JSON Schema. See JSON Schema.</li> <li><code>model_modify_json_schema()</code>: a method for how the \"generic\" properties of the JSON schema are populated.     See JSON Schema.</li> <li><code>model_parameterized_name()</code>: compute the class name for parametrizations of generic classes.</li> <li><code>model_post_init()</code>: perform additional initialization after the model is initialised.</li> <li><code>model_rebuild()</code>: rebuild the model schema.</li> <li><code>model_validate()</code>: a utility for loading any object into a model with error handling if the object is not a     dictionary. See Helper functions.</li> <li><code>model_validate_json()</code>: a utility for validating the given JSON data against the Pydantic model. See     Helper functions.</li> </ul> <p>Note</p> <p>See <code>BaseModel</code> for the class definition including a full list of methods and attributes.</p> <p>Tip</p> <p>See Changes to <code>pydantic.BaseModel</code> in the Migration Guide for details on changes from Pydantic V1.</p>"},{"location":"usage/models/#recursive-models","title":"Recursive models","text":"<p>More complex hierarchical data structures can be defined using models themselves as types in annotations.</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    count: int\n    size: Optional[float] = None\n\n\nclass Bar(BaseModel):\n    apple: str = 'x'\n    banana: str = 'y'\n\n\nclass Spam(BaseModel):\n    foo: Foo\n    bars: List[Bar]\n\n\nm = Spam(foo={'count': 4}, bars=[{'apple': 'x1'}, {'apple': 'x2'}])\nprint(m)\n\"\"\"\nfoo=Foo(count=4, size=None) bars=[Bar(apple='x1', banana='y'), Bar(apple='x2', banana='y')]\n\"\"\"\nprint(m.model_dump())\n\"\"\"\n{\n    'foo': {'count': 4, 'size': None},\n    'bars': [{'apple': 'x1', 'banana': 'y'}, {'apple': 'x2', 'banana': 'y'}],\n}\n\"\"\"\n</code></pre> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    count: int\n    size: Optional[float] = None\n\n\nclass Bar(BaseModel):\n    apple: str = 'x'\n    banana: str = 'y'\n\n\nclass Spam(BaseModel):\n    foo: Foo\n    bars: list[Bar]\n\n\nm = Spam(foo={'count': 4}, bars=[{'apple': 'x1'}, {'apple': 'x2'}])\nprint(m)\n\"\"\"\nfoo=Foo(count=4, size=None) bars=[Bar(apple='x1', banana='y'), Bar(apple='x2', banana='y')]\n\"\"\"\nprint(m.model_dump())\n\"\"\"\n{\n    'foo': {'count': 4, 'size': None},\n    'bars': [{'apple': 'x1', 'banana': 'y'}, {'apple': 'x2', 'banana': 'y'}],\n}\n\"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    count: int\n    size: float | None = None\n\n\nclass Bar(BaseModel):\n    apple: str = 'x'\n    banana: str = 'y'\n\n\nclass Spam(BaseModel):\n    foo: Foo\n    bars: list[Bar]\n\n\nm = Spam(foo={'count': 4}, bars=[{'apple': 'x1'}, {'apple': 'x2'}])\nprint(m)\n\"\"\"\nfoo=Foo(count=4, size=None) bars=[Bar(apple='x1', banana='y'), Bar(apple='x2', banana='y')]\n\"\"\"\nprint(m.model_dump())\n\"\"\"\n{\n    'foo': {'count': 4, 'size': None},\n    'bars': [{'apple': 'x1', 'banana': 'y'}, {'apple': 'x2', 'banana': 'y'}],\n}\n\"\"\"\n</code></pre> <p>For self-referencing models, see postponed annotations.</p>"},{"location":"usage/models/#arbitrary-class-instances","title":"Arbitrary class instances","text":"<p>(Formerly known as \"ORM Mode\"/<code>from_orm</code>.)</p> <p>Pydantic models can also be created from arbitrary class instances by reading the instance attributes corresponding to the model field names. One common application of this functionality is integration with object-relational mappings (ORMs).</p> <p>To do this, use the <code>model_config</code> property on the model with <code>from_attributes</code> set to <code>True</code>. See Model Config and ConfigDict for more information.</p> <p>The example here uses SQLAlchemy, but the same approach should work for any ORM.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom sqlalchemy import Column, Integer, String\nfrom sqlalchemy.dialects.postgresql import ARRAY\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom pydantic import BaseModel, ConfigDict, constr\n\nBase = declarative_base()\n\n\nclass CompanyOrm(Base):\n    __tablename__ = 'companies'\n\n    id = Column(Integer, primary_key=True, nullable=False)\n    public_key = Column(String(20), index=True, nullable=False, unique=True)\n    name = Column(String(63), unique=True)\n    domains = Column(ARRAY(String(255)))\n\n\nclass CompanyModel(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    id: int\n    public_key: constr(max_length=20)\n    name: constr(max_length=63)\n    domains: List[constr(max_length=255)]\n\n\nco_orm = CompanyOrm(\n    id=123,\n    public_key='foobar',\n    name='Testing',\n    domains=['example.com', 'foobar.com'],\n)\nprint(co_orm)\n#&gt; &lt;__main__.CompanyOrm object at 0x0123456789ab&gt;\nco_model = CompanyModel.model_validate(co_orm)\nprint(co_model)\n#&gt; id=123 public_key='foobar' name='Testing' domains=['example.com', 'foobar.com']\n</code></pre> <pre><code>from sqlalchemy import Column, Integer, String\nfrom sqlalchemy.dialects.postgresql import ARRAY\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom pydantic import BaseModel, ConfigDict, constr\n\nBase = declarative_base()\n\n\nclass CompanyOrm(Base):\n    __tablename__ = 'companies'\n\n    id = Column(Integer, primary_key=True, nullable=False)\n    public_key = Column(String(20), index=True, nullable=False, unique=True)\n    name = Column(String(63), unique=True)\n    domains = Column(ARRAY(String(255)))\n\n\nclass CompanyModel(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    id: int\n    public_key: constr(max_length=20)\n    name: constr(max_length=63)\n    domains: list[constr(max_length=255)]\n\n\nco_orm = CompanyOrm(\n    id=123,\n    public_key='foobar',\n    name='Testing',\n    domains=['example.com', 'foobar.com'],\n)\nprint(co_orm)\n#&gt; &lt;__main__.CompanyOrm object at 0x0123456789ab&gt;\nco_model = CompanyModel.model_validate(co_orm)\nprint(co_model)\n#&gt; id=123 public_key='foobar' name='Testing' domains=['example.com', 'foobar.com']\n</code></pre>"},{"location":"usage/models/#reserved-names","title":"Reserved names","text":"<p>You may want to name a <code>Column</code> after a reserved SQLAlchemy field. In that case, <code>Field</code> aliases will be convenient:</p> Python 3.7 and abovePython 3.9 and above <pre><code>import typing\n\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\n\nclass MyModel(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    metadata: typing.Dict[str, str] = Field(alias='metadata_')\n\n\nBase = declarative_base()\n\n\nclass SQLModel(Base):\n    __tablename__ = 'my_table'\n    id = sa.Column('id', sa.Integer, primary_key=True)\n    # 'metadata' is reserved by SQLAlchemy, hence the '_'\n    metadata_ = sa.Column('metadata', sa.JSON)\n\n\nsql_model = SQLModel(metadata_={'key': 'val'}, id=1)\n\npydantic_model = MyModel.model_validate(sql_model)\n\nprint(pydantic_model.model_dump())\n#&gt; {'metadata': {'key': 'val'}}\nprint(pydantic_model.model_dump(by_alias=True))\n#&gt; {'metadata_': {'key': 'val'}}\n</code></pre> <pre><code>import sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\n\nclass MyModel(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    metadata: dict[str, str] = Field(alias='metadata_')\n\n\nBase = declarative_base()\n\n\nclass SQLModel(Base):\n    __tablename__ = 'my_table'\n    id = sa.Column('id', sa.Integer, primary_key=True)\n    # 'metadata' is reserved by SQLAlchemy, hence the '_'\n    metadata_ = sa.Column('metadata', sa.JSON)\n\n\nsql_model = SQLModel(metadata_={'key': 'val'}, id=1)\n\npydantic_model = MyModel.model_validate(sql_model)\n\nprint(pydantic_model.model_dump())\n#&gt; {'metadata': {'key': 'val'}}\nprint(pydantic_model.model_dump(by_alias=True))\n#&gt; {'metadata_': {'key': 'val'}}\n</code></pre> <p>Note</p> <p>The example above works because aliases have priority over field names for field population. Accessing <code>SQLModel</code>'s <code>metadata</code> attribute would lead to a <code>ValidationError</code>.</p>"},{"location":"usage/models/#recursive-models_1","title":"Recursive models","text":"<p>Model instances will be parsed recursively as well as at the top level.</p> <p>Here a vanilla class is used to demonstrate the principle, but any class could be used instead.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ConfigDict\n\n\nclass PetCls:\n    def __init__(self, *, name: str, species: str):\n        self.name = name\n        self.species = species\n\n\nclass PersonCls:\n    def __init__(self, *, name: str, age: float = None, pets: List[PetCls]):\n        self.name = name\n        self.age = age\n        self.pets = pets\n\n\nclass Pet(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    species: str\n\n\nclass Person(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    age: float = None\n    pets: List[Pet]\n\n\nbones = PetCls(name='Bones', species='dog')\norion = PetCls(name='Orion', species='cat')\nanna = PersonCls(name='Anna', age=20, pets=[bones, orion])\nanna_model = Person.model_validate(anna)\nprint(anna_model)\n\"\"\"\nname='Anna' age=20.0 pets=[Pet(name='Bones', species='dog'), Pet(name='Orion', species='cat')]\n\"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass PetCls:\n    def __init__(self, *, name: str, species: str):\n        self.name = name\n        self.species = species\n\n\nclass PersonCls:\n    def __init__(self, *, name: str, age: float = None, pets: list[PetCls]):\n        self.name = name\n        self.age = age\n        self.pets = pets\n\n\nclass Pet(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    species: str\n\n\nclass Person(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    age: float = None\n    pets: list[Pet]\n\n\nbones = PetCls(name='Bones', species='dog')\norion = PetCls(name='Orion', species='cat')\nanna = PersonCls(name='Anna', age=20, pets=[bones, orion])\nanna_model = Person.model_validate(anna)\nprint(anna_model)\n\"\"\"\nname='Anna' age=20.0 pets=[Pet(name='Bones', species='dog'), Pet(name='Orion', species='cat')]\n\"\"\"\n</code></pre>"},{"location":"usage/models/#error-handling","title":"Error handling","text":"<p>Pydantic will raise <code>ValidationError</code> whenever it finds an error in the data it's validating.</p> <p>One exception will be raised regardless of the number of errors found, that <code>ValidationError</code> will contain information about all the errors and how they happened.</p> <p>See Error Handling for details on standard and custom errors.</p> <p>As a demonstration:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    list_of_ints: List[int]\n    a_float: float\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for Model\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='not a float', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    list_of_ints: list[int]\n    a_float: float\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for Model\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='not a float', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/models/#helper-functions","title":"Helper functions","text":"<p>Pydantic provides three <code>classmethod</code> helper functions on models for parsing data:</p> <ul> <li><code>model_validate</code>: this is very similar to the <code>__init__</code> method of the model, except it takes a dict   rather than keyword arguments. If the object passed is not a dict a <code>ValidationError</code> will be raised.</li> <li><code>model_validate_json</code>: this takes a str or bytes and parses it as json, then passes the result to <code>model_validate</code>.</li> </ul> Python 3.7 and abovePython 3.10 and above <pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n\n\nm = User.model_validate({'id': 123, 'name': 'James'})\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    User.model_validate(['not', 'a', 'dict'])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n      Input should be a valid dictionary [type=dict_type, input_value=['not', 'a', 'dict'], input_type=list]\n    \"\"\"\n\nm = User.model_validate_json('{\"id\": 123, \"name\": \"James\"}')\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    m = User.model_validate_json('{\"id\": 123, \"name\": 123}')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    name\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    \"\"\"\n\ntry:\n    m = User.model_validate_json('Invalid JSON')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n      Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='Invalid JSON', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime | None = None\n\n\nm = User.model_validate({'id': 123, 'name': 'James'})\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    User.model_validate(['not', 'a', 'dict'])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n      Input should be a valid dictionary [type=dict_type, input_value=['not', 'a', 'dict'], input_type=list]\n    \"\"\"\n\nm = User.model_validate_json('{\"id\": 123, \"name\": \"James\"}')\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    m = User.model_validate_json('{\"id\": 123, \"name\": 123}')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n    name\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    \"\"\"\n\ntry:\n    m = User.model_validate_json('Invalid JSON')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for User\n      Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='Invalid JSON', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/models/#creating-models-without-validation","title":"Creating models without validation","text":"<p>Pydantic also provides the <code>model_construct()</code> method, which allows models to be created without validation. This can be useful in at least a few cases:</p> <ul> <li>when working with complex data that is already known to be valid (for performance reasons)</li> <li>when one or more of the validator functions are non-idempotent, or</li> <li>when one or more of the validator functions have side effects that you don't want to be triggered.</li> </ul> <p>Note</p> <p>In Pydantic V2, the performance gap between <code>BaseModel.__init__</code> and <code>BaseModel.model_construct</code> has been narrowed considerably. For simple models, calling <code>BaseModel.__init__</code> may even be faster. If you are using <code>model_construct</code> for performance reasons, you may want to profile your use case before assuming that <code>model_construct</code> is faster.</p> <p>Warning</p> <p><code>model_construct()</code> does not do any validation, meaning it can create models which are invalid. You should only ever use the <code>model_construct()</code> method with data which has already been validated, or that you definitely trust.</p> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    age: int\n    name: str = 'John Doe'\n\n\noriginal_user = User(id=123, age=32)\n\nuser_data = original_user.model_dump()\nprint(user_data)\n#&gt; {'id': 123, 'age': 32, 'name': 'John Doe'}\nfields_set = original_user.model_fields_set\nprint(fields_set)\n#&gt; {'age', 'id'}\n\n# ...\n# pass user_data and fields_set to RPC or save to the database etc.\n# ...\n\n# you can then create a new instance of User without\n# re-running validation which would be unnecessary at this point:\nnew_user = User.model_construct(_fields_set=fields_set, **user_data)\nprint(repr(new_user))\n#&gt; User(id=123, age=32, name='John Doe')\nprint(new_user.model_fields_set)\n#&gt; {'age', 'id'}\n\n# construct can be dangerous, only use it with validated data!:\nbad_user = User.model_construct(id='dog')\nprint(repr(bad_user))\n#&gt; User(id='dog', name='John Doe')\n</code></pre> <p>The <code>_fields_set</code> keyword argument to <code>model_construct()</code> is optional, but allows you to be more precise about which fields were originally set and which weren't. If it's omitted <code>model_fields_set</code> will just be the keys of the data provided.</p> <p>For example, in the example above, if <code>_fields_set</code> was not provided, <code>new_user.model_fields_set</code> would be <code>{'id', 'age', 'name'}</code>.</p> <p>Note that for subclasses of <code>RootModel</code>, the root value can be passed to <code>model_construct</code> positionally, instead of using a keyword argument.</p> <p>Here are some additional notes on the behavior of <code>model_construct</code>:</p> <ul> <li>When we say \"no validation is performed\" \u2014 this includes converting dicts to model instances. So if you have a field   with a <code>Model</code> type, you will need to convert the inner dict to a model yourself before passing it to   <code>model_construct</code>.</li> <li>In particular, the <code>model_construct</code> method does not support recursively constructing models from dicts.</li> <li>If you do not pass keyword arguments for fields with defaults, the default values will still be used.</li> <li>For models with <code>model_config['extra'] == 'allow'</code>, data not corresponding to fields will be correctly stored in   the <code>__pydantic_extra__</code> dict.</li> <li>For models with private attributes, the <code>__pydantic_private__</code> dict will be initialized the same as it would be when   calling <code>__init__</code>.</li> <li>When constructing an instance using <code>model_construct()</code>, no <code>__init__</code> method from the model or any of its parent   classes will be called, even when a custom <code>__init__</code> method is defined.</li> </ul>"},{"location":"usage/models/#generic-models","title":"Generic models","text":"<p>Pydantic supports the creation of generic models to make it easier to reuse a common model structure.</p> <p>In order to declare a generic model, you perform the following steps:</p> <ul> <li>Declare one or more <code>typing.TypeVar</code> instances to use to parameterize your model.</li> <li>Declare a pydantic model that inherits from <code>pydantic.generics.GenericModel</code> and <code>typing.Generic</code>,   where you pass the <code>TypeVar</code> instances as parameters to <code>typing.Generic</code>.</li> <li>Use the <code>TypeVar</code> instances as annotations where you will want to replace them with other types or   pydantic models.</li> </ul> <p>Here is an example using <code>GenericModel</code> to create an easily-reused HTTP response payload wrapper:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Generic, List, Optional, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nDataT = TypeVar('DataT')\n\n\nclass Error(BaseModel):\n    code: int\n    message: str\n\n\nclass DataModel(BaseModel):\n    numbers: List[int]\n    people: List[str]\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: Optional[DataT] = None\n\n\ndata = DataModel(numbers=[1, 2, 3], people=[])\nerror = Error(code=404, message='Not found')\n\nprint(Response[int](data=1))\n#&gt; data=1\nprint(Response[str](data='value'))\n#&gt; data='value'\nprint(Response[str](data='value').model_dump())\n#&gt; {'data': 'value'}\nprint(Response[DataModel](data=data).model_dump())\n#&gt; {'data': {'numbers': [1, 2, 3], 'people': []}}\ntry:\n    Response[int](data='value')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Response[int]\n    data\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='value', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import Generic, Optional, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nDataT = TypeVar('DataT')\n\n\nclass Error(BaseModel):\n    code: int\n    message: str\n\n\nclass DataModel(BaseModel):\n    numbers: list[int]\n    people: list[str]\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: Optional[DataT] = None\n\n\ndata = DataModel(numbers=[1, 2, 3], people=[])\nerror = Error(code=404, message='Not found')\n\nprint(Response[int](data=1))\n#&gt; data=1\nprint(Response[str](data='value'))\n#&gt; data='value'\nprint(Response[str](data='value').model_dump())\n#&gt; {'data': 'value'}\nprint(Response[DataModel](data=data).model_dump())\n#&gt; {'data': {'numbers': [1, 2, 3], 'people': []}}\ntry:\n    Response[int](data='value')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Response[int]\n    data\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='value', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nDataT = TypeVar('DataT')\n\n\nclass Error(BaseModel):\n    code: int\n    message: str\n\n\nclass DataModel(BaseModel):\n    numbers: list[int]\n    people: list[str]\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: DataT | None = None\n\n\ndata = DataModel(numbers=[1, 2, 3], people=[])\nerror = Error(code=404, message='Not found')\n\nprint(Response[int](data=1))\n#&gt; data=1\nprint(Response[str](data='value'))\n#&gt; data='value'\nprint(Response[str](data='value').model_dump())\n#&gt; {'data': 'value'}\nprint(Response[DataModel](data=data).model_dump())\n#&gt; {'data': {'numbers': [1, 2, 3], 'people': []}}\ntry:\n    Response[int](data='value')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Response[int]\n    data\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='value', input_type=str]\n    \"\"\"\n</code></pre> <p>If you set <code>Config</code> or make use of <code>validator</code> in your generic model definition, it is applied to concrete subclasses in the same way as when inheriting from <code>BaseModel</code>. Any methods defined on your generic class will also be inherited.</p> <p>Pydantic's generics also integrate properly with mypy, so you get all the type checking you would expect mypy to provide if you were to declare the type without using <code>GenericModel</code>.</p> <p>Note</p> <p>Internally, pydantic uses <code>create_model</code> to generate a (cached) concrete <code>BaseModel</code> at runtime, so there is essentially zero overhead introduced by making use of <code>GenericModel</code>.</p> <p>To inherit from a GenericModel without replacing the <code>TypeVar</code> instance, a class must also inherit from <code>typing.Generic</code>:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nTypeX = TypeVar('TypeX')\n\n\nclass BaseClass(BaseModel, Generic[TypeX]):\n    X: TypeX\n\n\nclass ChildClass(BaseClass[TypeX], Generic[TypeX]):\n    # Inherit from Generic[TypeX]\n    pass\n\n\n# Replace TypeX by int\nprint(ChildClass[int](X=1))\n#&gt; X=1\n</code></pre> <p>You can also create a generic subclass of a <code>GenericModel</code> that partially or fully replaces the type parameters in the superclass.</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nTypeX = TypeVar('TypeX')\nTypeY = TypeVar('TypeY')\nTypeZ = TypeVar('TypeZ')\n\n\nclass BaseClass(BaseModel, Generic[TypeX, TypeY]):\n    x: TypeX\n    y: TypeY\n\n\nclass ChildClass(BaseClass[int, TypeY], Generic[TypeY, TypeZ]):\n    z: TypeZ\n\n\n# Replace TypeY by str\nprint(ChildClass[str, int](x='1', y='y', z='3'))\n#&gt; x=1 y='y' z=3\n</code></pre> <p>If the name of the concrete subclasses is important, you can also override the default behavior:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, Generic, Tuple, Type, TypeVar\n\nfrom pydantic import BaseModel\n\nDataT = TypeVar('DataT')\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: DataT\n\n    @classmethod\n    def model_parametrized_name(cls, params: Tuple[Type[Any], ...]) -&gt; str:\n        return f'{params[0].__name__.title()}Response'\n\n\nprint(repr(Response[int](data=1)))\n#&gt; IntResponse(data=1)\nprint(repr(Response[str](data='a')))\n#&gt; StrResponse(data='a')\n</code></pre> <pre><code>from typing import Any, Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nDataT = TypeVar('DataT')\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: DataT\n\n    @classmethod\n    def model_parametrized_name(cls, params: tuple[type[Any], ...]) -&gt; str:\n        return f'{params[0].__name__.title()}Response'\n\n\nprint(repr(Response[int](data=1)))\n#&gt; IntResponse(data=1)\nprint(repr(Response[str](data='a')))\n#&gt; StrResponse(data='a')\n</code></pre> <p>Using the same TypeVar in nested models allows you to enforce typing relationships at different points in your model:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')\n\n\nclass InnerT(BaseModel, Generic[T]):\n    inner: T\n\n\nclass OuterT(BaseModel, Generic[T]):\n    outer: T\n    nested: InnerT[T]\n\n\nnested = InnerT[int](inner=1)\nprint(OuterT[int](outer=1, nested=nested))\n#&gt; outer=1 nested=InnerT[int](inner=1)\ntry:\n    nested = InnerT[str](inner='a')\n    print(OuterT[int](outer='a', nested=nested))\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for OuterT[int]\n    outer\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    nested\n      Input should be a valid dictionary [type=dict_type, input_value=InnerT[str](inner='a'), input_type=InnerT[str]]\n    \"\"\"\n</code></pre> <p>Pydantic also treats <code>GenericModel</code> similarly to how it treats built-in generic types like <code>List</code> and <code>Dict</code> when it comes to leaving them unparameterized, or using bounded <code>TypeVar</code> instances:</p> <ul> <li>If you don't specify parameters before instantiating the generic model, they will be treated as <code>Any</code></li> <li>You can parametrize models with one or more bounded parameters to add subclass checks</li> </ul> <p>Also, like <code>List</code> and <code>Dict</code>, any parameters specified using a <code>TypeVar</code> can later be substituted with concrete types.</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nAT = TypeVar('AT')\nBT = TypeVar('BT')\n\n\nclass Model(BaseModel, Generic[AT, BT]):\n    a: AT\n    b: BT\n\n\nprint(Model(a='a', b='a'))\n#&gt; a='a' b='a'\n\nIntT = TypeVar('IntT', bound=int)\ntypevar_model = Model[int, IntT]\nprint(typevar_model(a=1, b=1))\n#&gt; a=1 b=1\ntry:\n    typevar_model(a='a', b='a')\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    2 validation errors for Model[int, ~IntT]\n    a\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    b\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n\nconcrete_model = typevar_model[int]\nprint(concrete_model(a=1, b=1))\n#&gt; a=1 b=1\n</code></pre>"},{"location":"usage/models/#dynamic-model-creation","title":"Dynamic model creation","text":"<p>There are some occasions where the shape of a model is not known until runtime. For this Pydantic provides the <code>create_model</code> method to allow models to be created on the fly.</p> <pre><code>from pydantic import BaseModel, create_model\n\nDynamicFoobarModel = create_model('DynamicFoobarModel', foo=(str, ...), bar=(int, 123))\n\n\nclass StaticFoobarModel(BaseModel):\n    foo: str\n    bar: int = 123\n</code></pre> <p>Here <code>StaticFoobarModel</code> and <code>DynamicFoobarModel</code> are identical.</p> <p>Warning</p> <p>See the note in Required Optional Fields for the distinction between an ellipsis as a field default and annotation-only fields. See pydantic/pydantic#1047 for more details.</p> <p>Fields are defined by a tuple of the form <code>(&lt;type&gt;, &lt;default value&gt;)</code>. The special keyword arguments <code>__config__</code> and <code>__base__</code> can be used to customise the new model. This includes extending a base model with extra fields.</p> <pre><code>from pydantic import BaseModel, create_model\n\n\nclass FooModel(BaseModel):\n    foo: str\n    bar: int = 123\n\n\nBarModel = create_model(\n    'BarModel',\n    apple=(str, 'russet'),\n    banana=(str, 'yellow'),\n    __base__=FooModel,\n)\nprint(BarModel)\n#&gt; &lt;class 'pydantic.main.BarModel'&gt;\nprint(BarModel.model_fields.keys())\n#&gt; dict_keys(['foo', 'bar', 'apple', 'banana'])\n</code></pre> <p>You can also add validators by passing a dict to the <code>__validators__</code> argument.</p> <pre><code>from pydantic import ValidationError, create_model, field_validator\n\n\ndef username_alphanumeric(cls, v):\n    assert v.isalnum(), 'must be alphanumeric'\n    return v\n\n\nvalidators = {'username_validator': field_validator('username')(username_alphanumeric)}\n\nUserModel = create_model('UserModel', username=(str, ...), __validators__=validators)\n\nuser = UserModel(username='scolvin')\nprint(user)\n#&gt; username='scolvin'\n\ntry:\n    UserModel(username='scolvi%n')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for UserModel\n    username\n      Assertion failed, must be alphanumeric [type=assertion_error, input_value='scolvi%n', input_type=str]\n    \"\"\"\n</code></pre> <p>Note</p> <p>To pickle a dynamically created model:</p> <ul> <li>the model must be defined globally</li> <li>it must provide <code>__module__</code></li> </ul>"},{"location":"usage/models/#typeadapter","title":"<code>TypeAdapter</code>","text":"<p><code>TypeAdapter</code> enables using Pydantic for type validation, serialization, and JSON schema without creating a <code>BaseModel</code></p> <p>You may have types that are not <code>BaseModel</code>s that you want to validate data against. Or you may want to validate a <code>List[SomeModel]</code>, or dump it to JSON.</p> <p>To do this, Pydantic provides <code>TypeAdapter</code>.</p> <p>A <code>TypeAdapter</code> instance exposes some of the functionality from <code>BaseModel</code> instance methods for types that do not have such methods (such as dataclasses, primitive types, and more).</p> <p>Note that <code>TypeAdapter</code> is not an actual type, so you cannot use it in type annotations.</p> Python 3.7 and abovePython 3.9 and abovePython 3.11 and above <pre><code>from typing import List\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\nclass User(TypedDict):\n    name: str\n    id: int\n\n\nUserListValidator = TypeAdapter(List[User])\nprint(repr(UserListValidator.validate_python([{'name': 'Fred', 'id': '3'}])))\n#&gt; [{'name': 'Fred', 'id': 3}]\n\ntry:\n    UserListValidator.validate_python([{'name': 'Fred', 'id': 'wrong', 'other': 'no'}])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for list[typed-dict]\n    0.id\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\nclass User(TypedDict):\n    name: str\n    id: int\n\n\nUserListValidator = TypeAdapter(list[User])\nprint(repr(UserListValidator.validate_python([{'name': 'Fred', 'id': '3'}])))\n#&gt; [{'name': 'Fred', 'id': 3}]\n\ntry:\n    UserListValidator.validate_python([{'name': 'Fred', 'id': 'wrong', 'other': 'no'}])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for list[typed-dict]\n    0.id\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import TypedDict\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\nclass User(TypedDict):\n    name: str\n    id: int\n\n\nUserListValidator = TypeAdapter(list[User])\nprint(repr(UserListValidator.validate_python([{'name': 'Fred', 'id': '3'}])))\n#&gt; [{'name': 'Fred', 'id': 3}]\n\ntry:\n    UserListValidator.validate_python([{'name': 'Fred', 'id': 'wrong', 'other': 'no'}])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for list[typed-dict]\n    0.id\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n</code></pre> <p>For some use cases, <code>TypeAdapter</code> can replace <code>BaseModel</code>s with a <code>__root__</code> field in Pydantic V1.</p>"},{"location":"usage/models/#parsing-data-into-a-specified-type","title":"Parsing data into a specified type","text":"<p><code>TypeAdapter</code> can be used to apply the parsing logic to populate pydantic models in a more ad-hoc way. This function behaves similarly to <code>BaseModel.model_validate</code>, but works with arbitrary Pydantic-compatible types.</p> <p>This is especially useful when you want to parse results into a type that is not a direct subclass of <code>BaseModel</code>. For example:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, TypeAdapter\n\n\nclass Item(BaseModel):\n    id: int\n    name: str\n\n\n# `item_data` could come from an API call, eg., via something like:\n# item_data = requests.get('https://my-api.com/items').json()\nitem_data = [{'id': 1, 'name': 'My Item'}]\n\nitems = TypeAdapter(List[Item]).validate_python(item_data)\nprint(items)\n#&gt; [Item(id=1, name='My Item')]\n</code></pre> <pre><code>from pydantic import BaseModel, TypeAdapter\n\n\nclass Item(BaseModel):\n    id: int\n    name: str\n\n\n# `item_data` could come from an API call, eg., via something like:\n# item_data = requests.get('https://my-api.com/items').json()\nitem_data = [{'id': 1, 'name': 'My Item'}]\n\nitems = TypeAdapter(list[Item]).validate_python(item_data)\nprint(items)\n#&gt; [Item(id=1, name='My Item')]\n</code></pre> <p><code>TypeAdapter</code> is capable of parsing data into any of the types pydantic can handle as fields of a <code>BaseModel</code>.</p>"},{"location":"usage/models/#rootmodel-and-custom-root-types","title":"<code>RootModel</code> and custom root types","text":"<p>Pydantic models can be defined with a custom root type by declaring the <code>RootModel</code>.</p> <p>The root type can be any type supported by pydantic, and is specified by the type hint of <code>RootModel</code>. The root value can be passed to the model <code>__init__</code> or <code>model_validate</code> as via the first and only argument.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Dict, List\n\nfrom pydantic import RootModel\n\nPets = RootModel[List[str]]\nPetsByName = RootModel[Dict[str, str]]\n\n\nprint(Pets(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets(['dog', 'cat']).model_dump_json())\n#&gt; [\"dog\",\"cat\"]\nprint(Pets.model_validate(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets.model_json_schema())\n#&gt; {'items': {'type': 'string'}, 'title': 'RootModel[List[str]]', 'type': 'array'}\n\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}).model_dump_json())\n#&gt; {\"Otis\":\"dog\",\"Milo\":\"cat\"}\nprint(PetsByName.model_validate({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\n</code></pre> <pre><code>from pydantic import RootModel\n\nPets = RootModel[list[str]]\nPetsByName = RootModel[dict[str, str]]\n\n\nprint(Pets(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets(['dog', 'cat']).model_dump_json())\n#&gt; [\"dog\",\"cat\"]\nprint(Pets.model_validate(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets.model_json_schema())\n#&gt; {'items': {'type': 'string'}, 'title': 'RootModel[List[str]]', 'type': 'array'}\n\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}).model_dump_json())\n#&gt; {\"Otis\":\"dog\",\"Milo\":\"cat\"}\nprint(PetsByName.model_validate({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\n</code></pre> <p>If you want to access items in the <code>root</code> field directly or to iterate over the items, you can implement custom <code>__iter__</code> and <code>__getitem__</code> functions, as shown in the following example.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import RootModel\n\n\nclass Pets(RootModel):\n    root: List[str]\n\n    def __iter__(self):\n        return iter(self.root)\n\n    def __getitem__(self, item):\n        return self.root[item]\n\n\npets = Pets.model_validate(['dog', 'cat'])\nprint(pets[0])\n#&gt; dog\nprint([pet for pet in pets])\n#&gt; ['dog', 'cat']\n</code></pre> <pre><code>from pydantic import RootModel\n\n\nclass Pets(RootModel):\n    root: list[str]\n\n    def __iter__(self):\n        return iter(self.root)\n\n    def __getitem__(self, item):\n        return self.root[item]\n\n\npets = Pets.model_validate(['dog', 'cat'])\nprint(pets[0])\n#&gt; dog\nprint([pet for pet in pets])\n#&gt; ['dog', 'cat']\n</code></pre>"},{"location":"usage/models/#faux-immutability","title":"Faux immutability","text":"<p>Models can be configured to be immutable via <code>frozen = True</code>. When this is set, attempting to change the values of instance attributes will raise errors. See model config for more details on <code>Config</code>.</p> <p>Note</p> <p>This behavior can be achieved in Pydantic V1 via <code>allow_mutation = False</code>. This config is deprecated in Pydantic V2.</p> <p>Warning</p> <p>Immutability in Python is never strict. If developers are determined/stupid they can always modify a so-called \"immutable\" object.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass FooBarModel(BaseModel):\n    model_config = ConfigDict(frozen=True)\n\n    a: str\n    b: dict\n\n\nfoobar = FooBarModel(a='hello', b={'apple': 'pear'})\n\ntry:\n    foobar.a = 'different'\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for FooBarModel\n    a\n      Instance is frozen [type=frozen_instance, input_value='different', input_type=str]\n    \"\"\"\n\nprint(foobar.a)\n#&gt; hello\nprint(foobar.b)\n#&gt; {'apple': 'pear'}\nfoobar.b['apple'] = 'grape'\nprint(foobar.b)\n#&gt; {'apple': 'grape'}\n</code></pre> <p>Trying to change <code>a</code> caused an error, and <code>a</code> remains unchanged. However, the dict <code>b</code> is mutable, and the immutability of <code>foobar</code> doesn't stop <code>b</code> from being changed.</p>"},{"location":"usage/models/#abstract-base-classes","title":"Abstract base classes","text":"<p>Pydantic models can be used alongside Python's Abstract Base Classes (ABCs).</p> <pre><code>import abc\n\nfrom pydantic import BaseModel\n\n\nclass FooBarModel(BaseModel, abc.ABC):\n    a: str\n    b: int\n\n    @abc.abstractmethod\n    def my_abstract_method(self):\n        pass\n</code></pre>"},{"location":"usage/models/#field-ordering","title":"Field ordering","text":"<p>Field order is important in models for the following reasons:</p> <ul> <li>validation is performed in the order fields are defined; fields validators   can access the values of earlier fields, but not later ones</li> <li>field order is preserved in the model schema</li> <li>field order is preserved in validation errors</li> <li>field order is preserved by <code>.model_dump()</code> and <code>.model_dump_json()</code> etc.</li> </ul> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: int\n    b: int = 2\n    c: int = 1\n    d: int = 0\n    e: float\n\n\nprint(Model.model_fields.keys())\n#&gt; dict_keys(['a', 'b', 'c', 'd', 'e'])\nm = Model(e=2, a=1)\nprint(m.model_dump())\n#&gt; {'a': 1, 'b': 2, 'c': 1, 'd': 0, 'e': 2.0}\ntry:\n    Model(a='x', b='x', c='x', d='x', e='x')\nexcept ValidationError as err:\n    error_locations = [e['loc'] for e in err.errors()]\n\nprint(error_locations)\n#&gt; [('a',), ('b',), ('c',), ('d',), ('e',)]\n</code></pre>"},{"location":"usage/models/#required-fields","title":"Required fields","text":"<p>To declare a field as required, you may declare it using just an annotation, or you may use an ellipsis (<code>...</code>) as the value:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    a: int\n    b: int = ...\n    c: int = Field(...)\n</code></pre> <p>Where <code>Field</code> refers to the field function.</p> <p>Here <code>a</code>, <code>b</code> and <code>c</code> are all required. However, use of the ellipses in <code>b</code> will not work well with mypy, and as of v1.0 should be avoided in most cases.</p>"},{"location":"usage/models/#required-optional-fields","title":"Required Optional fields","text":"<p>If you want to specify a field that can take a <code>None</code> value while still being required, you can use <code>Optional</code> with <code>...</code>:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: Optional[int]\n    b: Optional[int] = None\n\n\nprint(Model(a=1))\n#&gt; a=1 b=None\ntry:\n    Model(b=2)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    a\n      Field required [type=missing, input_value={'b': 2}, input_type=dict]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: int | None\n    b: int | None = None\n\n\nprint(Model(a=1))\n#&gt; a=1 b=None\ntry:\n    Model(b=2)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    a\n      Field required [type=missing, input_value={'b': 2}, input_type=dict]\n    \"\"\"\n</code></pre> <p>In this model, <code>a</code> and <code>b</code> can take <code>None</code> as a value. But <code>b</code> is optional, while <code>a</code> and is required. <code>a</code> requires a value, even if the value is <code>None</code>.</p>"},{"location":"usage/models/#fields-with-non-hashable-default-values","title":"Fields with non-hashable default values","text":"<p>A common source of bugs in python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call.</p> <p>The <code>dataclasses</code> module actually raises an error in this case, indicating that you should use the <code>default_factory</code> argument to <code>dataclasses.field</code>.</p> <p>Pydantic also supports the use of a <code>default_factory</code> for non-hashable default values, but it is not required. In the event that the default value is not hashable, Pydantic will deepcopy the default value when creating each instance of the model:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Dict, List\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    item_counts: List[Dict[str, int]] = [{}]\n\n\nm1 = Model()\nm1.item_counts[0]['a'] = 1\nprint(m1.item_counts)\n#&gt; [{'a': 1}]\n\nm2 = Model()\nprint(m2.item_counts)\n#&gt; [{}]\n</code></pre> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    item_counts: list[dict[str, int]] = [{}]\n\n\nm1 = Model()\nm1.item_counts[0]['a'] = 1\nprint(m1.item_counts)\n#&gt; [{'a': 1}]\n\nm2 = Model()\nprint(m2.item_counts)\n#&gt; [{}]\n</code></pre>"},{"location":"usage/models/#fields-with-dynamic-default-values","title":"Fields with dynamic default values","text":"<p>When declaring a field with a default value, you may want it to be dynamic (i.e. different for each model). To do this, you may want to use a <code>default_factory</code>.</p> <p>Example of usage:</p> <pre><code>from datetime import datetime\nfrom uuid import UUID, uuid4\n\nfrom pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    uid: UUID = Field(default_factory=uuid4)\n    updated: datetime = Field(default_factory=datetime.utcnow)\n\n\nm1 = Model()\nm2 = Model()\nassert m1.uid != m2.uid\nassert m1.updated != m2.updated\n</code></pre> <p>Where <code>Field</code> refers to the field function.</p> <p>Warning</p> <p>The <code>default_factory</code> expects the field type to be set.</p>"},{"location":"usage/models/#automatically-excluded-attributes","title":"Automatically excluded attributes","text":"<p>Class variables which begin with an underscore and attributes annotated with <code>typing.ClassVar</code> will be automatically excluded from the model.</p>"},{"location":"usage/models/#private-model-attributes","title":"Private model attributes","text":"<p>If you need to vary or manipulate internal attributes on instances of the model, you can declare them using <code>PrivateAttr</code>:</p> <pre><code>from datetime import datetime\nfrom random import randint\n\nfrom pydantic import BaseModel, PrivateAttr\n\n\nclass TimeAwareModel(BaseModel):\n    _processed_at: datetime = PrivateAttr(default_factory=datetime.now)\n    _secret_value: str = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        # this could also be done with default_factory\n        self._secret_value = randint(1, 5)\n\n\nm = TimeAwareModel()\nprint(m._processed_at)\n#&gt; 2032-01-02 03:04:05.000006\nprint(m._secret_value)\n#&gt; 3\n</code></pre> <p>Private attribute names must start with underscore to prevent conflicts with model fields: both <code>_attr</code> and <code>__attr__</code> are supported.</p>"},{"location":"usage/models/#data-conversion","title":"Data conversion","text":"<p>Pydantic may cast input data to force it to conform to model field types, and in some cases this may result in a loss of information. For example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: int\n    b: float\n    c: str\n\n\nprint(Model(a=3.000, b='2.72', c=b'binary data').model_dump())\n#&gt; {'a': 3, 'b': 2.72, 'c': 'binary data'}\n</code></pre> <p>This is a deliberate decision of Pydantic, and in general it's the most useful approach. See here for a longer discussion on the subject.</p> <p>Nevertheless, strict type checking is partially supported. [TODO: Discuss strict mode, but also retain the previous link to types/standard_types.md#strict-types]</p>"},{"location":"usage/models/#model-signature","title":"Model signature","text":"<p>All Pydantic models will have their signature generated based on their fields:</p> <pre><code>import inspect\n\nfrom pydantic import BaseModel, Field\n\n\nclass FooModel(BaseModel):\n    id: int\n    name: str = None\n    description: str = 'Foo'\n    apple: int = Field(alias='pear')\n\n\nprint(inspect.signature(FooModel))\n#&gt; (*, id: int, name: str = None, description: str = 'Foo', pear: int) -&gt; None\n</code></pre> <p>An accurate signature is useful for introspection purposes and libraries like <code>FastAPI</code> or <code>hypothesis</code>.</p> <p>The generated signature will also respect custom <code>__init__</code> functions:</p> <pre><code>import inspect\n\nfrom pydantic import BaseModel\n\n\nclass MyModel(BaseModel):\n    id: int\n    info: str = 'Foo'\n\n    def __init__(self, id: int = 1, *, bar: str, **data) -&gt; None:\n\"\"\"My custom init!\"\"\"\n        super().__init__(id=id, bar=bar, **data)\n\n\nprint(inspect.signature(MyModel))\n#&gt; (id: int = 1, *, bar: str, info: str = 'Foo') -&gt; None\n</code></pre> <p>To be included in the signature, a field's alias or name must be a valid Python identifier. Pydantic prefers aliases over names, but may use field names if the alias is not a valid Python identifier.</p> <p>If a field's alias and name are both invalid identifiers, a <code>**data</code> argument will be added. In addition, the <code>**data</code> argument will always be present in the signature if <code>Config.extra</code> is <code>'allow'</code>.</p>"},{"location":"usage/models/#structural-pattern-matching","title":"Structural pattern matching","text":"<p>Pydantic supports structural pattern matching for models, as introduced by PEP 636 in Python 3.10.</p> <pre><code>from pydantic import BaseModel\n\n\nclass Pet(BaseModel):\n    name: str\n    species: str\n\n\na = Pet(name='Bones', species='dog')\n\nmatch a:\n    # match `species` to 'dog', declare and initialize `dog_name`\n    case Pet(species='dog', name=dog_name):\n        print(f'{dog_name} is a dog')\n#&gt; Bones is a dog\n    # default case\n    case _:\n        print('No dog matched')\n</code></pre> <p>Note</p> <p>A match-case statement may seem as if it creates a new model, but don't be fooled; it is just syntactic sugar for getting an attribute and either comparing it or declaring and initializing it.</p>"},{"location":"usage/models/#attribute-copies","title":"Attribute copies","text":"<p>In many cases arguments passed to the constructor will be copied in order to perform validation and, where necessary, coercion. When constructing classes with data attributes, Pydantic copies the attributes in order to efficiently iterate over its elements for validation.</p> <p>In this example, note that the ID of the list changes after the class is constructed because it has been copied for validation.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass C1:\n    arr = []\n\n    def __init__(self, in_arr):\n        self.arr = in_arr\n\n\nclass C2(BaseModel):\n    arr: List[int]\n\n\narr_orig = [1, 9, 10, 3]\n\n\nc1 = C1(arr_orig)\nc2 = C2(arr=arr_orig)\nprint('id(c1.arr) == id(c2.arr)  ', id(c1.arr) == id(c2.arr))\n#&gt; id(c1.arr) == id(c2.arr)   False\n</code></pre> <pre><code>from pydantic import BaseModel\n\n\nclass C1:\n    arr = []\n\n    def __init__(self, in_arr):\n        self.arr = in_arr\n\n\nclass C2(BaseModel):\n    arr: list[int]\n\n\narr_orig = [1, 9, 10, 3]\n\n\nc1 = C1(arr_orig)\nc2 = C2(arr=arr_orig)\nprint('id(c1.arr) == id(c2.arr)  ', id(c1.arr) == id(c2.arr))\n#&gt; id(c1.arr) == id(c2.arr)   False\n</code></pre> <p>Note</p> <p>There are some situations where Pydantic does not copy attributes, such as when passing models \u2014 we use the model as is. You can override this behaviour by setting <code>config.revalidate_instances='always'</code> in your model.</p>"},{"location":"usage/models/#extra-fields","title":"Extra fields","text":"<p>By default Pydantic models won't error when you provide fields that don't belong to the model, it will discard them instead:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: int\n\n\nm = Model(x=1, y='a')\nassert m.model_dump() == {'x': 1}\n</code></pre> <p>If you want to error instead you can set this via <code>model_config</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='forbid')\n\n\ntry:\n    Model(x=1, y='a')\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for Model\n    y\n      Extra inputs are not permitted [type=extra_forbidden, input_value='a', input_type=str]\n    \"\"\"\n</code></pre> <p>To preserve this data instead you can set <code>extra='allow'</code>. The extra fields will then be stored in <code>BaseModel.__pydantic_extra__</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\nm = Model(x=1, y='a')\nassert m.__pydantic_extra__ == {'y': 'a'}\n</code></pre> <p>By default no validation will be applied to these extra items, but you can set a type for the values by overriding the type annotation for <code>__pydantic_extra__</code>:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Dict\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    __pydantic_extra__: Dict[str, int]\n\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\ntry:\n    Model(x=1, y='a')\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for Model\n    y\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n\nm = Model(x=1, y='2')\nassert m.x == 1\nassert m.y == 2\nassert m.model_dump() == {'x': 1, 'y': 2}\nassert m.__pydantic_extra__ == {'y': 2}\n</code></pre> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    __pydantic_extra__: dict[str, int]\n\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\ntry:\n    Model(x=1, y='a')\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for Model\n    y\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n\nm = Model(x=1, y='2')\nassert m.x == 1\nassert m.y == 2\nassert m.model_dump() == {'x': 1, 'y': 2}\nassert m.__pydantic_extra__ == {'y': 2}\n</code></pre> <p>The same configurations apply to <code>TypedDict</code> and <code>dataclass</code>' except the config is set via a <code>__pydantic_config__</code>.</p>"},{"location":"usage/postponed_annotations/","title":"Postponed annotations","text":"<p>Postponed annotations (as described in PEP563) \"just work\".</p> <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: list[int]\n    b: Any\n\n\nprint(Model(a=('1', 2, 3), b='ok'))\n#&gt; a=[1, 2, 3] b='ok'\n</code></pre> <p>Internally, Pydantic will call a method similar to <code>typing.get_type_hints</code> to resolve annotations.</p> <p>Even without using <code>from __future__ import annotations</code>, in cases where the referenced type is not yet defined, a <code>ForwardRef</code> or string can be used:</p> <pre><code>from typing import ForwardRef\n\nfrom pydantic import BaseModel\n\nFoo = ForwardRef('Foo')\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    b: Foo = None\n\n\nprint(Foo())\n#&gt; a=123 b=None\nprint(Foo(b={'a': '321'}))\n#&gt; a=123 b=Foo(a=321, b=None)\n</code></pre>"},{"location":"usage/postponed_annotations/#self-referencing-or-recursive-models","title":"Self-referencing (or \"Recursive\") Models","text":"<p>Models with self-referencing fields are also supported. Self-referencing fields will be automatically resolved after model creation.</p> <p>Within the model, you can refer to the not-yet-constructed model using a string:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    #: The sibling of `Foo` is referenced by string\n    sibling: 'Foo' = None\n\n\nprint(Foo())\n#&gt; a=123 sibling=None\nprint(Foo(sibling={'a': '321'}))\n#&gt; a=123 sibling=Foo(a=321, sibling=None)\n</code></pre> <p>If you use <code>from __future__ import annotations</code>, you can also just refer to the model by its type name:</p> <pre><code>from __future__ import annotations\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    #: The sibling of `Foo` is referenced directly by type\n    sibling: Foo = None\n\n\nprint(Foo())\n#&gt; a=123 sibling=None\nprint(Foo(sibling={'a': '321'}))\n#&gt; a=123 sibling=Foo(a=321, sibling=None)\n</code></pre>"},{"location":"usage/pydantic_settings/","title":"Settings Management","text":"<p>Pydantic Settings provides optional Pydantic features for loading a settings or config class from environment variables or secrets files.</p> <p>If you create a model that inherits from <code>BaseSettings</code>, the model initialiser will attempt to determine the values of any fields not passed as keyword arguments by reading from the environment. (Default values will still be used if the matching environment variable is not set.)</p> <p>This makes it easy to:</p> <ul> <li>Create a clearly-defined, type-hinted application configuration class</li> <li>Automatically read modifications to the configuration from environment variables</li> <li>Manually override specific settings in the initialiser where desired (e.g. in unit tests)</li> </ul> <p>For example:</p> <pre><code>from typing import Any, Callable, Set\n\nfrom pydantic import (\n    AliasChoices,\n    AmqpDsn,\n    BaseModel,\n    Field,\n    ImportString,\n    PostgresDsn,\n    RedisDsn,\n)\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass SubModel(BaseModel):\n    foo: str = 'bar'\n    apple: int = 1\n\n\nclass Settings(BaseSettings):\n    auth_key: str = Field(validation_alias='my_auth_key')  # (1)!\n\n    redis_dsn: RedisDsn = Field(\n        'redis://user:pass@localhost:6379/1',\n        validation_alias=AliasChoices('service_redis_dsn', 'redis_url'),  # (2)!\n    )\n    pg_dsn: PostgresDsn = 'postgres://user:pass@localhost:5432/foobar'\n    amqp_dsn: AmqpDsn = 'amqp://user:pass@localhost:5672/'\n\n    special_function: ImportString[Callable[[Any], Any]] = 'math.cos'  # (3)!\n\n    # to override domains:\n    # export my_prefix_domains='[\"foo.com\", \"bar.com\"]'\n    domains: Set[str] = set()\n\n    # to override more_settings:\n    # export my_prefix_more_settings='{\"foo\": \"x\", \"apple\": 1}'\n    more_settings: SubModel = SubModel()\n\n    model_config = SettingsConfigDict(env_prefix='my_prefix_')  # (4)!\n\n\nprint(Settings().model_dump())\n\"\"\"\n{\n    'auth_key': 'xxx',\n    'redis_dsn': Url('redis://user:pass@localhost:6379/1'),\n    'pg_dsn': Url('postgres://user:pass@localhost:5432/foobar'),\n    'amqp_dsn': Url('amqp://user:pass@localhost:5672/'),\n    'special_function': math.cos,\n    'domains': set(),\n    'more_settings': {'foo': 'bar', 'apple': 1},\n}\n\"\"\"\n</code></pre> <ol> <li> <p>The environment variable name is overridden using <code>validation_alias</code>. In this case, the environment variable    <code>my_auth_key</code> will be read instead of <code>auth_key</code>.</p> <p>Check the <code>Field</code> documentation for more information.</p> </li> <li> <p>The <code>AliasChoices</code> class allows to have multiple environment variable names for a single field.    The first environment variable that is found will be used.</p> <p>Check the <code>AliasChoices</code> for more information.</p> </li> <li> <p>The <code>ImportString</code> class allows to import an object from a string.    In this case, the environment variable <code>special_function</code> will be read and the function <code>math.cos</code> will be imported.</p> </li> <li> <p>The <code>env_prefix</code> config setting allows to set a prefix for all environment variables.</p> <p>Check the Environment variable names documentation for more information.</p> </li> </ol>"},{"location":"usage/pydantic_settings/#environment-variable-names","title":"Environment variable names","text":"<p>By default, the environment variable name is the same as the field name.</p> <p>You can change the prefix for all environment variables by setting the <code>env_prefix</code> config setting, or via the <code>_env_prefix</code> keyword argument on instantiation:</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_prefix='my_prefix_')\n\n    auth_key: str = 'xxx'  # will be read from `my_prefix_auth_key`\n</code></pre> <p>Note</p> <p>The default <code>env_prefix</code> is <code>''</code> (empty string).</p> <p>If you want to change the environment variable name for a single field, you can use an alias.</p> <p>There are two ways to do this:</p> <ul> <li>Using <code>Field(alias=...)</code> (see <code>api_key</code> above)</li> <li>Using <code>Field(validation_alias=...)</code> (see <code>auth_key</code> above)</li> </ul> <p>Check the <code>Field</code> aliases documentation for more information about aliases.</p>"},{"location":"usage/pydantic_settings/#case-sensitivity","title":"Case-sensitivity","text":"<p>By default, environment variable names are case-insensitive.</p> <p>If you want to make environment variable names case-sensitive, you can set the <code>case_sensitive</code> config setting:</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(case_sensitive=True)\n\n    redis_host: str = 'localhost'\n</code></pre> <p>When <code>case_sensitive</code> is <code>True</code>, the environment variable names must match field names (optionally with a prefix), so in this example <code>redis_host</code> could only be modified via <code>export redis_host</code>. If you want to name environment variables all upper-case, you should name attribute all upper-case too. You can still name environment variables anything you like through <code>Field(validation_alias=...)</code>.</p> <p>Case-sensitivity can also be set via the <code>_case_sensitive</code> keyword argument on instantiation.</p> <p>In case of nested models, the <code>case_sensitive</code> setting will be applied to all nested models.</p> <pre><code>import os\n\nfrom pydantic import ValidationError\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass RedisSettings(BaseSettings):\n    host: str\n    port: int\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(case_sensitive=True)\n\n    redis: RedisSettings\n\n\nos.environ['redis'] = '{\"host\": \"localhost\", \"port\": 6379}'\nprint(Settings().model_dump())\n#&gt; {'redis': {'host': 'localhost', 'port': 6379}}\nos.environ['redis'] = '{\"HOST\": \"localhost\", \"port\": 6379}'  # (1)!\ntry:\n    Settings()\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for RedisSettings\n    host\n      Field required [type=missing, input_value={'HOST': 'localhost', 'port': 6379}, input_type=dict]\n        For further information visit https://errors.pydantic.dev/2/v/missing\n    HOST\n      Extra inputs are not permitted [type=extra_forbidden, input_value='localhost', input_type=str]\n        For further information visit https://errors.pydantic.dev/2/v/extra_forbidden\n    \"\"\"\n</code></pre> <ol> <li>Note that the <code>host</code> field is not found because the environment variable name is <code>HOST</code> (all upper-case).</li> </ol> <p>Note</p> <p>On Windows, Python's <code>os</code> module always treats environment variables as case-insensitive, so the <code>case_sensitive</code> config setting will have no effect - settings will always be updated ignoring case.</p>"},{"location":"usage/pydantic_settings/#parsing-environment-variable-values","title":"Parsing environment variable values","text":"<p>For most simple field types (such as <code>int</code>, <code>float</code>, <code>str</code>, etc.), the environment variable value is parsed the same way it would be if passed directly to the initialiser (as a string).</p> <p>Complex types like <code>list</code>, <code>set</code>, <code>dict</code>, and sub-models are populated from the environment by treating the environment variable's value as a JSON-encoded string.</p> <p>Another way to populate nested complex variables is to configure your model with the <code>env_nested_delimiter</code> config setting, then use an environment variable with a name pointing to the nested module fields. What it does is simply explodes your variable into nested models or dicts. So if you define a variable <code>FOO__BAR__BAZ=123</code> it will convert it into <code>FOO={'BAR': {'BAZ': 123}}</code> If you have multiple variables with the same structure they will be merged.</p> <p>As an example, given the following environment variables: <pre><code># your environment\nexport V0=0\nexport SUB_MODEL='{\"v1\": \"json-1\", \"v2\": \"json-2\"}'\nexport SUB_MODEL__V2=nested-2\nexport SUB_MODEL__V3=3\nexport SUB_MODEL__DEEP__V4=v4\n</code></pre></p> <p>You could load them into the following settings model:</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass DeepSubModel(BaseModel):\n    v4: str\n\n\nclass SubModel(BaseModel):\n    v1: str\n    v2: bytes\n    v3: int\n    deep: DeepSubModel\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_nested_delimiter='__')\n\n    v0: str\n    sub_model: SubModel\n\n\nprint(Settings().model_dump())\n\"\"\"\n{\n    'v0': '0',\n    'sub_model': {'v1': 'json-1', 'v2': b'nested-2', 'v3': 3, 'deep': {'v4': 'v4'}},\n}\n\"\"\"\n</code></pre> <p><code>env_nested_delimiter</code> can be configured via the <code>model_config</code> as shown above, or via the <code>_env_nested_delimiter</code> keyword argument on instantiation.</p> <p>JSON is only parsed in top-level fields, if you need to parse JSON in sub-models, you will need to implement validators on those models.</p> <p>Nested environment variables take precedence over the top-level environment variable JSON (e.g. in the example above, <code>SUB_MODEL__V2</code> trumps <code>SUB_MODEL</code>).</p> <p>You may also populate a complex type by providing your own source class.</p> <pre><code>import json\nimport os\nfrom typing import Any, List, Tuple, Type\n\nfrom pydantic.fields import FieldInfo\n\nfrom pydantic_settings import (\n    BaseSettings,\n    EnvSettingsSource,\n    PydanticBaseSettingsSource,\n)\n\n\nclass MyCustomSource(EnvSettingsSource):\n    def prepare_field_value(\n        self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool\n    ) -&gt; Any:\n        if field_name == 'numbers':\n            return [int(x) for x in value.split(',')]\n        return json.loads(value)\n\n\nclass Settings(BaseSettings):\n    numbers: List[int]\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (MyCustomSource(settings_cls),)\n\n\nos.environ['numbers'] = '1,2,3'\nprint(Settings().model_dump())\n#&gt; {'numbers': [1, 2, 3]}\n</code></pre>"},{"location":"usage/pydantic_settings/#dotenv-env-support","title":"Dotenv (.env) support","text":"<p>Dotenv files (generally named <code>.env</code>) are a common pattern that make it easy to use environment variables in a platform-independent manner.</p> <p>A dotenv file follows the same general principles of all environment variables, and it looks like this:</p> .env<pre><code># ignore comment\nENVIRONMENT=\"production\"\nREDIS_ADDRESS=localhost:6379\nMEANING_OF_LIFE=42\nMY_VAR='Hello world'\n</code></pre> <p>Once you have your <code>.env</code> file filled with variables, pydantic supports loading it in two ways:</p> <ol> <li>Setting the <code>env_file</code> (and <code>env_file_encoding</code> if you don't want the default encoding of your OS) on <code>model_config</code> in the <code>BaseSettings</code> class:</li> </ol> <p>```py test=\"skip\" lint=\"skip\" class Settings(BaseSettings):     model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8') <pre><code>2. Instantiating the `BaseSettings` derived class with the `_env_file` keyword argument\n(and the `_env_file_encoding` if needed):\n\n```py test=\"skip\" lint=\"skip\"\nsettings = Settings(_env_file='prod.env', _env_file_encoding='utf-8')\n</code></pre></p> <p>In either case, the value of the passed argument can be any valid path or filename, either absolute or relative to the current working directory. From there, pydantic will handle everything for you by loading in your variables and validating them.</p> <p>Note</p> <p>If a filename is specified for <code>env_file</code>, Pydantic will only check the current working directory and won't check any parent directories for the <code>.env</code> file.</p> <p>Even when using a dotenv file, pydantic will still read environment variables as well as the dotenv file, environment variables will always take priority over values loaded from a dotenv file.</p> <p>Passing a file path via the <code>_env_file</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>model_config</code> class. If the above snippets were used in conjunction, <code>prod.env</code> would be loaded while <code>.env</code> would be ignored.</p> <p>If you need to load multiple dotenv files, you can pass multiple file paths as a tuple or list. The files will be loaded in order, with each file overriding the previous one.</p> <p><code>``py test=\"skip\" lint=\"skip\" class Settings(BaseSettings):     model_config = SettingsConfigDict(         #</code>.env.prod<code>takes priority over</code>.env`         env_file=('.env', '.env.prod')     ) <pre><code>You can also use the keyword argument override to tell Pydantic not to load any file at all (even if one is set in\nthe `model_config` class) by passing `None` as the instantiation keyword argument, e.g. `settings = Settings(_env_file=None)`.\n\nBecause python-dotenv is used to parse the file, bash-like semantics such as `export` can be used which\n(depending on your OS and environment) may allow your dotenv file to also be used with `source`,\nsee [python-dotenv's documentation](https://saurabh-kumar.com/python-dotenv/#usages) for more details.\n\nPydantic settings consider `extra` config in case of dotenv file. It means if you set the `extra=forbid`\non `model_config` and your dotenv file contains an entry for a field that is not defined in settings model,\nit will raise `ValidationError` in settings construction.\n\n## Secrets\n\nPlacing secret values in files is a common pattern to provide sensitive configuration to an application.\n\nA secret file follows the same principal as a dotenv file except it only contains a single value and the file name\nis used as the key. A secret file will look like the following:\n\n``` title=\"/var/run/database_password\"\nsuper_secret_database_password\n</code></pre></p> <p>Once you have your secret files, pydantic supports loading it in two ways:</p> <ol> <li>Setting the <code>secrets_dir</code> on <code>model_config</code> in a <code>BaseSettings</code> class to the directory where your secret files are stored.</li> </ol> <p>```py test=\"skip\" lint=\"skip\" class Settings(BaseSettings):     model_config = SettingsConfigDict(secrets_dir='/var/run')</p> <pre><code>database_password: str\n</code></pre> <p><code>2. Instantiating the `BaseSettings` derived class with the `_secrets_dir` keyword argument:</code>py test=\"skip\" lint=\"skip\" settings = Settings(_secrets_dir='/var/run') ```</p> <p>In either case, the value of the passed argument can be any valid directory, either absolute or relative to the current working directory. Note that a non existent directory will only generate a warning. From there, pydantic will handle everything for you by loading in your variables and validating them.</p> <p>Even when using a secrets directory, pydantic will still read environment variables from a dotenv file or the environment, a dotenv file and environment variables will always take priority over values loaded from the secrets directory.</p> <p>Passing a file path via the <code>_secrets_dir</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>model_config</code> class.</p>"},{"location":"usage/pydantic_settings/#use-case-docker-secrets","title":"Use Case: Docker Secrets","text":"<p>Docker Secrets can be used to provide sensitive configuration to an application running in a Docker container. To use these secrets in a pydantic application the process is simple. More information regarding creating, managing and using secrets in Docker see the official Docker documentation.</p> <p>First, define your <code>Settings</code> class with a <code>SettingsConfigDict</code> that specifies the secrets directory.</p> <p>```py test=\"skip\" lint=\"skip\" class Settings(BaseSettings):     model_config = SettingsConfigDict(secrets_dir='/run/secrets')</p> <pre><code>my_secret_data: str\n</code></pre> <p>``` </p> <p>Note</p> <p>By default Docker uses <code>/run/secrets</code> as the target mount point. If you want to use a different location, change <code>Config.secrets_dir</code> accordingly. </p> <p>Then, create your secret via the Docker CLI <code>bash printf \"This is a secret\" | docker secret create my_secret_data -</code></p> <p>Last, run your application inside a Docker container and supply your newly created secret <pre><code>docker service create --name pydantic-with-secrets --secret my_secret_data pydantic-app:latest\n</code></pre></p>"},{"location":"usage/pydantic_settings/#field-value-priority","title":"Field value priority","text":"<p>In the case where a value is specified for the same <code>Settings</code> field in multiple ways, the selected value is determined as follows (in descending order of priority):</p> <ol> <li>Arguments passed to the <code>Settings</code> class initialiser.</li> <li>Environment variables, e.g. <code>my_prefix_special_function</code> as described above.</li> <li>Variables loaded from a dotenv (<code>.env</code>) file.</li> <li>Variables loaded from the secrets directory.</li> <li>The default field values for the <code>Settings</code> model.</li> </ol>"},{"location":"usage/pydantic_settings/#customise-settings-sources","title":"Customise settings sources","text":"<p>If the default order of priority doesn't match your needs, it's possible to change it by overriding the <code>settings_customise_sources</code> method of your <code>Settings</code> .</p> <p><code>settings_customise_sources</code> takes four callables as arguments and returns any number of callables as a tuple. In turn these callables are called to build the inputs to the fields of the settings class.</p> <p>Each callable should take an instance of the settings class as its sole argument and return a <code>dict</code>.</p>"},{"location":"usage/pydantic_settings/#changing-priority","title":"Changing Priority","text":"<p>The order of the returned callables decides the priority of inputs; first item is the highest priority.</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic import PostgresDsn\n\nfrom pydantic_settings import BaseSettings, PydanticBaseSettingsSource\n\n\nclass Settings(BaseSettings):\n    database_dsn: PostgresDsn\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return env_settings, init_settings, file_secret_settings\n\n\nprint(Settings(database_dsn='postgres://postgres@localhost:5432/kwargs_db'))\n#&gt; database_dsn=Url('postgres://postgres@localhost:5432/kwargs_db')\n</code></pre> <p>By flipping <code>env_settings</code> and <code>init_settings</code>, environment variables now have precedence over <code>__init__</code> kwargs.</p>"},{"location":"usage/pydantic_settings/#adding-sources","title":"Adding sources","text":"<p>As explained earlier, pydantic ships with multiples built-in settings sources. However, you may occasionally need to add your own custom sources, <code>settings_customise_sources</code> makes this very easy:</p> <pre><code>import json\nfrom pathlib import Path\nfrom typing import Any, Dict, Tuple, Type\n\nfrom pydantic.fields import FieldInfo\n\nfrom pydantic_settings import (\n    BaseSettings,\n    PydanticBaseSettingsSource,\n    SettingsConfigDict,\n)\n\n\nclass JsonConfigSettingsSource(PydanticBaseSettingsSource):\n\"\"\"\n    A simple settings source class that loads variables from a JSON file\n    at the project's root.\n\n    Here we happen to choose to use the `env_file_encoding` from Config\n    when reading `config.json`\n    \"\"\"\n\n    def get_field_value(\n        self, field: FieldInfo, field_name: str\n    ) -&gt; Tuple[Any, str, bool]:\n        encoding = self.config.get('env_file_encoding')\n        file_content_json = json.loads(\n            Path('tests/example_test_config.json').read_text(encoding)\n        )\n        fiel_value = file_content_json.get(field_name)\n        return fiel_value, field_name, False\n\n    def prepare_field_value(\n        self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool\n    ) -&gt; Any:\n        return value\n\n    def __call__(self) -&gt; Dict[str, Any]:\n        d: Dict[str, Any] = {}\n\n        for field_name, field in self.settings_cls.model_fields.items():\n            field_value, field_key, value_is_complex = self.get_field_value(\n                field, field_name\n            )\n            field_value = self.prepare_field_value(\n                field_name, field, field_value, value_is_complex\n            )\n            if field_value is not None:\n                d[field_key] = field_value\n\n        return d\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_file_encoding='utf-8')\n\n    foobar: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (\n            init_settings,\n            JsonConfigSettingsSource(settings_cls),\n            env_settings,\n            file_secret_settings,\n        )\n\n\nprint(Settings())\n#&gt; foobar='test'\n</code></pre>"},{"location":"usage/pydantic_settings/#removing-sources","title":"Removing sources","text":"<p>You might also want to disable a source:</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic import ValidationError\n\nfrom pydantic_settings import BaseSettings, PydanticBaseSettingsSource\n\n\nclass Settings(BaseSettings):\n    my_api_key: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        # here we choose to ignore arguments from init_settings\n        return env_settings, file_secret_settings\n\n\ntry:\n    Settings(my_api_key='this is ignored')\nexcept ValidationError as exc_info:\n    print(exc_info)\n\"\"\"\n    1 validation error for Settings\n    my_api_key\n      Field required [type=missing, input_value={}, input_type=dict]\n        For further information visit https://errors.pydantic.dev/2/v/missing\n    \"\"\"\n</code></pre>"},{"location":"usage/validation_decorator/","title":"Validation decorator","text":"<p>The <code>validate_call</code> decorator allows the arguments passed to a function to be parsed and validated using the function's annotations before the function is called. While under the hood this uses the same approach of model creation and initialisation; it provides an extremely easy way to apply validation to your code with minimal boilerplate.</p> <p>In Beta</p> <p>The <code>validate_call</code> decorator is in beta, it has been added to Pydantic in v1.5 on a provisional basis. It may change significantly in future releases and its interface will not be concrete until v2. Feedback from the community while it's still provisional would be extremely useful; either comment on #1205 or create a new issue.</p> <p>Example of usage:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef repeat(s: str, count: int, *, separator: bytes = b'') -&gt; bytes:\n    b = s.encode()\n    return separator.join(b for _ in range(count))\n\n\na = repeat('hello', 3)\nprint(a)\n#&gt; b'hellohellohello'\n\nb = repeat('x', '4', separator=' ')\nprint(b)\n#&gt; b'x x x x'\n\ntry:\n    c = repeat('hello', 'wrong')\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for repeat\n    1\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/validation_decorator/#argument-types","title":"Argument Types","text":"<p>Argument types are inferred from type annotations on the function, arguments without a type decorator are considered as <code>Any</code>. All types listed in types can be validated, including Pydantic models and custom types. As with the rest of Pydantic, types can be coerced by the decorator before they're passed to the actual function:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code># TODO replace find_file with something that isn't affected the filesystem\nimport os\nfrom pathlib import Path\nfrom typing import Optional, Pattern\n\nfrom pydantic import DirectoryPath, validate_call\n\n\n@validate_call\ndef find_file(path: DirectoryPath, regex: Pattern, max=None) -&gt; Optional[Path]:\n    for i, f in enumerate(path.glob('**/*')):\n        if max and i &gt; max:\n            return\n        if f.is_file() and regex.fullmatch(str(f.relative_to(path))):\n            return f\n\n\n# note: this_dir is a string here\nthis_dir = os.path.dirname(__file__)\n\nprint(find_file(this_dir, '^validation.*'))\nprint(find_file(this_dir, '^foobar.*', max=3))\n</code></pre> <pre><code># TODO replace find_file with something that isn't affected the filesystem\nimport os\nfrom pathlib import Path\nfrom typing import Optional\nfrom re import Pattern\n\nfrom pydantic import DirectoryPath, validate_call\n\n\n@validate_call\ndef find_file(path: DirectoryPath, regex: Pattern, max=None) -&gt; Optional[Path]:\n    for i, f in enumerate(path.glob('**/*')):\n        if max and i &gt; max:\n            return\n        if f.is_file() and regex.fullmatch(str(f.relative_to(path))):\n            return f\n\n\n# note: this_dir is a string here\nthis_dir = os.path.dirname(__file__)\n\nprint(find_file(this_dir, '^validation.*'))\nprint(find_file(this_dir, '^foobar.*', max=3))\n</code></pre> <pre><code># TODO replace find_file with something that isn't affected the filesystem\nimport os\nfrom pathlib import Path\nfrom re import Pattern\n\nfrom pydantic import DirectoryPath, validate_call\n\n\n@validate_call\ndef find_file(path: DirectoryPath, regex: Pattern, max=None) -&gt; Path | None:\n    for i, f in enumerate(path.glob('**/*')):\n        if max and i &gt; max:\n            return\n        if f.is_file() and regex.fullmatch(str(f.relative_to(path))):\n            return f\n\n\n# note: this_dir is a string here\nthis_dir = os.path.dirname(__file__)\n\nprint(find_file(this_dir, '^validation.*'))\nprint(find_file(this_dir, '^foobar.*', max=3))\n</code></pre> <p>A few notes:</p> <ul> <li>though they're passed as strings, <code>path</code> and <code>regex</code> are converted to a <code>Path</code> object and regex respectively by the decorator</li> <li><code>max</code> has no type annotation, so will be considered as <code>Any</code> by the decorator</li> </ul> <p>Type coercion like this can be extremely helpful but also confusing or not desired, see below for a discussion of <code>validate_call</code>'s limitations in this regard.</p>"},{"location":"usage/validation_decorator/#function-signatures","title":"Function Signatures","text":"<p>The decorator is designed to work with functions using all possible parameter configurations and all possible combinations of these:</p> <ul> <li>positional or keyword arguments with or without defaults</li> <li>variable positional arguments defined via <code>*</code> (often <code>*args</code>)</li> <li>variable keyword arguments defined via <code>**</code> (often <code>**kwargs</code>)</li> <li>keyword only arguments - arguments after <code>*,</code></li> <li>positional only arguments - arguments before <code>, /</code> (new in Python 3.8)</li> </ul> <p>To demonstrate all the above parameter types:</p> <pre><code>from pydantic import validate_call\n\n\n@validate_call\ndef pos_or_kw(a: int, b: int = 2) -&gt; str:\n    return f'a={a} b={b}'\n\n\nprint(pos_or_kw(1))\n#&gt; a=1 b=2\nprint(pos_or_kw(a=1))\n#&gt; a=1 b=2\nprint(pos_or_kw(1, 3))\n#&gt; a=1 b=3\nprint(pos_or_kw(a=1, b=3))\n#&gt; a=1 b=3\n\n\n@validate_call\ndef kw_only(*, a: int, b: int = 2) -&gt; str:\n    return f'a={a} b={b}'\n\n\nprint(kw_only(a=1))\n#&gt; a=1 b=2\nprint(kw_only(a=1, b=3))\n#&gt; a=1 b=3\n\n\n@validate_call\ndef pos_only(a: int, b: int = 2, /) -&gt; str:  # python 3.8 only\n    return f'a={a} b={b}'\n\n\nprint(pos_only(1))\n#&gt; a=1 b=2\nprint(pos_only(1, 2))\n#&gt; a=1 b=2\n\n\n@validate_call\ndef var_args(*args: int) -&gt; str:\n    return str(args)\n\n\nprint(var_args(1))\n#&gt; (1,)\nprint(var_args(1, 2))\n#&gt; (1, 2)\nprint(var_args(1, 2, 3))\n#&gt; (1, 2, 3)\n\n\n@validate_call\ndef var_kwargs(**kwargs: int) -&gt; str:\n    return str(kwargs)\n\n\nprint(var_kwargs(a=1))\n#&gt; {'a': 1}\nprint(var_kwargs(a=1, b=2))\n#&gt; {'a': 1, 'b': 2}\n\n\n@validate_call\ndef armageddon(\n    a: int,\n    /,  # python 3.8 only\n    b: int,\n    *c: int,\n    d: int,\n    e: int = None,\n    **f: int,\n) -&gt; str:\n    return f'a={a} b={b} c={c} d={d} e={e} f={f}'\n\n\nprint(armageddon(1, 2, d=3))\n#&gt; a=1 b=2 c=() d=3 e=None f={}\nprint(armageddon(1, 2, 3, 4, 5, 6, d=8, e=9, f=10, spam=11))\n#&gt; a=1 b=2 c=(3, 4, 5, 6) d=8 e=9 f={'f': 10, 'spam': 11}\n</code></pre>"},{"location":"usage/validation_decorator/#using-field-to-describe-function-arguments","title":"Using Field to describe function arguments","text":"<p>Field can also be used with <code>validate_call</code> to provide extra information about the field and validations. In general it should be used in a type hint with Annotated, unless <code>default_factory</code> is specified, in which case it should be used as the default value of the field:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from datetime import datetime\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import Field, ValidationError, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10)]):\n    return num\n\n\ntry:\n    how_many(1)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for how_many\n    0\n      Input should be greater than 10 [type=greater_than, input_value=1, input_type=int]\n    \"\"\"\n\n\n@validate_call\ndef when(dt: datetime = Field(default_factory=datetime.now)):\n    return dt\n\n\nprint(type(when()))\n#&gt; &lt;class 'datetime.datetime'&gt;\n</code></pre> <pre><code>from datetime import datetime\n\nfrom typing import Annotated\n\nfrom pydantic import Field, ValidationError, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10)]):\n    return num\n\n\ntry:\n    how_many(1)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for how_many\n    0\n      Input should be greater than 10 [type=greater_than, input_value=1, input_type=int]\n    \"\"\"\n\n\n@validate_call\ndef when(dt: datetime = Field(default_factory=datetime.now)):\n    return dt\n\n\nprint(type(when()))\n#&gt; &lt;class 'datetime.datetime'&gt;\n</code></pre> <p>The <code>alias</code> can be used with the decorator as normal.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import Field, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10, alias='number')]):\n    return num\n\n\nhow_many(number=42)\n</code></pre> <pre><code>from typing import Annotated\n\nfrom pydantic import Field, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10, alias='number')]):\n    return num\n\n\nhow_many(number=42)\n</code></pre>"},{"location":"usage/validation_decorator/#usage-with-mypy","title":"Usage with mypy","text":"<p>The <code>validate_call</code> decorator should work \"out of the box\" with mypy since it's defined to return a function with the same signature as the function it decorates. The only limitation is that since we trick mypy into thinking the function returned by the decorator is the same as the function being decorated; access to the raw function or other attributes will require <code>type: ignore</code>.</p>"},{"location":"usage/validation_decorator/#raw-function","title":"Raw function","text":"<p>The raw function which was decorated is accessible, this is useful if in some scenarios you trust your input arguments and want to call the function in the most performant way (see notes on performance below):</p> <pre><code>from pydantic import validate_call\n\n\n@validate_call\ndef repeat(s: str, count: int, *, separator: bytes = b'') -&gt; bytes:\n    b = s.encode()\n    return separator.join(b for _ in range(count))\n\n\na = repeat('hello', 3)\nprint(a)\n#&gt; b'hellohellohello'\n\nb = repeat.raw_function('good bye', 2, separator=b', ')\nprint(b)\n#&gt; b'good bye, good bye'\n</code></pre>"},{"location":"usage/validation_decorator/#async-functions","title":"Async Functions","text":"<p><code>validate_call</code> can also be used on async functions:</p> <pre><code>class Connection:\n    async def execute(self, sql, *args):\n        return 'testing@example.com'\n\n\nconn = Connection()\n# ignore-above\nimport asyncio\n\nfrom pydantic import PositiveInt, ValidationError, validate_call\n\n\n@validate_call\nasync def get_user_email(user_id: PositiveInt):\n    # `conn` is some fictional connection to a database\n    email = await conn.execute('select email from users where id=$1', user_id)\n    if email is None:\n        raise RuntimeError('user not found')\n    else:\n        return email\n\n\nasync def main():\n    email = await get_user_email(123)\n    print(email)\n    #&gt; testing@example.com\n    try:\n        await get_user_email(-4)\n    except ValidationError as exc:\n        print(exc.errors())\n\"\"\"\n        [\n            {\n                'type': 'greater_than',\n                'loc': (0,),\n                'msg': 'Input should be greater than 0',\n                'input': -4,\n                'ctx': {'gt': 0},\n                'url': 'https://errors.pydantic.dev/2/v/greater_than',\n            }\n        ]\n        \"\"\"\n\n\nasyncio.run(main())\n# requires: `conn.execute()` that will return `'testing@example.com'`\n</code></pre>"},{"location":"usage/validation_decorator/#custom-config","title":"Custom Config","text":"<p>The model behind <code>validate_call</code> can be customised using a config setting which is equivalent to setting the <code>Config</code> sub-class in normal models.</p> <p>Warning</p> <p>The <code>fields</code> and <code>alias_generator</code> properties of <code>Config</code> which allow aliases to be configured are not supported yet with <code>@validate_call</code>, using them will raise an error.</p> <p>Configuration is set using the <code>config</code> keyword argument to the decorator, it may be either a config class or a dict of properties which are converted to a class later.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\nclass Foobar:\n    def __init__(self, v: str):\n        self.v = v\n\n    def __add__(self, other: 'Foobar') -&gt; str:\n        return f'{self} + {other}'\n\n    def __str__(self) -&gt; str:\n        return f'Foobar({self.v})'\n\n\n@validate_call(config=dict(arbitrary_types_allowed=True))\ndef add_foobars(a: Foobar, b: Foobar):\n    return a + b\n\n\nc = add_foobars(Foobar('a'), Foobar('b'))\nprint(c)\n#&gt; Foobar(a) + Foobar(b)\n\ntry:\n    add_foobars(1, 2)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for add_foobars\n    0\n      Input should be an instance of Foobar [type=is_instance_of, input_value=1, input_type=int]\n    1\n      Input should be an instance of Foobar [type=is_instance_of, input_value=2, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"usage/validation_decorator/#limitations","title":"Limitations","text":"<p><code>validate_call</code> has been released on a provisional basis without all the bells and whistles, which may be added later, see #1205 for some more discussion of this.</p> <p>In particular:</p>"},{"location":"usage/validation_decorator/#validation-exception","title":"Validation Exception","text":"<p>Currently upon validation failure, a standard Pydantic <code>ValidationError</code> is raised, see model error handling.</p> <p>This is helpful since it's <code>str()</code> method provides useful details of the error which occurred and methods like <code>.errors()</code> and <code>.json()</code> can be useful when exposing the errors to end users, however <code>ValidationError</code> inherits from <code>ValueError</code> not <code>TypeError</code> which may be unexpected since Python would raise a <code>TypeError</code> upon invalid or missing arguments. This may be addressed in future by either allow a custom error or raising a different exception by default, or both.</p>"},{"location":"usage/validation_decorator/#coercion-and-strictness","title":"Coercion and Strictness","text":"<p>Pydantic currently leans on the side of trying to coerce types rather than raise an error if a type is wrong, see model data conversion and <code>validate_call</code> is no different.</p> <p>See #1098 and other issues with the \"strictness\" label for a discussion of this. If Pydantic gets a \"strict\" mode in future, <code>validate_call</code> will have an option to use this, it may even become the default for the decorator.</p>"},{"location":"usage/validation_decorator/#performance","title":"Performance","text":"<p>We've made a big effort to make Pydantic as performant as possible and argument inspect and model creation is only performed once when the function is defined, however there will still be a performance impact to using the <code>validate_call</code> decorator compared to calling the raw function.</p> <p>In many situations this will have little or no noticeable effect, however be aware that <code>validate_call</code> is not an equivalent or alternative to function definitions in strongly typed languages; it never will be.</p>"},{"location":"usage/validation_decorator/#return-value","title":"Return Value","text":"<p>The return value of the function is not validated against its return type annotation, this may be added as an option in future.</p>"},{"location":"usage/validation_decorator/#config-and-validators","title":"Config and Validators","text":"<p><code>fields</code> and <code>alias_generator</code> on custom <code>Config</code> are not supported, see above.</p> <p>Neither are validators.</p>"},{"location":"usage/validation_decorator/#model-fields-and-reserved-arguments","title":"Model fields and reserved arguments","text":"<p>The following names may not be used by arguments since they can be used internally to store information about the function's signature:</p> <ul> <li><code>v__args</code></li> <li><code>v__kwargs</code></li> <li><code>v__positional_only</code></li> </ul> <p>These names (together with <code>\"args\"</code> and <code>\"kwargs\"</code>) may or may not (depending on the function's signature) appear as fields on the internal Pydantic model accessible via <code>.model</code> thus this model isn't especially useful (e.g. for generating a schema) at the moment.</p> <p>This should be fixable in future as the way error are raised is changed.</p>"},{"location":"usage/validation_errors/","title":"Validation Errors","text":"<p>Pydantic attempts to provide useful validation errors. Below are details on common validation errors users may encounter when working with pydantic, together with some suggestions on how to fix them.</p>"},{"location":"usage/validation_errors/#arguments_type","title":"<code>arguments_type</code>","text":"<p>This error is raised when arguments passed to a function are not a tuple, list, or dictionary.</p>"},{"location":"usage/validation_errors/#assertion_error","title":"<code>assertion_error</code>","text":"<p>This error is raised when a failing <code>assert</code> statement is encountered during validation.</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    @classmethod\n    def force_x_positive(cls, v):\n        assert v &gt; 0\n        return v\n\n\ntry:\n    Model(x=-1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'assertion_error'\n</code></pre>"},{"location":"usage/validation_errors/#bool","title":"<code>bool</code>","text":"<p>This error is raised when the value type is not valid for a Boolean field.</p>"},{"location":"usage/validation_errors/#bool_parsing","title":"<code>bool_parsing</code>","text":"<p>This error is raised when the value is a string that is not valid for coercion to a boolean.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bool\n\n\nModel(x='true')  # OK\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'bool_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#bool_type","title":"<code>bool_type</code>","text":"<p>This error is raised when the value type is not valid for a Boolean field.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bool\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'bool_type'\n</code></pre>"},{"location":"usage/validation_errors/#bytes_too_long","title":"<code>bytes_too_long</code>","text":"<p>This error is raised when the length of a <code>bytes</code> value is greater than <code>Field.max_length</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes = Field(max_length=3)\n\n\ntry:\n    Model(x=b'test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'bytes_too_long'\n</code></pre>"},{"location":"usage/validation_errors/#bytes_too_short","title":"<code>bytes_too_short</code>","text":"<p>This error is raised when the length of a <code>bytes</code> value is less than <code>Field.min_length</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes = Field(min_length=3)\n\n\ntry:\n    Model(x=b't')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'bytes_too_short'\n</code></pre>"},{"location":"usage/validation_errors/#bytes_type","title":"<code>bytes_type</code>","text":"<p>This error is raised when the type of an input value is not valid for a <code>bytes</code> field.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes\n\n\ntry:\n    Model(x=123)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'bytes_type'\n</code></pre>"},{"location":"usage/validation_errors/#callable_type","title":"<code>callable_type</code>","text":"<p>This error is raised when the value is not a <code>Callable</code>.</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Any, Callable\n\nfrom pydantic import BaseModel, ImportString, ValidationError\n\n\nclass Model(BaseModel):\n    x: ImportString[Callable[[Any], Any]]\n\n\ntry:\n    Model(x='os.path')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'callable_type'\n</code></pre> <pre><code>from typing import Any\nfrom collections.abc import Callable\n\nfrom pydantic import BaseModel, ImportString, ValidationError\n\n\nclass Model(BaseModel):\n    x: ImportString[Callable[[Any], Any]]\n\n\ntry:\n    Model(x='os.path')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'callable_type'\n</code></pre> <p>Valid example:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Any, Callable\n\nfrom pydantic import BaseModel, ImportString\n\n\nclass Model(BaseModel):\n    x: ImportString[Callable[[Any], Any]]\n\n\nModel(x='math:cos')\n</code></pre> <pre><code>from typing import Any\nfrom collections.abc import Callable\n\nfrom pydantic import BaseModel, ImportString\n\n\nclass Model(BaseModel):\n    x: ImportString[Callable[[Any], Any]]\n\n\nModel(x='math:cos')\n</code></pre>"},{"location":"usage/validation_errors/#dataclass_type","title":"<code>dataclass_type</code>","text":"<p>This error is raised when the value is not valid for a <code>dataclass</code> field.</p> <pre><code>from pydantic import ValidationError, dataclasses\n\n\n@dataclasses.dataclass\nclass Nested:\n    x: int\n\n\n@dataclasses.dataclass\nclass Model:\n    y: Nested\n\n\ntry:\n    Model(y=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dataclass_type'\n</code></pre> <p>Valid example:</p> <pre><code>from pydantic import dataclasses\n\n\n@dataclasses.dataclass\nclass Nested:\n    x: int\n\n\n@dataclasses.dataclass\nclass Model:\n    y: Nested\n\n\nModel(y=Nested(x=1))\n</code></pre>"},{"location":"usage/validation_errors/#date_from_datetime_inexact","title":"<code>date_from_datetime_inexact</code>","text":"<p>This error is raised when the <code>datetime</code> value provided for a <code>date</code> field has a nonzero time component. For a timestamp to parse into a field of type <code>date</code>, the time components must all be zero.</p> <pre><code>from datetime import date, datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: date\n\n\nModel(x='2023-01-01')  # OK\nModel(x=datetime(2023, 1, 1))  # OK\n\ntry:\n    Model(x=datetime(2023, 1, 1, 12))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_from_datetime_inexact'\n</code></pre>"},{"location":"usage/validation_errors/#date_from_datetime_parsing","title":"<code>date_from_datetime_parsing</code>","text":"<p>This error is raised when the value is a string that is not valid for coercion to a <code>date</code>.</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: date\n\n\ntry:\n    Model(x='XX1494012000')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_from_datetime_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#date_future","title":"<code>date_future</code>","text":"<p>This error is raised when the value provided for a <code>FutureDate</code> field is not in the future.</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, FutureDate, ValidationError\n\n\nclass Model(BaseModel):\n    x: FutureDate\n\n\ntry:\n    Model(x=date(2000, 1, 1))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_future'\n</code></pre>"},{"location":"usage/validation_errors/#date_parsing","title":"<code>date_parsing</code>","text":"<p>This error is raised when the value for is not a valid JSON value for a <code>date</code> field.</p> <pre><code>import json\nfrom datetime import date\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: date = Field(strict=True)\n\n\ntry:\n    Model.model_validate_json(json.dumps({'x': '1'}))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#date_past","title":"<code>date_past</code>","text":"<p>This error is raised when the value provided for a <code>PastDate</code> field is not in the past.</p> <pre><code>from datetime import date, timedelta\n\nfrom pydantic import BaseModel, PastDate, ValidationError\n\n\nclass Model(BaseModel):\n    x: PastDate\n\n\ntry:\n    Model(x=date.today() + timedelta(1))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_past'\n</code></pre>"},{"location":"usage/validation_errors/#date_type","title":"<code>date_type</code>","text":"<p>This error is raised when the value type is not of type <code>date</code> for a strict <code>date</code> field.</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: date = Field(strict=True)\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'date_type'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_aware","title":"<code>datetime_aware</code>","text":"<p>This error is raised when the <code>datetime</code> value provided for a timezone-aware <code>datetime</code> field doesn't have timezone information.</p> <pre><code>from datetime import datetime\n\nfrom pydantic import AwareDatetime, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: AwareDatetime\n\n\ntry:\n    Model(x=datetime.now())\nexcept ValidationError as exc_info:\n    print(exc_info.errors())\n\"\"\"\n    [\n        {\n            'type': 'timezone_aware',\n            'loc': ('x',),\n            'msg': 'Input should have timezone info',\n            'input': datetime.datetime(2032, 1, 2, 3, 4, 5, 6),\n            'url': 'https://errors.pydantic.dev/2/v/timezone_aware',\n        }\n    ]\n    \"\"\"\n</code></pre>"},{"location":"usage/validation_errors/#datetime_future","title":"<code>datetime_future</code>","text":"<p>This error is raised when the value provided for a <code>FutureDatetime</code> field is not in the future.</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, FutureDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: FutureDatetime\n\n\ntry:\n    Model(x=datetime(2000, 1, 1))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_future'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_naive","title":"<code>datetime_naive</code>","text":"<p>This error is raised when the <code>datetime</code> value provided for a timezone-naive <code>datetime</code> field has timezone info.</p> <pre><code>from datetime import datetime, timezone\n\nfrom pydantic import BaseModel, NaiveDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: NaiveDatetime\n\n\ntry:\n    Model(x=datetime.now(tz=timezone.utc))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_naive'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_object_invalid","title":"<code>datetime_object_invalid</code>","text":"<p>This error is raised when something about the <code>datetime</code> object is not valid.</p> <pre><code>from datetime import datetime, tzinfo\n\nfrom pydantic import AwareDatetime, BaseModel, ValidationError\n\n\nclass CustomTz(tzinfo):\n    # utcoffset is not implemented!\n\n    def tzname(self, _dt):\n        return 'CustomTZ'\n\n\nclass Model(BaseModel):\n    x: AwareDatetime\n\n\ntry:\n    Model(x=datetime(2023, 1, 1, tzinfo=CustomTz()))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_object_invalid'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_parsing","title":"<code>datetime_parsing</code>","text":"<p>This error is raised when the value provided for a <code>datetime</code> field can't be parsed as <code>datetime</code>.</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: datetime\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_past","title":"<code>datetime_past</code>","text":"<p>This error is raised when the value provided for a <code>PastDatetime</code> field is not in the past.</p> <pre><code>from datetime import datetime, timedelta\n\nfrom pydantic import BaseModel, PastDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: PastDatetime\n\n\ntry:\n    Model(x=datetime.now() + timedelta(100))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_past'\n</code></pre>"},{"location":"usage/validation_errors/#datetime_type","title":"<code>datetime_type</code>","text":"<p>This error is raised when the value type is not <code>datetime</code> for a strict <code>datetime</code> field.</p> <pre><code>from datetime import date, datetime\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: datetime = Field(strict=True)\n\n\ntry:\n    Model(x=date(2023, 1, 1))\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'datetime_type'\n</code></pre>"},{"location":"usage/validation_errors/#dict_attributes_type","title":"<code>dict_attributes_type</code>","text":"<p>This error is raised when the input is not a valid dictionary or instance to extract fields from.</p> Python 3.7 and abovePython 3.8 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Annotated, Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    m: str\n\n\nclass Model(BaseModel):\n    pet: Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n    number: int\n\n\ntry:\n    Model.model_validate({'pet': 'fish', 'number': 2})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dict_attributes_type'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing_extensions import Annotated\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    m: str\n\n\nclass Model(BaseModel):\n    pet: Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n    number: int\n\n\ntry:\n    Model.model_validate({'pet': 'fish', 'number': 2})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dict_attributes_type'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Annotated, Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    m: str\n\n\nclass Model(BaseModel):\n    pet: Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n    number: int\n\n\ntry:\n    Model.model_validate({'pet': 'fish', 'number': 2})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dict_attributes_type'\n</code></pre> <pre><code>from typing import Annotated, Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    m: str\n\n\nclass Model(BaseModel):\n    pet: Annotated[Cat | Dog, Field(discriminator='pet_type')]\n    number: int\n\n\ntry:\n    Model.model_validate({'pet': 'fish', 'number': 2})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dict_attributes_type'\n</code></pre> <p>Valid example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: str\n\n\nModel.model_validate({'x': 'test'})\n</code></pre>"},{"location":"usage/validation_errors/#dict_type","title":"<code>dict_type</code>","text":"<p>This error is raised when the value type is not <code>dict</code> for a <code>dict</code> field.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: dict\n\n\ntry:\n    Model(x=['1', '2'])\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'dict_type'\n</code></pre>"},{"location":"usage/validation_errors/#extra_forbidden","title":"<code>extra_forbidden</code>","text":"<p>This error is raised when the input values contain extra fields and <code>model_config['extra'] == 'forbid'</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n    model_config = ConfigDict(extra='forbid')\n\n\ntry:\n    Model(x='test', y='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'extra_forbidden'\n</code></pre> <p>You can read more about the <code>extra</code> configuration on the Extra Attributes section.</p>"},{"location":"usage/validation_errors/#finite_number","title":"<code>finite_number</code>","text":"<p>This error is raised when the value is an infinite number.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=2.2250738585072011e308)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'finite_number'\n</code></pre>"},{"location":"usage/validation_errors/#float_parsing","title":"<code>float_parsing</code>","text":"<p>This error is raised when the value can't be parsed as <code>float</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: float\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'float_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#float_type","title":"<code>float_type</code>","text":"<p>This error is raised when the value type is not <code>float</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: float\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'float_type'\n</code></pre>"},{"location":"usage/validation_errors/#frozen_field","title":"<code>frozen_field</code>","text":"<p>This error is raised when the <code>config.validate_assignment=True</code> and you assign a value to a field with <code>Field.frozen=True</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field('test', frozen=True)\n\n    model_config = ConfigDict(validate_assignment=True)\n\n\nmodel = Model()\ntry:\n    model.x = 'test1'\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'frozen_field'\n</code></pre>"},{"location":"usage/validation_errors/#frozen_instance","title":"<code>frozen_instance</code>","text":"<p>This error is raised when the model is frozen and you assign a new value to one of the fields.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(frozen=True)\n\n\nm = Model(x=1)\ntry:\n    m.x = 2\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'frozen_instance'\n</code></pre>"},{"location":"usage/validation_errors/#frozen_set_type","title":"<code>frozen_set_type</code>","text":"<p>This error is raised when the value type is not <code>frozenset</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: frozenset\n\n\ntry:\n    model = Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'frozen_set_type'\n</code></pre>"},{"location":"usage/validation_errors/#get_attribute_error","title":"<code>get_attribute_error</code>","text":"<p>This error is raised when <code>config.from_attributes=True</code> and an error occurs during collecting values.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Foobar:\n    def __init__(self):\n        self.x = 1\n\n    @property\n    def y(self):\n        raise RuntimeError('intentional error')\n\n\nclass Model(BaseModel):\n    x: int\n    y: str\n\n    model_config = ConfigDict(from_attributes=True)\n\n\ntry:\n    Model.model_validate(Foobar())\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'get_attribute_error'\n</code></pre>"},{"location":"usage/validation_errors/#greater_than","title":"<code>greater_than</code>","text":"<p>This error is raised when the value is not greater than <code>Field.gt</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(gt=10)\n\n\ntry:\n    Model(x=10)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'greater_than'\n</code></pre>"},{"location":"usage/validation_errors/#greater_than_equal","title":"<code>greater_than_equal</code>","text":"<p>This error is raised when the value is not greater than or equal to the specified constraint.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(ge=10)\n\n\ntry:\n    Model(x=9)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'greater_than_equal'\n</code></pre>"},{"location":"usage/validation_errors/#int_from_float","title":"<code>int_from_float</code>","text":"<p>This error is raised when you provide a <code>float</code> value for an <code>int</code> field.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=0.5)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'int_from_float'\n</code></pre>"},{"location":"usage/validation_errors/#int_parsing","title":"<code>int_parsing</code>","text":"<p>This error is raised when the value can't be parsed as <code>int</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'int_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#int_type","title":"<code>int_type</code>","text":"<p>This error is raised when the value type is not <code>int</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'int_type'\n</code></pre>"},{"location":"usage/validation_errors/#invalid_key","title":"<code>invalid_key</code>","text":"<p>This error is raised when the type of a <code>dict</code> key is not valid.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\ntry:\n    Model.model_validate({'x': 1, b'y': 2})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'invalid_key'\n</code></pre>"},{"location":"usage/validation_errors/#is_instance_of","title":"<code>is_instance_of</code>","text":"<p>This error is raised when the input value is not an instance of the expected type.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Nested:\n    x: str\n\n\nclass Model(BaseModel):\n    y: Nested\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n\ntry:\n    Model(y='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'is_instance_of'\n</code></pre>"},{"location":"usage/validation_errors/#is_subclass_of","title":"<code>is_subclass_of</code>","text":"<p>This error is raised when the input value is not a subclass of expected type.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Nested:\n    x: str\n\n\nclass Model(BaseModel):\n    y: Type[Nested]\n\n\ntry:\n    Model(y='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'is_subclass_of'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Nested:\n    x: str\n\n\nclass Model(BaseModel):\n    y: type[Nested]\n\n\ntry:\n    Model(y='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'is_subclass_of'\n</code></pre>"},{"location":"usage/validation_errors/#iterable_type","title":"<code>iterable_type</code>","text":"<p>This error is raised when the input value is not an <code>Iterable</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    y: Iterable\n\n\ntry:\n    Model(y=123)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'iterable_type'\n</code></pre> <pre><code>from collections.abc import Iterable\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    y: Iterable\n\n\ntry:\n    Model(y=123)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'iterable_type'\n</code></pre>"},{"location":"usage/validation_errors/#iteration_error","title":"<code>iteration_error</code>","text":"<p>This error is raised when an error occurs during iteration.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\ndef gen():\n    yield 1\n    raise RuntimeError('error')\n\n\nclass Model(BaseModel):\n    x: List[int]\n\n\ntry:\n    Model(x=gen())\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'iteration_error'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\ndef gen():\n    yield 1\n    raise RuntimeError('error')\n\n\nclass Model(BaseModel):\n    x: list[int]\n\n\ntry:\n    Model(x=gen())\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'iteration_error'\n</code></pre>"},{"location":"usage/validation_errors/#json_invalid","title":"<code>json_invalid</code>","text":"<p>This error is raised when the input value is not a valid JSON string.</p> <pre><code>from pydantic import BaseModel, Json, ValidationError\n\n\nclass Model(BaseModel):\n    x: Json\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'json_invalid'\n</code></pre>"},{"location":"usage/validation_errors/#json_type","title":"<code>json_type</code>","text":"<p>This error is raised when the input value is of a type that cannot be parsed as JSON.</p> <pre><code>from pydantic import BaseModel, Json, ValidationError\n\n\nclass Model(BaseModel):\n    x: Json\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'json_type'\n</code></pre>"},{"location":"usage/validation_errors/#less_than","title":"<code>less_than</code>","text":"<p>This error is raised when the value is not less than <code>Field.lt</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(lt=10)\n\n\ntry:\n    Model(x=10)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'less_than'\n</code></pre>"},{"location":"usage/validation_errors/#less_than_equal","title":"<code>less_than_equal</code>","text":"<p>This error is raised when the value is not less than or equal to the specified constraint.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(le=10)\n\n\ntry:\n    Model(x=11)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'less_than_equal'\n</code></pre>"},{"location":"usage/validation_errors/#list_type","title":"<code>list_type</code>","text":"<p>This error is raised when the input value is not a <code>list</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int]\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'list_type'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: list[int]\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'list_type'\n</code></pre>"},{"location":"usage/validation_errors/#literal_error","title":"<code>literal_error</code>","text":"<p>This error is raised when the input value is not in expected literals.</p> Python 3.7 and abovePython 3.8 and above <pre><code>from typing_extensions import Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Literal['a']\n\n\ntry:\n    Model(x='b')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'literal_error'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Literal['a']\n\n\ntry:\n    Model(x='b')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'literal_error'\n</code></pre>"},{"location":"usage/validation_errors/#mapping_type","title":"<code>mapping_type</code>","text":"<p>This error is raised when the input value is not a valid mapping.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from collections.abc import Mapping\nfrom typing import Dict\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass BadMapping(Mapping):\n    def items(self):\n        raise ValueError()\n\n    def __iter__(self):\n        raise ValueError()\n\n    def __getitem__(self, key):\n        raise ValueError()\n\n    def __len__(self):\n        return 1\n\n\nclass Model(BaseModel):\n    x: Dict[str, str]\n\n\ntry:\n    Model(x=BadMapping())\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'mapping_type'\n</code></pre> <pre><code>from collections.abc import Mapping\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass BadMapping(Mapping):\n    def items(self):\n        raise ValueError()\n\n    def __iter__(self):\n        raise ValueError()\n\n    def __getitem__(self, key):\n        raise ValueError()\n\n    def __len__(self):\n        return 1\n\n\nclass Model(BaseModel):\n    x: dict[str, str]\n\n\ntry:\n    Model(x=BadMapping())\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'mapping_type'\n</code></pre>"},{"location":"usage/validation_errors/#missing","title":"<code>missing</code>","text":"<p>This error is raised when you don't provide required input fields.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model()\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'missing'\n</code></pre>"},{"location":"usage/validation_errors/#missing_argument","title":"<code>missing_argument</code>","text":"<p>This error is raised when you missed arguments in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'missing_argument'\n</code></pre>"},{"location":"usage/validation_errors/#missing_keyword_only_argument","title":"<code>missing_keyword_only_argument</code>","text":"<p>This error is raised when you missed keyword-only arguments in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(*, a: int):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'missing_keyword_only_argument'\n</code></pre>"},{"location":"usage/validation_errors/#missing_positional_only_argument","title":"<code>missing_positional_only_argument</code>","text":"<p>This error is raised when you missed positional-only arguments in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int, /):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'missing_positional_only_argument'\n</code></pre>"},{"location":"usage/validation_errors/#model_class_type","title":"<code>model_class_type</code>","text":"<p>This error is raised when you validate with <code>strict=True</code> and the input value is not an instance of the model.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model.model_validate({'x': 'test'}, strict=True)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'model_class_type'\n</code></pre> <p>Valid example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: str\n\n\nModel.model_validate(Model(x='test'), strict=True)\n</code></pre>"},{"location":"usage/validation_errors/#multiple_argument_values","title":"<code>multiple_argument_values</code>","text":"<p>This error is raised when you provide multiple values for an argument in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int):\n    return a\n\n\ntry:\n    foo(1, a=2)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'multiple_argument_values'\n</code></pre>"},{"location":"usage/validation_errors/#multiple_of","title":"<code>multiple_of</code>","text":"<p>This error is raised when the input is not a multiple of <code>FieldInfo.multiple_of</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(multiple_of=5)\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'multiple_of'\n</code></pre>"},{"location":"usage/validation_errors/#no_such_attribute","title":"<code>no_such_attribute</code>","text":"<p>This error is raised when you assign a value to an attribute that does not exist.</p> <pre><code>from pydantic import ConfigDict, ValidationError, dataclasses\n\n\n@dataclasses.dataclass(config=ConfigDict(validate_assignment=True))\nclass MyDataclass:\n    x: int\n\n\nm = MyDataclass(x=1)\ntry:\n    m.y = 10\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'no_such_attribute'\n</code></pre>"},{"location":"usage/validation_errors/#none_required","title":"<code>none_required</code>","text":"<p>This error is raised when the input value is not <code>None</code> for a field that requires <code>None</code>.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: None\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'none_required'\n</code></pre>"},{"location":"usage/validation_errors/#recursion_loop","title":"<code>recursion_loop</code>","text":"<p>This error is raised when a cyclic reference is detected.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: List['Model']\n\n\nd = {'x': []}\nd['x'].append(d)\ntry:\n    Model(**d)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'recursion_loop'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: list['Model']\n\n\nd = {'x': []}\nd['x'].append(d)\ntry:\n    Model(**d)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'recursion_loop'\n</code></pre>"},{"location":"usage/validation_errors/#set_type","title":"<code>set_type</code>","text":"<p>This error is raised when the value type is not <code>set</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Set\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Set[int]\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'set_type'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: set[int]\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'set_type'\n</code></pre>"},{"location":"usage/validation_errors/#string_pattern_mismatch","title":"<code>string_pattern_mismatch</code>","text":"<p>This error is raised when the value doesn't match with <code>Field.pattern</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(pattern='test')\n\n\ntry:\n    Model(x='1')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_pattern_mismatch'\n</code></pre>"},{"location":"usage/validation_errors/#string_sub_type","title":"<code>string_sub_type</code>","text":"<p>This error is raised when the value is not an instance of a subclass of string when <code>Field.strict=True</code>.</p> <pre><code>from enum import Enum\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass MyEnum(str, Enum):\n    foo = 'foo'\n\n\nclass Model(BaseModel):\n    x: str = Field(strict=True)\n\n\ntry:\n    Model(x=MyEnum.foo)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_sub_type'\n</code></pre>"},{"location":"usage/validation_errors/#string_too_long","title":"<code>string_too_long</code>","text":"<p>This error is raised when the string value length is greater than <code>Field.max_length</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(max_length=3)\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_too_long'\n</code></pre>"},{"location":"usage/validation_errors/#string_too_short","title":"<code>string_too_short</code>","text":"<p>This error is raised when the string value length is less than <code>Field.min_length</code>.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(min_length=3)\n\n\ntry:\n    Model(x='t')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_too_short'\n</code></pre>"},{"location":"usage/validation_errors/#string_type","title":"<code>string_type</code>","text":"<p>This error is raised when the value is not a string.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_type'\n</code></pre>"},{"location":"usage/validation_errors/#string_unicode","title":"<code>string_unicode</code>","text":"<p>This error is raised when the value cannot be parsed as a Unicode string.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model(x=b'\\x81')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'string_unicode'\n</code></pre>"},{"location":"usage/validation_errors/#time_delta_parsing","title":"<code>time_delta_parsing</code>","text":"<p>This error is raised when the value provided for a <code>timedelta</code> field cannot be parsed.</p> <pre><code>from datetime import timedelta\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: timedelta\n\n\ntry:\n    Model(x='t')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'time_delta_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#time_delta_type","title":"<code>time_delta_type</code>","text":"<p>This error is raised when the value type is not valid for a <code>timedelta</code> field.</p> <pre><code>from datetime import timedelta\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: timedelta\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'time_delta_type'\n</code></pre>"},{"location":"usage/validation_errors/#time_parsing","title":"<code>time_parsing</code>","text":"<p>This error is raised when the value provided for a <code>time</code> field cannot be parsed.</p> <pre><code>from datetime import time\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: time\n\n\ntry:\n    Model(x='25:20:30.400')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'time_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#time_type","title":"<code>time_type</code>","text":"<p>This error is raised when the value type is not valid for a <code>time</code> field.</p> <pre><code>from datetime import time\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: time\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'time_type'\n</code></pre>"},{"location":"usage/validation_errors/#too_long","title":"<code>too_long</code>","text":"<p>This error is raised when the value length is greater than <code>Field.max_length</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int] = Field(max_length=3)\n\n\ntry:\n    Model(x=[1, 2, 3, 4])\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'too_long'\n</code></pre> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: list[int] = Field(max_length=3)\n\n\ntry:\n    Model(x=[1, 2, 3, 4])\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'too_long'\n</code></pre>"},{"location":"usage/validation_errors/#too_short","title":"<code>too_short</code>","text":"<p>This error is raised when the value length is less than <code>Field.min_length</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int] = Field(min_length=3)\n\n\ntry:\n    Model(x=[1, 2])\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'too_short'\n</code></pre> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: list[int] = Field(min_length=3)\n\n\ntry:\n    Model(x=[1, 2])\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'too_short'\n</code></pre>"},{"location":"usage/validation_errors/#tuple_type","title":"<code>tuple_type</code>","text":"<p>This error is raised when the value type is not valid for a <code>tuple</code> field.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Tuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Tuple[int]\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'tuple_type'\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: tuple[int]\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'tuple_type'\n</code></pre>"},{"location":"usage/validation_errors/#unexpected_keyword_argument","title":"<code>unexpected_keyword_argument</code>","text":"<p>This error is raised when you provide a value by keyword for a positional-only argument in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int, /):\n    return a\n\n\ntry:\n    foo(a=2)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[1]['type'] == 'unexpected_keyword_argument'\n</code></pre>"},{"location":"usage/validation_errors/#unexpected_positional_argument","title":"<code>unexpected_positional_argument</code>","text":"<p>This error is raised when you provide a positional value for a keyword-only argument in calling a function decorated by <code>validate_call</code>.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(*, a: int):\n    return a\n\n\ntry:\n    foo(2)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[1]['type'] == 'unexpected_positional_argument'\n</code></pre>"},{"location":"usage/validation_errors/#union_tag_invalid","title":"<code>union_tag_invalid</code>","text":"<p>This error is raised when the tag does not match any of the expected tags.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'pet_type': 't'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_invalid'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'pet_type': 't'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_invalid'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: BlackCat | WhiteCat = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'pet_type': 't'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_invalid'\n</code></pre>"},{"location":"usage/validation_errors/#union_tag_not_found","title":"<code>union_tag_not_found</code>","text":"<p>This error is raised when it is not possible to extract a tag using the discriminator.</p> Python 3.7 and abovePython 3.8 and abovePython 3.10 and above <pre><code>from typing import Union\n\nfrom typing_extensions import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'name': 'blackcat'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_not_found'\n</code></pre> <pre><code>from typing import Union\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'name': 'blackcat'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_not_found'\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: BlackCat | WhiteCat = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'name': 'blackcat'})\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'union_tag_not_found'\n</code></pre>"},{"location":"usage/validation_errors/#url_parsing","title":"<code>url_parsing</code>","text":"<p>This error is raised when the input value cannot be parsed as a URL.</p> <pre><code>from pydantic import AnyUrl, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: AnyUrl\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'url_parsing'\n</code></pre>"},{"location":"usage/validation_errors/#url_scheme","title":"<code>url_scheme</code>","text":"<p>This error is raised when the URL scheme is not valid for the URL type of the field.</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x='ftp://example.com')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'url_scheme'\n</code></pre>"},{"location":"usage/validation_errors/#url_syntax_violation","title":"<code>url_syntax_violation</code>","text":"<p>This error is raised when the URL syntax is not valid.</p> <pre><code>from pydantic import BaseModel, Field, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl = Field(strict=True)\n\n\ntry:\n    Model(x='http:////example.com')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'url_syntax_violation'\n</code></pre>"},{"location":"usage/validation_errors/#url_too_long","title":"<code>url_too_long</code>","text":"<p>This error is raised when the URL length is greater than 2083.</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x='x' * 2084)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'url_too_long'\n</code></pre>"},{"location":"usage/validation_errors/#url_type","title":"<code>url_type</code>","text":"<p>This error is raised when the input value type is not valid for a URL field.</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'url_type'\n</code></pre>"},{"location":"usage/validation_errors/#value_error","title":"<code>value_error</code>","text":"<p>This error is raised when there is a <code>ValueError</code> during validation.</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    x: str\n\n    @field_validator('x')\n    @classmethod\n    def repeat_b(cls, v):\n        raise ValueError()\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc_info:\n    assert exc_info.errors()[0]['type'] == 'value_error'\n</code></pre>"},{"location":"usage/validators/","title":"Validators","text":"<p>Custom validation and complex relationships between objects can be achieved using the <code>@field_validator</code> decorator.</p> <pre><code>from pydantic_core.core_schema import FieldValidationInfo\n\nfrom pydantic import BaseModel, ValidationError, field_validator\n\n\nclass UserModel(BaseModel):\n    name: str\n    username: str\n    password1: str\n    password2: str\n\n    @field_validator('name')\n    def name_must_contain_space(cls, v):\n        if ' ' not in v:\n            raise ValueError('must contain a space')\n        return v.title()\n\n    @field_validator('password2')\n    def passwords_match(cls, v, info: FieldValidationInfo):\n        if 'password1' in info.data and v != info.data['password1']:\n            raise ValueError('passwords do not match')\n        return v\n\n    @field_validator('username')\n    def username_alphanumeric(cls, v):\n        assert v.isalnum(), 'must be alphanumeric'\n        return v\n\n\nuser = UserModel(\n    name='samuel colvin',\n    username='scolvin',\n    password1='zxcvbn',\n    password2='zxcvbn',\n)\nprint(user)\n#&gt; name='Samuel Colvin' username='scolvin' password1='zxcvbn' password2='zxcvbn'\n\ntry:\n    UserModel(\n        name='samuel',\n        username='scolvin',\n        password1='zxcvbn',\n        password2='zxcvbn2',\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for UserModel\n    name\n      Value error, must contain a space [type=value_error, input_value='samuel', input_type=str]\n    password2\n      Value error, passwords do not match [type=value_error, input_value='zxcvbn2', input_type=str]\n    \"\"\"\n</code></pre> <p>A few things to note on validators:</p> <ul> <li>validators are \"class methods\", so the first argument value they receive is the <code>UserModel</code> class, not an instance   of <code>UserModel</code>.</li> <li>the second argument is always the field value to validate; it can be named as you please</li> <li>you can also add any subset of the following arguments to the signature (the names must match):</li> <li><code>values</code>: a dict containing the name-to-value mapping of any previously-validated fields</li> <li><code>config</code>: the model config</li> <li><code>field</code>: the field being validated. Type of object is <code>pydantic.fields.ModelField</code>.</li> <li><code>**kwargs</code>: if provided, this will include the arguments above not explicitly listed in the signature</li> <li>validators should either return the parsed value or raise a <code>ValueError</code>, <code>TypeError</code>, or <code>AssertionError</code>   (<code>assert</code> statements may be used).</li> </ul> <p>Warning</p> <p>If you make use of <code>assert</code> statements, keep in mind that running Python with the <code>-O</code> optimization flag disables <code>assert</code> statements, and validators will stop working.</p> <ul> <li> <p>where validators rely on other values, you should be aware that:</p> </li> <li> <p>Validation is done in the order fields are defined.     E.g. in the example above, <code>password2</code> has access to <code>password1</code> (and <code>name</code>),     but <code>password1</code> does not have access to <code>password2</code>. See Field Ordering     for more information on how fields are ordered</p> </li> <li> <p>If validation fails on another field (or that field is missing) it will not be included in <code>values</code>, hence     <code>if 'password1' in values and ...</code> in this example.</p> </li> </ul>"},{"location":"usage/validators/#pre-and-per-item-validators","title":"Pre and per-item validators","text":"<p>Validators can do a few more complex things:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, ValidationError, field_validator\nfrom pydantic.functional_validators import AfterValidator\n\n\ndef check_squares(v: int) -&gt; int:\n    assert v**0.5 % 1 == 0, f'{v} is not a square number'\n    return v\n\n\ndef check_cubes(v: int) -&gt; int:\n    # 64 ** (1 / 3) == 3.9999999999999996 (!)\n    # this is not a good way of checking cubes\n    assert v ** (1 / 3) % 1 == 0, f'{v} is not a cubed number'\n    return v\n\n\nSquaredNumber = Annotated[int, AfterValidator(check_squares)]\nCubedNumberNumber = Annotated[int, AfterValidator(check_cubes)]\n\n\nclass DemoModel(BaseModel):\n    square_numbers: List[SquaredNumber] = []\n    cube_numbers: List[CubedNumberNumber] = []\n\n    @field_validator('square_numbers', 'cube_numbers', mode='before')\n    def split_str(cls, v):\n        if isinstance(v, str):\n            return v.split('|')\n        return v\n\n    @field_validator('cube_numbers', 'square_numbers')\n    def check_sum(cls, v):\n        if sum(v) &gt; 42:\n            raise ValueError('sum of numbers greater than 42')\n        return v\n\n\nprint(DemoModel(square_numbers=[1, 4, 9]))\n#&gt; square_numbers=[1, 4, 9] cube_numbers=[]\nprint(DemoModel(square_numbers='1|4|16'))\n#&gt; square_numbers=[1, 4, 16] cube_numbers=[]\nprint(DemoModel(square_numbers=[16], cube_numbers=[8, 27]))\n#&gt; square_numbers=[16] cube_numbers=[8, 27]\ntry:\n    DemoModel(square_numbers=[1, 4, 2])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for DemoModel\n    square_numbers.2\n      Assertion failed, 2 is not a square number\n    assert ((2 ** 0.5) % 1) == 0 [type=assertion_error, input_value=2, input_type=int]\n    \"\"\"\n\ntry:\n    DemoModel(cube_numbers=[27, 27])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for DemoModel\n    cube_numbers\n      Value error, sum of numbers greater than 42 [type=value_error, input_value=[27, 27], input_type=list]\n    \"\"\"\n</code></pre> <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, ValidationError, field_validator\nfrom pydantic.functional_validators import AfterValidator\n\n\ndef check_squares(v: int) -&gt; int:\n    assert v**0.5 % 1 == 0, f'{v} is not a square number'\n    return v\n\n\ndef check_cubes(v: int) -&gt; int:\n    # 64 ** (1 / 3) == 3.9999999999999996 (!)\n    # this is not a good way of checking cubes\n    assert v ** (1 / 3) % 1 == 0, f'{v} is not a cubed number'\n    return v\n\n\nSquaredNumber = Annotated[int, AfterValidator(check_squares)]\nCubedNumberNumber = Annotated[int, AfterValidator(check_cubes)]\n\n\nclass DemoModel(BaseModel):\n    square_numbers: list[SquaredNumber] = []\n    cube_numbers: list[CubedNumberNumber] = []\n\n    @field_validator('square_numbers', 'cube_numbers', mode='before')\n    def split_str(cls, v):\n        if isinstance(v, str):\n            return v.split('|')\n        return v\n\n    @field_validator('cube_numbers', 'square_numbers')\n    def check_sum(cls, v):\n        if sum(v) &gt; 42:\n            raise ValueError('sum of numbers greater than 42')\n        return v\n\n\nprint(DemoModel(square_numbers=[1, 4, 9]))\n#&gt; square_numbers=[1, 4, 9] cube_numbers=[]\nprint(DemoModel(square_numbers='1|4|16'))\n#&gt; square_numbers=[1, 4, 16] cube_numbers=[]\nprint(DemoModel(square_numbers=[16], cube_numbers=[8, 27]))\n#&gt; square_numbers=[16] cube_numbers=[8, 27]\ntry:\n    DemoModel(square_numbers=[1, 4, 2])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for DemoModel\n    square_numbers.2\n      Assertion failed, 2 is not a square number\n    assert ((2 ** 0.5) % 1) == 0 [type=assertion_error, input_value=2, input_type=int]\n    \"\"\"\n\ntry:\n    DemoModel(cube_numbers=[27, 27])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for DemoModel\n    cube_numbers\n      Value error, sum of numbers greater than 42 [type=value_error, input_value=[27, 27], input_type=list]\n    \"\"\"\n</code></pre> <p>A few more things to note:</p> <ul> <li>a single validator can be applied to multiple fields by passing it multiple field names</li> <li>a single validator can also be called on all fields by passing the special value <code>'*'</code></li> <li>the keyword argument <code>mode='before'</code> will cause the validator to be called prior to other validation</li> <li>using validator annotations inside of Annotated allows applying validators to items of collections</li> </ul>"},{"location":"usage/validators/#generic-validated-collections","title":"Generic validated collections","text":"<p>To validate individual items of a collection (list, dict, etc.) field you can use <code>Annotated</code> to apply validators to the inner items. In this example we also use type aliases to create a generic validated collection to demonstrate how this approach leads to composability and coda re-use.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List, TypeVar\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel\nfrom pydantic.functional_validators import AfterValidator\n\nT = TypeVar('T')\n\nSortedList = Annotated[List[T], AfterValidator(lambda x: sorted(x))]\n\nName = Annotated[str, AfterValidator(lambda x: x.title())]\n\n\nclass DemoModel(BaseModel):\n    int_list: SortedList[int]\n    name_list: SortedList[Name]\n\n\nprint(DemoModel(int_list=[3, 2, 1], name_list=['adrian g', 'David']))\n#&gt; int_list=[1, 2, 3] name_list=['Adrian G', 'David']\n</code></pre> <pre><code>from typing import TypeVar\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel\nfrom pydantic.functional_validators import AfterValidator\n\nT = TypeVar('T')\n\nSortedList = Annotated[list[T], AfterValidator(lambda x: sorted(x))]\n\nName = Annotated[str, AfterValidator(lambda x: x.title())]\n\n\nclass DemoModel(BaseModel):\n    int_list: SortedList[int]\n    name_list: SortedList[Name]\n\n\nprint(DemoModel(int_list=[3, 2, 1], name_list=['adrian g', 'David']))\n#&gt; int_list=[1, 2, 3] name_list=['Adrian G', 'David']\n</code></pre>"},{"location":"usage/validators/#validate-always","title":"Validate Always","text":"<p>TODO this content is wrong!</p> <p>For performance reasons, by default validators are not called for fields when a value is not supplied. However there are situations where it may be useful or required to always call the validator, e.g. to set a dynamic default value.</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, field_validator\n\n\nclass DemoModel(BaseModel):\n    ts: datetime\n\n    @field_validator('ts', mode='before')\n    def set_ts_now(cls, v):\n        return v or datetime.now()\n\n\nprint(DemoModel(ts=None))\n#&gt; ts=datetime.datetime(2032, 1, 2, 3, 4, 5, 6)\nprint(DemoModel(ts='2017-11-08T14:00'))\n#&gt; ts=datetime.datetime(2017, 11, 8, 14, 0)\n</code></pre> <p>You'll often want to use this together with <code>pre</code>, since otherwise with <code>always=True</code> Pydantic would try to validate the default <code>None</code> which would cause an error.</p>"},{"location":"usage/validators/#reuse-validators","title":"Reuse validators","text":"<p>Occasionally, you will want to use the same validator on multiple fields/models (e.g. to normalize some input data). The \"naive\" approach would be to write a separate function, then call it from multiple decorators.  Obviously, this entails a lot of repetition and boiler plate code. To circumvent this, the <code>allow_reuse</code> parameter has been added to <code>pydantic.validator</code> in v1.2 (<code>False</code> by default):</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\ndef normalize(name: str) -&gt; str:\n    return ' '.join((word.capitalize()) for word in name.split(' '))\n\n\nclass Producer(BaseModel):\n    name: str\n\n    # validators\n    normalize_name = field_validator('name')(normalize)\n\n\nclass Consumer(BaseModel):\n    name: str\n\n    # validators\n    normalize_name = field_validator('name')(normalize)\n\n\njane_doe = Producer(name='JaNe DOE')\njohn_doe = Consumer(name='joHN dOe')\nassert jane_doe.name == 'Jane Doe'\nassert john_doe.name == 'John Doe'\n</code></pre> <p>As it is obvious, repetition has been reduced and the models become again almost declarative.</p> <p>Tip</p> <p>If you have a lot of fields that you want to validate, it usually makes sense to define a help function with which you will avoid setting <code>allow_reuse=True</code> over and over again.</p>"},{"location":"usage/validators/#model-validators","title":"Model Validators","text":"<p>Validation can also be performed on the entire model's data.</p> <pre><code>from pydantic import BaseModel, ValidationError, model_validator\n\n\nclass UserModel(BaseModel):\n    username: str\n    password1: str\n    password2: str\n\n    @model_validator(mode='before')\n    def check_card_number_omitted(cls, data):\n        assert 'card_number' not in data, 'card_number should not be included'\n        return data\n\n    @model_validator(mode='after')\n    def check_passwords_match(cls, m: 'UserModel'):\n        pw1 = m.password1\n        pw2 = m.password2\n        if pw1 is not None and pw2 is not None and pw1 != pw2:\n            raise ValueError('passwords do not match')\n        return m\n\n\nprint(UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn'))\n#&gt; username='scolvin' password1='zxcvbn' password2='zxcvbn'\ntry:\n    UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn2')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for UserModel\n      Value error, passwords do not match [type=value_error, input_value={'username': 'scolvin', '... 'password2': 'zxcvbn2'}, input_type=dict]\n    \"\"\"\n\ntry:\n    UserModel(\n        username='scolvin',\n        password1='zxcvbn',\n        password2='zxcvbn',\n        card_number='1234',\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for UserModel\n      Assertion failed, card_number should not be included\n    assert 'card_number' not in {'card_number': '1234', 'password1': 'zxcvbn', 'password2': 'zxcvbn', 'username': 'scolvin'} [type=assertion_error, input_value={'username': 'scolvin', '..., 'card_number': '1234'}, input_type=dict]\n    \"\"\"\n</code></pre> <p>As with field validators, root validators can have <code>pre=True</code>, in which case they're called before field validation occurs (and are provided with the raw input data), or <code>pre=False</code> (the default), in which case they're called after field validation.</p> <p>Field validation will not occur if <code>pre=True</code> root validators raise an error. As with field validators, \"post\" (i.e. <code>pre=False</code>) root validators by default will be called even if prior validators fail; this behaviour can be changed by setting the <code>skip_on_failure=True</code> keyword argument to the validator. The <code>values</code> argument will be a dict containing the values which passed field validation and field defaults where applicable.</p>"},{"location":"usage/validators/#field-checks","title":"Field Checks","text":"<p>On class creation, validators are checked to confirm that the fields they specify actually exist on the model.</p> <p>Occasionally however this is undesirable: e.g. if you define a validator to validate fields on inheriting models. In this case you should set <code>check_fields=False</code> on the validator.</p>"},{"location":"usage/validators/#dataclass-validators","title":"Dataclass Validators","text":"<p>Validators also work with Pydantic dataclasses.</p> <p>TODO: Change this example so that it should use a validator; right now it would be better off with default_factory..</p> <pre><code>from datetime import datetime\n\nfrom pydantic import Field, field_validator\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass DemoDataclass:\n    ts: datetime = Field(None, validate_default=True)\n\n    @field_validator('ts', mode='before')\n    def set_ts_now(cls, v):\n        return v or datetime.now()\n\n\nprint(DemoDataclass())\n#&gt; DemoDataclass(ts=datetime.datetime(2032, 1, 2, 3, 4, 5, 6))\nprint(DemoDataclass(ts='2017-11-08T14:00'))\n#&gt; DemoDataclass(ts=datetime.datetime(2017, 11, 8, 14, 0))\n</code></pre>"},{"location":"usage/types/booleans/","title":"Booleans","text":"<code>bool</code> see below for details on how bools are validated and what values are permitted <p>A standard <code>bool</code> field will raise a <code>ValidationError</code> if the value is not one of the following:</p> <ul> <li>A valid boolean (i.e. <code>True</code> or <code>False</code>),</li> <li>The integers <code>0</code> or <code>1</code>,</li> <li>a <code>str</code> which when converted to lower case is one of   <code>'0', 'off', 'f', 'false', 'n', 'no', '1', 'on', 't', 'true', 'y', 'yes'</code></li> <li>a <code>bytes</code> which is valid per the previous rule when decoded to <code>str</code></li> </ul> <p>Note</p> <p>If you want stricter boolean logic (e.g. a field which only permits <code>True</code> and <code>False</code>) you can use <code>StrictBool</code>.</p> <p>Here is a script demonstrating some of these behaviors:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass BooleanModel(BaseModel):\n    bool_value: bool\n\n\nprint(BooleanModel(bool_value=False))\n#&gt; bool_value=False\nprint(BooleanModel(bool_value='False'))\n#&gt; bool_value=False\nprint(BooleanModel(bool_value=1))\n#&gt; bool_value=True\ntry:\n    BooleanModel(bool_value=[])\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    1 validation error for BooleanModel\n    bool_value\n      Input should be a valid boolean [type=bool_type, input_value=[], input_type=list]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/bytesize/","title":"Bytes and ByteSize","text":"<code>bytes</code> <code>bytes</code> are accepted as-is, <code>bytearray</code> is converted using <code>bytes(v)</code>, and <code>str</code> is converted using <code>v.encode()</code>. <code>SecretBytes</code> Like <code>bytes</code>, but where the value is kept partially secret; see Secrets. <code>ByteSize</code> Converts a string representing a number of bytes with units (such as <code>'1KB'</code> or <code>'11.5MiB'</code>) into an integer. <code>conbytes</code> A function which returns a type that can be used to add constraints to <code>bytes</code>."},{"location":"usage/types/bytesize/#arguments-to-conbytes","title":"Arguments to <code>conbytes</code>","text":"<p>The following arguments are available when using the <code>conbytes</code> type function</p> <ul> <li><code>min_length: int = None</code>: minimum length of the byte string</li> <li><code>max_length: int = None</code>: maximum length of the byte string</li> <li><code>strict: bool = False</code>: controls type coercion</li> </ul> <p>However, for the sake of improved integration with type checkers, we now discourage the use of <code>conbytes</code> and other function calls used to return constrained types. Instead, you can use <code>pydantic.types.Strict</code> and <code>annotated_types.Len</code> as annotations to achieve these constraints:</p> Python 3.7 and abovePython 3.9 and above <pre><code>import annotated_types\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Strict\n\n\nclass MyModel(BaseModel):\n    # Instead of `my_bytes: conbytes(strict=True, min_length=10, max_length=20)`, use:\n    my_bytes: Annotated[bytes, Strict(), annotated_types.Len(10, 20)]\n</code></pre> <pre><code>import annotated_types\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Strict\n\n\nclass MyModel(BaseModel):\n    # Instead of `my_bytes: conbytes(strict=True, min_length=10, max_length=20)`, use:\n    my_bytes: Annotated[bytes, Strict(), annotated_types.Len(10, 20)]\n</code></pre>"},{"location":"usage/types/bytesize/#using-bytesize","title":"Using ByteSize","text":"<p>You can use the <code>ByteSize</code> data type to (case-insensitively) convert a string representation of a number of bytes into an integer, and also to print out human-readable strings representing a number of bytes.</p> <p>In conformance with IEC 80000-13 Standard we interpret <code>'1KB'</code> to mean 1000 bytes, and <code>'1KiB'</code> to mean 1024 bytes. In general, including a middle <code>'i'</code> will cause the unit to be interpreted as a power of 2, rather than a power of 10 (so, for example, <code>'1 MB'</code> is treated as <code>1_000_000</code> bytes, whereas <code>'1 MiB'</code> is treated as <code>1_048_576</code> bytes).</p> <p>Info</p> <p>Note that <code>1b</code> will be parsed as \"1 byte\" and not \"1 bit\".</p> <pre><code>from pydantic import BaseModel, ByteSize\n\n\nclass MyModel(BaseModel):\n    size: ByteSize\n\n\nprint(MyModel(size=52000).size)\n#&gt; 52000\nprint(MyModel(size='3000 KiB').size)\n#&gt; 3072000\n\nm = MyModel(size='50 PB')\nprint(m.size.human_readable())\n#&gt; 44.4PiB\nprint(m.size.human_readable(decimal=True))\n#&gt; 50.0PB\n\nprint(m.size.to('TiB'))\n#&gt; 45474.73508864641\n</code></pre>"},{"location":"usage/types/callables/","title":"Callables","text":"<code>typing.Callable</code> see below for more detail on parsing and validation <p>Fields can also be of type <code>Callable</code>:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Callable\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    callback: Callable[[int], int]\n\n\nm = Foo(callback=lambda x: x)\nprint(m)\n#&gt; callback=&lt;function &lt;lambda&gt; at 0x0123456789ab&gt;\n</code></pre> <pre><code>from collections.abc import Callable\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    callback: Callable[[int], int]\n\n\nm = Foo(callback=lambda x: x)\nprint(m)\n#&gt; callback=&lt;function &lt;lambda&gt; at 0x0123456789ab&gt;\n</code></pre> <p>Warning</p> <p>Callable fields only perform a simple check that the argument is callable; no validation of arguments, their types, or the return type is performed.</p>"},{"location":"usage/types/custom/","title":"Custom Data Types","text":"<p>You can also define your own custom data types. There are several ways to achieve it.</p>"},{"location":"usage/types/custom/#composing-types-via-annotated","title":"Composing types via <code>Annotated</code>","text":"<p>PEP 593 introduced <code>Annotated</code> as a way to attach runtime metadata to types without changing how type checkers interpret them. Pydantic takes advantage of this to allow you to create types that are identical to the original type as far as type checkers are concerned, but add validation, serialize differently, etc. For example, to create a type representing a positive int:</p> Python 3.7 and abovePython 3.9 and above <pre><code># or `from typing import Annotated` for Python 3.9+\nfrom typing_extensions import Annotated\n\nfrom pydantic import Field, TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Field(gt=0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <pre><code># or `from typing import Annotated` for Python 3.9+\nfrom typing import Annotated\n\nfrom pydantic import Field, TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Field(gt=0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <p>Note that you can also use constraints from [<code>annotated-types</code>] to make this Pydantic-agnostic:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from annotated_types import Gt\nfrom typing_extensions import Annotated\n\nfrom pydantic import TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Gt(0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <pre><code>from annotated_types import Gt\nfrom typing import Annotated\n\nfrom pydantic import TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Gt(0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/custom/#adding-validation-and-serialization","title":"Adding validation and serialization","text":"<p>You can add or override validation, serialization, and json schemas to an arbitrary type using the markers that Pydantic exports:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import AfterValidator, PlainSerializer, TypeAdapter, WithJsonSchema\n\n\nclass MyType:\n    def __init__(self, value: str) -&gt; None:\n        self.value = value\n\n\nTrucatedFloat = Annotated[\n    float,\n    AfterValidator(lambda x: round(x, 1)),\n    PlainSerializer(lambda x: f'{x:.1e}', return_type=str),\n    WithJsonSchema({'type': 'string'}, mode='serialization'),\n]\n\n\nta = TypeAdapter(TrucatedFloat)\n\ninput = 1.02345\nassert input != 1.0\n\nassert ta.validate_python(input) == 1.0\n\nassert ta.dump_json(input) == b'\"1.0e+00\"'\n\nassert ta.json_schema(mode='validation') == {'type': 'number'}\nassert ta.json_schema(mode='serialization') == {'type': 'string'}\n</code></pre> <pre><code>from typing import Annotated\n\nfrom pydantic import AfterValidator, PlainSerializer, TypeAdapter, WithJsonSchema\n\n\nclass MyType:\n    def __init__(self, value: str) -&gt; None:\n        self.value = value\n\n\nTrucatedFloat = Annotated[\n    float,\n    AfterValidator(lambda x: round(x, 1)),\n    PlainSerializer(lambda x: f'{x:.1e}', return_type=str),\n    WithJsonSchema({'type': 'string'}, mode='serialization'),\n]\n\n\nta = TypeAdapter(TrucatedFloat)\n\ninput = 1.02345\nassert input != 1.0\n\nassert ta.validate_python(input) == 1.0\n\nassert ta.dump_json(input) == b'\"1.0e+00\"'\n\nassert ta.json_schema(mode='validation') == {'type': 'number'}\nassert ta.json_schema(mode='serialization') == {'type': 'string'}\n</code></pre>"},{"location":"usage/types/custom/#generics","title":"Generics","text":"<p>You can use type variables within <code>Annotated</code> to make re-usable modifications to types:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, List, Sequence, TypeVar\n\nfrom annotated_types import Gt, Len\nfrom typing_extensions import Annotated\n\nfrom pydantic import ValidationError\nfrom pydantic.type_adapter import TypeAdapter\n\nSequenceType = TypeVar('SequenceType', bound=Sequence[Any])\n\n\nShortSequence = Annotated[SequenceType, Len(max_length=10)]\n\n\nta = TypeAdapter(ShortSequence[List[int]])\n\nv = ta.validate_python([1, 2, 3, 4, 5])\nassert v == [1, 2, 3, 4, 5]\n\ntry:\n    ta.validate_python([1] * 100)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for list[int]\n      List should have at most 10 items after validation, not 11 [type=too_long, input_value=[1, 1, 1, 1, 1, 1, 1, 1, ... 1, 1, 1, 1, 1, 1, 1, 1], input_type=list]\n    \"\"\"\n\n\nT = TypeVar('T')  # or a bound=SupportGt\n\nPositiveList = List[Annotated[T, Gt(0)]]\n\nta = TypeAdapter(PositiveList[float])\n\nv = ta.validate_python([1])\nassert type(v[0]) is float\n\n\ntry:\n    ta.validate_python([-1])\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for list[constrained-float]\n    0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <pre><code>from typing import Any, TypeVar\nfrom collections.abc import Sequence\n\nfrom annotated_types import Gt, Len\nfrom typing import Annotated\n\nfrom pydantic import ValidationError\nfrom pydantic.type_adapter import TypeAdapter\n\nSequenceType = TypeVar('SequenceType', bound=Sequence[Any])\n\n\nShortSequence = Annotated[SequenceType, Len(max_length=10)]\n\n\nta = TypeAdapter(ShortSequence[list[int]])\n\nv = ta.validate_python([1, 2, 3, 4, 5])\nassert v == [1, 2, 3, 4, 5]\n\ntry:\n    ta.validate_python([1] * 100)\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for list[int]\n      List should have at most 10 items after validation, not 11 [type=too_long, input_value=[1, 1, 1, 1, 1, 1, 1, 1, ... 1, 1, 1, 1, 1, 1, 1, 1], input_type=list]\n    \"\"\"\n\n\nT = TypeVar('T')  # or a bound=SupportGt\n\nPositiveList = list[Annotated[T, Gt(0)]]\n\nta = TypeAdapter(PositiveList[float])\n\nv = ta.validate_python([1])\nassert type(v[0]) is float\n\n\ntry:\n    ta.validate_python([-1])\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for list[constrained-float]\n    0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/custom/#named-type-aliases","title":"Named type aliases","text":"<p>The above examples make use of implicit type aliases. This means that they will not be able to have a <code>title</code> in JSON schemas and their schema will be copied between fields. You can use PEP 695's <code>TypeAliasType</code> via its typing-extensions backport to make named aliases, allowing you to define a new type without creating subclasses. This new type can be as simple as a name or have complex validation logic attached to it:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import List, TypeVar\n\nfrom annotated_types import Gt\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import BaseModel\n\nT = TypeVar('T')  # or a `bound=SupportGt`\n\nImplicitAliasPositiveIntList = List[Annotated[int, Gt(0)]]\n\n\nclass Model1(BaseModel):\n    x: ImplicitAliasPositiveIntList\n    y: ImplicitAliasPositiveIntList\n\n\nprint(Model1.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'x': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'X',\n            'type': 'array',\n        },\n        'y': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'Y',\n            'type': 'array',\n        },\n    },\n    'required': ['x', 'y'],\n    'title': 'Model1',\n    'type': 'object',\n}\n\"\"\"\n\nPositiveIntList = TypeAliasType('PositiveIntList', List[Annotated[int, Gt(0)]])\n\n\nclass Model2(BaseModel):\n    x: PositiveIntList\n    y: PositiveIntList\n\n\nprint(Model2.model_json_schema())\n\"\"\"\n{\n    '$defs': {\n        'PositiveIntList': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'type': 'array',\n        }\n    },\n    'properties': {\n        'x': {'$ref': '#/$defs/PositiveIntList'},\n        'y': {'$ref': '#/$defs/PositiveIntList'},\n    },\n    'required': ['x', 'y'],\n    'title': 'Model2',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <pre><code>from typing import TypeVar\n\nfrom annotated_types import Gt\nfrom typing_extensions import TypeAliasType\nfrom typing import Annotated\n\nfrom pydantic import BaseModel\n\nT = TypeVar('T')  # or a `bound=SupportGt`\n\nImplicitAliasPositiveIntList = list[Annotated[int, Gt(0)]]\n\n\nclass Model1(BaseModel):\n    x: ImplicitAliasPositiveIntList\n    y: ImplicitAliasPositiveIntList\n\n\nprint(Model1.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'x': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'X',\n            'type': 'array',\n        },\n        'y': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'Y',\n            'type': 'array',\n        },\n    },\n    'required': ['x', 'y'],\n    'title': 'Model1',\n    'type': 'object',\n}\n\"\"\"\n\nPositiveIntList = TypeAliasType('PositiveIntList', list[Annotated[int, Gt(0)]])\n\n\nclass Model2(BaseModel):\n    x: PositiveIntList\n    y: PositiveIntList\n\n\nprint(Model2.model_json_schema())\n\"\"\"\n{\n    '$defs': {\n        'PositiveIntList': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'type': 'array',\n        }\n    },\n    'properties': {\n        'x': {'$ref': '#/$defs/PositiveIntList'},\n        'y': {'$ref': '#/$defs/PositiveIntList'},\n    },\n    'required': ['x', 'y'],\n    'title': 'Model2',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p>These named type aliases can also be generic:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Generic, List, TypeVar\n\nfrom annotated_types import Gt\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')  # or a bound=SupportGt\n\nPositiveList = TypeAliasType(\n    'PositiveList', List[Annotated[T, Gt(0)]], type_params=(T,)\n)\n\n\nclass Model(BaseModel, Generic[T]):\n    x: PositiveList[T]\n\n\nassert Model[int].model_validate_json('{\"x\": [\"1\"]}').x == [1]\n\ntry:\n    Model[int](x=[-1])\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for Model[int]\n    x.0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <pre><code>from typing import Generic, TypeVar\n\nfrom annotated_types import Gt\nfrom typing_extensions import TypeAliasType\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')  # or a bound=SupportGt\n\nPositiveList = TypeAliasType(\n    'PositiveList', list[Annotated[T, Gt(0)]], type_params=(T,)\n)\n\n\nclass Model(BaseModel, Generic[T]):\n    x: PositiveList[T]\n\n\nassert Model[int].model_validate_json('{\"x\": [\"1\"]}').x == [1]\n\ntry:\n    Model[int](x=[-1])\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for Model[int]\n    x.0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/custom/#named-recursive-types","title":"Named recursive types","text":"<p>You can also use <code>TypeAliasType</code> to create recursive types:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, Dict, List, Union\n\nfrom pydantic_core import PydanticCustomError\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationError,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef json_custom_error_validator(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n\"\"\"Simplify the error message to avoid a gross error stemming\n    from exhaustive checking of all union options.\n    \"\"\"\n    try:\n        return handler(value)\n    except ValidationError:\n        raise PydanticCustomError(\n            'invalid_json',\n            'Input is not valid json',\n        )\n\n\nJson = TypeAliasType(\n    'Json',\n    Annotated[\n        Union[Dict[str, 'Json'], List['Json'], str, int, float, bool, None],\n        WrapValidator(json_custom_error_validator),\n    ],\n)\n\n\nta = TypeAdapter(Json)\n\nv = ta.validate_python({'x': [1], 'y': {'z': True}})\nassert v == {'x': [1], 'y': {'z': True}}\n\ntry:\n    ta.validate_python({'x': object()})\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for function-wrap[json_custom_error_validator()]\n      Input is not valid json [type=invalid_json, input_value={'x': &lt;object object at 0x0123456789ab&gt;}, input_type=dict]\n    \"\"\"\n</code></pre> <pre><code>from typing import Any, Union\n\nfrom pydantic_core import PydanticCustomError\nfrom typing_extensions import TypeAliasType\nfrom typing import Annotated\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationError,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef json_custom_error_validator(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n\"\"\"Simplify the error message to avoid a gross error stemming\n    from exhaustive checking of all union options.\n    \"\"\"\n    try:\n        return handler(value)\n    except ValidationError:\n        raise PydanticCustomError(\n            'invalid_json',\n            'Input is not valid json',\n        )\n\n\nJson = TypeAliasType(\n    'Json',\n    Annotated[\n        Union[dict[str, 'Json'], list['Json'], str, int, float, bool, None],\n        WrapValidator(json_custom_error_validator),\n    ],\n)\n\n\nta = TypeAdapter(Json)\n\nv = ta.validate_python({'x': [1], 'y': {'z': True}})\nassert v == {'x': [1], 'y': {'z': True}}\n\ntry:\n    ta.validate_python({'x': object()})\nexcept ValidationError as exc:\n    print(exc)\n\"\"\"\n    1 validation error for function-wrap[json_custom_error_validator()]\n      Input is not valid json [type=invalid_json, input_value={'x': &lt;object object at 0x0123456789ab&gt;}, input_type=dict]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/custom/#classes-with-__get_pydantic_core_schema__","title":"Classes with <code>__get_pydantic_core_schema__</code>","text":"Python 3.7 and abovePython 3.9 and above <pre><code>import re\nfrom typing import Any\n\nfrom pydantic_core import PydanticCustomError, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    GetCoreSchemaHandler,\n    GetJsonSchemaHandler,\n    ValidationError,\n)\nfrom pydantic.json_schema import JsonSchemaValue\n\n# https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom#Validation\npost_code_regex = re.compile(\n    r'(?:'\n    r'([A-Z]{1,2}[0-9][A-Z0-9]?|ASCN|STHL|TDCU|BBND|[BFS]IQQ|PCRN|TKCA) ?'\n    r'([0-9][A-Z]{2})|'\n    r'(BFPO) ?([0-9]{1,4})|'\n    r'(KY[0-9]|MSR|VG|AI)[ -]?[0-9]{4}|'\n    r'([A-Z]{2}) ?([0-9]{2})|'\n    r'(GE) ?(CX)|'\n    r'(GIR) ?(0A{2})|'\n    r'(SAN) ?(TA1)'\n    r')'\n)\n\n\nclass PostCodeAnnotation:\n\"\"\"\n    Partial UK postcode validation. Note: this is just an example, and is not\n    intended for use in production; in particular this does NOT guarantee\n    a postcode exists, just that it has a valid format.\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, _source_type: Any, _handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.no_info_after_validator_function(\n            cls.validate,\n            core_schema.str_schema(),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        json_schema = handler(schema)\n        json_schema.update(\n            # simplified regex here for brevity, see the wikipedia link above\n            pattern='^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$',\n            # some example postcodes\n            examples=['SP11 9DG', 'W1J 7BU'],\n        )\n        return json_schema\n\n    @classmethod\n    def validate(cls, v: str):\n        m = post_code_regex.fullmatch(v.upper())\n        if m:\n            return f'{m.group(1)} {m.group(2)}'\n        else:\n            raise PydanticCustomError('postcode', 'invalid postcode format')\n\n\nclass Model(BaseModel):\n    post_code: Annotated[str, PostCodeAnnotation]\n\n\nmodel = Model(post_code='sw8 5el')\nprint(model)\n#&gt; post_code='SW8 5EL'\nprint(model.post_code)\n#&gt; SW8 5EL\nprint(Model.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'post_code': {\n            'examples': ['SP11 9DG', 'W1J 7BU'],\n            'pattern': '^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$',\n            'title': 'Post Code',\n            'type': 'string',\n        }\n    },\n    'required': ['post_code'],\n    'title': 'Model',\n    'type': 'object',\n}\n\"\"\"\ntry:\n    Model(post_code='invalid')\nexcept ValidationError as e:\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'postcode',\n            'loc': ('post_code',),\n            'msg': 'invalid postcode format',\n            'input': 'invalid',\n        }\n    ]\n    \"\"\"\n</code></pre> <pre><code>import re\nfrom typing import Any\n\nfrom pydantic_core import PydanticCustomError, core_schema\nfrom typing import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    GetCoreSchemaHandler,\n    GetJsonSchemaHandler,\n    ValidationError,\n)\nfrom pydantic.json_schema import JsonSchemaValue\n\n# https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom#Validation\npost_code_regex = re.compile(\n    r'(?:'\n    r'([A-Z]{1,2}[0-9][A-Z0-9]?|ASCN|STHL|TDCU|BBND|[BFS]IQQ|PCRN|TKCA) ?'\n    r'([0-9][A-Z]{2})|'\n    r'(BFPO) ?([0-9]{1,4})|'\n    r'(KY[0-9]|MSR|VG|AI)[ -]?[0-9]{4}|'\n    r'([A-Z]{2}) ?([0-9]{2})|'\n    r'(GE) ?(CX)|'\n    r'(GIR) ?(0A{2})|'\n    r'(SAN) ?(TA1)'\n    r')'\n)\n\n\nclass PostCodeAnnotation:\n\"\"\"\n    Partial UK postcode validation. Note: this is just an example, and is not\n    intended for use in production; in particular this does NOT guarantee\n    a postcode exists, just that it has a valid format.\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, _source_type: Any, _handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.no_info_after_validator_function(\n            cls.validate,\n            core_schema.str_schema(),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        json_schema = handler(schema)\n        json_schema.update(\n            # simplified regex here for brevity, see the wikipedia link above\n            pattern='^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$',\n            # some example postcodes\n            examples=['SP11 9DG', 'W1J 7BU'],\n        )\n        return json_schema\n\n    @classmethod\n    def validate(cls, v: str):\n        m = post_code_regex.fullmatch(v.upper())\n        if m:\n            return f'{m.group(1)} {m.group(2)}'\n        else:\n            raise PydanticCustomError('postcode', 'invalid postcode format')\n\n\nclass Model(BaseModel):\n    post_code: Annotated[str, PostCodeAnnotation]\n\n\nmodel = Model(post_code='sw8 5el')\nprint(model)\n#&gt; post_code='SW8 5EL'\nprint(model.post_code)\n#&gt; SW8 5EL\nprint(Model.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'post_code': {\n            'examples': ['SP11 9DG', 'W1J 7BU'],\n            'pattern': '^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$',\n            'title': 'Post Code',\n            'type': 'string',\n        }\n    },\n    'required': ['post_code'],\n    'title': 'Model',\n    'type': 'object',\n}\n\"\"\"\ntry:\n    Model(post_code='invalid')\nexcept ValidationError as e:\n    print(e.errors())\n\"\"\"\n    [\n        {\n            'type': 'postcode',\n            'loc': ('post_code',),\n            'msg': 'invalid postcode format',\n            'input': 'invalid',\n        }\n    ]\n    \"\"\"\n</code></pre> <p>Similar validation could be achieved using <code>constr(regex=...)</code> except the value won't be formatted with a space, the schema would just include the full pattern and the returned value would be a vanilla string.</p> <p>See schema for more details on how the model's schema is generated.</p>"},{"location":"usage/types/custom/#generic-classes-as-types","title":"Generic Classes as Types","text":"<p>Warning</p> <p>This is an advanced technique that you might not need in the beginning. In most of the cases you will probably be fine with standard Pydantic models.</p> <p>You can use Generic Classes as field types and perform custom validation based on the \"type parameters\" (or sub-types) with <code>__get_validators__</code>.</p> <p>If the Generic class that you are using as a sub-type has a classmethod <code>__get_validators__</code> you don't need to use <code>arbitrary_types_allowed</code> for it to work.</p> <p>Because you can declare validators that receive the current <code>field</code>, you can extract the <code>sub_fields</code> (from the generic class type parameters) and validate data with them.</p> Python 3.7 and abovePython 3.10 and above <pre><code>from dataclasses import dataclass\nfrom typing import Any, Generic, TypeVar\n\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing_extensions import get_args, get_origin\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationError\n\nAgedType = TypeVar('AgedType')\nQualityType = TypeVar('QualityType')\n\n\n# This is not a pydantic model, it's an arbitrary generic class\n@dataclass\nclass TastingModel(Generic[AgedType, QualityType]):\n    name: str\n    aged: AgedType\n    quality: QualityType\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        origin = get_origin(source_type)\n        if origin is None:  # used as `x: TastingModel` without params\n            origin = source_type\n            age_tp = quality_tp = Any\n        else:\n            age_tp, quality_tp = get_args(source_type)\n        aged_schema = handler(age_tp)\n        quality_schema = handler(quality_tp)\n\n        def val_aged(\n            v: TastingModel[Any, Any], handler: core_schema.ValidatorFunctionWrapHandler\n        ) -&gt; Any:\n            v.aged = handler(v.aged)\n            return v\n\n        def val_quality(\n            v: TastingModel[Any, Any], handler: core_schema.ValidatorFunctionWrapHandler\n        ) -&gt; Any:\n            v.quality = handler(v.quality)\n            return v\n\n        return core_schema.chain_schema(\n            # `chain_schema` means do the following steps in order:\n            [\n                # Ensure the value is an instance of TastingModel\n                core_schema.is_instance_schema(cls),\n                # Use the aged_schema to validate the `aged` field of generic type `AgedType`\n                core_schema.no_info_wrap_validator_function(val_aged, aged_schema),\n                # Use the quality_schema to validate the `quality` field of generic type `QualityType`\n                core_schema.no_info_wrap_validator_function(\n                    val_quality, quality_schema\n                ),\n            ]\n        )\n\n\nclass Model(BaseModel):\n    # for wine, \"aged\" is an int with years, \"quality\" is a float\n    wine: TastingModel[int, float]\n    # for cheese, \"aged\" is a bool, \"quality\" is a str\n    cheese: TastingModel[bool, str]\n    # for thing, \"aged\" is a Any, \"quality\" is Any\n    thing: TastingModel\n\n\nmodel = Model(\n    # This wine was aged for 20 years and has a quality of 85.6\n    wine=TastingModel(name='Cabernet Sauvignon', aged=20, quality=85.6),\n    # This cheese is aged (is mature) and has \"Good\" quality\n    cheese=TastingModel(name='Gouda', aged=True, quality='Good'),\n    # This Python thing has aged \"Not much\" and has a quality \"Awesome\"\n    thing=TastingModel(name='Python', aged='Not much', quality='Awesome'),\n)\nprint(model)\n\"\"\"\nwine=TastingModel(name='Cabernet Sauvignon', aged=20, quality=85.6) cheese=TastingModel(name='Gouda', aged=True, quality='Good') thing=TastingModel(name='Python', aged='Not much', quality='Awesome')\n\"\"\"\nprint(model.wine.aged)\n#&gt; 20\nprint(model.wine.quality)\n#&gt; 85.6\nprint(model.cheese.aged)\n#&gt; True\nprint(model.cheese.quality)\n#&gt; Good\nprint(model.thing.aged)\n#&gt; Not much\ntry:\n    # If the values of the sub-types are invalid, we get an error\n    Model(\n        # For wine, aged should be an int with the years, and quality a float\n        wine=TastingModel(name='Merlot', aged=True, quality='Kinda good'),\n        # For cheese, aged should be a bool, and quality a str\n        cheese=TastingModel(name='Gouda', aged='yeah', quality=5),\n        # For thing, no type parameters are declared, and we skipped validation\n        # in those cases in the Assessment.validate() function\n        thing=TastingModel(name='Python', aged='Not much', quality='Awesome'),\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for Model\n    wine\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='Kinda good', input_type=str]\n    cheese\n      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='yeah', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from dataclasses import dataclass\nfrom typing import Any, Generic, TypeVar\n\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing import get_args, get_origin\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationError\n\nAgedType = TypeVar('AgedType')\nQualityType = TypeVar('QualityType')\n\n\n# This is not a pydantic model, it's an arbitrary generic class\n@dataclass\nclass TastingModel(Generic[AgedType, QualityType]):\n    name: str\n    aged: AgedType\n    quality: QualityType\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        origin = get_origin(source_type)\n        if origin is None:  # used as `x: TastingModel` without params\n            origin = source_type\n            age_tp = quality_tp = Any\n        else:\n            age_tp, quality_tp = get_args(source_type)\n        aged_schema = handler(age_tp)\n        quality_schema = handler(quality_tp)\n\n        def val_aged(\n            v: TastingModel[Any, Any], handler: core_schema.ValidatorFunctionWrapHandler\n        ) -&gt; Any:\n            v.aged = handler(v.aged)\n            return v\n\n        def val_quality(\n            v: TastingModel[Any, Any], handler: core_schema.ValidatorFunctionWrapHandler\n        ) -&gt; Any:\n            v.quality = handler(v.quality)\n            return v\n\n        return core_schema.chain_schema(\n            # `chain_schema` means do the following steps in order:\n            [\n                # Ensure the value is an instance of TastingModel\n                core_schema.is_instance_schema(cls),\n                # Use the aged_schema to validate the `aged` field of generic type `AgedType`\n                core_schema.no_info_wrap_validator_function(val_aged, aged_schema),\n                # Use the quality_schema to validate the `quality` field of generic type `QualityType`\n                core_schema.no_info_wrap_validator_function(\n                    val_quality, quality_schema\n                ),\n            ]\n        )\n\n\nclass Model(BaseModel):\n    # for wine, \"aged\" is an int with years, \"quality\" is a float\n    wine: TastingModel[int, float]\n    # for cheese, \"aged\" is a bool, \"quality\" is a str\n    cheese: TastingModel[bool, str]\n    # for thing, \"aged\" is a Any, \"quality\" is Any\n    thing: TastingModel\n\n\nmodel = Model(\n    # This wine was aged for 20 years and has a quality of 85.6\n    wine=TastingModel(name='Cabernet Sauvignon', aged=20, quality=85.6),\n    # This cheese is aged (is mature) and has \"Good\" quality\n    cheese=TastingModel(name='Gouda', aged=True, quality='Good'),\n    # This Python thing has aged \"Not much\" and has a quality \"Awesome\"\n    thing=TastingModel(name='Python', aged='Not much', quality='Awesome'),\n)\nprint(model)\n\"\"\"\nwine=TastingModel(name='Cabernet Sauvignon', aged=20, quality=85.6) cheese=TastingModel(name='Gouda', aged=True, quality='Good') thing=TastingModel(name='Python', aged='Not much', quality='Awesome')\n\"\"\"\nprint(model.wine.aged)\n#&gt; 20\nprint(model.wine.quality)\n#&gt; 85.6\nprint(model.cheese.aged)\n#&gt; True\nprint(model.cheese.quality)\n#&gt; Good\nprint(model.thing.aged)\n#&gt; Not much\ntry:\n    # If the values of the sub-types are invalid, we get an error\n    Model(\n        # For wine, aged should be an int with the years, and quality a float\n        wine=TastingModel(name='Merlot', aged=True, quality='Kinda good'),\n        # For cheese, aged should be a bool, and quality a str\n        cheese=TastingModel(name='Gouda', aged='yeah', quality=5),\n        # For thing, no type parameters are declared, and we skipped validation\n        # in those cases in the Assessment.validate() function\n        thing=TastingModel(name='Python', aged='Not much', quality='Awesome'),\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for Model\n    wine\n      Input should be a valid number, unable to parse string as an number [type=float_parsing, input_value='Kinda good', input_type=str]\n    cheese\n      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='yeah', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/datetime/","title":"Datetimes","text":"<p>Pydantic supports the following datetime types:</p> <ul> <li><code>datetime.date</code></li> <li><code>datetime.time</code></li> <li><code>datetime.datetime</code></li> <li><code>datetime.timedelta</code></li> </ul>"},{"location":"usage/types/datetime/#validation-of-datetime-types","title":"Validation of datetime types","text":"<ul> <li> <p><code>datetime</code> fields will accept values of type:</p> </li> <li> <p><code>datetime</code>; an existing <code>datetime</code> object</p> </li> <li><code>int</code> or <code>float</code>; assumed as Unix time, i.e. seconds (if &gt;= <code>-2e10</code> and &lt;= <code>2e10</code>) or milliseconds     (if &lt; <code>-2e10</code>or &gt; <code>2e10</code>) since 1 January 1970</li> <li> <p><code>str</code>; the following formats are accepted:</p> <ul> <li><code>YYYY-MM-DD[T]HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> <li><code>int</code> or <code>float</code> as a string (assumed as Unix time)</li> </ul> </li> <li> <p><code>date</code> fields will accept values of type:</p> </li> <li> <p><code>date</code>; an existing <code>date</code> object</p> </li> <li><code>int</code> or <code>float</code>; handled the same as described for <code>datetime</code> above</li> <li> <p><code>str</code>; the following formats are accepted:</p> <ul> <li><code>YYYY-MM-DD</code></li> <li><code>int</code> or <code>float</code> as a string (assumed as Unix time)</li> </ul> </li> <li> <p><code>time</code> fields will accept values of type:</p> </li> <li> <p><code>time</code>; an existing <code>time</code> object</p> </li> <li> <p><code>str</code>; the following formats are accepted:</p> <ul> <li><code>HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> </ul> </li> <li> <p><code>timedelta</code> fields will accept values of type:</p> </li> <li> <p><code>timedelta</code>; an existing <code>timedelta</code> object</p> </li> <li><code>int</code> or <code>float</code>; assumed to be seconds</li> <li> <p><code>str</code>; the following formats are accepted:</p> <ul> <li><code>[-][DD ][HH:MM]SS[.ffffff]</code></li> <li><code>[\u00b1]P[DD]DT[HH]H[MM]M[SS]S</code> (ISO 8601 format for timedelta)</li> </ul> </li> </ul> <pre><code>from datetime import date, datetime, time, timedelta\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    d: date = None\n    dt: datetime = None\n    t: time = None\n    td: timedelta = None\n\n\nm = Model(\n    d=1679616000.0,\n    dt='2032-04-23T10:20:30.400+02:30',\n    t=time(4, 8, 16),\n    td='P3DT12H30M5S',\n)\n\nprint(m.model_dump())\n\"\"\"\n{'d': datetime.date(2023, 3, 24), 'dt': datetime.datetime(2032, 4, 23, 10, 20, 30, 400000, tzinfo=TzInfo(+02:30)), 't': datetime.time(4, 8, 16), 'td': datetime.timedelta(days=3, seconds=45005)}\n\"\"\"\n</code></pre>"},{"location":"usage/types/datetime/#pydantic-date-types","title":"Pydantic date types","text":"<p>The following types can be imported from <code>pydantic</code>, and augment the types described above with additional validation constraints:</p> <code>PastDate</code> like <code>date</code>, with the constraint that the value must be in the past <code>FutureDate</code> like <code>date</code>, with the constraint that the value must be in the future <code>PastDatetime</code> like <code>PastDate</code>, but for <code>datetime</code> <code>FutureDatetime</code> like <code>FutureDate</code>, but for <code>datetime</code> <code>AwareDatetime</code> like <code>datetime</code>, with the constraint that the value must have timezone info <code>NaiveDatetime</code> like <code>datetime</code>, with the constraint that the value must lack timezone info"},{"location":"usage/types/dicts_mapping/","title":"Dicts and Mapping Types","text":"<code>dict</code> <code>dict(v)</code> is used to attempt to convert a dictionary;   see <code>typing.Dict</code> below for sub-type constraints <code>typing.Dict</code> see Typing Iterables below for more detail on parsing and validation <code>subclass of typing.TypedDict</code> Same as <code>dict</code> but pydantic will validate the dictionary since keys are annotated.   See Annotated Types below for more detail on parsing and validation"},{"location":"usage/types/dicts_mapping/#typeddict","title":"TypedDict","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8. Prior to Python 3.8, it requires the typing-extensions package. But required and optional fields are properly differentiated only since Python 3.9. We therefore recommend using typing-extensions with Python 3.8 as well.</p>"},{"location":"usage/types/encoded/","title":"Encoded","text":"<code>EncodedBytes</code> a bytes value which is decoded from/encoded into a (different) bytes value during validation/serialization <code>EncodedStr</code> a string value which is decoded from/encoded into a (different) string value during validation/serialization <p><code>EncodedBytes</code> and <code>EncodedStr</code> needs an encoder that implements <code>EncoderProtocol</code> to operate.</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Optional\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    EncodedBytes,\n    EncodedStr,\n    EncoderProtocol,\n    ValidationError,\n)\n\n\nclass MyEncoder(EncoderProtocol):\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        if data == b'**undecodable**':\n            raise ValueError('Cannot decode data')\n        return data[13:]\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        return b'**encoded**: ' + value\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        return 'my-encoder'\n\n\nMyEncodedBytes = Annotated[bytes, EncodedBytes(encoder=MyEncoder)]\nMyEncodedStr = Annotated[str, EncodedStr(encoder=MyEncoder)]\n\n\nclass Model(BaseModel):\n    my_encoded_bytes: MyEncodedBytes\n    my_encoded_str: Optional[MyEncodedStr] = None\n\n\n# Initialize the model with encoded data\nm = Model(\n    my_encoded_bytes=b'**encoded**: some bytes', my_encoded_str='**encoded**: some str'\n)\n\n# Access decoded value\nprint(m.my_encoded_bytes)\n#&gt; b'some bytes'\nprint(m.my_encoded_str)\n#&gt; some str\n\n# Serialize into the encoded form\nprint(m.model_dump())\n\"\"\"\n{\n    'my_encoded_bytes': b'**encoded**: some bytes',\n    'my_encoded_str': '**encoded**: some str',\n}\n\"\"\"\n\n# Validate encoded data\ntry:\n    Model(my_encoded_bytes=b'**undecodable**')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    my_encoded_bytes\n      Value error, Cannot decode data [type=value_error, input_value=b'**undecodable**', input_type=bytes]\n    \"\"\"\n</code></pre> <pre><code>from typing import Optional\n\nfrom typing import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    EncodedBytes,\n    EncodedStr,\n    EncoderProtocol,\n    ValidationError,\n)\n\n\nclass MyEncoder(EncoderProtocol):\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        if data == b'**undecodable**':\n            raise ValueError('Cannot decode data')\n        return data[13:]\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        return b'**encoded**: ' + value\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        return 'my-encoder'\n\n\nMyEncodedBytes = Annotated[bytes, EncodedBytes(encoder=MyEncoder)]\nMyEncodedStr = Annotated[str, EncodedStr(encoder=MyEncoder)]\n\n\nclass Model(BaseModel):\n    my_encoded_bytes: MyEncodedBytes\n    my_encoded_str: Optional[MyEncodedStr] = None\n\n\n# Initialize the model with encoded data\nm = Model(\n    my_encoded_bytes=b'**encoded**: some bytes', my_encoded_str='**encoded**: some str'\n)\n\n# Access decoded value\nprint(m.my_encoded_bytes)\n#&gt; b'some bytes'\nprint(m.my_encoded_str)\n#&gt; some str\n\n# Serialize into the encoded form\nprint(m.model_dump())\n\"\"\"\n{\n    'my_encoded_bytes': b'**encoded**: some bytes',\n    'my_encoded_str': '**encoded**: some str',\n}\n\"\"\"\n\n# Validate encoded data\ntry:\n    Model(my_encoded_bytes=b'**undecodable**')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    my_encoded_bytes\n      Value error, Cannot decode data [type=value_error, input_value=b'**undecodable**', input_type=bytes]\n    \"\"\"\n</code></pre> <pre><code>from typing import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    EncodedBytes,\n    EncodedStr,\n    EncoderProtocol,\n    ValidationError,\n)\n\n\nclass MyEncoder(EncoderProtocol):\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        if data == b'**undecodable**':\n            raise ValueError('Cannot decode data')\n        return data[13:]\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        return b'**encoded**: ' + value\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        return 'my-encoder'\n\n\nMyEncodedBytes = Annotated[bytes, EncodedBytes(encoder=MyEncoder)]\nMyEncodedStr = Annotated[str, EncodedStr(encoder=MyEncoder)]\n\n\nclass Model(BaseModel):\n    my_encoded_bytes: MyEncodedBytes\n    my_encoded_str: MyEncodedStr | None = None\n\n\n# Initialize the model with encoded data\nm = Model(\n    my_encoded_bytes=b'**encoded**: some bytes', my_encoded_str='**encoded**: some str'\n)\n\n# Access decoded value\nprint(m.my_encoded_bytes)\n#&gt; b'some bytes'\nprint(m.my_encoded_str)\n#&gt; some str\n\n# Serialize into the encoded form\nprint(m.model_dump())\n\"\"\"\n{\n    'my_encoded_bytes': b'**encoded**: some bytes',\n    'my_encoded_str': '**encoded**: some str',\n}\n\"\"\"\n\n# Validate encoded data\ntry:\n    Model(my_encoded_bytes=b'**undecodable**')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    my_encoded_bytes\n      Value error, Cannot decode data [type=value_error, input_value=b'**undecodable**', input_type=bytes]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/encoded/#base64-encoding-support","title":"Base64 encoding support","text":"<p>Internally, pydantic uses the <code>pydantic.types.EncodedBytes</code> and <code>pydantic.types.EncodedStr</code> annotations with <code>pydantic.types.Base64Encoder</code> to implement base64 encoding/decoding in the <code>Base64Bytes</code> and <code>Base64Str</code> types, respectively.</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Optional\n\nfrom pydantic import Base64Bytes, Base64Str, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    base64_bytes: Base64Bytes\n    base64_str: Optional[Base64Str] = None\n\n\n# Initialize the model with base64 data\nm = Model(\n    base64_bytes=b'VGhpcyBpcyB0aGUgd2F5',\n    base64_str='VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y',\n)\n\n# Access decoded value\nprint(m.base64_bytes)\n#&gt; b'This is the way'\nprint(m.base64_str)\n#&gt; These aren't the droids you're looking for\n\n# Serialize into the base64 form\nprint(m.model_dump())\n\"\"\"\n{\n    'base64_bytes': b'VGhpcyBpcyB0aGUgd2F5\\n',\n    'base64_str': 'VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y\\n',\n}\n\"\"\"\n\n# Validate base64 data\ntry:\n    print(Model(base64_bytes=b'undecodable').base64_bytes)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    base64_bytes\n      Base64 decoding error: 'Incorrect padding' [type=base64_decode, input_value=b'undecodable', input_type=bytes]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import Base64Bytes, Base64Str, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    base64_bytes: Base64Bytes\n    base64_str: Base64Str | None = None\n\n\n# Initialize the model with base64 data\nm = Model(\n    base64_bytes=b'VGhpcyBpcyB0aGUgd2F5',\n    base64_str='VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y',\n)\n\n# Access decoded value\nprint(m.base64_bytes)\n#&gt; b'This is the way'\nprint(m.base64_str)\n#&gt; These aren't the droids you're looking for\n\n# Serialize into the base64 form\nprint(m.model_dump())\n\"\"\"\n{\n    'base64_bytes': b'VGhpcyBpcyB0aGUgd2F5\\n',\n    'base64_str': 'VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y\\n',\n}\n\"\"\"\n\n# Validate base64 data\ntry:\n    print(Model(base64_bytes=b'undecodable').base64_bytes)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    base64_bytes\n      Base64 decoding error: 'Incorrect padding' [type=base64_decode, input_value=b'undecodable', input_type=bytes]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/enums/","title":"Enums and Choices","text":"<p>Pydantic uses Python's standard <code>enum</code> classes to define choices.</p> <code>enum.Enum</code> checks that the value is a valid Enum instance <code>subclass of enum.Enum</code> checks that the value is a valid member of the enum <code>enum.IntEnum</code> checks that the value is a valid IntEnum instance <code>subclass of enum.IntEnum</code> checks that the value is a valid member of the integer enum <pre><code>from enum import Enum, IntEnum\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass FruitEnum(str, Enum):\n    pear = 'pear'\n    banana = 'banana'\n\n\nclass ToolEnum(IntEnum):\n    spanner = 1\n    wrench = 2\n\n\nclass CookingModel(BaseModel):\n    fruit: FruitEnum = FruitEnum.pear\n    tool: ToolEnum = ToolEnum.spanner\n\n\nprint(CookingModel())\n#&gt; fruit=&lt;FruitEnum.pear: 'pear'&gt; tool=&lt;ToolEnum.spanner: 1&gt;\nprint(CookingModel(tool=2, fruit='banana'))\n#&gt; fruit=&lt;FruitEnum.banana: 'banana'&gt; tool=&lt;ToolEnum.wrench: 2&gt;\ntry:\n    CookingModel(fruit='other')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for CookingModel\n    fruit\n      Input should be 'pear' or 'banana' [type=enum, input_value='other', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/file_types/","title":"File Types","text":"<code>FilePath</code> like <code>Path</code>, but the path must exist and be a file <code>DirectoryPath</code> like <code>Path</code>, but the path must exist and be a directory"},{"location":"usage/types/json/","title":"JSON","text":"<code>Json</code> a special type wrapper which loads JSON before parsing <p>You can use <code>Json</code> data type to make Pydantic first load a raw JSON string. It can also optionally be used to parse the loaded object into another type base on the type <code>Json</code> is parameterised with:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Any, List\n\nfrom pydantic import BaseModel, Json, ValidationError\n\n\nclass AnyJsonModel(BaseModel):\n    json_obj: Json[Any]\n\n\nclass ConstrainedJsonModel(BaseModel):\n    json_obj: Json[List[int]]\n\n\nprint(AnyJsonModel(json_obj='{\"b\": 1}'))\n#&gt; json_obj={'b': 1}\nprint(ConstrainedJsonModel(json_obj='[1, 2, 3]'))\n#&gt; json_obj=[1, 2, 3]\ntry:\n    ConstrainedJsonModel(json_obj=12)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      JSON input should be string, bytes or bytearray [type=json_type, input_value=12, input_type=int]\n    \"\"\"\n\ntry:\n    ConstrainedJsonModel(json_obj='[a, b]')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      Invalid JSON: expected value at line 1 column 2 [type=json_invalid, input_value='[a, b]', input_type=str]\n    \"\"\"\n\ntry:\n    ConstrainedJsonModel(json_obj='[\"a\", \"b\"]')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for ConstrainedJsonModel\n    json_obj.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    json_obj.1\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='b', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, Json, ValidationError\n\n\nclass AnyJsonModel(BaseModel):\n    json_obj: Json[Any]\n\n\nclass ConstrainedJsonModel(BaseModel):\n    json_obj: Json[list[int]]\n\n\nprint(AnyJsonModel(json_obj='{\"b\": 1}'))\n#&gt; json_obj={'b': 1}\nprint(ConstrainedJsonModel(json_obj='[1, 2, 3]'))\n#&gt; json_obj=[1, 2, 3]\ntry:\n    ConstrainedJsonModel(json_obj=12)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      JSON input should be string, bytes or bytearray [type=json_type, input_value=12, input_type=int]\n    \"\"\"\n\ntry:\n    ConstrainedJsonModel(json_obj='[a, b]')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      Invalid JSON: expected value at line 1 column 2 [type=json_invalid, input_value='[a, b]', input_type=str]\n    \"\"\"\n\ntry:\n    ConstrainedJsonModel(json_obj='[\"a\", \"b\"]')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for ConstrainedJsonModel\n    json_obj.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    json_obj.1\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='b', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/list_types/","title":"Lists and Tuples","text":"<code>list</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a list;   see <code>typing.List</code> below for sub-type constraints <code>tuple</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a tuple;   see <code>typing.Tuple</code> below for sub-type constraints <code>typing.List</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Tuple</code> see Typing Iterables below for more detail on parsing and validation <code>subclass of typing.NamedTuple</code> Same as <code>tuple</code> but instantiates with the given namedtuple and validates fields since they are annotated.   See Annotated Types below for more detail on parsing and validation <code>subclass of collections.namedtuple</code> Same as <code>subclass of typing.NamedTuple</code> but all fields will have type <code>Any</code> since they are not annotated"},{"location":"usage/types/list_types/#typing-iterables","title":"Typing Iterables","text":"<p>Pydantic uses standard library <code>typing</code> types as defined in PEP 484 to define complex objects.</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Deque, Dict, FrozenSet, List, Optional, Sequence, Set, Tuple, Union\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: List[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: Tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: Dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: Set[bytes] = None\n    frozen_set: FrozenSet[int] = None\n\n    str_or_bytes: Union[str, bytes] = None\n    none_or_str: Optional[str] = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: Dict[Union[str, bytes], List[Set[int]]] = None\n\n    deque: Deque[int] = None\n</code></pre> <pre><code>from typing import Deque, Optional, Union\nfrom collections.abc import Sequence\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: list[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: set[bytes] = None\n    frozen_set: frozenset[int] = None\n\n    str_or_bytes: Union[str, bytes] = None\n    none_or_str: Optional[str] = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: dict[Union[str, bytes], list[set[int]]] = None\n\n    deque: Deque[int] = None\n</code></pre> <pre><code>from typing import Deque\nfrom collections.abc import Sequence\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: list[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: set[bytes] = None\n    frozen_set: frozenset[int] = None\n\n    str_or_bytes: str | bytes = None\n    none_or_str: str | None = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: dict[str | bytes, list[set[int]]] = None\n\n    deque: Deque[int] = None\n</code></pre>"},{"location":"usage/types/list_types/#namedtuple","title":"NamedTuple","text":"<pre><code>from typing import NamedTuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\n\nclass Model(BaseModel):\n    p: Point\n\n\ntry:\n    Model(p=('1.3', '2'))\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    p.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='1.3', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/number_types/","title":"Number Types","text":"<code>int</code> Pydantic uses <code>int(v)</code> to coerce types to an <code>int</code>;   see this warning on loss of information during data conversion <code>float</code> similarly, <code>float(v)</code> is used to coerce values to floats <code>enum.IntEnum</code> checks that the value is a valid IntEnum instance <code>subclass of enum.IntEnum</code> checks that the value is a valid member of the integer enum;   see Enums and Choices for more details <code>decimal.Decimal</code> Pydantic attempts to convert the value to a string, then passes the string to <code>Decimal(v)</code> <code>NegativeFloat</code> allows a float which is negative; uses standard <code>float</code> parsing then checks the value is less than 0;   see Constrained Types <code>NegativeInt</code> allows an int which is negative; uses standard <code>int</code> parsing then checks the value is less than 0;   see Constrained Types <code>PositiveFloat</code> allows a float which is positive; uses standard <code>float</code> parsing then checks the value is greater than 0;   see Constrained Types <code>PositiveInt</code> allows an int which is positive; uses standard <code>int</code> parsing then checks the value is greater than 0;   see Constrained Types <code>condecimal</code> type method for constraining Decimals;   see Constrained Types <code>confloat</code> type method for constraining floats;   see Constrained Types <code>conint</code> type method for constraining ints;   see Constrained Types"},{"location":"usage/types/number_types/#constrained-types","title":"Constrained Types","text":"<p>The value of numerous common types can be restricted using <code>con*</code> type functions:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, condecimal, confloat, conint\n\n\nclass Model(BaseModel):\n    big_int: conint(gt=1000, lt=1024)\n    mod_int: conint(multiple_of=5)\n    big_float: confloat(gt=1000, lt=1024)\n    unit_interval: confloat(ge=0, le=1)\n    mod_float: confloat(multiple_of=0.5)\n    decimal_positive: condecimal(gt=0)\n    decimal_negative: condecimal(lt=0)\n    decimal_max_digits_and_places: condecimal(max_digits=2, decimal_places=2)\n    mod_decimal: condecimal(multiple_of=Decimal('0.25'))\n</code></pre> <p>Where <code>Field</code> refers to the field function.</p>"},{"location":"usage/types/number_types/#arguments-to-conint","title":"Arguments to <code>conint</code>","text":"<p>The following arguments are available when using the <code>conint</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: int = None</code>: enforces integer to be greater than the set value</li> <li><code>ge: int = None</code>: enforces integer to be greater than or equal to the set value</li> <li><code>lt: int = None</code>: enforces integer to be less than the set value</li> <li><code>le: int = None</code>: enforces integer to be less than or equal to the set value</li> <li><code>multiple_of: int = None</code>: enforces integer to be a multiple of the set value</li> </ul>"},{"location":"usage/types/number_types/#arguments-to-confloat","title":"Arguments to <code>confloat</code>","text":"<p>The following arguments are available when using the <code>confloat</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: float = None</code>: enforces float to be greater than the set value</li> <li><code>ge: float = None</code>: enforces float to be greater than or equal to the set value</li> <li><code>lt: float = None</code>: enforces float to be less than the set value</li> <li><code>le: float = None</code>: enforces float to be less than or equal to the set value</li> <li><code>multiple_of: float = None</code>: enforces float to be a multiple of the set value</li> <li><code>allow_inf_nan: bool = True</code>: whether to allows infinity (<code>+inf</code> an <code>-inf</code>) and NaN values, defaults to <code>True</code>,   set to <code>False</code> for compatibility with <code>JSON</code>,   see #3994 for more details, added in V1.10</li> </ul>"},{"location":"usage/types/number_types/#arguments-to-condecimal","title":"Arguments to <code>condecimal</code>","text":"<p>The following arguments are available when using the <code>condecimal</code> type function</p> <ul> <li><code>gt: Decimal = None</code>: enforces decimal to be greater than the set value</li> <li><code>ge: Decimal = None</code>: enforces decimal to be greater than or equal to the set value</li> <li><code>lt: Decimal = None</code>: enforces decimal to be less than the set value</li> <li><code>le: Decimal = None</code>: enforces decimal to be less than or equal to the set value</li> <li><code>max_digits: int = None</code>: maximum number of digits within the decimal. it does not include a zero before the decimal point or trailing decimal zeroes</li> <li><code>decimal_places: int = None</code>: max number of decimal places allowed. it does not include trailing decimal zeroes</li> <li><code>multiple_of: Decimal = None</code>: enforces decimal to be a multiple of the set value</li> </ul>"},{"location":"usage/types/number_types/#strict-types","title":"Strict Types","text":"<p>You can use the <code>StrictStr</code>, <code>StrictBytes</code>, <code>StrictInt</code>, <code>StrictFloat</code>, and <code>StrictBool</code> types to prevent coercion from compatible types. These types will only pass validation when the validated value is of the respective type or is a subtype of that type. This behavior is also exposed via the <code>strict</code> field of the <code>ConstrainedStr</code>, <code>ConstrainedBytes</code>, <code>ConstrainedFloat</code> and <code>ConstrainedInt</code> classes and can be combined with a multitude of complex validation rules.</p> <p>The following caveats apply:</p> <ul> <li><code>StrictBytes</code> (and the <code>strict</code> option of <code>ConstrainedBytes</code>) will accept both <code>bytes</code>,    and <code>bytearray</code> types.</li> <li><code>StrictInt</code> (and the <code>strict</code> option of <code>ConstrainedInt</code>) will not accept <code>bool</code> types,     even though <code>bool</code> is a subclass of <code>int</code> in Python. Other subclasses will work.</li> <li><code>StrictFloat</code> (and the <code>strict</code> option of <code>ConstrainedFloat</code>) will not accept <code>int</code>.</li> </ul> <pre><code>from pydantic import BaseModel, StrictInt, ValidationError\n\n\nclass StrictIntModel(BaseModel):\n    strict_int: StrictInt\n\n\ntry:\n    StrictIntModel(strict_int=3.14159)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for StrictIntModel\n    strict_int\n      Input should be a valid integer [type=int_type, input_value=3.14159, input_type=float]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/secrets/","title":"Secret Types","text":"<code>SecretBytes</code> bytes where the value is kept partially secret <code>SecretStr</code> string where the value is kept partially secret <p>You can use the <code>SecretStr</code> and the <code>SecretBytes</code> data types for storing sensitive information that you do not want to be visible in logging or tracebacks. <code>SecretStr</code> and <code>SecretBytes</code> can be initialized idempotently or by using <code>str</code> or <code>bytes</code> literals respectively. The <code>SecretStr</code> and <code>SecretBytes</code> will be formatted as either <code>'**********'</code> or <code>''</code> on conversion to json.</p> <pre><code>from pydantic import (\n    BaseModel,\n    SecretBytes,\n    SecretStr,\n    ValidationError,\n    field_serializer,\n)\n\n\nclass SimpleModel(BaseModel):\n    password: SecretStr\n    password_bytes: SecretBytes\n\n\nsm = SimpleModel(password='IAmSensitive', password_bytes=b'IAmSensitiveBytes')\n\n# Standard access methods will not display the secret\nprint(sm)\n#&gt; password=SecretStr('**********') password_bytes=SecretBytes(b'**********')\nprint(sm.password)\n#&gt; **********\nprint(sm.model_dump())\n#&gt; {'password': SecretStr('**********'), 'password_bytes': SecretBytes(b'**********')}\nprint(sm.model_dump_json())\n#&gt; {\"password\":\"**********\",\"password_bytes\":\"**********\"}\n\n# Use get_secret_value method to see the secret's content.\nprint(sm.password.get_secret_value())\n#&gt; IAmSensitive\nprint(sm.password_bytes.get_secret_value())\n#&gt; b'IAmSensitiveBytes'\n\ntry:\n    SimpleModel(password=[1, 2, 3], password_bytes=[1, 2, 3])\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    2 validation errors for SimpleModel\n    password\n      Input should be a valid string [type=string_type, input_value=[1, 2, 3], input_type=list]\n    password_bytes\n      Input should be a valid bytes [type=bytes_type, input_value=[1, 2, 3], input_type=list]\n    \"\"\"\n\n\n# If you want the secret to be dumped as plain-text using the json method,\n# you can use a serializer\nclass SimpleModelDumpable(BaseModel):\n    password: SecretStr\n    password_bytes: SecretBytes\n\n    @field_serializer('password', 'password_bytes', when_used='json')\n    def dump_secret(self, v):\n        return v.get_secret_value()\n\n\nsm2 = SimpleModelDumpable(password='IAmSensitive', password_bytes=b'IAmSensitiveBytes')\n\n# Standard access methods will not display the secret\nprint(sm2)\n#&gt; password=SecretStr('**********') password_bytes=SecretBytes(b'**********')\nprint(sm2.password)\n#&gt; **********\nprint(sm2.model_dump())\n#&gt; {'password': SecretStr('**********'), 'password_bytes': SecretBytes(b'**********')}\n\n# But the json method will\nprint(sm2.model_dump_json())\n#&gt; {\"password\":\"IAmSensitive\",\"password_bytes\":\"IAmSensitiveBytes\"}\n</code></pre>"},{"location":"usage/types/sequence_iterable/","title":"Sequence, Iterable, & Iterator","text":"<code>typing.Sequence</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Iterable</code> this is reserved for iterables that shouldn't be consumed. See Infinite Generators below for more detail on parsing and validation <p>Pydantic uses standard library <code>typing</code> types as defined in PEP 484 to define complex objects.</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Deque, Dict, FrozenSet, List, Optional, Sequence, Set, Tuple, Union\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: List[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: Tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: Dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: Set[bytes] = None\n    frozen_set: FrozenSet[int] = None\n\n    str_or_bytes: Union[str, bytes] = None\n    none_or_str: Optional[str] = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: Dict[Union[str, bytes], List[Set[int]]] = None\n\n    deque: Deque[int] = None\n\n\nprint(Model(simple_list=['1', '2', '3']).simple_list)\n#&gt; ['1', '2', '3']\nprint(Model(list_of_ints=['1', '2', '3']).list_of_ints)\n#&gt; [1, 2, 3]\n\nprint(Model(simple_dict={'a': 1, b'b': 2}).simple_dict)\n#&gt; {'a': 1, b'b': 2}\nprint(Model(dict_str_float={'a': 1, b'b': 2}).dict_str_float)\n#&gt; {'a': 1.0, 'b': 2.0}\n\nprint(Model(simple_tuple=[1, 2, 3, 4]).simple_tuple)\n#&gt; (1, 2, 3, 4)\nprint(Model(tuple_of_different_types=[4, 3, '2', 1]).tuple_of_different_types)\n#&gt; (4, 3.0, '2', True)\n\nprint(Model(sequence_of_ints=[1, 2, 3, 4]).sequence_of_ints)\n#&gt; [1, 2, 3, 4]\nprint(Model(sequence_of_ints=(1, 2, 3, 4)).sequence_of_ints)\n#&gt; (1, 2, 3, 4)\n\nprint(Model(deque=[1, 2, 3]).deque)\n#&gt; deque([1, 2, 3])\n</code></pre> <pre><code>from typing import Deque, Optional, Union\nfrom collections.abc import Sequence\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: list[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: set[bytes] = None\n    frozen_set: frozenset[int] = None\n\n    str_or_bytes: Union[str, bytes] = None\n    none_or_str: Optional[str] = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: dict[Union[str, bytes], list[set[int]]] = None\n\n    deque: Deque[int] = None\n\n\nprint(Model(simple_list=['1', '2', '3']).simple_list)\n#&gt; ['1', '2', '3']\nprint(Model(list_of_ints=['1', '2', '3']).list_of_ints)\n#&gt; [1, 2, 3]\n\nprint(Model(simple_dict={'a': 1, b'b': 2}).simple_dict)\n#&gt; {'a': 1, b'b': 2}\nprint(Model(dict_str_float={'a': 1, b'b': 2}).dict_str_float)\n#&gt; {'a': 1.0, 'b': 2.0}\n\nprint(Model(simple_tuple=[1, 2, 3, 4]).simple_tuple)\n#&gt; (1, 2, 3, 4)\nprint(Model(tuple_of_different_types=[4, 3, '2', 1]).tuple_of_different_types)\n#&gt; (4, 3.0, '2', True)\n\nprint(Model(sequence_of_ints=[1, 2, 3, 4]).sequence_of_ints)\n#&gt; [1, 2, 3, 4]\nprint(Model(sequence_of_ints=(1, 2, 3, 4)).sequence_of_ints)\n#&gt; (1, 2, 3, 4)\n\nprint(Model(deque=[1, 2, 3]).deque)\n#&gt; deque([1, 2, 3])\n</code></pre> <pre><code>from typing import Deque\nfrom collections.abc import Sequence\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: list = None\n    list_of_ints: list[int] = None\n\n    simple_tuple: tuple = None\n    tuple_of_different_types: tuple[int, float, str, bool] = None\n\n    simple_dict: dict = None\n    dict_str_float: dict[str, float] = None\n\n    simple_set: set = None\n    set_bytes: set[bytes] = None\n    frozen_set: frozenset[int] = None\n\n    str_or_bytes: str | bytes = None\n    none_or_str: str | None = None\n\n    sequence_of_ints: Sequence[int] = None\n\n    compound: dict[str | bytes, list[set[int]]] = None\n\n    deque: Deque[int] = None\n\n\nprint(Model(simple_list=['1', '2', '3']).simple_list)\n#&gt; ['1', '2', '3']\nprint(Model(list_of_ints=['1', '2', '3']).list_of_ints)\n#&gt; [1, 2, 3]\n\nprint(Model(simple_dict={'a': 1, b'b': 2}).simple_dict)\n#&gt; {'a': 1, b'b': 2}\nprint(Model(dict_str_float={'a': 1, b'b': 2}).dict_str_float)\n#&gt; {'a': 1.0, 'b': 2.0}\n\nprint(Model(simple_tuple=[1, 2, 3, 4]).simple_tuple)\n#&gt; (1, 2, 3, 4)\nprint(Model(tuple_of_different_types=[4, 3, '2', 1]).tuple_of_different_types)\n#&gt; (4, 3.0, '2', True)\n\nprint(Model(sequence_of_ints=[1, 2, 3, 4]).sequence_of_ints)\n#&gt; [1, 2, 3, 4]\nprint(Model(sequence_of_ints=(1, 2, 3, 4)).sequence_of_ints)\n#&gt; (1, 2, 3, 4)\n\nprint(Model(deque=[1, 2, 3]).deque)\n#&gt; deque([1, 2, 3])\n</code></pre>"},{"location":"usage/types/sequence_iterable/#strings-arent-sequences","title":"Strings aren't Sequences","text":"<p>Pydantic doesn't treat strings, i.e. <code>str</code> and <code>bytes</code> subclasses, as sequences:</p> Python 3.7 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import Optional, Sequence\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    sequence_of_strs: Optional[Sequence[str]] = None\n    sequence_of_bytes: Optional[Sequence[bytes]] = None\n\n\nprint(Model(sequence_of_strs=['a', 'bc']).sequence_of_strs)\n#&gt; ['a', 'bc']\nprint(Model(sequence_of_strs=('a', 'bc')).sequence_of_strs)\n#&gt; ('a', 'bc')\nprint(Model(sequence_of_bytes=[b'a', b'bc']).sequence_of_bytes)\n#&gt; [b'a', b'bc']\nprint(Model(sequence_of_bytes=(b'a', b'bc')).sequence_of_bytes)\n#&gt; (b'a', b'bc')\n\n\ntry:\n    Model(sequence_of_strs='abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_strs\n      'str' instances are not allowed as a Sequence value [type=sequence_str, input_value='abc', input_type=str]\n    \"\"\"\ntry:\n    Model(sequence_of_bytes=b'abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_bytes\n      'bytes' instances are not allowed as a Sequence value [type=sequence_str, input_value=b'abc', input_type=bytes]\n    \"\"\"\n</code></pre> <pre><code>from typing import Optional\nfrom collections.abc import Sequence\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    sequence_of_strs: Optional[Sequence[str]] = None\n    sequence_of_bytes: Optional[Sequence[bytes]] = None\n\n\nprint(Model(sequence_of_strs=['a', 'bc']).sequence_of_strs)\n#&gt; ['a', 'bc']\nprint(Model(sequence_of_strs=('a', 'bc')).sequence_of_strs)\n#&gt; ('a', 'bc')\nprint(Model(sequence_of_bytes=[b'a', b'bc']).sequence_of_bytes)\n#&gt; [b'a', b'bc']\nprint(Model(sequence_of_bytes=(b'a', b'bc')).sequence_of_bytes)\n#&gt; (b'a', b'bc')\n\n\ntry:\n    Model(sequence_of_strs='abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_strs\n      'str' instances are not allowed as a Sequence value [type=sequence_str, input_value='abc', input_type=str]\n    \"\"\"\ntry:\n    Model(sequence_of_bytes=b'abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_bytes\n      'bytes' instances are not allowed as a Sequence value [type=sequence_str, input_value=b'abc', input_type=bytes]\n    \"\"\"\n</code></pre> <pre><code>from collections.abc import Sequence\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    sequence_of_strs: Sequence[str] | None = None\n    sequence_of_bytes: Sequence[bytes] | None = None\n\n\nprint(Model(sequence_of_strs=['a', 'bc']).sequence_of_strs)\n#&gt; ['a', 'bc']\nprint(Model(sequence_of_strs=('a', 'bc')).sequence_of_strs)\n#&gt; ('a', 'bc')\nprint(Model(sequence_of_bytes=[b'a', b'bc']).sequence_of_bytes)\n#&gt; [b'a', b'bc']\nprint(Model(sequence_of_bytes=(b'a', b'bc')).sequence_of_bytes)\n#&gt; (b'a', b'bc')\n\n\ntry:\n    Model(sequence_of_strs='abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_strs\n      'str' instances are not allowed as a Sequence value [type=sequence_str, input_value='abc', input_type=str]\n    \"\"\"\ntry:\n    Model(sequence_of_bytes=b'abc')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    sequence_of_bytes\n      'bytes' instances are not allowed as a Sequence value [type=sequence_str, input_value=b'abc', input_type=bytes]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/sequence_iterable/#infinite-generators","title":"Infinite Generators","text":"<p>If you have a generator you can use <code>Sequence</code> as described above. In that case, the generator will be consumed and stored on the model as a list and its values will be validated with the sub-type of <code>Sequence</code> (e.g. <code>int</code> in <code>Sequence[int]</code>).</p> <p>But if you have a generator that you don't want to be consumed, e.g. an infinite generator or a remote data loader, you can define its type with <code>Iterable</code>:</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    infinite: Iterable[int]\n\n\ndef infinite_ints():\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n\nm = Model(infinite=infinite_ints())\nprint(m)\n\"\"\"\ninfinite=ValidatorIterator(index=0, schema=Some(Int(IntValidator { strict: false })))\n\"\"\"\n\nfor i in m.infinite:\n    print(i)\n    #&gt; 0\n    #&gt; 1\n    #&gt; 2\n    #&gt; 3\n    #&gt; 4\n    #&gt; 5\n    #&gt; 6\n    #&gt; 7\n    #&gt; 8\n    #&gt; 9\n    #&gt; 10\n    if i == 10:\n        break\n</code></pre> <pre><code>from collections.abc import Iterable\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    infinite: Iterable[int]\n\n\ndef infinite_ints():\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n\nm = Model(infinite=infinite_ints())\nprint(m)\n\"\"\"\ninfinite=ValidatorIterator(index=0, schema=Some(Int(IntValidator { strict: false })))\n\"\"\"\n\nfor i in m.infinite:\n    print(i)\n    #&gt; 0\n    #&gt; 1\n    #&gt; 2\n    #&gt; 3\n    #&gt; 4\n    #&gt; 5\n    #&gt; 6\n    #&gt; 7\n    #&gt; 8\n    #&gt; 9\n    #&gt; 10\n    if i == 10:\n        break\n</code></pre> <p>Warning</p> <p><code>Iterable</code> fields only perform a simple check that the argument is iterable and won't be consumed.</p> <p>No validation of their values is performed as it cannot be done without consuming the iterable.</p> <p>Tip</p> <p>If you want to validate the values of an infinite generator you can create a separate model and use it while consuming the generator, reporting the validation errors as appropriate.</p> <p>pydantic can't validate the values automatically for you because it would require consuming the infinite generator.</p>"},{"location":"usage/types/sequence_iterable/#validating-the-first-value","title":"Validating the first value","text":"<p>You can create a validator to validate the first value in an infinite generator and still not consume it entirely.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    infinite: Iterable[int]\n\n    @field_validator('infinite', mode='wrap')\n    def infinite_first_int(cls, iterable, handler):\n        first_value = next(iterable)\n        if isinstance(first_value, int):\n            yield first_value\n        else:\n            raise ValueError(f'first value must be an int, not {type(first_value)}')\n\n        yield from handler(iterable)\n\n\ndef infinite_ints():\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n\nm = Model(infinite=infinite_ints())\nprint(next(m.infinite))\n#&gt; 0\nprint(next(m.infinite))\n#&gt; 1\nprint(next(m.infinite))\n#&gt; 2\n\n\ndef infinite_strs():\n    while True:\n        yield from '123'\n\n\nm = Model(infinite=infinite_strs())\ntry:\n    next(m.infinite)\nexcept ValueError as e:\n    print(e)\n    #&gt; first value must be an int, not &lt;class 'str'&gt;\n</code></pre> <pre><code>from collections.abc import Iterable\n\nfrom pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    infinite: Iterable[int]\n\n    @field_validator('infinite', mode='wrap')\n    def infinite_first_int(cls, iterable, handler):\n        first_value = next(iterable)\n        if isinstance(first_value, int):\n            yield first_value\n        else:\n            raise ValueError(f'first value must be an int, not {type(first_value)}')\n\n        yield from handler(iterable)\n\n\ndef infinite_ints():\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n\nm = Model(infinite=infinite_ints())\nprint(next(m.infinite))\n#&gt; 0\nprint(next(m.infinite))\n#&gt; 1\nprint(next(m.infinite))\n#&gt; 2\n\n\ndef infinite_strs():\n    while True:\n        yield from '123'\n\n\nm = Model(infinite=infinite_strs())\ntry:\n    next(m.infinite)\nexcept ValueError as e:\n    print(e)\n    #&gt; first value must be an int, not &lt;class 'str'&gt;\n</code></pre>"},{"location":"usage/types/set_types/","title":"Sets and frozenset","text":"<code>set</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a set;   see <code>typing.Set</code> below for sub-type constraints <code>frozenset</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a frozen set;   see <code>typing.FrozenSet</code> below for sub-type constraints <code>deque</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a deque;   see <code>typing.Deque</code> below for sub-type constraints <code>typing.Set</code> see Typing Iterables below for more detail on parsing and validation <code>typing.FrozenSet</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Deque</code> see Typing Iterables below for more detail on parsing and validation"},{"location":"usage/types/set_types/#constrained-types","title":"Constrained Types","text":"<p>The value of numerous common types can be restricted using <code>con*</code> type functions:</p> <code>conset</code> type method for constraining sets;   see Constrained Types <code>confrozenset</code> type method for constraining frozen sets;   see Constrained Types"},{"location":"usage/types/set_types/#arguments-to-conset","title":"Arguments to <code>conset</code>","text":"<p>The following arguments are available when using the <code>conset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the set items</li> <li><code>min_items: int = None</code>: minimum number of items in the set</li> <li><code>max_items: int = None</code>: maximum number of items in the set</li> </ul>"},{"location":"usage/types/set_types/#arguments-to-confrozenset","title":"Arguments to <code>confrozenset</code>","text":"<p>The following arguments are available when using the <code>confrozenset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the frozenset items</li> <li><code>min_items: int = None</code>: minimum number of items in the frozenset</li> <li><code>max_items: int = None</code>: maximum number of items in the frozenset</li> </ul>"},{"location":"usage/types/standard_types/","title":"Standard Library Types","text":"<p>Pydantic supports many common types from the Python standard library. If you need stricter processing see Strict types. If you need to constrain the values allowed (e.g. to require a positive <code>int</code>) see Constrained types.</p> Type Description <code>None</code>, <code>type(None)</code>, or <code>Literal[None]</code> Equivalent according to PEP 484. Allows only <code>None</code> value. <code>bool</code> See Booleans for details on how bools are validated and what values are permitted. <code>int</code> Pydantic uses <code>int(v)</code> to coerce types to an <code>int</code>. See the Data Conversion warning on loss of information during data conversion. <code>float</code> <code>float(v)</code> is used to coerce values to floats. <code>str</code> Strings are accepted as-is. <code>int</code> <code>float</code> and <code>Decimal</code> are coerced using <code>str(v)</code>. <code>bytes</code> and <code>bytearray</code> are converted using <code>v.decode()</code>. <code>Enum</code>s inheriting from <code>str</code> are converted using <code>v.value</code>. All other types cause an error. <code>bytes</code> <code>bytes</code> are accepted as-is. <code>bytearray</code> is converted using <code>bytes(v)</code>. <code>str</code> are converted using <code>v.encode()</code>. <code>int</code>, <code>float</code>, and <code>Decimal</code> are coerced using <code>str(v).encode()</code>. <code>list</code> Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a list. See <code>typing.List</code> for sub-type constraints. <code>tuple</code> Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a tuple. See <code>typing.Tuple</code> for sub-type constraints. <code>dict</code> <code>dict(v)</code> is used to attempt to convert a dictionary. See <code>typing.Dict</code> for sub-type constraints. <code>set</code> Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a set. See <code>typing.Set</code> below for sub-type constraints. <code>frozenset</code> Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a frozen set. See <code>typing.FrozenSet</code> below for sub-type constraints. <code>deque</code> Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a deque. See <code>typing.Deque</code> below for sub-type constraints. <code>datetime.date</code> See Datetime Types  for more detail on parsing and validation. <code>datetime.time</code> See Datetime Types  for more detail on parsing and validation. <code>datetime.datetime</code> See Datetime Types  for more detail on parsing and validation. <code>datetime.timedelta</code> See Datetime Types  for more detail on parsing and validation. <code>typing.Any</code> Allows any value including <code>None</code>, thus an <code>Any</code> field is optional. <code>typing.Annotated</code> Allows wrapping another type with arbitrary metadata, as per PEP-593. The <code>Annotated</code> hint may contain a single call to the [<code>Field</code> function]../schema.md#typingannotated-fields), but otherwise the additional metadata is ignored and the root type is used. <code>typing.TypeVar</code> Constrains the values allowed based on <code>constraints</code> or <code>bound</code>, see TypeVar. <code>typing.Union</code> See Unions for more detail on parsing and validation. <code>typing.Optional</code> <code>Optional[x]</code> is simply short hand for <code>Union[x, None]</code>. See Unions below for more detail on parsing and validation and Required Fields for details about required fields that can receive <code>None</code> as a value. <code>typing.List</code> See Lists and Tuples for more detail on parsing and validation. <code>typing.Tuple</code> See Lists and Tuples for more detail on parsing and validation. Subclass of <code>typing.NamedTuple</code> Same as <code>tuple</code>, but instantiates with the given namedtuple and validates fields since they are annotated. Subclass of <code>collections.namedtuple</code> Same as subclass of <code>typing.NamedTuple</code>, but all fields will have type <code>Any</code> since they are not annotated. <code>typing.Dict</code> See Dicts and mapping for more detail on parsing and validation. Subclass of <code>typing.TypedDict</code> Same as <code>dict</code>, but Pydantic will validate the dictionary since keys are annotated. <code>typing.Set</code> See Sets and frozenset for more detail on parsing and validation. <code>typing.FrozenSet</code> See Sets and frozenset for more detail on parsing and validation. <code>typing.Deque</code> See Sequence, Iterable &amp; Iterator for more detail on parsing and validation. <code>typing.Sequence</code> See Sequence, Iterable &amp; Iterator for more detail on parsing and validation. <code>typing.Iterable</code> This is reserved for iterables that shouldn't be consumed. See Sequence, Iterable &amp; Iterator for more detail on parsing and validation. <code>typing.Type</code> See Type and Typevars for more detail on parsing and validation. <code>typing.Callable</code> See Callables below for more detail on parsing and validation. <code>typing.Pattern</code> Will cause the input value to be passed to <code>re.compile(v)</code> to create a regex pattern. <code>ipaddress.IPv4Address</code> Simply uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>. See URLs for other custom IP address types. <code>ipaddress.IPv4Interface</code> Simply uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>. See URLs for other custom IP address types. <code>ipaddress.IPv4Network</code> Simply uses the type itself for validation by passing the value to <code>IPv4Network(v)</code>. See URLs for other custom IP address types. <code>ipaddress.IPv6Address</code> Simply uses the type itself for validation by passing the value to <code>IPv6Address(v)</code>. See URLs for other custom IP address types. <code>ipaddress.IPv6Interface</code> Simply uses the type itself for validation by passing the value to <code>IPv6Interface(v)</code>. See URLs for other custom IP address types. <code>ipaddress.IPv6Network</code> Simply uses the type itself for validation by passing the value to <code>IPv6Network(v)</code>. See URLs for other custom IP address types. <code>enum.Enum</code> Checks that the value is a valid <code>Enum</code> instance. Subclass of <code>enum.Enum</code> Checks that the value is a valid member of the <code>enum</code>. See Enums and Choices for more details. <code>enum.IntEnum</code> Checks that the value is a valid <code>IntEnum</code> instance. Subclass of <code>enum.IntEnum</code> Checks that the value is a valid member of the integer <code>enum</code>. See Enums and Choices for more details. <code>decimal.Decimal</code> Pydantic attempts to convert the value to a string, then passes the string to <code>Decimal(v)</code>. <code>pathlib.Path</code> Simply uses the type itself for validation by passing the value to <code>Path(v)</code>. See File Types for other more strict path types. <code>uuid.UUID</code> Strings and bytes (converted to strings) are passed to <code>UUID(v)</code>, with a fallback to <code>UUID(bytes=v)</code> for <code>bytes</code> and <code>bytearray</code>. See UUIDs for other stricter UUID types. <code>ByteSize</code> Converts a bytes string with units to bytes."},{"location":"usage/types/standard_types/#literal-type","title":"Literal Type","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8; prior to Python 3.8, it requires the typing-extensions package.</p> <p>Pydantic supports the use of <code>typing.Literal</code> (or <code>typing_extensions.Literal</code> prior to Python 3.8) as a lightweight way to specify that a field may accept only specific literal values:</p> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Pie(BaseModel):\n    flavor: Literal['apple', 'pumpkin']\n\n\nPie(flavor='apple')\nPie(flavor='pumpkin')\ntry:\n    Pie(flavor='cherry')\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    1 validation error for Pie\n    flavor\n      Input should be 'apple' or 'pumpkin' [type=literal_error, input_value='cherry', input_type=str]\n    \"\"\"\n</code></pre> <p>One benefit of this field type is that it can be used to check for equality with one or more specific values without needing to declare custom validators:</p> Python 3.8 and abovePython 3.9 and abovePython 3.10 and above <pre><code>from typing import ClassVar, List, Literal, Union\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Cake(BaseModel):\n    kind: Literal['cake']\n    required_utensils: ClassVar[List[str]] = ['fork', 'knife']\n\n\nclass IceCream(BaseModel):\n    kind: Literal['icecream']\n    required_utensils: ClassVar[List[str]] = ['spoon']\n\n\nclass Meal(BaseModel):\n    dessert: Union[Cake, IceCream]\n\n\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Cake\nprint(type(Meal(dessert={'kind': 'icecream'}).dessert).__name__)\n#&gt; IceCream\ntry:\n    Meal(dessert={'kind': 'pie'})\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    2 validation errors for Meal\n    dessert.Cake.kind\n      Input should be 'cake' [type=literal_error, input_value='pie', input_type=str]\n    dessert.IceCream.kind\n      Input should be 'icecream' [type=literal_error, input_value='pie', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import ClassVar, Literal, Union\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Cake(BaseModel):\n    kind: Literal['cake']\n    required_utensils: ClassVar[list[str]] = ['fork', 'knife']\n\n\nclass IceCream(BaseModel):\n    kind: Literal['icecream']\n    required_utensils: ClassVar[list[str]] = ['spoon']\n\n\nclass Meal(BaseModel):\n    dessert: Union[Cake, IceCream]\n\n\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Cake\nprint(type(Meal(dessert={'kind': 'icecream'}).dessert).__name__)\n#&gt; IceCream\ntry:\n    Meal(dessert={'kind': 'pie'})\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    2 validation errors for Meal\n    dessert.Cake.kind\n      Input should be 'cake' [type=literal_error, input_value='pie', input_type=str]\n    dessert.IceCream.kind\n      Input should be 'icecream' [type=literal_error, input_value='pie', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import ClassVar, Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Cake(BaseModel):\n    kind: Literal['cake']\n    required_utensils: ClassVar[list[str]] = ['fork', 'knife']\n\n\nclass IceCream(BaseModel):\n    kind: Literal['icecream']\n    required_utensils: ClassVar[list[str]] = ['spoon']\n\n\nclass Meal(BaseModel):\n    dessert: Cake | IceCream\n\n\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Cake\nprint(type(Meal(dessert={'kind': 'icecream'}).dessert).__name__)\n#&gt; IceCream\ntry:\n    Meal(dessert={'kind': 'pie'})\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    2 validation errors for Meal\n    dessert.Cake.kind\n      Input should be 'cake' [type=literal_error, input_value='pie', input_type=str]\n    dessert.IceCream.kind\n      Input should be 'icecream' [type=literal_error, input_value='pie', input_type=str]\n    \"\"\"\n</code></pre> <p>With proper ordering in an annotated <code>Union</code>, you can use this to parse types of decreasing specificity:</p> Python 3.8 and abovePython 3.10 and above <pre><code>from typing import Literal, Optional, Union\n\nfrom pydantic import BaseModel\n\n\nclass Dessert(BaseModel):\n    kind: str\n\n\nclass Pie(Dessert):\n    kind: Literal['pie']\n    flavor: Optional[str]\n\n\nclass ApplePie(Pie):\n    flavor: Literal['apple']\n\n\nclass PumpkinPie(Pie):\n    flavor: Literal['pumpkin']\n\n\nclass Meal(BaseModel):\n    dessert: Union[ApplePie, PumpkinPie, Pie, Dessert]\n\n\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'apple'}).dessert).__name__)\n#&gt; ApplePie\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'pumpkin'}).dessert).__name__)\n#&gt; PumpkinPie\nprint(type(Meal(dessert={'kind': 'pie'}).dessert).__name__)\n#&gt; Dessert\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Dessert\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel\n\n\nclass Dessert(BaseModel):\n    kind: str\n\n\nclass Pie(Dessert):\n    kind: Literal['pie']\n    flavor: str | None\n\n\nclass ApplePie(Pie):\n    flavor: Literal['apple']\n\n\nclass PumpkinPie(Pie):\n    flavor: Literal['pumpkin']\n\n\nclass Meal(BaseModel):\n    dessert: ApplePie | PumpkinPie | Pie | Dessert\n\n\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'apple'}).dessert).__name__)\n#&gt; ApplePie\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'pumpkin'}).dessert).__name__)\n#&gt; PumpkinPie\nprint(type(Meal(dessert={'kind': 'pie'}).dessert).__name__)\n#&gt; Dessert\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Dessert\n</code></pre>"},{"location":"usage/types/standard_types/#strict-types","title":"Strict types","text":"<p>You can use the <code>StrictStr</code>, <code>StrictBytes</code>, <code>StrictInt</code>, <code>StrictFloat</code>, and <code>StrictBool</code> types to prevent coercion from compatible types. These types will only pass validation when the validated value is of the respective type or is a subtype of that type. This behavior is also exposed via the <code>strict</code> field of the <code>ConstrainedStr</code>, <code>ConstrainedBytes</code>, <code>ConstrainedFloat</code> and <code>ConstrainedInt</code> classes and can be combined with a multitude of complex validation rules.</p> <p>The following caveats apply:</p> <ul> <li><code>StrictBytes</code> (and the <code>strict</code> option of <code>ConstrainedBytes</code>) will accept both <code>bytes</code>,    and <code>bytearray</code> types.</li> <li><code>StrictInt</code> (and the <code>strict</code> option of <code>ConstrainedInt</code>) will not accept <code>bool</code> types,     even though <code>bool</code> is a subclass of <code>int</code> in Python. Other subclasses will work.</li> <li><code>StrictFloat</code> (and the <code>strict</code> option of <code>ConstrainedFloat</code>) will not accept <code>int</code>.</li> </ul> <pre><code>from pydantic import (\n    BaseModel,\n    StrictBool,\n    StrictBytes,\n    StrictInt,\n    ValidationError,\n    confloat,\n)\n\n\nclass StrictBytesModel(BaseModel):\n    strict_bytes: StrictBytes\n\n\ntry:\n    StrictBytesModel(strict_bytes='hello world')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for StrictBytesModel\n    strict_bytes\n      Input should be a valid bytes [type=bytes_type, input_value='hello world', input_type=str]\n    \"\"\"\n\n\nclass StrictIntModel(BaseModel):\n    strict_int: StrictInt\n\n\ntry:\n    StrictIntModel(strict_int=3.14159)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for StrictIntModel\n    strict_int\n      Input should be a valid integer [type=int_type, input_value=3.14159, input_type=float]\n    \"\"\"\n\n\nclass ConstrainedFloatModel(BaseModel):\n    constrained_float: confloat(strict=True, ge=0.0)\n\n\ntry:\n    ConstrainedFloatModel(constrained_float=3)\nexcept ValidationError as e:\n    print(e)\n\ntry:\n    ConstrainedFloatModel(constrained_float=-1.23)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ConstrainedFloatModel\n    constrained_float\n      Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1.23, input_type=float]\n    \"\"\"\n\n\nclass StrictBoolModel(BaseModel):\n    strict_bool: StrictBool\n\n\ntry:\n    StrictBoolModel(strict_bool='False')\nexcept ValidationError as e:\n    print(str(e))\n\"\"\"\n    1 validation error for StrictBoolModel\n    strict_bool\n      Input should be a valid boolean [type=bool_type, input_value='False', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/standard_types/#constrained-types","title":"Constrained types","text":"<code>NegativeFloat</code> allows a float which is negative; uses standard <code>float</code> parsing then checks the value is less than 0;   see Constrained Types <code>NegativeInt</code> allows an int which is negative; uses standard <code>int</code> parsing then checks the value is less than 0;   see Constrained Types <code>PositiveFloat</code> allows a float which is positive; uses standard <code>float</code> parsing then checks the value is greater than 0;   see Constrained Types <code>PositiveInt</code> allows an int which is positive; uses standard <code>int</code> parsing then checks the value is greater than 0;   see Constrained Types <code>conbytes</code> type method for constraining bytes;   see Constrained Types <code>condecimal</code> type method for constraining Decimals;   see Constrained Types <code>confloat</code> type method for constraining floats;   see Constrained Types <code>conint</code> type method for constraining ints;   see Constrained Types <code>condate</code> type method for constraining dates;   see Constrained Types <code>conlist</code> type method for constraining lists;   see Constrained Types <code>conset</code> type method for constraining sets;   see Constrained Types <code>confrozenset</code> type method for constraining frozen sets;   see Constrained Types <code>constr</code> type method for constraining strs;   see Constrained Types <p>The value of numerous common types can be restricted using <code>con*</code> type functions:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import (\n    BaseModel,\n    Field,\n    NegativeFloat,\n    NegativeInt,\n    NonNegativeFloat,\n    NonNegativeInt,\n    NonPositiveFloat,\n    NonPositiveInt,\n    PositiveFloat,\n    PositiveInt,\n    conbytes,\n    condecimal,\n    confloat,\n    conint,\n    conlist,\n    conset,\n    constr,\n)\n\n\nclass Model(BaseModel):\n    short_bytes: conbytes(min_length=2, max_length=10)\n    strict_bytes: conbytes(strict=True)\n\n    upper_str: constr(to_upper=True)\n    lower_str: constr(to_lower=True)\n    short_str: constr(min_length=2, max_length=10)\n    regex_str: constr(pattern=r'^apple (pie|tart|sandwich)$')\n    strip_str: constr(strip_whitespace=True)\n\n    big_int: conint(gt=1000, lt=1024)\n    mod_int: conint(multiple_of=5)\n    pos_int: PositiveInt\n    neg_int: NegativeInt\n    non_neg_int: NonNegativeInt\n    non_pos_int: NonPositiveInt\n\n    big_float: confloat(gt=1000, lt=1024)\n    unit_interval: confloat(ge=0, le=1)\n    mod_float: confloat(multiple_of=0.5)\n    pos_float: PositiveFloat\n    neg_float: NegativeFloat\n    non_neg_float: NonNegativeFloat\n    non_pos_float: NonPositiveFloat\n\n    short_list: conlist(int, min_length=1, max_length=4)\n    short_set: conset(int, min_length=1, max_length=4)\n\n    decimal_positive: condecimal(gt=0)\n    decimal_negative: condecimal(lt=0)\n    decimal_max_digits_and_places: condecimal(max_digits=2, decimal_places=2)\n    mod_decimal: condecimal(multiple_of=Decimal('0.25'))\n\n    bigger_int: int = Field(..., gt=10000)\n</code></pre> <p>Where <code>Field</code> refers to the field function.</p>"},{"location":"usage/types/standard_types/#arguments-to-conlist","title":"Arguments to <code>conlist</code>","text":"<p>The following arguments are available when using the <code>conlist</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the list items</li> <li><code>min_items: int = None</code>: minimum number of items in the list</li> <li><code>max_items: int = None</code>: maximum number of items in the list</li> <li><code>unique_items: bool = None</code>: enforces list elements to be unique</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-conset","title":"Arguments to <code>conset</code>","text":"<p>The following arguments are available when using the <code>conset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the set items</li> <li><code>min_items: int = None</code>: minimum number of items in the set</li> <li><code>max_items: int = None</code>: maximum number of items in the set</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-confrozenset","title":"Arguments to <code>confrozenset</code>","text":"<p>The following arguments are available when using the <code>confrozenset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the frozenset items</li> <li><code>min_items: int = None</code>: minimum number of items in the frozenset</li> <li><code>max_items: int = None</code>: maximum number of items in the frozenset</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-conint","title":"Arguments to <code>conint</code>","text":"<p>The following arguments are available when using the <code>conint</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: int = None</code>: enforces integer to be greater than the set value</li> <li><code>ge: int = None</code>: enforces integer to be greater than or equal to the set value</li> <li><code>lt: int = None</code>: enforces integer to be less than the set value</li> <li><code>le: int = None</code>: enforces integer to be less than or equal to the set value</li> <li><code>multiple_of: int = None</code>: enforces integer to be a multiple of the set value</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-confloat","title":"Arguments to <code>confloat</code>","text":"<p>The following arguments are available when using the <code>confloat</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: float = None</code>: enforces float to be greater than the set value</li> <li><code>ge: float = None</code>: enforces float to be greater than or equal to the set value</li> <li><code>lt: float = None</code>: enforces float to be less than the set value</li> <li><code>le: float = None</code>: enforces float to be less than or equal to the set value</li> <li><code>multiple_of: float = None</code>: enforces float to be a multiple of the set value</li> <li><code>allow_inf_nan: bool = True</code>: whether to allows infinity (<code>+inf</code> an <code>-inf</code>) and NaN values, defaults to <code>True</code>,   set to <code>False</code> for compatibility with <code>JSON</code>,   see #3994 for more details, added in V1.10</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-condecimal","title":"Arguments to <code>condecimal</code>","text":"<p>The following arguments are available when using the <code>condecimal</code> type function</p> <ul> <li><code>gt: Decimal = None</code>: enforces decimal to be greater than the set value</li> <li><code>ge: Decimal = None</code>: enforces decimal to be greater than or equal to the set value</li> <li><code>lt: Decimal = None</code>: enforces decimal to be less than the set value</li> <li><code>le: Decimal = None</code>: enforces decimal to be less than or equal to the set value</li> <li><code>max_digits: int = None</code>: maximum number of digits within the decimal. it does not include a zero before the decimal point or trailing decimal zeroes</li> <li><code>decimal_places: int = None</code>: max number of decimal places allowed. it does not include trailing decimal zeroes</li> <li><code>multiple_of: Decimal = None</code>: enforces decimal to be a multiple of the set value</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-constr","title":"Arguments to <code>constr</code>","text":"<p>The following arguments are available when using the <code>constr</code> type function</p> <ul> <li><code>strip_whitespace: bool = False</code>: removes leading and trailing whitespace</li> <li><code>to_upper: bool = False</code>: turns all characters to uppercase</li> <li><code>to_lower: bool = False</code>: turns all characters to lowercase</li> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>min_length: int = None</code>: minimum length of the string</li> <li><code>max_length: int = None</code>: maximum length of the string</li> <li><code>curtail_length: int = None</code>: shrinks the string length to the set value when it is longer than the set value</li> <li><code>regex: str = None</code>: regex to validate the string against</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-conbytes","title":"Arguments to <code>conbytes</code>","text":"<p>The following arguments are available when using the <code>conbytes</code> type function</p> <ul> <li><code>strip_whitespace: bool = False</code>: removes leading and trailing whitespace</li> <li><code>to_upper: bool = False</code>: turns all characters to uppercase</li> <li><code>to_lower: bool = False</code>: turns all characters to lowercase</li> <li><code>min_length: int = None</code>: minimum length of the byte string</li> <li><code>max_length: int = None</code>: maximum length of the byte string</li> <li><code>strict: bool = False</code>: controls type coercion</li> </ul>"},{"location":"usage/types/standard_types/#arguments-to-condate","title":"Arguments to <code>condate</code>","text":"<p>The following arguments are available when using the <code>condate</code> type function</p> <ul> <li><code>gt: date = None</code>: enforces date to be greater than the set value</li> <li><code>ge: date = None</code>: enforces date to be greater than or equal to the set value</li> <li><code>lt: date = None</code>: enforces date to be less than the set value</li> <li><code>le: date = None</code>: enforces date to be less than or equal to the set value</li> </ul>"},{"location":"usage/types/string_types/","title":"String Types","text":""},{"location":"usage/types/string_types/#str","title":"str","text":"<p>Strings are accepted as-is, <code>bytes</code> and <code>bytearray</code> are converted using <code>v.decode()</code>, enums inheriting from <code>str</code> are converted using <code>v.value</code>, and all other types cause an error</p>"},{"location":"usage/types/string_types/#emailstr","title":"EmailStr","text":"<p><code>EmailStr</code> requires email-validator to be installed. The input string must be a valid email address, and the output is a simple string</p>"},{"location":"usage/types/string_types/#nameemail","title":"NameEmail","text":"<p><code>NameEmail</code> requires email-validator to be installed. The input string must be either a valid email address or in the format <code>Fred Bloggs &lt;fred.bloggs@example.com&gt;</code>, and the output is a <code>NameEmail</code> object which has two properties: <code>name</code> and <code>email</code>. For <code>Fred Bloggs &lt;fred.bloggs@example.com&gt;</code> the name would be <code>\"Fred Bloggs\"</code>. For <code>fred.bloggs@example.com</code> it would be <code>\"fred.bloggs\"</code>.</p>"},{"location":"usage/types/string_types/#importstring","title":"ImportString","text":"<p><code>ImportString</code> expects a string and loads the Python object importable at that dotted path. Attributes of modules may be separated from the module by <code>:</code> or <code>.</code>, e.g. if <code>'math:cos'</code> was provided, the resulting field value would be the function<code>cos</code>. If a <code>.</code> is used and both an attribute and submodule are present at the same path, the module will be preferred.</p> <p>On model instantiation, pointers will be evaluated and imported. There is some nuance to this behavior, demonstrated in the examples below.</p> <p>A known limitation: setting a default value to a string won't result in validation (thus evaluation). This is actively being worked on.</p> <p>Good behavior: <pre><code>from math import cos\n\nfrom pydantic import BaseModel, ImportString, ValidationError\n\n\nclass ImportThings(BaseModel):\n    obj: ImportString\n\n\n# A string value will cause an automatic import\nmy_cos = ImportThings(obj='math.cos')\n\n# You can use the imported function as you would expect\ncos_of_0 = my_cos.obj(0)\nassert cos_of_0 == 1\n\n\n# A string whose value cannot be imported will raise an error\ntry:\n    ImportThings(obj='foo.bar')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for ImportThings\n    obj\n      Invalid python path: No module named 'foo.bar' [type=import_error, input_value='foo.bar', input_type=str]\n    \"\"\"\n\n\n# Actual python objects can be assigned as well\nmy_cos = ImportThings(obj=cos)\nmy_cos_2 = ImportThings(obj='math.cos')\nassert my_cos == my_cos_2\n</code></pre></p> <p>Serializing an <code>ImportString</code> type to json is also possible.</p> <pre><code>from pydantic import BaseModel, ImportString\n\n\nclass ImportThings(BaseModel):\n    obj: ImportString\n\n\n# Create an instance\nm = ImportThings(obj='math:cos')\nm.model_dump_json()\n</code></pre>"},{"location":"usage/types/string_types/#constrained-types","title":"Constrained Types","text":"<p>The value of numerous common types can be restricted using <code>con*</code> type functions.</p>"},{"location":"usage/types/string_types/#arguments-to-constr","title":"Arguments to <code>constr</code>","text":"<p>The following arguments are available when using the <code>constr</code> type function</p> <ul> <li><code>strip_whitespace: bool = False</code>: removes leading and trailing whitespace</li> <li><code>to_upper: bool = False</code>: turns all characters to uppercase</li> <li><code>to_lower: bool = False</code>: turns all characters to lowercase</li> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>min_length: int = None</code>: minimum length of the string</li> <li><code>max_length: int = None</code>: maximum length of the string</li> <li><code>curtail_length: int = None</code>: shrinks the string length to the set value when it is longer than the set value</li> <li><code>regex: str = None</code>: regex to validate the string against</li> </ul>"},{"location":"usage/types/types/","title":"Types Overview","text":"<p>Where possible Pydantic uses standard library types to define fields, thus smoothing the learning curve. For many useful applications, however, no standard library type exists, so Pydantic implements many commonly used types.</p> <p>There are also more complex types that can be found in the [Pydantic Extra Types].</p> <p>If no existing type suits your purpose you can also implement your own Pydantic-compatible types with custom properties and validation.</p> <p>The following sections describe the types supported by Pydantic.</p> <ul> <li>Standard Library Types \u2014 types from the Python standard library.</li> <li>Booleans \u2014 <code>bool</code> types.</li> <li>ByteSize \u2014 a type that allows handling byte string representations in your model.</li> <li>Callables \u2014 <code>Callable</code> types.</li> <li>Datetimes \u2014 <code>datetime</code>, <code>date</code>, <code>time</code>, and <code>timedelta</code> types.</li> <li>Dicts and Mapping Types \u2014 <code>dict</code> types and mapping types.</li> <li>Enums and Choices \u2014 uses Python's standard <code>enum</code> classes to define choices.</li> <li>File Types \u2014 types for handling files and paths.</li> <li>JSON \u2014 a type that allows you to store JSON data in your model.</li> <li>Lists and Tuples \u2014 <code>list</code> and <code>tuple</code> types.</li> <li>Number Types \u2014 <code>int</code>, <code>float</code>, <code>Decimal</code>, and other number types.</li> <li>Secret Types \u2014 types for storing sensitive information that you do not want to be visible in logging or tracebacks.</li> <li>Sequence, Iterable, &amp; Iterator \u2014 iterable types including <code>Sequence</code>, <code>Iterable</code>, and <code>Iterator</code>.</li> <li>Sets and frozenset \u2014 <code>set</code> and <code>frozenset</code> types.</li> <li>String Types \u2014 <code>str</code> types.</li> <li>Type and TypeVar \u2014 <code>Type</code> and <code>TypeVar</code> types.</li> <li>Types with Fields \u2014 types that allow you to define fields.</li> <li>Unions \u2014 allows a model attribute to accept different types.</li> <li>URLs \u2014 URI/URL validation types.</li> <li>UUIDs \u2014 types that allow you to store UUIDs in your model.</li> <li>Base64 and other encodings \u2014 types that allow serializing values into an encoded form, e.g. <code>base64</code>.</li> <li>Custom Data Types \u2014 create your own custom data types.</li> <li>Field Type Conversions \u2014 strict and lax conversion between different field types.</li> <li>Extra Types: Types that can be found in the optional Pydantic Extra Types package. These include:<ul> <li>Color Types \u2014 types that enable you to store RGB color values in your model.</li> <li>Payment Card Numbers \u2014 types that enable you to store payment cards such as debit or credit cards.</li> <li>Phone Numbers \u2014 types that enable you to store phone numbers in your model.</li> <li>Routing Numbers \u2014 types that enable you to store ABA routing transit numbers in your model.</li> </ul> </li> </ul>"},{"location":"usage/types/types_fields/","title":"Types with Fields","text":"<p>Pydantic supports four types with fields:</p> <ul> <li><code>BaseModel</code></li> <li>dataclasses</li> <li><code>NamedTuple</code></li> <li><code>TypedDict</code></li> </ul>"},{"location":"usage/types/types_fields/#namedtuple","title":"NamedTuple","text":"<pre><code>from typing import NamedTuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\n\nclass Model(BaseModel):\n    p: Point\n\n\nprint(Model(p=('1', '2')))\n#&gt; p=Point(x=1, y=2)\n\ntry:\n    Model(p=('1.3', '2'))\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    p.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='1.3', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/types_fields/#typeddict","title":"TypedDict","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8. Prior to Python 3.8, it requires the typing-extensions package. But required and optional fields are properly differentiated only since Python 3.9. We therefore recommend using typing-extensions with Python 3.8 as well.</p> Python 3.7 and abovePython 3.11 and above <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\n# `total=False` means keys are non-required\nclass UserIdentity(TypedDict, total=False):\n    name: str\n    surname: str\n\n\nclass User(TypedDict):\n    identity: UserIdentity\n    age: int\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(extra='forbid')\n    u: User\n\n\nprint(Model(u={'identity': {'name': 'Smith', 'surname': 'John'}, 'age': '37'}))\n#&gt; u={'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37}\n\nprint(Model(u={'identity': {'surname': 'John'}, 'age': '37'}))\n#&gt; u={'identity': {'surname': 'John'}, 'age': 37}\n\nprint(Model(u={'identity': {}, 'age': '37'}))\n#&gt; u={'identity': {}, 'age': 37}\n\n\ntry:\n    Model(u={'identity': {'name': ['Smith'], 'surname': 'John'}, 'age': '24'})\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    u.identity.name\n      Input should be a valid string [type=string_type, input_value=['Smith'], input_type=list]\n    \"\"\"\n\ntry:\n    Model(\n        u={\n            'identity': {'name': 'Smith', 'surname': 'John'},\n            'age': '37',\n            'email': 'john.smith@me.com',\n        }\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    u.email\n      Extra inputs are not permitted [type=extra_forbidden, input_value='john.smith@me.com', input_type=str]\n    \"\"\"\n</code></pre> <pre><code>from typing import TypedDict\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\n# `total=False` means keys are non-required\nclass UserIdentity(TypedDict, total=False):\n    name: str\n    surname: str\n\n\nclass User(TypedDict):\n    identity: UserIdentity\n    age: int\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(extra='forbid')\n    u: User\n\n\nprint(Model(u={'identity': {'name': 'Smith', 'surname': 'John'}, 'age': '37'}))\n#&gt; u={'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37}\n\nprint(Model(u={'identity': {'surname': 'John'}, 'age': '37'}))\n#&gt; u={'identity': {'surname': 'John'}, 'age': 37}\n\nprint(Model(u={'identity': {}, 'age': '37'}))\n#&gt; u={'identity': {}, 'age': 37}\n\n\ntry:\n    Model(u={'identity': {'name': ['Smith'], 'surname': 'John'}, 'age': '24'})\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    u.identity.name\n      Input should be a valid string [type=string_type, input_value=['Smith'], input_type=list]\n    \"\"\"\n\ntry:\n    Model(\n        u={\n            'identity': {'name': 'Smith', 'surname': 'John'},\n            'age': '37',\n            'email': 'john.smith@me.com',\n        }\n    )\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    u.email\n      Extra inputs are not permitted [type=extra_forbidden, input_value='john.smith@me.com', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/typevars/","title":"Type and TypeVar","text":""},{"location":"usage/types/typevars/#type","title":"Type","text":"<p>Pydantic supports the use of <code>Type[T]</code> to specify that a field may only accept classes (not instances) that are subclasses of <code>T</code>.</p> Python 3.7 and abovePython 3.9 and above <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo:\n    pass\n\n\nclass Bar(Foo):\n    pass\n\n\nclass Other:\n    pass\n\n\nclass SimpleModel(BaseModel):\n    just_subclasses: Type[Foo]\n\n\nSimpleModel(just_subclasses=Foo)\nSimpleModel(just_subclasses=Bar)\ntry:\n    SimpleModel(just_subclasses=Other)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for SimpleModel\n    just_subclasses\n      Input should be a subclass of Foo [type=is_subclass_of, input_value=&lt;class '__main__.Other'&gt;, input_type=type]\n    \"\"\"\n</code></pre> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Foo:\n    pass\n\n\nclass Bar(Foo):\n    pass\n\n\nclass Other:\n    pass\n\n\nclass SimpleModel(BaseModel):\n    just_subclasses: type[Foo]\n\n\nSimpleModel(just_subclasses=Foo)\nSimpleModel(just_subclasses=Bar)\ntry:\n    SimpleModel(just_subclasses=Other)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for SimpleModel\n    just_subclasses\n      Input should be a subclass of Foo [type=is_subclass_of, input_value=&lt;class '__main__.Other'&gt;, input_type=type]\n    \"\"\"\n</code></pre> <p>You may also use <code>Type</code> to specify that any class is allowed.</p> <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo:\n    pass\n\n\nclass LenientSimpleModel(BaseModel):\n    any_class_goes: Type\n\n\nLenientSimpleModel(any_class_goes=int)\nLenientSimpleModel(any_class_goes=Foo)\ntry:\n    LenientSimpleModel(any_class_goes=Foo())\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for LenientSimpleModel\n    any_class_goes\n      Input should be a type [type=is_type, input_value=&lt;__main__.Foo object at 0x0123456789ab&gt;, input_type=Foo]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/typevars/#typevar","title":"TypeVar","text":"<p><code>TypeVar</code> is supported either unconstrained, constrained or with a bound.</p> <pre><code>from typing import TypeVar\n\nfrom pydantic import BaseModel\n\nFoobar = TypeVar('Foobar')\nBoundFloat = TypeVar('BoundFloat', bound=float)\nIntStr = TypeVar('IntStr', int, str)\n\n\nclass Model(BaseModel):\n    a: Foobar  # equivalent of \": Any\"\n    b: BoundFloat  # equivalent of \": float\"\n    c: IntStr  # equivalent of \": Union[int, str]\"\n\n\nprint(Model(a=[1], b=4.2, c='x'))\n#&gt; a=[1] b=4.2 c='x'\n\n# a may be None\nprint(Model(a=None, b=1, c=1))\n#&gt; a=None b=1.0 c=1\n</code></pre>"},{"location":"usage/types/unions/","title":"Unions","text":"<p>The <code>Union</code> type allows a model attribute to accept different types, e.g.:</p> Python 3.7 and abovePython 3.10 and above <pre><code>from typing import Union\nfrom uuid import UUID\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: Union[int, str, UUID]\n    name: str\n\n\nuser_01 = User(id=123, name='John Doe')\nprint(user_01)\n#&gt; id=123 name='John Doe'\nprint(user_01.id)\n#&gt; 123\nuser_02 = User(id='1234', name='John Doe')\nprint(user_02)\n#&gt; id='1234' name='John Doe'\nprint(user_02.id)\n#&gt; 1234\nuser_03_uuid = UUID('cf57432e-809e-4353-adbd-9d5c0d733868')\nuser_03 = User(id=user_03_uuid, name='John Doe')\nprint(user_03)\n#&gt; id=UUID('cf57432e-809e-4353-adbd-9d5c0d733868') name='John Doe'\nprint(user_03.id)\n#&gt; cf57432e-809e-4353-adbd-9d5c0d733868\nprint(user_03_uuid.int)\n#&gt; 275603287559914445491632874575877060712\n</code></pre> <pre><code>from uuid import UUID\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int | str | UUID\n    name: str\n\n\nuser_01 = User(id=123, name='John Doe')\nprint(user_01)\n#&gt; id=123 name='John Doe'\nprint(user_01.id)\n#&gt; 123\nuser_02 = User(id='1234', name='John Doe')\nprint(user_02)\n#&gt; id='1234' name='John Doe'\nprint(user_02.id)\n#&gt; 1234\nuser_03_uuid = UUID('cf57432e-809e-4353-adbd-9d5c0d733868')\nuser_03 = User(id=user_03_uuid, name='John Doe')\nprint(user_03)\n#&gt; id=UUID('cf57432e-809e-4353-adbd-9d5c0d733868') name='John Doe'\nprint(user_03.id)\n#&gt; cf57432e-809e-4353-adbd-9d5c0d733868\nprint(user_03_uuid.int)\n#&gt; 275603287559914445491632874575877060712\n</code></pre> <p>Tip</p> <p>The type <code>Optional[x]</code> is a shorthand for <code>Union[x, None]</code>.</p> <p><code>Optional[x]</code> can also be used to specify a required field that can take <code>None</code> as a value.</p> <p>See more details in Required Fields.</p>"},{"location":"usage/types/unions/#discriminated-unions-aka-tagged-unions","title":"Discriminated Unions (a.k.a. Tagged Unions)","text":"<p>When <code>Union</code> is used with multiple submodels, you sometimes know exactly which submodel needs to be checked and validated and want to enforce this. To do that you can set the same field - let's call it <code>my_discriminator</code> - in each of the submodels with a discriminated value, which is one (or many) <code>Literal</code> value(s). For your <code>Union</code>, you can set the discriminator in its value: <code>Field(discriminator='my_discriminator')</code>.</p> <p>Setting a discriminated union has many benefits:</p> <ul> <li>validation is faster since it is only attempted against one model</li> <li>only one explicit error is raised in case of failure</li> <li>the generated JSON schema implements the associated OpenAPI specification</li> </ul> Python 3.8 and abovePython 3.10 and above <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    meows: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    barks: float\n\n\nclass Lizard(BaseModel):\n    pet_type: Literal['reptile', 'lizard']\n    scales: bool\n\n\nclass Model(BaseModel):\n    pet: Union[Cat, Dog, Lizard] = Field(..., discriminator='pet_type')\n    n: int\n\n\nprint(Model(pet={'pet_type': 'dog', 'barks': 3.14}, n=1))\n#&gt; pet=Dog(pet_type='dog', barks=3.14) n=1\ntry:\n    Model(pet={'pet_type': 'dog'}, n=1)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.dog.barks\n      Field required [type=missing, input_value={'pet_type': 'dog'}, input_type=dict]\n    \"\"\"\n</code></pre> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    meows: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    barks: float\n\n\nclass Lizard(BaseModel):\n    pet_type: Literal['reptile', 'lizard']\n    scales: bool\n\n\nclass Model(BaseModel):\n    pet: Cat | Dog | Lizard = Field(..., discriminator='pet_type')\n    n: int\n\n\nprint(Model(pet={'pet_type': 'dog', 'barks': 3.14}, n=1))\n#&gt; pet=Dog(pet_type='dog', barks=3.14) n=1\ntry:\n    Model(pet={'pet_type': 'dog'}, n=1)\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.dog.barks\n      Field required [type=missing, input_value={'pet_type': 'dog'}, input_type=dict]\n    \"\"\"\n</code></pre> <p>Note</p> <p>Using the Annotated Fields syntax can be handy to regroup the <code>Union</code> and <code>discriminator</code> information. See below for an example!</p> <p>Warning</p> <p>Discriminated unions cannot be used with only a single variant, such as <code>Union[Cat]</code>.</p> <p>Python changes <code>Union[T]</code> into <code>T</code> at interpretation time, so it is not possible for <code>pydantic</code> to distinguish fields of <code>Union[T]</code> from <code>T</code>.</p>"},{"location":"usage/types/unions/#nested-discriminated-unions","title":"Nested Discriminated Unions","text":"<p>Only one discriminator can be set for a field but sometimes you want to combine multiple discriminators. You can do it by creating nested <code>Annotated</code> types, e.g.:</p> Python 3.8 and abovePython 3.9 and above <pre><code>from typing import Literal, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['black']\n    black_name: str\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['white']\n    white_name: str\n\n\nCat = Annotated[Union[BlackCat, WhiteCat], Field(discriminator='color')]\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    name: str\n\n\nPet = Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n\n\nclass Model(BaseModel):\n    pet: Pet\n    n: int\n\n\nm = Model(pet={'pet_type': 'cat', 'color': 'black', 'black_name': 'felix'}, n=1)\nprint(m)\n#&gt; pet=BlackCat(pet_type='cat', color='black', black_name='felix') n=1\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'red'}, n='1')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.cat\n      Input tag 'red' found using 'color' does not match any of the expected tags: 'black', 'white' [type=union_tag_invalid, input_value={'pet_type': 'cat', 'color': 'red'}, input_type=dict]\n    \"\"\"\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'black'}, n='1')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.cat.black.black_name\n      Field required [type=missing, input_value={'pet_type': 'cat', 'color': 'black'}, input_type=dict]\n    \"\"\"\n</code></pre> <pre><code>from typing import Literal, Union\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['black']\n    black_name: str\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['white']\n    white_name: str\n\n\nCat = Annotated[Union[BlackCat, WhiteCat], Field(discriminator='color')]\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    name: str\n\n\nPet = Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n\n\nclass Model(BaseModel):\n    pet: Pet\n    n: int\n\n\nm = Model(pet={'pet_type': 'cat', 'color': 'black', 'black_name': 'felix'}, n=1)\nprint(m)\n#&gt; pet=BlackCat(pet_type='cat', color='black', black_name='felix') n=1\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'red'}, n='1')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.cat\n      Input tag 'red' found using 'color' does not match any of the expected tags: 'black', 'white' [type=union_tag_invalid, input_value={'pet_type': 'cat', 'color': 'red'}, input_type=dict]\n    \"\"\"\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'black'}, n='1')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    pet.cat.black.black_name\n      Field required [type=missing, input_value={'pet_type': 'cat', 'color': 'black'}, input_type=dict]\n    \"\"\"\n</code></pre>"},{"location":"usage/types/urls/","title":"URLs","text":"<p>For URI/URL validation the following types are available:</p> <ul> <li><code>AnyUrl</code>: any scheme allowed, TLD not required, host required</li> <li><code>AnyHttpUrl</code>: scheme <code>http</code> or <code>https</code>, TLD not required, host required</li> <li><code>HttpUrl</code>: scheme <code>http</code> or <code>https</code>, TLD required, host required, max length 2083</li> <li><code>FileUrl</code>: scheme <code>file</code>, host not required</li> <li><code>PostgresDsn</code>: user info required, TLD not required, host required,   as of V.10 <code>PostgresDsn</code> supports multiple hosts. The following schemes are supported:</li> <li><code>postgres</code></li> <li><code>postgresql</code></li> <li><code>postgresql+asyncpg</code></li> <li><code>postgresql+pg8000</code></li> <li><code>postgresql+psycopg</code></li> <li><code>postgresql+psycopg2</code></li> <li><code>postgresql+psycopg2cffi</code></li> <li><code>postgresql+py-postgresql</code></li> <li><code>postgresql+pygresql</code></li> <li><code>MySQLDsn</code>: scheme <code>mysql</code>, user info required, TLD not required, host required. Also, its supported DBAPI dialects:</li> <li><code>mysql</code></li> <li><code>mysql+mysqlconnector</code></li> <li><code>mysql+aiomysql</code></li> <li><code>mysql+asyncmy</code></li> <li><code>mysql+mysqldb</code></li> <li><code>mysql+pymysql</code></li> <li><code>mysql+cymysql</code></li> <li><code>mysql+pyodbc</code></li> <li><code>MariaDBDsn</code>: scheme <code>mariadb</code>, user info required, TLD not required, host required. Also, its supported DBAPI dialects:</li> <li><code>mariadb</code></li> <li><code>mariadb+mariadbconnector</code></li> <li><code>mariadb+pymysql</code></li> <li><code>CockroachDsn</code>: scheme <code>cockroachdb</code>, user info required, TLD not required, host required. Also, its supported DBAPI dialects:</li> <li><code>cockroachdb+asyncpg</code></li> <li><code>cockroachdb+psycopg2</code></li> <li><code>AmqpDsn</code>: schema <code>amqp</code> or <code>amqps</code>, user info not required, TLD not required, host not required</li> <li><code>RedisDsn</code>: scheme <code>redis</code> or <code>rediss</code>, user info not required, tld not required, host not required (CHANGED: user info) (e.g., <code>rediss://:pass@localhost</code>)</li> <li><code>MongoDsn</code> : scheme <code>mongodb</code>, user info not required, database name not required, port   not required from v1.6 onwards), user info may be passed without user part (e.g., <code>mongodb://mongodb0.example.com:27017</code>)</li> <li><code>stricturl</code>: method with the following keyword arguments:<ul> <li><code>strip_whitespace: bool = True</code></li> <li><code>min_length: int = 1</code></li> <li><code>max_length: int = 2 ** 16</code></li> <li><code>tld_required: bool = True</code></li> <li><code>host_required: bool = True</code></li> <li><code>allowed_schemes: Optional[Set[str]] = None</code></li> </ul> </li> </ul> <p>Warning</p> <p>In V1.10.0 and v1.10.1 <code>stricturl</code> also took an optional <code>quote_plus</code> argument and URL components were percent encoded in some cases. This feature was removed in v1.10.2, see #4470 for explanation and more details.</p> <p>The above types (which all inherit from <code>AnyUrl</code>) will attempt to give descriptive errors when invalid URLs are provided:</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\n\nm = MyModel(url='http://www.example.com')\nprint(m.url)\n#&gt; http://www.example.com/\n\ntry:\n    MyModel(url='ftp://invalid.url')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    url\n      URL scheme should be 'http' or 'https' [type=url_scheme, input_value='ftp://invalid.url', input_type=str]\n    \"\"\"\n\ntry:\n    MyModel(url='not a url')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for MyModel\n    url\n      Input should be a valid URL, relative URL without a base [type=url_parsing, input_value='not a url', input_type=str]\n    \"\"\"\n</code></pre> <p>If you require a custom URI/URL type, it can be created in a similar way to the types defined above.</p>"},{"location":"usage/types/urls/#url-properties","title":"URL Properties","text":"<p>Assuming an input URL of <code>http://samuel:pass@example.com:8000/the/path/?query=here#fragment=is;this=bit</code>, the above types export the following properties:</p> <ul> <li><code>scheme</code>: always set - the url scheme (<code>http</code> above)</li> <li><code>host</code>: always set - the url host (<code>example.com</code> above)</li> <li> <p><code>host_type</code>: always set - describes the type of host, either:</p> </li> <li> <p><code>domain</code>: e.g. <code>example.com</code>,</p> </li> <li><code>int_domain</code>: international domain, see below, e.g. <code>exampl\u00a3e.org</code>,</li> <li><code>ipv4</code>: an IP V4 address, e.g. <code>127.0.0.1</code>, or</li> <li> <p><code>ipv6</code>: an IP V6 address, e.g. <code>2001:db8:ff00:42</code></p> </li> <li> <p><code>user</code>: optional - the username if included (<code>samuel</code> above)</p> </li> <li><code>password</code>: optional - the password if included (<code>pass</code> above)</li> <li><code>tld</code>: optional - the top level domain (<code>com</code> above),   Note: this will be wrong for any two-level domain, e.g. \"co.uk\". You'll need to implement your own list of TLDs   if you require full TLD validation</li> <li><code>port</code>: optional - the port (<code>8000</code> above)</li> <li><code>path</code>: optional - the path (<code>/the/path/</code> above)</li> <li><code>query</code>: optional - the URL query (aka GET arguments or \"search string\") (<code>query=here</code> above)</li> <li><code>fragment</code>: optional - the fragment (<code>fragment=is;this=bit</code> above)</li> </ul> <p>If further validation is required, these properties can be used by validators to enforce specific behaviour:</p> <pre><code>from pydantic import BaseModel, HttpUrl, PostgresDsn, ValidationError, field_validator\n\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\n\nm = MyModel(url='http://www.example.com')\n\n# the repr() method for a url will display all properties of the url\nprint(repr(m.url))\n#&gt; Url('http://www.example.com/')\nprint(m.url.scheme)\n#&gt; http\nprint(m.url.host)\n#&gt; www.example.com\nprint(m.url.port)\n#&gt; 80\n\n\nclass MyDatabaseModel(BaseModel):\n    db: PostgresDsn\n\n    @field_validator('db')\n    def check_db_name(cls, v):\n        assert v.path and len(v.path) &gt; 1, 'database must be provided'\n        return v\n\n\nm = MyDatabaseModel(db='postgres://user:pass@localhost:5432/foobar')\nprint(m.db)\n#&gt; postgres://user:pass@localhost:5432/foobar\n\ntry:\n    MyDatabaseModel(db='postgres://user:pass@localhost:5432')\nexcept ValidationError:\n    pass\n    # TODO the error output here is wrong!\n    # print(e)\n</code></pre>"},{"location":"usage/types/urls/#international-domains","title":"International Domains","text":"<p>\"International domains\" (e.g. a URL where the host or TLD includes non-ascii characters) will be encoded via punycode (see this article for a good description of why this is important):</p> <pre><code>from pydantic import BaseModel, HttpUrl\n\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\n\nm1 = MyModel(url='http://puny\u00a3code.com')\nprint(m1.url)\n#&gt; http://xn--punycode-eja.com/\nm2 = MyModel(url='https://www.\u0430\u0440\u0440\u04cf\u0435.com/')\nprint(m2.url)\n#&gt; https://www.xn--80ak6aa92e.com/\nm3 = MyModel(url='https://www.example.\u73e0\u5b9d/')\nprint(m3.url)\n#&gt; https://www.example.xn--pbt977c/\n</code></pre> <p>Underscores in Hostnames</p> <p>In Pydantic underscores are allowed in all parts of a domain except the tld. Technically this might be wrong - in theory the hostname cannot have underscores, but subdomains can.</p> <p>To explain this; consider the following two cases:</p> <ul> <li><code>exam_ple.co.uk</code>: the hostname is <code>exam_ple</code>, which should not be allowed since it contains an underscore</li> <li><code>foo_bar.example.com</code> the hostname is <code>example</code>, which should be allowed since the underscore is in the subdomain</li> </ul> <p>Without having an exhaustive list of TLDs, it would be impossible to differentiate between these two. Therefore underscores are allowed, but you can always do further validation in a validator if desired.</p> <p>Also, Chrome, Firefox, and Safari all currently accept <code>http://exam_ple.com</code> as a URL, so we're in good (or at least big) company.</p>"},{"location":"usage/types/urls/#ip-addresses","title":"IP Addresses","text":"<code>IPvAnyAddress</code> allows either an <code>IPv4Address</code> or an <code>IPv6Address</code> <code>IPvAnyInterface</code> allows either an <code>IPv4Interface</code> or an <code>IPv6Interface</code> <code>IPvAnyNetwork</code> allows either an <code>IPv4Network</code> or an <code>IPv6Network</code>"},{"location":"usage/types/uuids/","title":"UUIDs","text":"<code>uuid.UUID</code> strings and bytes (converted to strings) are passed to <code>UUID(v)</code>, with a fallback to <code>UUID(bytes=v)</code> for <code>bytes</code> and <code>bytearray</code> <code>UUID1</code> requires a valid UUID of type 1; see <code>UUID</code> above <code>UUID3</code> requires a valid UUID of type 3; see <code>UUID</code> above <code>UUID4</code> requires a valid UUID of type 4; see <code>UUID</code> above <code>UUID5</code> requires a valid UUID of type 5; see <code>UUID</code> above"},{"location":"usage/types/extra_types/color_types/","title":"Color Types","text":"<p>Warning</p> <p>To use this type, you need to install the optional pydantic-extra-types package:</p> <pre><code>pip install pydantic-extra-types\n</code></pre> <p><code>Color</code> parses HTML and CSS colors.</p> <p>You can use the <code>Color</code> data type for storing colors as per CSS3 specification. Colors can be defined via:</p> <ul> <li>name (e.g. <code>\"Black\"</code>, <code>\"azure\"</code>)</li> <li>hexadecimal value   (e.g. <code>\"0x000\"</code>, <code>\"#FFFFFF\"</code>, <code>\"7fffd4\"</code>)</li> <li>RGB/RGBA tuples (e.g. <code>(255, 255, 255)</code>, <code>(255, 255, 255, 0.5)</code>)</li> <li>RGB/RGBA strings   (e.g. <code>\"rgb(255, 255, 255)\"</code>, <code>\"rgba(255, 255, 255, 0.5)\"</code>)</li> <li>HSL strings   (e.g. <code>\"hsl(270, 60%, 70%)\"</code>, <code>\"hsl(270, 60%, 70%, .5)\"</code>)</li> </ul> <pre><code>from pydantic import BaseModel, ValidationError\n\nfrom pydantic_extra_types import Color\n\nc = Color('ff00ff')\nprint(c.as_named())\n#&gt; magenta\nprint(c.as_hex())\n#&gt; #f0f\nc2 = Color('green')\nprint(c2.as_rgb_tuple())\n#&gt; (0, 128, 0)\nprint(c2.original())\n#&gt; green\nprint(repr(Color('hsl(180, 100%, 50%)')))\n#&gt; Color('cyan', rgb=(0, 255, 255))\n\n\nclass Model(BaseModel):\n    color: Color\n\n\nprint(Model(color='purple'))\n#&gt; color=Color('purple', rgb=(128, 0, 128))\ntry:\n    Model(color='hello')\nexcept ValidationError as e:\n    print(e)\n\"\"\"\n    1 validation error for Model\n    color\n      value is not a valid color: string not recognised as a valid color [type=color_error, input_value='hello', input_type=str]\n    \"\"\"\n</code></pre> <p><code>Color</code> has the following methods:</p> <code>original</code> the original string or tuple passed to <code>Color</code> <code>as_named</code> returns a named CSS3 color; fails if the alpha channel is set or no such color exists unless   <code>fallback=True</code> is supplied, in which case it falls back to <code>as_hex</code> <code>as_hex</code> returns a string in the format <code>#fff</code> or <code>#ffffff</code>; will contain 4 (or 8) hex values if the alpha channel is set,   e.g. <code>#7f33cc26</code> <code>as_rgb</code> returns a string in the format <code>rgb(&lt;red&gt;, &lt;green&gt;, &lt;blue&gt;)</code>, or <code>rgba(&lt;red&gt;, &lt;green&gt;, &lt;blue&gt;, &lt;alpha&gt;)</code>   if the alpha channel is set <code>as_rgb_tuple</code> returns a 3- or 4-tuple in RGB(a) format. The <code>alpha</code> keyword argument can be used to define whether   the alpha channel should be included;   options: <code>True</code> - always include, <code>False</code> - never include, <code>None</code> (default) - include if set <code>as_hsl</code> string in the format <code>hsl(&lt;hue deg&gt;, &lt;saturation %&gt;, &lt;lightness %&gt;)</code>   or <code>hsl(&lt;hue deg&gt;, &lt;saturation %&gt;, &lt;lightness %&gt;, &lt;alpha&gt;)</code> if the alpha channel is set <code>as_hsl_tuple</code> returns a 3- or 4-tuple in HSL(a) format. The <code>alpha</code> keyword argument can be used to define whether   the alpha channel should be included;   options: <code>True</code> - always include, <code>False</code> - never include, <code>None</code> (the default)  - include if set <p>The <code>__str__</code> method for <code>Color</code> returns <code>self.as_named(fallback=True)</code>.</p> <p>Note</p> <p>The <code>as_hsl*</code> refer to hue, saturation, lightness \"HSL\" as used in html and most of the world, not \"HLS\" as used in Python's <code>colorsys</code>.</p>"},{"location":"usage/types/extra_types/extra_types/","title":"Extra Types Overview","text":"<p>For types that are more complex, or don't need to be on Pydantic itself, we have the Pydantic Extra Types project.</p> <p>Warning</p> <p>To use this type, you need to install the optional pydantic-extra-types package:</p> <pre><code>pip install pydantic-extra-types\n</code></pre> <p>The following types are supported by Pydantic Extra Types:</p> <ul> <li>Color Types \u2014 color validation types.</li> <li>Payment Card Numbers \u2014 a type that allows you to store payment card numbers in your model.</li> <li>Phone Numbers \u2014 a type that allows you to store phone numbers in your model.</li> <li>Routing Numbers \u2014 a type that allows you to store ABA transit routing numbers in your model.</li> </ul>"},{"location":"usage/types/extra_types/payment_cards/","title":"Payment Card Numbers","text":"<p>Warning</p> <p>To use this type, you need to install the optional pydantic-extra-types package:</p> <pre><code>pip install pydantic-extra-types\n</code></pre> <p>The <code>PaymentCardNumber</code> type validates payment cards (such as a debit or credit card).</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, constr\n\nfrom pydantic_extra_types.payment import PaymentCardBrand, PaymentCardNumber\n\n\nclass Card(BaseModel):\n    name: constr(strip_whitespace=True, min_length=1)\n    number: PaymentCardNumber\n    exp: date\n\n    @property\n    def brand(self) -&gt; PaymentCardBrand:\n        return self.number.brand\n\n    @property\n    def expired(self) -&gt; bool:\n        return self.exp &lt; date.today()\n\n\ncard = Card(\n    name='Georg Wilhelm Friedrich Hegel',\n    number='4000000000000002',\n    exp=date(2023, 9, 30),\n)\n\nassert card.number.brand == PaymentCardBrand.visa\nassert card.number.bin == '400000'\nassert card.number.last4 == '0002'\nassert card.number.masked == '400000******0002'\n</code></pre> <p><code>PaymentCardBrand</code> can be one of the following based on the BIN:</p> <ul> <li><code>PaymentCardBrand.amex</code></li> <li><code>PaymentCardBrand.mastercard</code></li> <li><code>PaymentCardBrand.visa</code></li> <li><code>PaymentCardBrand.other</code></li> </ul> <p>The actual validation verifies the card number is:</p> <ul> <li>a <code>str</code> of only digits</li> <li>luhn valid</li> <li>the correct length based on the BIN, if Amex, Mastercard or Visa, and between   12 and 19 digits for all other brands</li> </ul>"},{"location":"usage/types/extra_types/phone_numbers/","title":"Phone Numbers","text":"<p>Warning</p> <p>To use this type, you need to install the optional pydantic-extra-types package:</p> <pre><code>pip install pydantic-extra-types\n</code></pre> <p>The <code>PhoneNumber</code> type validates phone numbers.</p> <p>This class depends on the phonenumbers package, which is a Python port of Google's libphonenumber.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\n\n\nclass User(BaseModel):\n    name: str\n    phone_number: PhoneNumber\n\n\nuser = User(name='John', phone_number='+447911123456')\nprint(user.phone_number)  # (1)!\n#&gt; tel:+44-7911-123456\n</code></pre> <ol> <li>The phone format used is described on the RFC3966.</li> </ol>"},{"location":"usage/types/extra_types/routing_numbers/","title":"Routing Numbers","text":"<p>Warning</p> <p>To use this type, you need to install the optional pydantic-extra-types package:</p> <pre><code>pip install pydantic-extra-types\n</code></pre> <p>The <code>ABARoutingNumber</code> type validates ABA routing transit numbers.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.routing_number import ABARoutingNumber\n\n\nclass BankAccount(BaseModel):\n    name: str\n    routing_number: ABARoutingNumber\n    account_number: str\n\n\naccount = BankAccount(\n    name=\"John\",\n    routing_number=\"122105155\",\n    account_number=\"123456789\",\n)\n\nprint(account.routing_number)\n# &gt; 122105155\n</code></pre> <p>The algorithm used to validate the routing number is described on this section of the Wikipedia page.</p>"}]}